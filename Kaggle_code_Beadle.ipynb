{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "        \n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "#path = './data'\n",
    "path = \"/Users/SarahBeadle/Documents/!WUSTL/Deep_Neural_Networks/Kaggle\"\n",
    "\n",
    "filename_test = os.path.join(path,\"test.csv\")\n",
    "filename_train = os.path.join(path,\"train.csv\")\n",
    "filename_sample = os.path.join(path,\"sample.csv\")\n",
    "filename_submit = os.path.join(path,\"submit.csv\")\n",
    "filename_checkpoint = os.path.join(path,\"checkpoint.hdf5\")\n",
    "\n",
    "df_train = pd.read_csv(filename_train,na_values=['NA','?'])\n",
    "\n",
    "np.random.seed(42) # Uncomment this line to get the same shuffle each time\n",
    "df_train = df_train.reindex(np.random.permutation(df_train.index))\n",
    "df_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode Features\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def extract_and_encode_features(df):\n",
    "    color_regex='(?P<color>red|blue|green|yellow|orange|pink|black|brown|white)'\n",
    "    df['color'] = df.name.str.extract(color_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    quality_regex='(?P<quality>generic|medium\\shigh\\squality|high\\squality)'\n",
    "    df['quality'] = df.name.str.extract(quality_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    size_regex='(?P<size>tiny|small|medium|large)'\n",
    "    df['size'] = df.name.str.extract(size_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    item_regex='(?P<item>paperclips|paperweights|ink\\spens|pencils|stapler|tablets|thumbtacks|post\\sit\\snotes)'\n",
    "    df['item'] = df.name.str.extract(item_regex, flags=re.IGNORECASE, expand=False)\n",
    "    \n",
    "    for column in ['pack','weight','height','width','length']:\n",
    "        missing_median(df,column)\n",
    "    \n",
    "\n",
    "extract_and_encode_features(df_train)\n",
    "ids_train = df_train['id']\n",
    "df_train.drop('id',1,inplace=True)\n",
    "\n",
    "names_train = df_train['name']\n",
    "df_train.drop('name',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_default(df_train, \"quality\", \"Unknown\")\n",
    "missing_default(df_train, \"size\", \"Unknown\")\n",
    "missing_default(df_train, \"color\", \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode text/categorical features\n",
    "for column in ['manufacturer','color','quality','size','item']:\n",
    "    encode_text_dummy(df_train,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/1000\n",
      "7500/7500 [==============================] - 1s 166us/step - loss: 5087.5010 - val_loss: 4384.2793\n",
      "Epoch 2/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 4682.2438 - val_loss: 4327.9726\n",
      "Epoch 3/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 4530.1508 - val_loss: 4146.3087\n",
      "Epoch 4/1000\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 4290.0310 - val_loss: 4061.9453\n",
      "Epoch 5/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 4211.9335 - val_loss: 3810.2652\n",
      "Epoch 6/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 4263.3557 - val_loss: 4100.0885\n",
      "Epoch 7/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 4077.9316 - val_loss: 4223.8632\n",
      "Epoch 8/1000\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 4059.6892 - val_loss: 3750.6401\n",
      "Epoch 9/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 3988.2143 - val_loss: 4069.8422\n",
      "Epoch 10/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 4060.7348 - val_loss: 4761.4949\n",
      "Epoch 11/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 3899.4987 - val_loss: 3621.5774\n",
      "Epoch 12/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 3862.4907 - val_loss: 3450.8139\n",
      "Epoch 13/1000\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 3697.2249 - val_loss: 3261.1295\n",
      "Epoch 14/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 3560.4483 - val_loss: 3635.1419\n",
      "Epoch 15/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 3563.1833 - val_loss: 3576.1768\n",
      "Epoch 16/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 3277.4863 - val_loss: 3890.9596\n",
      "Epoch 17/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 2995.2732 - val_loss: 2558.3375\n",
      "Epoch 18/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 2691.8492 - val_loss: 2216.4184\n",
      "Epoch 19/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 2544.5416 - val_loss: 2545.1684\n",
      "Epoch 20/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 2480.3813 - val_loss: 1990.9023\n",
      "Epoch 21/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 2540.1547 - val_loss: 2408.2986\n",
      "Epoch 22/1000\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 2038.4597 - val_loss: 1375.4709\n",
      "Epoch 23/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1763.4937 - val_loss: 1192.5367\n",
      "Epoch 24/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 1332.7128 - val_loss: 983.8503\n",
      "Epoch 25/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 1158.0073 - val_loss: 926.0964\n",
      "Epoch 26/1000\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 1170.6770 - val_loss: 837.3690\n",
      "Epoch 27/1000\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 865.7480 - val_loss: 626.6985\n",
      "Epoch 28/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 913.7949 - val_loss: 458.1377\n",
      "Epoch 29/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 788.8548 - val_loss: 651.8951\n",
      "Epoch 30/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 738.8140 - val_loss: 498.4187\n",
      "Epoch 31/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 620.4473 - val_loss: 378.9181\n",
      "Epoch 32/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 724.6036 - val_loss: 626.1133\n",
      "Epoch 33/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 577.0755 - val_loss: 377.1241\n",
      "Epoch 34/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 572.5795 - val_loss: 441.2102\n",
      "Epoch 35/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 618.8776 - val_loss: 407.6120\n",
      "Epoch 36/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 669.2562 - val_loss: 654.0097\n",
      "Epoch 37/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 537.0501 - val_loss: 402.4841\n",
      "Epoch 38/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 560.9005 - val_loss: 1335.2301\n",
      "Epoch 39/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 559.0253 - val_loss: 396.1148\n",
      "Epoch 40/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 539.5745 - val_loss: 399.2286\n",
      "Epoch 41/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 570.3307 - val_loss: 617.5538\n",
      "Epoch 42/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 481.1472 - val_loss: 523.0730\n",
      "Epoch 43/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 512.2798 - val_loss: 393.9465\n",
      "Epoch 44/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 516.0066 - val_loss: 482.0239\n",
      "Epoch 45/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 611.5385 - val_loss: 545.4037\n",
      "Epoch 46/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 509.8216 - val_loss: 835.2014\n",
      "Epoch 47/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 466.1275 - val_loss: 389.1332\n",
      "Epoch 48/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 502.2387 - val_loss: 1022.6723\n",
      "Epoch 49/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 580.8255 - val_loss: 301.8240\n",
      "Epoch 50/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 537.4814 - val_loss: 742.7741\n",
      "Epoch 51/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 442.8198 - val_loss: 371.5752\n",
      "Epoch 52/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 400.4721 - val_loss: 379.7130\n",
      "Epoch 53/1000\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 536.1872 - val_loss: 416.6444\n",
      "Epoch 54/1000\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 465.2879 - val_loss: 289.0039\n",
      "Epoch 55/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 516.3962 - val_loss: 372.1119\n",
      "Epoch 56/1000\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 436.8615 - val_loss: 284.6926\n",
      "Epoch 57/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 421.0914 - val_loss: 296.7938\n",
      "Epoch 58/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 412.0835 - val_loss: 282.9005\n",
      "Epoch 59/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 443.5858 - val_loss: 476.1666\n",
      "Epoch 60/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 381.7411 - val_loss: 501.4228\n",
      "Epoch 61/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 403.5812 - val_loss: 249.2675\n",
      "Epoch 62/1000\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 495.9998 - val_loss: 319.5067\n",
      "Epoch 63/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 356.0358 - val_loss: 370.0168\n",
      "Epoch 64/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 382.4343 - val_loss: 711.7141\n",
      "Epoch 65/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 443.5319 - val_loss: 314.8410\n",
      "Epoch 66/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 436.5472 - val_loss: 339.6070\n",
      "Epoch 67/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 402.7145 - val_loss: 260.0065\n",
      "Epoch 68/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 397.2685 - val_loss: 258.3844\n",
      "Epoch 69/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 378.4651 - val_loss: 282.6989\n",
      "Epoch 70/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 425.0814 - val_loss: 280.6106\n",
      "Epoch 71/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 328.6709 - val_loss: 265.2890\n",
      "Epoch 72/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 353.9726 - val_loss: 249.0777\n",
      "Epoch 73/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 483.2004 - val_loss: 282.6838\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 63us/step - loss: 340.9654 - val_loss: 346.6682\n",
      "Epoch 75/1000\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 417.5067 - val_loss: 597.4543\n",
      "Epoch 76/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 407.4519 - val_loss: 332.7393\n",
      "Epoch 77/1000\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 375.7521 - val_loss: 241.0559\n",
      "Epoch 78/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 367.8156 - val_loss: 270.5881\n",
      "Epoch 79/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 320.8260 - val_loss: 522.5417\n",
      "Epoch 80/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 365.6131 - val_loss: 263.9486\n",
      "Epoch 81/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 371.5362 - val_loss: 244.1264\n",
      "Epoch 82/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 405.8181 - val_loss: 234.4090\n",
      "Epoch 83/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 315.2081 - val_loss: 250.1569\n",
      "Epoch 84/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 367.4061 - val_loss: 247.1465\n",
      "Epoch 85/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 452.4383 - val_loss: 230.5366\n",
      "Epoch 86/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 358.5759 - val_loss: 304.6345\n",
      "Epoch 87/1000\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 351.5423 - val_loss: 236.5153\n",
      "Epoch 88/1000\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 405.8549 - val_loss: 238.3899\n",
      "Epoch 89/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 376.2022 - val_loss: 240.6269\n",
      "Epoch 90/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 343.3971 - val_loss: 309.7210\n",
      "Epoch 91/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 290.3321 - val_loss: 243.7020\n",
      "Epoch 92/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 288.7092 - val_loss: 264.3491\n",
      "Epoch 93/1000\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 331.0245 - val_loss: 255.2868\n",
      "Epoch 94/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 381.1831 - val_loss: 398.3310\n",
      "Epoch 95/1000\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 447.8230 - val_loss: 686.4977\n",
      "Epoch 96/1000\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 330.0980 - val_loss: 232.8611\n",
      "Epoch 97/1000\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 341.2059 - val_loss: 238.8388\n",
      "Epoch 98/1000\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 333.1755 - val_loss: 648.5028\n",
      "Epoch 99/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 313.2899 - val_loss: 257.1539\n",
      "Epoch 100/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 335.7264 - val_loss: 353.6796\n",
      "Epoch 101/1000\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 355.1868 - val_loss: 364.3558\n",
      "Epoch 102/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 313.9261 - val_loss: 307.0971\n",
      "Epoch 103/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 309.7048 - val_loss: 239.3831\n",
      "Epoch 104/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 312.4345 - val_loss: 250.0194\n",
      "Epoch 105/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 335.1192 - val_loss: 464.2436\n",
      "Epoch 106/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 322.8361 - val_loss: 256.8099\n",
      "Epoch 107/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 406.3453 - val_loss: 644.5758\n",
      "Epoch 108/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 345.8994 - val_loss: 444.2246\n",
      "Epoch 109/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 312.1996 - val_loss: 305.6152\n",
      "Epoch 110/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 309.7454 - val_loss: 237.4386\n",
      "Epoch 111/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 339.6172 - val_loss: 264.8005\n",
      "Epoch 112/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 314.8420 - val_loss: 226.2770\n",
      "Epoch 113/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 340.1293 - val_loss: 222.8800\n",
      "Epoch 114/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 295.2667 - val_loss: 545.3683\n",
      "Epoch 115/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 316.4767 - val_loss: 520.0957\n",
      "Epoch 116/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 448.3354 - val_loss: 236.2219\n",
      "Epoch 117/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 339.1623 - val_loss: 321.0446\n",
      "Epoch 118/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 352.8404 - val_loss: 200.2664\n",
      "Epoch 119/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 277.5145 - val_loss: 335.4926\n",
      "Epoch 120/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 310.9546 - val_loss: 340.1212\n",
      "Epoch 121/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 340.3791 - val_loss: 359.9242\n",
      "Epoch 122/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 313.4918 - val_loss: 229.5613\n",
      "Epoch 123/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 398.5407 - val_loss: 305.3868\n",
      "Epoch 124/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 338.2660 - val_loss: 361.9344\n",
      "Epoch 125/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 349.6850 - val_loss: 329.5251\n",
      "Epoch 126/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 312.0324 - val_loss: 248.7548\n",
      "Epoch 127/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 296.1511 - val_loss: 228.4816\n",
      "Epoch 128/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 292.2605 - val_loss: 238.6636\n",
      "Epoch 129/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 262.7405 - val_loss: 218.6485\n",
      "Epoch 130/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 291.7941 - val_loss: 221.7966\n",
      "Epoch 131/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 330.1452 - val_loss: 197.3772\n",
      "Epoch 132/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 272.0826 - val_loss: 507.1598\n",
      "Epoch 133/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 314.2579 - val_loss: 489.5764\n",
      "Epoch 134/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 283.4307 - val_loss: 448.2890\n",
      "Epoch 135/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 330.8155 - val_loss: 199.3320\n",
      "Epoch 136/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 270.8039 - val_loss: 282.2874\n",
      "Epoch 137/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 319.8459 - val_loss: 217.7899\n",
      "Epoch 138/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 353.2420 - val_loss: 232.0324\n",
      "Epoch 139/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 284.0089 - val_loss: 250.7166\n",
      "Epoch 140/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 265.4909 - val_loss: 228.2856\n",
      "Epoch 141/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 290.1426 - val_loss: 526.1919\n",
      "Epoch 142/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 328.3312 - val_loss: 264.3495\n",
      "Epoch 143/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 269.7560 - val_loss: 243.1801\n",
      "Epoch 144/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 272.5977 - val_loss: 259.0382\n",
      "Epoch 145/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 262.3381 - val_loss: 202.6707\n",
      "Epoch 146/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 363.0424 - val_loss: 517.7761\n",
      "Epoch 147/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 353.6886 - val_loss: 216.2434\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 59us/step - loss: 262.3094 - val_loss: 296.0117\n",
      "Epoch 149/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 263.8046 - val_loss: 238.1942\n",
      "Epoch 150/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 279.1620 - val_loss: 395.5625\n",
      "Epoch 151/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 270.0057 - val_loss: 221.4589\n",
      "Epoch 152/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 292.9482 - val_loss: 247.5808\n",
      "Epoch 153/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 300.0999 - val_loss: 225.6520\n",
      "Epoch 154/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 248.6700 - val_loss: 197.1946\n",
      "Epoch 155/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 254.9199 - val_loss: 451.0877\n",
      "Epoch 156/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 397.9315 - val_loss: 389.3257\n",
      "Epoch 157/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 252.7964 - val_loss: 238.4289\n",
      "Epoch 158/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 259.7049 - val_loss: 420.4202\n",
      "Epoch 159/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 301.9288 - val_loss: 190.9257\n",
      "Epoch 160/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 250.5886 - val_loss: 267.3358\n",
      "Epoch 161/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 249.7269 - val_loss: 229.6443\n",
      "Epoch 162/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 379.0991 - val_loss: 203.7031\n",
      "Epoch 163/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 258.7759 - val_loss: 184.3946\n",
      "Epoch 164/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 263.0426 - val_loss: 289.3764\n",
      "Epoch 165/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 411.9577 - val_loss: 348.5555\n",
      "Epoch 166/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 280.1399 - val_loss: 188.2290\n",
      "Epoch 167/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 290.3086 - val_loss: 236.9039\n",
      "Epoch 168/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 228.7511 - val_loss: 238.5468\n",
      "Epoch 169/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 288.3608 - val_loss: 620.1446\n",
      "Epoch 170/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 283.6829 - val_loss: 231.0995\n",
      "Epoch 171/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 320.6476 - val_loss: 263.4090\n",
      "Epoch 172/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 259.1669 - val_loss: 191.3080\n",
      "Epoch 173/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 293.8577 - val_loss: 308.9968\n",
      "Epoch 174/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 317.5213 - val_loss: 206.2248\n",
      "Epoch 175/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 311.3298 - val_loss: 312.5384\n",
      "Epoch 176/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 261.1004 - val_loss: 189.5249\n",
      "Epoch 177/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 281.0140 - val_loss: 230.6878\n",
      "Epoch 178/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 273.0142 - val_loss: 200.3216\n",
      "Epoch 179/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 230.2809 - val_loss: 222.1718\n",
      "Epoch 180/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 249.8750 - val_loss: 187.3656\n",
      "Epoch 181/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 286.369 - 0s 61us/step - loss: 282.4853 - val_loss: 277.5494\n",
      "Epoch 182/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 280.3474 - val_loss: 415.2698\n",
      "Epoch 183/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 291.9078 - val_loss: 253.2592\n",
      "Epoch 184/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 323.0413 - val_loss: 218.2190\n",
      "Epoch 185/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 251.7790 - val_loss: 179.2426\n",
      "Epoch 186/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 269.1779 - val_loss: 588.8611\n",
      "Epoch 187/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 263.9064 - val_loss: 193.3328\n",
      "Epoch 188/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 255.7651 - val_loss: 226.4477\n",
      "Epoch 189/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 317.2548 - val_loss: 564.6735\n",
      "Epoch 190/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 279.9750 - val_loss: 280.3396\n",
      "Epoch 191/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 294.2670 - val_loss: 180.2828\n",
      "Epoch 192/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 294.8318 - val_loss: 200.8231\n",
      "Epoch 193/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 271.3889 - val_loss: 230.5739\n",
      "Epoch 194/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 322.1045 - val_loss: 199.9819\n",
      "Epoch 195/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 240.2333 - val_loss: 178.4922\n",
      "Epoch 196/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 214.9130 - val_loss: 225.9132\n",
      "Epoch 197/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 233.4537 - val_loss: 171.6855\n",
      "Epoch 198/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 257.2945 - val_loss: 249.2909\n",
      "Epoch 199/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 294.7786 - val_loss: 341.8776\n",
      "Epoch 200/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 226.1709 - val_loss: 171.5744\n",
      "Epoch 201/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 227.4779 - val_loss: 183.1954\n",
      "Epoch 202/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 420.7006 - val_loss: 471.1442\n",
      "Epoch 203/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 302.4287 - val_loss: 193.9336\n",
      "Epoch 204/1000\n",
      "7500/7500 [==============================] - 0s 67us/step - loss: 289.6108 - val_loss: 289.0360\n",
      "Epoch 205/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 274.0547 - val_loss: 194.1360\n",
      "Epoch 206/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 298.8550 - val_loss: 189.3843\n",
      "Epoch 207/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 389.7361 - val_loss: 482.3088\n",
      "Epoch 208/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 260.3028 - val_loss: 180.7199\n",
      "Epoch 209/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 258.1045 - val_loss: 203.1097\n",
      "Epoch 210/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 261.1799 - val_loss: 284.0460\n",
      "Epoch 211/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 261.2155 - val_loss: 502.7418\n",
      "Epoch 212/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 253.3801 - val_loss: 186.6167\n",
      "Epoch 213/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 223.7389 - val_loss: 204.1363\n",
      "Epoch 214/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 264.3685 - val_loss: 253.9820\n",
      "Epoch 215/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 330.3336 - val_loss: 205.2391\n",
      "Epoch 216/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 236.6779 - val_loss: 175.4816\n",
      "Epoch 217/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 478.1746 - val_loss: 222.2485\n",
      "Epoch 218/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 222.9784 - val_loss: 209.6903\n",
      "Epoch 219/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 236.5427 - val_loss: 196.2035\n",
      "Epoch 220/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 232.2802 - val_loss: 169.4194\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 58us/step - loss: 225.4027 - val_loss: 208.5243\n",
      "Epoch 222/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 231.6611 - val_loss: 168.0730\n",
      "Epoch 223/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 247.3820 - val_loss: 219.0396\n",
      "Epoch 224/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 258.8814 - val_loss: 211.5883\n",
      "Epoch 225/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 295.1194 - val_loss: 300.4324\n",
      "Epoch 226/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 297.4882 - val_loss: 173.0760\n",
      "Epoch 227/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 210.4346 - val_loss: 164.7683\n",
      "Epoch 228/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 298.0920 - val_loss: 169.7123\n",
      "Epoch 229/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 220.6544 - val_loss: 172.3742\n",
      "Epoch 230/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 294.8354 - val_loss: 202.1845\n",
      "Epoch 231/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 220.0084 - val_loss: 177.4659\n",
      "Epoch 232/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 232.2959 - val_loss: 382.3783\n",
      "Epoch 233/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 306.8546 - val_loss: 222.6299\n",
      "Epoch 234/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 236.2021 - val_loss: 195.4468\n",
      "Epoch 235/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 242.3785 - val_loss: 225.3527\n",
      "Epoch 236/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 285.4735 - val_loss: 379.1325\n",
      "Epoch 237/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 337.2053 - val_loss: 191.6771\n",
      "Epoch 238/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 271.6863 - val_loss: 166.5529\n",
      "Epoch 239/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 214.7241 - val_loss: 192.4424\n",
      "Epoch 240/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 234.2447 - val_loss: 180.5777\n",
      "Epoch 241/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 221.2981 - val_loss: 173.4685\n",
      "Epoch 242/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 229.4656 - val_loss: 171.2353\n",
      "Epoch 243/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 230.4624 - val_loss: 164.1624\n",
      "Epoch 244/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 237.1290 - val_loss: 163.5855\n",
      "Epoch 245/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 300.0040 - val_loss: 187.5872\n",
      "Epoch 246/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 241.4838 - val_loss: 170.0353\n",
      "Epoch 247/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 229.4412 - val_loss: 169.4137\n",
      "Epoch 248/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 224.4984 - val_loss: 1626.2881\n",
      "Epoch 249/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 373.8812 - val_loss: 301.7716\n",
      "Epoch 250/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 273.1253 - val_loss: 227.3060\n",
      "Epoch 251/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 240.6827 - val_loss: 325.7344\n",
      "Epoch 252/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 220.0519 - val_loss: 169.0696\n",
      "Epoch 253/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 236.1366 - val_loss: 308.5890\n",
      "Epoch 254/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 297.9108 - val_loss: 176.6691\n",
      "Epoch 255/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 283.8763 - val_loss: 280.8845\n",
      "Epoch 256/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 232.0700 - val_loss: 165.2596\n",
      "Epoch 257/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 229.9871 - val_loss: 194.5201\n",
      "Epoch 258/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 237.7822 - val_loss: 174.4858\n",
      "Epoch 259/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 219.6475 - val_loss: 232.5713\n",
      "Epoch 260/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 281.0766 - val_loss: 195.4066\n",
      "Epoch 261/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 217.8703 - val_loss: 206.5752\n",
      "Epoch 262/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 222.0094 - val_loss: 198.4771\n",
      "Epoch 263/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 250.1624 - val_loss: 181.2415\n",
      "Epoch 264/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 202.6974 - val_loss: 222.7105\n",
      "Epoch 265/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 199.0810 - val_loss: 237.7532\n",
      "Epoch 266/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 296.7778 - val_loss: 336.8856\n",
      "Epoch 267/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 232.4393 - val_loss: 250.7492\n",
      "Epoch 268/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 358.0851 - val_loss: 232.0244\n",
      "Epoch 269/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 314.0974 - val_loss: 185.0362\n",
      "Epoch 270/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 227.7652 - val_loss: 207.5334\n",
      "Epoch 271/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 210.3225 - val_loss: 183.5020\n",
      "Epoch 272/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 272.0511 - val_loss: 165.1354\n",
      "Epoch 273/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 240.6534 - val_loss: 220.0952\n",
      "Epoch 274/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 215.5953 - val_loss: 447.3576\n",
      "Epoch 275/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 259.8280 - val_loss: 169.5242\n",
      "Epoch 276/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 215.0725 - val_loss: 183.1323\n",
      "Epoch 277/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 341.6785 - val_loss: 209.3263\n",
      "Epoch 278/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 208.9231 - val_loss: 216.9561\n",
      "Epoch 279/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 211.1528 - val_loss: 192.6073\n",
      "Epoch 280/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 251.8216 - val_loss: 283.2376\n",
      "Epoch 281/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 228.4171 - val_loss: 200.7454\n",
      "Epoch 282/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 212.7040 - val_loss: 278.3255\n",
      "Epoch 283/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 192.3664 - val_loss: 182.9018\n",
      "Epoch 284/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 203.0396 - val_loss: 168.5510\n",
      "Epoch 285/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 206.0693 - val_loss: 253.1528\n",
      "Epoch 286/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 215.4660 - val_loss: 180.7523\n",
      "Epoch 287/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 266.2514 - val_loss: 197.2619\n",
      "Epoch 288/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 306.6855 - val_loss: 159.9140\n",
      "Epoch 289/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 211.8671 - val_loss: 747.9375\n",
      "Epoch 290/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 325.3227 - val_loss: 180.8523\n",
      "Epoch 291/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 246.5375 - val_loss: 172.6726\n",
      "Epoch 292/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 258.8751 - val_loss: 208.7771\n",
      "Epoch 293/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 295.9059 - val_loss: 190.1319\n",
      "Epoch 294/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 243.6653 - val_loss: 239.5871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 213.4310 - val_loss: 176.1030\n",
      "Epoch 296/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 353.7564 - val_loss: 212.2841\n",
      "Epoch 297/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 239.7922 - val_loss: 346.4353\n",
      "Epoch 298/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 240.3225 - val_loss: 334.9918\n",
      "Epoch 299/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 250.9488 - val_loss: 1190.7646\n",
      "Epoch 300/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 386.5031 - val_loss: 460.4032\n",
      "Epoch 301/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 263.7918 - val_loss: 159.4532\n",
      "Epoch 302/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 214.4598 - val_loss: 178.6758\n",
      "Epoch 303/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 220.3004 - val_loss: 158.9602\n",
      "Epoch 304/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 220.3406 - val_loss: 158.6402\n",
      "Epoch 305/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 257.5637 - val_loss: 186.9981\n",
      "Epoch 306/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 254.3103 - val_loss: 188.3303\n",
      "Epoch 307/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 221.6357 - val_loss: 166.5067\n",
      "Epoch 308/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 187.3813 - val_loss: 159.6603\n",
      "Epoch 309/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 197.1564 - val_loss: 254.4539\n",
      "Epoch 310/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 231.7767 - val_loss: 241.3105\n",
      "Epoch 311/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 233.1366 - val_loss: 300.8679\n",
      "Epoch 312/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 250.8226 - val_loss: 210.8684\n",
      "Epoch 313/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 194.6359 - val_loss: 194.6160\n",
      "Epoch 314/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 299.5844 - val_loss: 260.1965\n",
      "Epoch 315/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 201.4679 - val_loss: 163.9628\n",
      "Epoch 316/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 217.8601 - val_loss: 167.1578\n",
      "Epoch 317/1000\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 234.6177 - val_loss: 156.4521\n",
      "Epoch 318/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 199.2742 - val_loss: 155.0127\n",
      "Epoch 319/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 209.4362 - val_loss: 175.1013\n",
      "Epoch 320/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 215.8395 - val_loss: 160.0075\n",
      "Epoch 321/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 291.9803 - val_loss: 555.0392\n",
      "Epoch 322/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 243.3839 - val_loss: 208.4719\n",
      "Epoch 323/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 217.7292 - val_loss: 195.4543\n",
      "Epoch 324/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 193.1751 - val_loss: 211.7499\n",
      "Epoch 325/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 207.6987 - val_loss: 189.9759\n",
      "Epoch 326/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 190.8669 - val_loss: 185.1107\n",
      "Epoch 327/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 319.2710 - val_loss: 163.4957\n",
      "Epoch 328/1000\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 214.9329 - val_loss: 164.1149\n",
      "Epoch 329/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 214.0004 - val_loss: 269.1919\n",
      "Epoch 330/1000\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 195.2517 - val_loss: 399.7234\n",
      "Epoch 331/1000\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 463.5604 - val_loss: 293.1554\n",
      "Epoch 332/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 309.1071 - val_loss: 158.7432\n",
      "Epoch 333/1000\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 189.2677 - val_loss: 238.0177\n",
      "Epoch 334/1000\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 209.5709 - val_loss: 187.5733\n",
      "Epoch 335/1000\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 212.9763 - val_loss: 228.0157\n",
      "Epoch 336/1000\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 193.4134 - val_loss: 178.6553\n",
      "Epoch 337/1000\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 180.1784 - val_loss: 155.8651\n",
      "Epoch 338/1000\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 206.6215 - val_loss: 172.9678\n",
      "Epoch 339/1000\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 306.7587 - val_loss: 195.4029\n",
      "Epoch 340/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 208.5063 - val_loss: 165.8168\n",
      "Epoch 341/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 222.1123 - val_loss: 175.7797\n",
      "Epoch 342/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 234.3610 - val_loss: 172.6251\n",
      "Epoch 343/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 260.4279 - val_loss: 209.4845\n",
      "Epoch 344/1000\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 199.0791 - val_loss: 231.2877\n",
      "Epoch 345/1000\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 231.1130 - val_loss: 294.6014\n",
      "Epoch 346/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 296.0981 - val_loss: 179.0801\n",
      "Epoch 347/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 193.8711 - val_loss: 151.8328\n",
      "Epoch 348/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 202.0943 - val_loss: 166.4145\n",
      "Epoch 349/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 265.7111 - val_loss: 225.6267\n",
      "Epoch 350/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 190.7042 - val_loss: 191.1082\n",
      "Epoch 351/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 192.4842 - val_loss: 169.8635\n",
      "Epoch 352/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 228.1479 - val_loss: 214.9293\n",
      "Epoch 353/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 236.0781 - val_loss: 174.3384\n",
      "Epoch 354/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 199.0475 - val_loss: 245.0284\n",
      "Epoch 355/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 209.5140 - val_loss: 160.8752\n",
      "Epoch 356/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 183.2814 - val_loss: 160.7588\n",
      "Epoch 357/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 230.4582 - val_loss: 347.2094\n",
      "Epoch 358/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 319.5717 - val_loss: 165.5014\n",
      "Epoch 359/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 204.2564 - val_loss: 203.8482\n",
      "Epoch 360/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 177.3275 - val_loss: 160.9282\n",
      "Epoch 361/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 209.3749 - val_loss: 173.8436\n",
      "Epoch 362/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 191.0856 - val_loss: 162.2512\n",
      "Epoch 363/1000\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 315.6257 - val_loss: 188.0212\n",
      "Epoch 364/1000\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 215.4762 - val_loss: 196.3187\n",
      "Epoch 365/1000\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 200.1243 - val_loss: 246.4403\n",
      "Epoch 366/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 202.5706 - val_loss: 251.0341\n",
      "Epoch 367/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 200.2785 - val_loss: 182.4104\n",
      "Epoch 368/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 206.4188 - val_loss: 173.2913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 215.0057 - val_loss: 154.5362\n",
      "Epoch 370/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 194.4500 - val_loss: 198.8562\n",
      "Epoch 371/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 250.5442 - val_loss: 160.4474\n",
      "Epoch 372/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 186.1939 - val_loss: 162.0587\n",
      "Epoch 373/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 187.4765 - val_loss: 150.5945\n",
      "Epoch 374/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 206.3106 - val_loss: 149.8351\n",
      "Epoch 375/1000\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 196.3895 - val_loss: 166.9290\n",
      "Epoch 376/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 190.2583 - val_loss: 172.2516\n",
      "Epoch 377/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 191.2786 - val_loss: 158.7575\n",
      "Epoch 378/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 188.6211 - val_loss: 175.3980\n",
      "Epoch 379/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 225.9234 - val_loss: 598.8661\n",
      "Epoch 380/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 334.4197 - val_loss: 165.0290\n",
      "Epoch 381/1000\n",
      "7500/7500 [==============================] - 1s 93us/step - loss: 185.2368 - val_loss: 156.0447\n",
      "Epoch 382/1000\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 236.6694 - val_loss: 171.3367\n",
      "Epoch 383/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 188.0298 - val_loss: 158.7401\n",
      "Epoch 384/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 185.3748 - val_loss: 166.8362\n",
      "Epoch 385/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 196.250 - 0s 61us/step - loss: 197.2961 - val_loss: 245.0875\n",
      "Epoch 386/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 205.2617 - val_loss: 154.9937\n",
      "Epoch 387/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 182.7456 - val_loss: 207.3924\n",
      "Epoch 388/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 453.2176 - val_loss: 773.9935\n",
      "Epoch 389/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 375.1644 - val_loss: 160.6855\n",
      "Epoch 390/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 187.4075 - val_loss: 207.2133\n",
      "Epoch 391/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 195.0544 - val_loss: 167.8093\n",
      "Epoch 392/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 179.6386 - val_loss: 185.7254\n",
      "Epoch 393/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 196.5400 - val_loss: 180.5116\n",
      "Epoch 394/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 196.0828 - val_loss: 155.0455\n",
      "Epoch 395/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 248.0800 - val_loss: 224.8764\n",
      "Epoch 396/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 185.6486 - val_loss: 167.1076\n",
      "Epoch 397/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 186.5886 - val_loss: 171.2821\n",
      "Epoch 398/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 241.6979 - val_loss: 152.0427\n",
      "Epoch 399/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 210.5271 - val_loss: 428.8544\n",
      "Epoch 400/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 617.2840 - val_loss: 207.4585\n",
      "Epoch 401/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 193.8192 - val_loss: 191.9520\n",
      "Epoch 402/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 236.0730 - val_loss: 227.3543\n",
      "Epoch 403/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 181.1929 - val_loss: 158.3548\n",
      "Epoch 404/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 172.6242 - val_loss: 170.9701\n",
      "Epoch 405/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 241.9101 - val_loss: 185.1681\n",
      "Epoch 406/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 193.3888 - val_loss: 190.5182\n",
      "Epoch 407/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 356.7907 - val_loss: 164.3747\n",
      "Epoch 408/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 182.2703 - val_loss: 163.4827\n",
      "Epoch 409/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 201.3205 - val_loss: 201.6389\n",
      "Epoch 410/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 190.9025 - val_loss: 288.1666\n",
      "Epoch 411/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 199.9378 - val_loss: 153.9741\n",
      "Epoch 412/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 172.7446 - val_loss: 151.2084\n",
      "Epoch 413/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 191.6589 - val_loss: 152.0697\n",
      "Epoch 414/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 207.1324 - val_loss: 173.7146\n",
      "Epoch 415/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 186.2194 - val_loss: 151.4134\n",
      "Epoch 416/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 289.4620 - val_loss: 235.9087\n",
      "Epoch 417/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 214.0689 - val_loss: 162.7506\n",
      "Epoch 418/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 172.1203 - val_loss: 155.6792\n",
      "Epoch 419/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 206.5569 - val_loss: 151.7476\n",
      "Epoch 420/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 172.8390 - val_loss: 153.7239\n",
      "Epoch 421/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 183.1337 - val_loss: 163.1363\n",
      "Epoch 422/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 249.8789 - val_loss: 273.6452\n",
      "Epoch 423/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 216.4461 - val_loss: 578.1963\n",
      "Epoch 424/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 242.4114 - val_loss: 207.0805\n",
      "Epoch 425/1000\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 239.4512 - val_loss: 166.5113\n",
      "Epoch 426/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 257.6947 - val_loss: 164.2547\n",
      "Epoch 427/1000\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 178.9878 - val_loss: 158.7673\n",
      "Epoch 428/1000\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 363.9987 - val_loss: 733.9213\n",
      "Epoch 429/1000\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 305.1095 - val_loss: 188.3702\n",
      "Epoch 430/1000\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 248.3804 - val_loss: 227.3843\n",
      "Epoch 431/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 212.4411 - val_loss: 202.3942\n",
      "Epoch 432/1000\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 208.8211 - val_loss: 188.2022\n",
      "Epoch 433/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 204.5231 - val_loss: 276.3533\n",
      "Epoch 434/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 304.6836 - val_loss: 443.7278\n",
      "Epoch 435/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 228.8305 - val_loss: 190.8226\n",
      "Epoch 436/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 217.2282 - val_loss: 213.0868\n",
      "Epoch 437/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 224.9803 - val_loss: 181.6440\n",
      "Epoch 438/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 188.7479 - val_loss: 302.7005\n",
      "Epoch 439/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 293.8453 - val_loss: 156.0807\n",
      "Epoch 440/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 197.0538 - val_loss: 291.6629\n",
      "Epoch 441/1000\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 254.4009 - val_loss: 202.9314\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s 95us/step - loss: 205.4604 - val_loss: 158.8569\n",
      "Epoch 443/1000\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 375.9670 - val_loss: 298.0763\n",
      "Epoch 444/1000\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 280.1198 - val_loss: 211.3745\n",
      "Epoch 445/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 237.6327 - val_loss: 228.0147\n",
      "Epoch 446/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 222.0473 - val_loss: 204.9855\n",
      "Epoch 447/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 259.2399 - val_loss: 221.8816\n",
      "Epoch 448/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 249.7226 - val_loss: 168.6216\n",
      "Epoch 449/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 217.5407 - val_loss: 280.9992\n",
      "Epoch 450/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 211.4179 - val_loss: 208.7867\n",
      "Epoch 451/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 229.2538 - val_loss: 225.0216\n",
      "Epoch 452/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 215.2775 - val_loss: 182.1600\n",
      "Epoch 453/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 199.3416 - val_loss: 192.8704\n",
      "Epoch 454/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 222.4469 - val_loss: 164.3128\n",
      "Epoch 455/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 239.0011 - val_loss: 197.0428\n",
      "Epoch 456/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 233.4849 - val_loss: 213.6606\n",
      "Epoch 457/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 198.1943 - val_loss: 168.8463\n",
      "Epoch 458/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 235.8776 - val_loss: 176.5161\n",
      "Epoch 459/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 199.0193 - val_loss: 314.4016\n",
      "Epoch 460/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 206.1279 - val_loss: 170.9384\n",
      "Epoch 461/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 220.8848 - val_loss: 253.9169\n",
      "Epoch 462/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 204.5131 - val_loss: 279.9805\n",
      "Epoch 463/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 211.1015 - val_loss: 184.3221\n",
      "Epoch 464/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 211.6417 - val_loss: 159.7804\n",
      "Epoch 465/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 205.9144 - val_loss: 152.3729\n",
      "Epoch 466/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 192.8989 - val_loss: 236.9186\n",
      "Epoch 467/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 240.0267 - val_loss: 165.2970\n",
      "Epoch 468/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 215.1982 - val_loss: 193.1647\n",
      "Epoch 469/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 222.9331 - val_loss: 151.2871\n",
      "Epoch 470/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 203.1351 - val_loss: 188.4386\n",
      "Epoch 471/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 200.6582 - val_loss: 153.6394\n",
      "Epoch 472/1000\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 226.5150 - val_loss: 215.2120\n",
      "Epoch 473/1000\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 207.1888 - val_loss: 156.1085\n",
      "Epoch 474/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 197.5353 - val_loss: 164.2137\n",
      "Epoch 475/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 185.9596 - val_loss: 167.6470\n",
      "Epoch 476/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 204.6011 - val_loss: 181.4448\n",
      "Epoch 477/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 198.3874 - val_loss: 164.9678\n",
      "Epoch 478/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 208.4952 - val_loss: 255.4068\n",
      "Epoch 479/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 233.3306 - val_loss: 154.4181\n",
      "Epoch 480/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 204.2446 - val_loss: 176.0458\n",
      "Epoch 481/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 211.8844 - val_loss: 210.6271\n",
      "Epoch 482/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 183.4215 - val_loss: 166.5632\n",
      "Epoch 483/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 187.9385 - val_loss: 177.3727\n",
      "Epoch 484/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 183.9633 - val_loss: 160.3016\n",
      "Epoch 485/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 216.9571 - val_loss: 194.6019\n",
      "Epoch 486/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 223.7671 - val_loss: 366.4387\n",
      "Epoch 487/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 216.0397 - val_loss: 185.4449\n",
      "Epoch 488/1000\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 189.6898 - val_loss: 151.4939\n",
      "Epoch 489/1000\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 183.7303 - val_loss: 171.9188\n",
      "Epoch 490/1000\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 210.7708 - val_loss: 166.7565\n",
      "Epoch 491/1000\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 199.0457 - val_loss: 172.6488\n",
      "Epoch 492/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 187.4493 - val_loss: 152.7582\n",
      "Epoch 493/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 227.8919 - val_loss: 170.8261\n",
      "Epoch 494/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 191.4454 - val_loss: 160.2085\n",
      "Epoch 495/1000\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 219.8645 - val_loss: 167.2864\n",
      "Epoch 496/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 185.7678 - val_loss: 212.2564\n",
      "Epoch 497/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 202.1735 - val_loss: 267.8428\n",
      "Epoch 498/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 203.1896 - val_loss: 313.0164\n",
      "Epoch 499/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 208.1226 - val_loss: 221.9526\n",
      "Epoch 500/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 188.0142 - val_loss: 208.0443\n",
      "Epoch 501/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 200.4173 - val_loss: 175.9305\n",
      "Epoch 502/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 184.2658 - val_loss: 155.1866\n",
      "Epoch 503/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 203.6196 - val_loss: 337.6963\n",
      "Epoch 504/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 231.4430 - val_loss: 278.7210\n",
      "Epoch 505/1000\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 188.0232 - val_loss: 152.0505\n",
      "Epoch 506/1000\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 204.6319 - val_loss: 152.2412\n",
      "Epoch 507/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 179.8130 - val_loss: 327.9338\n",
      "Epoch 508/1000\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 205.7080 - val_loss: 150.8335\n",
      "Epoch 509/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 191.4454 - val_loss: 159.9457\n",
      "Epoch 510/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 205.4980 - val_loss: 173.8844\n",
      "Epoch 511/1000\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 201.5092 - val_loss: 173.9029\n",
      "Epoch 512/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 191.4441 - val_loss: 229.7372\n",
      "Epoch 513/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 194.8237 - val_loss: 145.1098\n",
      "Epoch 514/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 197.1511 - val_loss: 175.6272\n",
      "Epoch 515/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 187.2115 - val_loss: 153.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 516/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 178.1266 - val_loss: 163.1918\n",
      "Epoch 517/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 196.7915 - val_loss: 164.6589\n",
      "Epoch 518/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 229.5012 - val_loss: 156.7872\n",
      "Epoch 519/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 194.2822 - val_loss: 154.4416\n",
      "Epoch 520/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 195.5503 - val_loss: 166.1364\n",
      "Epoch 521/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 193.8960 - val_loss: 177.8432\n",
      "Epoch 522/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 176.7614 - val_loss: 251.9194\n",
      "Epoch 523/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 229.7675 - val_loss: 172.4320\n",
      "Epoch 524/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 166.5684 - val_loss: 172.0457\n",
      "Epoch 525/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 174.0855 - val_loss: 151.3111\n",
      "Epoch 526/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 193.6702 - val_loss: 191.6351\n",
      "Epoch 527/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 206.0236 - val_loss: 256.6024\n",
      "Epoch 528/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 191.3322 - val_loss: 167.1564\n",
      "Epoch 529/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 200.7520 - val_loss: 150.4732\n",
      "Epoch 530/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 234.7736 - val_loss: 201.7062\n",
      "Epoch 531/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 176.5918 - val_loss: 160.7812\n",
      "Epoch 532/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 183.6425 - val_loss: 151.2810\n",
      "Epoch 533/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 197.1007 - val_loss: 194.5971\n",
      "Epoch 534/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 189.0920 - val_loss: 261.6977\n",
      "Epoch 535/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 197.6206 - val_loss: 192.4903\n",
      "Epoch 536/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 180.7958 - val_loss: 148.3302\n",
      "Epoch 537/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 201.4371 - val_loss: 165.3687\n",
      "Epoch 538/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 194.1063 - val_loss: 162.4783\n",
      "Epoch 539/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 169.6725 - val_loss: 190.2195\n",
      "Epoch 540/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 207.5128 - val_loss: 157.4969\n",
      "Epoch 541/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 190.6979 - val_loss: 195.2194\n",
      "Epoch 542/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 176.7459 - val_loss: 160.9034\n",
      "Epoch 543/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 193.7319 - val_loss: 152.1997\n",
      "Epoch 544/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 188.4909 - val_loss: 164.2546\n",
      "Epoch 545/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 180.7325 - val_loss: 318.1578\n",
      "Epoch 546/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 192.0864 - val_loss: 153.7643\n",
      "Epoch 547/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 171.7911 - val_loss: 144.7792\n",
      "Epoch 548/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 186.1261 - val_loss: 228.6525\n",
      "Epoch 549/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 178.9112 - val_loss: 184.9723\n",
      "Epoch 550/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 165.8526 - val_loss: 154.0281\n",
      "Epoch 551/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 189.6538 - val_loss: 300.2265\n",
      "Epoch 552/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 195.7193 - val_loss: 149.8246\n",
      "Epoch 553/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 223.0459 - val_loss: 151.0205\n",
      "Epoch 554/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 224.9788 - val_loss: 176.8068\n",
      "Epoch 555/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 195.9684 - val_loss: 272.3548\n",
      "Epoch 556/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 192.2193 - val_loss: 157.1461\n",
      "Epoch 557/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 160.4454 - val_loss: 142.0471\n",
      "Epoch 558/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 169.6501 - val_loss: 222.9979\n",
      "Epoch 559/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 209.0128 - val_loss: 169.4269\n",
      "Epoch 560/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 174.5489 - val_loss: 192.2919\n",
      "Epoch 561/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 197.4297 - val_loss: 159.2508\n",
      "Epoch 562/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 200.3417 - val_loss: 168.2603\n",
      "Epoch 563/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 170.3396 - val_loss: 144.9681\n",
      "Epoch 564/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 422.5540 - val_loss: 184.0474\n",
      "Epoch 565/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 220.6535 - val_loss: 232.6219\n",
      "Epoch 566/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 171.0724 - val_loss: 157.2837\n",
      "Epoch 567/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 175.9614 - val_loss: 149.1777\n",
      "Epoch 568/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 195.4134 - val_loss: 145.9467\n",
      "Epoch 569/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 226.7662 - val_loss: 159.6018\n",
      "Epoch 570/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 171.1865 - val_loss: 150.1611\n",
      "Epoch 571/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 168.9363 - val_loss: 206.5727\n",
      "Epoch 572/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 190.7597 - val_loss: 193.3187\n",
      "Epoch 573/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 210.5912 - val_loss: 145.6453\n",
      "Epoch 574/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 209.1136 - val_loss: 151.9761\n",
      "Epoch 575/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 171.8882 - val_loss: 179.0676\n",
      "Epoch 576/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 182.5681 - val_loss: 146.5923\n",
      "Epoch 577/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 193.6415 - val_loss: 214.5170\n",
      "Epoch 578/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 176.4632 - val_loss: 158.3456\n",
      "Epoch 579/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 199.4824 - val_loss: 192.4308\n",
      "Epoch 580/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 175.9625 - val_loss: 173.8071\n",
      "Epoch 581/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 179.2153 - val_loss: 171.0149\n",
      "Epoch 582/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 209.1228 - val_loss: 162.5228\n",
      "Epoch 583/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 177.9225 - val_loss: 160.6351\n",
      "Epoch 584/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 194.5077 - val_loss: 147.8517\n",
      "Epoch 585/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 201.1191 - val_loss: 180.6003\n",
      "Epoch 586/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 182.9934 - val_loss: 182.2802\n",
      "Epoch 587/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 192.4685 - val_loss: 204.0810\n",
      "Epoch 588/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 174.8981 - val_loss: 199.4527\n",
      "Epoch 589/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 196.2294 - val_loss: 180.2279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 176.2216 - val_loss: 150.6400\n",
      "Epoch 591/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 186.0364 - val_loss: 171.4729\n",
      "Epoch 592/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 200.8888 - val_loss: 218.7462\n",
      "Epoch 593/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 187.1539 - val_loss: 153.1138\n",
      "Epoch 594/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 187.3103 - val_loss: 143.4687\n",
      "Epoch 595/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 205.3646 - val_loss: 216.9109\n",
      "Epoch 596/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 177.2028 - val_loss: 164.9105\n",
      "Epoch 597/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 165.3974 - val_loss: 151.4011\n",
      "Epoch 598/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 168.5085 - val_loss: 169.8282\n",
      "Epoch 599/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 185.5704 - val_loss: 151.5532\n",
      "Epoch 600/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 208.2767 - val_loss: 168.8962\n",
      "Epoch 601/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 176.7133 - val_loss: 260.1634\n",
      "Epoch 602/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 186.3550 - val_loss: 147.4316\n",
      "Epoch 603/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 215.5962 - val_loss: 161.7240\n",
      "Epoch 604/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 348.5683 - val_loss: 161.6493\n",
      "Epoch 605/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 168.2446 - val_loss: 147.3656\n",
      "Epoch 606/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 173.7358 - val_loss: 164.0569\n",
      "Epoch 607/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 175.2958 - val_loss: 191.1802\n",
      "Epoch 608/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 176.8194 - val_loss: 190.4163\n",
      "Epoch 609/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 180.3530 - val_loss: 278.7678\n",
      "Epoch 610/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 192.5077 - val_loss: 141.9751\n",
      "Epoch 611/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 194.8592 - val_loss: 147.4108\n",
      "Epoch 612/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 200.7813 - val_loss: 202.6849\n",
      "Epoch 613/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 169.0982 - val_loss: 149.8255\n",
      "Epoch 614/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 168.7172 - val_loss: 144.9326\n",
      "Epoch 615/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 166.2455 - val_loss: 167.5308\n",
      "Epoch 616/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 174.7354 - val_loss: 206.1105\n",
      "Epoch 617/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 201.2250 - val_loss: 144.2901\n",
      "Epoch 618/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 170.9335 - val_loss: 156.1933\n",
      "Epoch 619/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 178.4467 - val_loss: 167.0611\n",
      "Epoch 620/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 186.0851 - val_loss: 153.7529\n",
      "Epoch 621/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 189.6446 - val_loss: 161.7736\n",
      "Epoch 622/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 185.6122 - val_loss: 147.9145\n",
      "Epoch 623/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 175.5927 - val_loss: 188.7899\n",
      "Epoch 624/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 175.1862 - val_loss: 274.3371\n",
      "Epoch 625/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 198.6672 - val_loss: 197.5186\n",
      "Epoch 626/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 182.4996 - val_loss: 159.3256\n",
      "Epoch 627/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 175.2309 - val_loss: 158.0105\n",
      "Epoch 628/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 189.3240 - val_loss: 146.6320\n",
      "Epoch 629/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 171.8688 - val_loss: 177.4852\n",
      "Epoch 630/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 248.0652 - val_loss: 307.2820\n",
      "Epoch 631/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 200.7837 - val_loss: 150.1965\n",
      "Epoch 632/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 157.2859 - val_loss: 159.0446\n",
      "Epoch 633/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 170.6952 - val_loss: 235.8938\n",
      "Epoch 634/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 161.5977 - val_loss: 461.9376\n",
      "Epoch 635/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 213.0777 - val_loss: 223.5934\n",
      "Epoch 636/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 198.7776 - val_loss: 154.3803\n",
      "Epoch 637/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 186.3473 - val_loss: 167.2742\n",
      "Epoch 638/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 173.8851 - val_loss: 157.0715\n",
      "Epoch 639/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 177.4202 - val_loss: 196.7188\n",
      "Epoch 640/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 182.6156 - val_loss: 187.3049\n",
      "Epoch 641/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 170.1605 - val_loss: 190.5876\n",
      "Epoch 642/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 192.2782 - val_loss: 152.3726\n",
      "Epoch 643/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 210.0426 - val_loss: 187.1492\n",
      "Epoch 644/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 172.7167 - val_loss: 199.7297\n",
      "Epoch 645/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 227.3056 - val_loss: 160.9391\n",
      "Epoch 646/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 161.0993 - val_loss: 145.7157\n",
      "Epoch 647/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 161.2013 - val_loss: 153.4745\n",
      "Epoch 648/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 183.0353 - val_loss: 168.3054\n",
      "Epoch 649/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 177.5136 - val_loss: 186.7018\n",
      "Epoch 650/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 180.8316 - val_loss: 171.9899\n",
      "Epoch 651/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 270.8983 - val_loss: 326.9051\n",
      "Epoch 652/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 262.2638 - val_loss: 206.5197\n",
      "Epoch 653/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 235.4842 - val_loss: 189.3880\n",
      "Epoch 654/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 193.0503 - val_loss: 291.4713\n",
      "Epoch 655/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 234.2679 - val_loss: 246.1955\n",
      "Epoch 656/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 174.3330 - val_loss: 147.4097\n",
      "Epoch 657/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 174.9304 - val_loss: 156.1604\n",
      "Epoch 658/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 165.5476 - val_loss: 200.3542\n",
      "Epoch 659/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 212.0913 - val_loss: 148.9784\n",
      "Epoch 660/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 165.5326 - val_loss: 141.7018\n",
      "Epoch 661/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 193.4198 - val_loss: 201.7197\n",
      "Epoch 662/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 165.6662 - val_loss: 147.6366\n",
      "Epoch 663/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 183.4408 - val_loss: 152.1502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 664/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 188.5072 - val_loss: 145.6126\n",
      "Epoch 665/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 176.3982 - val_loss: 153.3231\n",
      "Epoch 666/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 163.3039 - val_loss: 153.7898\n",
      "Epoch 667/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 177.3621 - val_loss: 143.0542\n",
      "Epoch 668/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 235.1766 - val_loss: 145.5065\n",
      "Epoch 669/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 169.1045 - val_loss: 146.6605\n",
      "Epoch 670/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 170.0993 - val_loss: 220.3758\n",
      "Epoch 671/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 173.9937 - val_loss: 148.0949\n",
      "Epoch 672/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 181.7351 - val_loss: 141.6720\n",
      "Epoch 673/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 169.6935 - val_loss: 300.3001\n",
      "Epoch 674/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 183.2831 - val_loss: 145.7517\n",
      "Epoch 675/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 234.5904 - val_loss: 166.8474\n",
      "Epoch 676/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 170.1438 - val_loss: 143.3201\n",
      "Epoch 677/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 168.3240 - val_loss: 169.2842\n",
      "Epoch 678/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 183.5003 - val_loss: 197.1028\n",
      "Epoch 679/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 210.0094 - val_loss: 237.7597\n",
      "Epoch 680/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 171.6099 - val_loss: 159.0920\n",
      "Epoch 681/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 172.6796 - val_loss: 140.1690\n",
      "Epoch 682/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 231.8230 - val_loss: 152.4886\n",
      "Epoch 683/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 172.2621 - val_loss: 181.9988\n",
      "Epoch 684/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 280.7310 - val_loss: 337.0134\n",
      "Epoch 685/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 255.5233 - val_loss: 159.9024\n",
      "Epoch 686/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 168.2576 - val_loss: 158.9313\n",
      "Epoch 687/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 167.1471 - val_loss: 141.1407\n",
      "Epoch 688/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 190.1018 - val_loss: 160.0762\n",
      "Epoch 689/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 166.1118 - val_loss: 184.4174\n",
      "Epoch 690/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 159.6076 - val_loss: 153.6679\n",
      "Epoch 691/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 174.9570 - val_loss: 193.2174\n",
      "Epoch 692/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 210.2891 - val_loss: 439.0003\n",
      "Epoch 693/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 204.4463 - val_loss: 199.4014\n",
      "Epoch 694/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 167.6834 - val_loss: 140.6612\n",
      "Epoch 695/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 204.4670 - val_loss: 373.2578\n",
      "Epoch 696/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 236.6036 - val_loss: 179.1758\n",
      "Epoch 697/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 156.9923 - val_loss: 138.7937\n",
      "Epoch 698/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 164.0450 - val_loss: 167.5240\n",
      "Epoch 699/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 210.8631 - val_loss: 167.1835\n",
      "Epoch 700/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 178.6346 - val_loss: 250.8138\n",
      "Epoch 701/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 155.2429 - val_loss: 191.1988\n",
      "Epoch 702/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 167.9292 - val_loss: 190.7178\n",
      "Epoch 703/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 211.6447 - val_loss: 226.5939\n",
      "Epoch 704/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 249.0517 - val_loss: 160.9615\n",
      "Epoch 705/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 172.4148 - val_loss: 159.3194\n",
      "Epoch 706/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 202.7830 - val_loss: 229.9496\n",
      "Epoch 707/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 181.0964 - val_loss: 147.9696\n",
      "Epoch 708/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 159.5647 - val_loss: 143.9350\n",
      "Epoch 709/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 182.7653 - val_loss: 160.8360\n",
      "Epoch 710/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 160.7611 - val_loss: 144.5684\n",
      "Epoch 711/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 165.1889 - val_loss: 209.6944\n",
      "Epoch 712/1000\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 176.7045 - val_loss: 584.1669\n",
      "Epoch 713/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 357.1294 - val_loss: 149.2397\n",
      "Epoch 714/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 164.7860 - val_loss: 152.5624\n",
      "Epoch 715/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 152.3103 - val_loss: 144.1346\n",
      "Epoch 716/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 155.2625 - val_loss: 144.7063\n",
      "Epoch 717/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 163.0316 - val_loss: 154.3163\n",
      "Epoch 718/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 163.5817 - val_loss: 172.7760\n",
      "Epoch 719/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 161.1171 - val_loss: 143.4751\n",
      "Epoch 720/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 155.4944 - val_loss: 139.5026\n",
      "Epoch 721/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 196.5691 - val_loss: 148.0648\n",
      "Epoch 722/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 299.1671 - val_loss: 151.2715\n",
      "Epoch 723/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 164.5199 - val_loss: 153.2580\n",
      "Epoch 724/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 168.7871 - val_loss: 141.0284\n",
      "Epoch 725/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 153.4201 - val_loss: 194.4660\n",
      "Epoch 726/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 155.5137 - val_loss: 150.2198\n",
      "Epoch 727/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 165.6997 - val_loss: 161.7008\n",
      "Epoch 728/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 176.9161 - val_loss: 145.0029\n",
      "Epoch 729/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 178.0147 - val_loss: 157.5106\n",
      "Epoch 730/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 164.5452 - val_loss: 212.5845\n",
      "Epoch 731/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 293.6639 - val_loss: 181.3094\n",
      "Epoch 732/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 167.1035 - val_loss: 215.2271\n",
      "Epoch 733/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 169.8793 - val_loss: 165.9558\n",
      "Epoch 734/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 284.5229 - val_loss: 201.9170\n",
      "Epoch 735/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 194.6583 - val_loss: 192.5769\n",
      "Epoch 736/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 165.5023 - val_loss: 142.8908\n",
      "Epoch 737/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 163.5937 - val_loss: 185.0175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 738/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 158.1197 - val_loss: 156.4657\n",
      "Epoch 739/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 157.2572 - val_loss: 187.3909\n",
      "Epoch 740/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 162.7132 - val_loss: 186.0432\n",
      "Epoch 741/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 176.8395 - val_loss: 140.0698\n",
      "Epoch 742/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 198.8727 - val_loss: 429.7610\n",
      "Epoch 743/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 211.9016 - val_loss: 154.2210\n",
      "Epoch 744/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 160.5902 - val_loss: 146.1758\n",
      "Epoch 745/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 167.7024 - val_loss: 510.2064\n",
      "Epoch 746/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 178.5053 - val_loss: 152.6840\n",
      "Epoch 747/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 154.8034 - val_loss: 151.0551\n",
      "Epoch 748/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 175.6314 - val_loss: 140.3757\n",
      "Epoch 749/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 175.5246 - val_loss: 150.8753\n",
      "Epoch 750/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 230.6921 - val_loss: 160.7155\n",
      "Epoch 751/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 161.1420 - val_loss: 149.1061\n",
      "Epoch 752/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 158.2608 - val_loss: 162.3056\n",
      "Epoch 753/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 172.1561 - val_loss: 142.5124\n",
      "Epoch 754/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 157.1235 - val_loss: 147.6288\n",
      "Epoch 755/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 165.4832 - val_loss: 189.3069\n",
      "Epoch 756/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 180.2373 - val_loss: 143.3457\n",
      "Epoch 757/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 167.3402 - val_loss: 148.2671\n",
      "Epoch 758/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 173.4998 - val_loss: 141.7532\n",
      "Epoch 759/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 169.7316 - val_loss: 142.5505\n",
      "Epoch 760/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 165.9232 - val_loss: 179.5818\n",
      "Epoch 761/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 172.0381 - val_loss: 176.9007\n",
      "Epoch 762/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 170.6609 - val_loss: 171.7002\n",
      "Epoch 763/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 159.2280 - val_loss: 168.0874\n",
      "Epoch 764/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 188.4202 - val_loss: 179.9968\n",
      "Epoch 765/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 189.6306 - val_loss: 155.1559\n",
      "Epoch 766/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 190.2464 - val_loss: 157.1041\n",
      "Epoch 767/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 344.8271 - val_loss: 143.7417\n",
      "Epoch 768/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 163.0329 - val_loss: 175.1269\n",
      "Epoch 769/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 152.4982 - val_loss: 162.8412\n",
      "Epoch 770/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 157.4693 - val_loss: 172.9106\n",
      "Epoch 771/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 155.5038 - val_loss: 150.4810\n",
      "Epoch 772/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 190.0344 - val_loss: 160.6866\n",
      "Epoch 773/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 151.9278 - val_loss: 168.3225\n",
      "Epoch 774/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 162.4295 - val_loss: 181.4987\n",
      "Epoch 775/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 212.9147 - val_loss: 177.1398\n",
      "Epoch 776/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 168.3192 - val_loss: 221.9031\n",
      "Epoch 777/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 165.4955 - val_loss: 224.1659\n",
      "Epoch 778/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 158.1419 - val_loss: 246.4085\n",
      "Epoch 779/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 166.9542 - val_loss: 142.2800\n",
      "Epoch 780/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 182.2280 - val_loss: 150.6841\n",
      "Epoch 781/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 165.4064 - val_loss: 146.5708\n",
      "Epoch 782/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 160.1987 - val_loss: 353.0704\n",
      "Epoch 783/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 186.8634 - val_loss: 160.0347\n",
      "Epoch 784/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 167.2967 - val_loss: 400.9646\n",
      "Epoch 785/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 398.2281 - val_loss: 176.5311\n",
      "Epoch 786/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 174.5953 - val_loss: 154.8998\n",
      "Epoch 787/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 195.7931 - val_loss: 157.5331\n",
      "Epoch 788/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 157.1013 - val_loss: 154.7416\n",
      "Epoch 789/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 164.7409 - val_loss: 187.2868\n",
      "Epoch 790/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 173.9971 - val_loss: 143.8714\n",
      "Epoch 791/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 149.9780 - val_loss: 165.3680\n",
      "Epoch 792/1000\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 182.1281 - val_loss: 260.2660\n",
      "Epoch 793/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 158.1378 - val_loss: 138.8663\n",
      "Epoch 794/1000\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 162.5107 - val_loss: 140.6474\n",
      "Epoch 795/1000\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 169.4388 - val_loss: 172.6993\n",
      "Epoch 796/1000\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 163.4714 - val_loss: 141.3083\n",
      "Epoch 797/1000\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 171.5287 - val_loss: 158.6712\n",
      "Epoch 798/1000\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 283.3267 - val_loss: 263.0845\n",
      "Epoch 799/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 161.5110 - val_loss: 156.0360\n",
      "Epoch 800/1000\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 147.4508 - val_loss: 145.7221\n",
      "Epoch 801/1000\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 183.4512 - val_loss: 145.4210\n",
      "Epoch 802/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 154.3251 - val_loss: 147.7810\n",
      "Epoch 803/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 142.4315 - val_loss: 145.5612\n",
      "Epoch 804/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 149.1963 - val_loss: 161.4388\n",
      "Epoch 805/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 223.9607 - val_loss: 157.1508\n",
      "Epoch 806/1000\n",
      "7500/7500 [==============================] - 0s 67us/step - loss: 165.6784 - val_loss: 162.8431\n",
      "Epoch 807/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 160.7266 - val_loss: 172.1650\n",
      "Epoch 808/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 157.8441 - val_loss: 154.1004\n",
      "Epoch 809/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 153.2353 - val_loss: 165.3620\n",
      "Epoch 810/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 168.0912 - val_loss: 169.3426\n",
      "Epoch 811/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 151.4183 - val_loss: 185.0676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 812/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 164.3240 - val_loss: 159.9621\n",
      "Epoch 813/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 235.5987 - val_loss: 162.0194\n",
      "Epoch 814/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 163.1835 - val_loss: 184.8222\n",
      "Epoch 815/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 186.5259 - val_loss: 299.2153\n",
      "Epoch 816/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 175.7810 - val_loss: 143.2499\n",
      "Epoch 817/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 165.1533 - val_loss: 139.3245\n",
      "Epoch 818/1000\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 170.5460 - val_loss: 192.0367\n",
      "Epoch 819/1000\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 187.6504 - val_loss: 266.3229\n",
      "Epoch 820/1000\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 162.8807 - val_loss: 140.7993\n",
      "Epoch 821/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 160.3506 - val_loss: 181.4864\n",
      "Epoch 822/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 158.3840 - val_loss: 186.4009\n",
      "Epoch 823/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 169.1882 - val_loss: 153.1182\n",
      "Epoch 824/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 193.2713 - val_loss: 145.4567\n",
      "Epoch 825/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 158.461 - 1s 68us/step - loss: 160.5579 - val_loss: 168.2519\n",
      "Epoch 826/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 158.1386 - val_loss: 168.1907\n",
      "Epoch 827/1000\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 163.8146 - val_loss: 163.9028\n",
      "Epoch 828/1000\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 182.1155 - val_loss: 183.0103\n",
      "Epoch 829/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 155.9970 - val_loss: 158.3479\n",
      "Epoch 830/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 185.0775 - val_loss: 345.1737\n",
      "Epoch 831/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 406.9449 - val_loss: 289.9390\n",
      "Epoch 832/1000\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 254.1334 - val_loss: 169.2182\n",
      "Epoch 833/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 207.1117 - val_loss: 233.1625\n",
      "Epoch 834/1000\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 198.0134 - val_loss: 160.2944\n",
      "Epoch 835/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 247.6233 - val_loss: 271.3010\n",
      "Epoch 836/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 230.5873 - val_loss: 191.8218\n",
      "Epoch 837/1000\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 219.0663 - val_loss: 157.7288\n",
      "Epoch 838/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 184.5865 - val_loss: 159.2851\n",
      "Epoch 839/1000\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 186.9750 - val_loss: 152.9055\n",
      "Epoch 840/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 187.7336 - val_loss: 152.7231\n",
      "Epoch 841/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 175.5386 - val_loss: 155.6476\n",
      "Epoch 842/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 184.2733 - val_loss: 203.6000\n",
      "Epoch 843/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 183.6930 - val_loss: 144.5389\n",
      "Epoch 844/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 179.0982 - val_loss: 167.2632\n",
      "Epoch 845/1000\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 185.5360 - val_loss: 153.5509\n",
      "Epoch 846/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 179.5882 - val_loss: 151.3891\n",
      "Epoch 847/1000\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 180.3843 - val_loss: 140.9497\n",
      "Epoch 00847: early stopping\n",
      "Fold score (RMSE): 11.183201789855957\n"
     ]
    }
   ],
   "source": [
    "x,y = to_xy(df_train,'cost')\n",
    "# Cross-Validate\n",
    "#kf = KFold(5)\n",
    "\n",
    "# Used before KFold\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "#oos_y = []\n",
    "#oos_pred = []\n",
    "#fold = 0\n",
    "checkpoint = ModelCheckpoint(filepath=filename_checkpoint, verbose=0, save_best_only=True)\n",
    "#for train, test in kf.split(x):\n",
    "#    fold+=1\n",
    "#    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "#x_train = x[train]\n",
    "#y_train = y[train]\n",
    "#x_test = x[test]\n",
    "#y_test = y[test]\n",
    "\n",
    "#changed dense values from (50, 25, 10) to (45, 30, 15), patience = 100\n",
    "#original RMSE was 13.15, new value is 11.87, 2nd RMSE is 11.057, results kagglecode.csv\n",
    "#2nd RMSE changed 3rd layer to 10 (45, 30, 10)\n",
    "#1st RMSE is 11.75, 2nd RMSE is 11.10, results kagglecode2.csv\n",
    "#3rd try, (45,30,10), changed patience from 100 to 50\n",
    "#1st RMSE is 13.65, 11.49, did not save results\n",
    "#4th try, (45,30,10), changed patience to 150\n",
    "#1st RMSE is 11.18, 2nd RMSE is 10.94, results kagglesubmission.csv\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(45, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dropout(0.01)) # Dropout Layer\n",
    "model.add(Dense(30, activation='relu')) # Hidden 2\n",
    "model.add(Dense(10, \n",
    "            kernel_regularizer=regularizers.l2(0.01),\n",
    "            activity_regularizer=regularizers.l1(0.01),activation='relu')) # Hidden 3 w/regularization\n",
    "model.add(Dense(1)) # Output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=150, verbose=1, mode='auto')\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpoint],verbose=1,epochs=1000)\n",
    "    \n",
    "pred = model.predict(x_test)\n",
    "    \n",
    "    #oos_y.append(y_test)\n",
    "    #oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's RMSE\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Fold score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 10.943763732910156\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filename_checkpoint)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "#chart_regression(pred.flatten(),y_test)\n",
    "#chart_regression(pred.flatten(),y_test,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(filename_test,na_values=['NA','?'])\n",
    "\n",
    "extract_and_encode_features(df_test)\n",
    "missing_default(df_test, \"quality\", \"Unknown\")\n",
    "missing_default(df_test, \"size\", \"Unknown\")\n",
    "missing_default(df_test, \"color\", \"Unknown\")\n",
    "\n",
    "for column in ['manufacturer','color','quality','size','item']:\n",
    "    encode_text_dummy(df_test,column)\n",
    "\n",
    "ids_test = df_test['id']\n",
    "df_test.drop('id',1,inplace=True)\n",
    "\n",
    "names_test = df_test['name']\n",
    "df_test.drop('name',1,inplace=True)\n",
    "\n",
    "x_submit = df_test.as_matrix().astype(np.float32)\n",
    "pred_submit = model.predict(x_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame(pred_submit)\n",
    "df_submit.insert(0,'id',ids_test)\n",
    "df_submit.columns = ['id','cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv('kagglesubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
