{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Kaggle Assignment: **\n",
    "\n",
    "**Student Name: Jason Walker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Description\n",
    "This is one of the projects from the course T81-855: Applications of Deep Learning at Washington University in St. Louis. All students must create a Kaggle account and submit a solution. Once you have submitted your solution entry log into Blackboard (at WUSTL) and submit a single file telling me your Kaggle name on the leaderboard (you do not need to register to Kaggle with your real name). This competition will be visible to the public, so there may be non-student submissions as well as student.\n",
    "\n",
    "The data set for this competition consists of a number of input columns that should be used to predict a stores sales. This is a regression problem. The inputs are a mixture of discrete and category values. The data set is from a simulation.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The evaluation pages describes how submissions will be scored and how students should format their submissions. The scores are in RMSE.\n",
    "Submission Format\n",
    "\n",
    "For every store in the dataset, submission files should contain a sales volume.\n",
    "\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "```\n",
    "100000,1.23\n",
    "100001,1.123\n",
    "100002,3.332\n",
    "100003,1.53\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Data Description\n",
    "\n",
    "The data contains data and costs for various office supplies. The data came from a simulation and do not directly correspond to any real-world items. See how well you can predict the cost of an item using the provided data. Feature engineering will likely help you. The *name* column may seem useless at first glance; however, it contains information that you can parse to help your predictions.\n",
    "File descriptions\n",
    "```\n",
    "    id - The identifier/primary key.\n",
    "    name - The name of this item.\n",
    "    manufacturer - The manufacturer.\n",
    "    pack - The number of items in this pack.\n",
    "    weight - The weight of a pack of these items.\n",
    "    height - The height of a pack of these items.\n",
    "    width - The width of a pack of these items.\n",
    "    length - The length of a pack of these items.\n",
    "    cost - The cost for this item pack. This is what you are to predict (the target). \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions\n",
    "\n",
    "You will see these at the top of every module and assignment.  These are simply a set of reusable functions that we will make use of.  Each of them will be explained as the semester progresses.  They are explained in greater detail as the course progresses.  Class 4 contains a complete overview of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "        \n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kaggle Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwalker/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "path = './data'\n",
    "\n",
    "filename_test = os.path.join(path,\"test.csv\")\n",
    "filename_train = os.path.join(path,\"train.csv\")\n",
    "filename_sample = os.path.join(path,\"sample.csv\")\n",
    "filename_submit = os.path.join(path,\"submit.csv\")\n",
    "filename_checkpoint = os.path.join(path,\"checkpoint.hdf5\")\n",
    "\n",
    "df_train = pd.read_csv(filename_train,na_values=['NA','?'])\n",
    "\n",
    "np.random.seed(42) # Uncomment this line to get the same shuffle each time\n",
    "df_train = df_train.reindex(np.random.permutation(df_train.index))\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Encode Features\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def extract_and_encode_features(df):\n",
    "    color_regex='(?P<color>red|blue|green|yellow|orange|pink|black|brown|white)'\n",
    "    df['color'] = df.name.str.extract(color_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    quality_regex='(?P<quality>generic|high\\squality)'\n",
    "    df['quality'] = df.name.str.extract(quality_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    size_regex='(?P<size>tiny|small|medium|large)'\n",
    "    df['size'] = df.name.str.extract(size_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    item_regex='(?P<item>paperclips|paperweights|ink\\spens|pencils|stapler|tablets|thumbtacks|post\\sit\\snotes)'\n",
    "    df['item'] = df.name.str.extract(item_regex, flags=re.IGNORECASE, expand=False)\n",
    "    \n",
    "    for column in ['pack','weight','height','width','length']:\n",
    "        missing_median(df,column)\n",
    "    \n",
    "    #df.insert(1,'surface_area',(df['height']*df['width']*df['length']).astype(int))\n",
    "    \n",
    "    ## encode numeric features\n",
    "    #for column in ['pack','weight','height','width','length','surface_area']:\n",
    "    #    encode_numeric_zscore(df,column)\n",
    "\n",
    "    # encode text/categorical features\n",
    "    for column in ['manufacturer','color','quality','size','item']:\n",
    "        encode_text_dummy(df,column)\n",
    "  \n",
    "extract_and_encode_features(df_train)\n",
    "\n",
    "ids_train = df_train['id']\n",
    "df_train.drop('id',1,inplace=True)\n",
    "\n",
    "names_train = df_train['name']\n",
    "df_train.drop('name',1,inplace=True)\n",
    "\n",
    "x,y = to_xy(df_train,'cost')\n",
    "\n",
    "# Used before KFold\n",
    "#x_train, x_test, y_train, y_test = train_test_split(    \n",
    "#    x, y, test_size=0.25, random_state=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to evaluate the coefficients of a regression\n",
    "%matplotlib inline    \n",
    "from IPython.display import display, HTML    \n",
    "\n",
    "def report_coef(names,coef,intercept):\n",
    "    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n",
    "    r = r.sort_values(by=['coef'])\n",
    "    display(r)\n",
    "    print(\"Intercept: {}\".format(intercept))\n",
    "    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))\n",
    "    \n",
    "# Create linear regression\n",
    "regressor = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# Fit/train linear regression\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "print(names)\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_[0,:],\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Lasso(random_state=0,alpha=0.01)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lasso = Lasso(random_state=42)\n",
    "alphas = np.logspace(-8, 8, 10)\n",
    "\n",
    "scores = list()\n",
    "scores_std = list()\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.alpha = alpha\n",
    "    this_scores = cross_val_score(lasso, x, y, cv=n_folds, n_jobs=1)\n",
    "    scores.append(np.mean(this_scores))\n",
    "    scores_std.append(np.std(this_scores))\n",
    "\n",
    "scores, scores_std = np.array(scores), np.array(scores_std)\n",
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Ridge(alpha=1)\n",
    "\n",
    "# Fit/train Ridge\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_[0,:],\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create linear regression\n",
    "regressor = ElasticNet(alpha=0.01, l1_ratio=0.1)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 151us/step - loss: 5542.4198 - val_loss: 4699.7373\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 5151.3610 - val_loss: 3855.0095\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 4701.0312 - val_loss: 3762.5239\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 4443.5086 - val_loss: 3803.5507\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 4377.9454 - val_loss: 3614.9407\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 4275.7371 - val_loss: 3611.1970\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 4232.6299 - val_loss: 3482.9041\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 4101.5485 - val_loss: 3390.3751\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 4086.4589 - val_loss: 3455.0069\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 3904.9285 - val_loss: 3500.1216\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 3873.4027 - val_loss: 4502.1838\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 3790.3402 - val_loss: 3102.0748\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 3373.7983 - val_loss: 2707.8933\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 3143.2016 - val_loss: 2438.6341\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 2594.5143 - val_loss: 1690.8986\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 2226.5526 - val_loss: 1646.9524\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 2055.5297 - val_loss: 1595.0831\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 1383.2519 - val_loss: 1291.6952\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 1328.3227 - val_loss: 929.6546\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 1070.5320 - val_loss: 1000.1394\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 911.7113 - val_loss: 506.7644\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 804.5719 - val_loss: 651.2614\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 805.3376 - val_loss: 797.4109\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 728.7180 - val_loss: 491.0305\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 676.5410 - val_loss: 504.9297\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 903.4995 - val_loss: 578.6704\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 618.1108 - val_loss: 466.1258\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 616.0134 - val_loss: 400.0933\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 726.2456 - val_loss: 488.0793\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 645.2943 - val_loss: 535.0402\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 581.1338 - val_loss: 407.6775\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 597.2255 - val_loss: 414.8331\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 542.2371 - val_loss: 409.1834\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 800.3157 - val_loss: 453.4083\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 510.7704 - val_loss: 346.5461\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 516.0758 - val_loss: 972.9354\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 643.6668 - val_loss: 370.9028\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 599.5605 - val_loss: 354.4009\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 489.1742 - val_loss: 366.5559\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 456.2228 - val_loss: 378.6966\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 709.3652 - val_loss: 340.7187\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 471.5637 - val_loss: 325.6254\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 536.5581 - val_loss: 521.4214\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 452.9260 - val_loss: 289.1027\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 518.4754 - val_loss: 306.0565\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 493.8064 - val_loss: 402.6915\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 436.5618 - val_loss: 440.6344\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 444.9466 - val_loss: 390.8351\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 474.0120 - val_loss: 391.8509\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 503.3673 - val_loss: 318.5883\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 418.2360 - val_loss: 265.5223\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 375.8125 - val_loss: 555.2139\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 560.8285 - val_loss: 635.7587\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 400.6972 - val_loss: 307.8245\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 342.7730 - val_loss: 289.8920\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 474.3061 - val_loss: 354.9972\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 397.4253 - val_loss: 399.4485\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 459.9289 - val_loss: 764.5283\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 421.2414 - val_loss: 322.6290\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 444.7072 - val_loss: 603.1506\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 512.4307 - val_loss: 601.5619\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 378.3933 - val_loss: 276.8373\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 358.1083 - val_loss: 299.3057\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 365.0061 - val_loss: 292.6019\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 358.7906 - val_loss: 319.7260\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 412.4905 - val_loss: 307.5901\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 427.3934 - val_loss: 435.8943\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 325.1032 - val_loss: 287.6487\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 315.2870 - val_loss: 303.0179\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 597.5217 - val_loss: 297.8441\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 334.2336 - val_loss: 331.2068\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 384.3878 - val_loss: 323.2625\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 348.8228 - val_loss: 354.3776\n",
      "Epoch 74/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 346.6398 - val_loss: 475.7433\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 481.2379 - val_loss: 271.4594\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 328.4434 - val_loss: 253.5800\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 423.7274 - val_loss: 609.1757\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 323.5319 - val_loss: 815.4265\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 362.3962 - val_loss: 248.6740\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 361.0229 - val_loss: 275.9653\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 365.9872 - val_loss: 265.9604\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 333.8603 - val_loss: 363.1123\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 293.3607 - val_loss: 375.1121\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 310.5522 - val_loss: 273.6806\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 294.326 - 0s 57us/step - loss: 301.2305 - val_loss: 247.3444\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 354.7993 - val_loss: 268.0605\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 334.0720 - val_loss: 778.5150\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 342.0948 - val_loss: 229.0533\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 357.6238 - val_loss: 2271.8241\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 331.9224 - val_loss: 225.0633\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 324.5675 - val_loss: 354.5111\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 444.8849 - val_loss: 417.4063\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 258.5030 - val_loss: 391.6698\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 297.6450 - val_loss: 450.4646\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 272.8736 - val_loss: 242.4303\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 336.3667 - val_loss: 209.9792\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 294.9967 - val_loss: 241.4610\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 369.5718 - val_loss: 229.1777\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 269.7907 - val_loss: 218.7297\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 470.4141 - val_loss: 688.5496\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 460.9412 - val_loss: 719.6934\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 320.2728 - val_loss: 384.4276\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 266.4714 - val_loss: 213.7782\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 315.2315 - val_loss: 223.3197\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 269.1043 - val_loss: 210.6654\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 429.0849 - val_loss: 483.5333\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 262.5922 - val_loss: 234.2208\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 309.3356 - val_loss: 215.9509\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 255.1873 - val_loss: 197.8778\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 275.3037 - val_loss: 453.6570\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 297.8985 - val_loss: 241.9696\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 373.2750 - val_loss: 245.0671\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 403.7129 - val_loss: 243.0777\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 289.3056 - val_loss: 191.8080\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 240.7370 - val_loss: 195.8825\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 283.0901 - val_loss: 263.5895\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 350.4154 - val_loss: 369.8622\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 310.6725 - val_loss: 203.8184\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 267.2168 - val_loss: 218.9347\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 269.2022 - val_loss: 201.7554\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.1570 - val_loss: 280.1983\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 287.5997 - val_loss: 185.4507\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 249.4258 - val_loss: 217.1662\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 289.0378 - val_loss: 253.7708\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 320.9724 - val_loss: 244.2054\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 343.5666 - val_loss: 273.0205\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 351.0417 - val_loss: 214.8859\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 228.6483 - val_loss: 211.8123\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 239.5768 - val_loss: 259.4504\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 274.7515 - val_loss: 241.2249\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 267.1489 - val_loss: 293.1778\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 279.5234 - val_loss: 308.4805\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.2111 - val_loss: 806.5590\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 344.7985 - val_loss: 194.8338\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 266.3902 - val_loss: 198.4027\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.0215 - val_loss: 608.5900\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 530.5297 - val_loss: 353.0507\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 344.4351 - val_loss: 197.8993\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 226.6716 - val_loss: 243.7744\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 286.3501 - val_loss: 204.2471\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 312.5128 - val_loss: 751.6071\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 288.1680 - val_loss: 203.3748\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.4494 - val_loss: 210.9179\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 258.1678 - val_loss: 297.4708\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 241.2515 - val_loss: 184.6488\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 232.4669 - val_loss: 228.2661\n",
      "Epoch 147/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 430.9202 - val_loss: 388.7279\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 258.8731 - val_loss: 204.4665\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 317.5652 - val_loss: 184.5655\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 267.5885 - val_loss: 190.9828\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 225.3826 - val_loss: 197.6655\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 395.5725 - val_loss: 192.7583\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 227.9660 - val_loss: 220.8218\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 250.2709 - val_loss: 224.8644\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 296.1811 - val_loss: 215.6535\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 239.5428 - val_loss: 360.2416\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 540.2107 - val_loss: 210.8570\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.0183 - val_loss: 186.5033\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 260.3226 - val_loss: 216.0309\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 294.7252 - val_loss: 263.1719\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 283.3564 - val_loss: 306.0542\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 271.0431 - val_loss: 208.8708\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 259.8362 - val_loss: 432.5571\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.2972 - val_loss: 187.1242\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 368.6598 - val_loss: 205.1634\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.3396 - val_loss: 239.9343\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.3569 - val_loss: 206.2723\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.2935 - val_loss: 208.6769\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 438.1897 - val_loss: 328.9008\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 400.8133 - val_loss: 255.9992\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 265.7442 - val_loss: 205.1323\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.2811 - val_loss: 250.9649\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 309.2358 - val_loss: 187.8842\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.6513 - val_loss: 199.9595\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.2514 - val_loss: 231.8406\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 319.2721 - val_loss: 207.6963\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 216.3417 - val_loss: 260.7727\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 253.1675 - val_loss: 205.8088\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 299.3819 - val_loss: 289.2474\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 293.7367 - val_loss: 641.1848\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 329.6470 - val_loss: 192.0545\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 324.2675 - val_loss: 256.8257\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.9067 - val_loss: 299.4633\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 232.9590 - val_loss: 195.5608\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.6916 - val_loss: 226.1072\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 262.1978 - val_loss: 283.6711\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 323.4523 - val_loss: 211.3515\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.7361 - val_loss: 255.1447\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.2910 - val_loss: 234.7328\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 200.9700 - val_loss: 181.5813\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 368.7120 - val_loss: 384.1539\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 241.8418 - val_loss: 170.3623\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 267.4244 - val_loss: 183.3248\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 236.6922 - val_loss: 192.9271\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 263.3506 - val_loss: 174.6241\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 306.7955 - val_loss: 254.5575\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.4306 - val_loss: 185.1453\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 220.8478 - val_loss: 190.0995\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 210.7575 - val_loss: 209.5055\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 276.0602 - val_loss: 316.9318\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 247.2015 - val_loss: 220.9308\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 222.8032 - val_loss: 286.9686\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.4767 - val_loss: 490.1014\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 339.7401 - val_loss: 173.8048\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.0265 - val_loss: 256.0594\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 214.6551 - val_loss: 163.6824\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 240.0707 - val_loss: 385.2157\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.8267 - val_loss: 310.5979\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 375.6050 - val_loss: 240.0062\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.9417 - val_loss: 194.7803\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.5545 - val_loss: 237.0740\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 243.9165 - val_loss: 241.3417\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 367.6623 - val_loss: 203.3929\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 250.6670 - val_loss: 192.3410\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 246.9814 - val_loss: 1076.7216\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.0966 - val_loss: 278.9368\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 267.4528 - val_loss: 201.0217\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 206.4596 - val_loss: 172.2383\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 334.7772 - val_loss: 166.4351\n",
      "Epoch 220/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.3645 - val_loss: 591.3960\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 271.6010 - val_loss: 327.9612\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.0144 - val_loss: 203.5637\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.2353 - val_loss: 181.2845\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.0120 - val_loss: 166.4935\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.0705 - val_loss: 188.4116\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 233.4135 - val_loss: 250.8965\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 351.6262 - val_loss: 233.8412\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 339.4414 - val_loss: 180.2873\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.4225 - val_loss: 207.0544\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 280.9663 - val_loss: 386.4424\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 230.3338 - val_loss: 196.5228\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 216.2770 - val_loss: 169.7362\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.3054 - val_loss: 172.7072\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.6673 - val_loss: 164.0417\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.1695 - val_loss: 224.2080\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 946.9259 - val_loss: 344.3701\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 456.2984 - val_loss: 349.6640\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 330.0942 - val_loss: 199.0359\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 331.7329 - val_loss: 255.6535\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 253.6824 - val_loss: 250.8753\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 226.0834 - val_loss: 208.4439\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.2062 - val_loss: 181.8470\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 285.5514 - val_loss: 176.2490\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 209.0472 - val_loss: 233.8004\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 248.3226 - val_loss: 192.5922\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 229.6065 - val_loss: 296.5110\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 220.6816 - val_loss: 229.4938\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.6141 - val_loss: 208.4280\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 234.2794 - val_loss: 233.4016\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 233.9856 - val_loss: 176.9190\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.4547 - val_loss: 213.4633\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.8923 - val_loss: 195.7563\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.1638 - val_loss: 238.2978\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 205.2577 - val_loss: 212.6746\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 266.7605 - val_loss: 240.9253\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.0892 - val_loss: 184.4266\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.3869 - val_loss: 164.9503\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.1055 - val_loss: 173.9891\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.6011 - val_loss: 214.4628\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.5238 - val_loss: 222.3084\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 268.2058 - val_loss: 206.2285\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.9831 - val_loss: 296.2712\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 200.2333 - val_loss: 168.3459\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 282.7062 - val_loss: 189.5302\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 223.3852 - val_loss: 165.3786\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 190.8222 - val_loss: 166.5217\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 224.7224 - val_loss: 184.3971\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.6834 - val_loss: 204.6716\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.3190 - val_loss: 181.0520\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.4284 - val_loss: 181.6690\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.3232 - val_loss: 175.6639\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.9273 - val_loss: 180.5511\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.4162 - val_loss: 367.9306\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 245.3432 - val_loss: 323.8500\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.9943 - val_loss: 181.4587\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.8083 - val_loss: 225.9977\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5688 - val_loss: 175.6529\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.8933 - val_loss: 285.2544\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 281.3678 - val_loss: 447.1906\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 211.3001 - val_loss: 160.1150\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.0358 - val_loss: 188.4500\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.7027 - val_loss: 200.7416\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.9140 - val_loss: 181.6842\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.9084 - val_loss: 262.1695\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.7110 - val_loss: 166.1816\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 211.6903 - val_loss: 198.9356\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.3694 - val_loss: 189.1340\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.6055 - val_loss: 220.6224\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.0958 - val_loss: 231.3420\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 247.3951 - val_loss: 242.9146\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.0628 - val_loss: 170.9279\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.1619 - val_loss: 175.2275\n",
      "Epoch 293/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.9896 - val_loss: 180.6810\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 172.156 - 0s 51us/step - loss: 172.5917 - val_loss: 185.6810\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 253.0229 - val_loss: 219.2940\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.5356 - val_loss: 263.3913\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.7812 - val_loss: 255.0612\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.9733 - val_loss: 299.2057\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.8095 - val_loss: 182.4518\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.0270 - val_loss: 569.3970\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 198.5701 - val_loss: 361.9639\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.1526 - val_loss: 179.7666\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.9777 - val_loss: 172.2202\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.8999 - val_loss: 223.1753\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.3494 - val_loss: 156.7471\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 392.2278 - val_loss: 231.3578\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.3381 - val_loss: 167.3471\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.0807 - val_loss: 171.4816\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.9402 - val_loss: 179.2050\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.1746 - val_loss: 289.7769\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 225.1688 - val_loss: 158.0699\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.1659 - val_loss: 156.9251\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.6258 - val_loss: 354.2281\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.3502 - val_loss: 179.7843\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 246.5293 - val_loss: 256.2208\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.0246 - val_loss: 218.0918\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 186.3625 - val_loss: 154.7413\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 175.7485 - val_loss: 166.2245\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.1415 - val_loss: 174.6221\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 206.2969 - val_loss: 161.7043\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 177.7744 - val_loss: 169.5981\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 213.8609 - val_loss: 301.8592\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.7715 - val_loss: 157.2363\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2352 - val_loss: 192.0028\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4330 - val_loss: 463.7499\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.7706 - val_loss: 156.9478\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.4396 - val_loss: 162.2521\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.8276 - val_loss: 157.5485\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.9146 - val_loss: 176.1328\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.3973 - val_loss: 156.1827\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.9584 - val_loss: 861.4098\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.1461 - val_loss: 284.5776\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.3474 - val_loss: 190.4762\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 179.0407 - val_loss: 171.3945\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 202.6833 - val_loss: 158.6387\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 158.7760 - val_loss: 162.1147\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 193.3154 - val_loss: 166.4270\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 217.0004 - val_loss: 170.0525\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 180.6782 - val_loss: 152.2465\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.1961 - val_loss: 169.1853\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.0337 - val_loss: 214.8828\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.6988 - val_loss: 201.4291\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.3452 - val_loss: 151.6920\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.4407 - val_loss: 260.2248\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.0586 - val_loss: 177.3631\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.7791 - val_loss: 170.8032\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.9796 - val_loss: 237.1334\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 276.1585 - val_loss: 257.5275\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.3673 - val_loss: 165.2422\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.3118 - val_loss: 229.8681\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2735 - val_loss: 178.8788\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.2800 - val_loss: 161.1178\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.8437 - val_loss: 180.2443\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5574 - val_loss: 284.5216\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.8530 - val_loss: 153.7481\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.1023 - val_loss: 161.7147\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.4695 - val_loss: 161.0796\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.7936 - val_loss: 273.0106\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.3298 - val_loss: 186.0857\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 255.8097 - val_loss: 168.2176\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1054 - val_loss: 230.2321\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.6303 - val_loss: 176.7763\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.3427 - val_loss: 172.3407\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.2053 - val_loss: 166.4069\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.5915 - val_loss: 159.5151\n",
      "Epoch 366/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.0879 - val_loss: 148.6591\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.9673 - val_loss: 278.5900\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.4485 - val_loss: 213.9288\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.2525 - val_loss: 190.7397\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2741 - val_loss: 192.9100\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.4484 - val_loss: 241.5457\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.2317 - val_loss: 204.3473\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.7535 - val_loss: 164.6335\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.9541 - val_loss: 168.2201\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.8189 - val_loss: 219.5660\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.8388 - val_loss: 159.0878\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.0404 - val_loss: 227.3297\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.9113 - val_loss: 160.9045\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8613 - val_loss: 171.0932\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 504.1494 - val_loss: 199.5746\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.0484 - val_loss: 233.7077\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.2861 - val_loss: 177.1426\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.6010 - val_loss: 156.2260\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.6063 - val_loss: 219.0959\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4593 - val_loss: 224.7605\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.6402 - val_loss: 224.0476\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.8611 - val_loss: 416.3666\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.8652 - val_loss: 173.6781\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2592 - val_loss: 210.2912\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.5002 - val_loss: 163.6706\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.1376 - val_loss: 164.0597\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.0247 - val_loss: 157.7915\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.3729 - val_loss: 156.0375\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.1419 - val_loss: 152.1529\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.1960 - val_loss: 163.5203\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.0636 - val_loss: 146.1029\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.5205 - val_loss: 458.2104\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.4183 - val_loss: 156.7574\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0008 - val_loss: 148.1275\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.4387 - val_loss: 160.9764\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.5324 - val_loss: 216.2142\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.6653 - val_loss: 160.9892\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3717 - val_loss: 171.6612\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.5151 - val_loss: 394.7420\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.4580 - val_loss: 149.9312\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 245.7556 - val_loss: 299.3761\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 304.5821 - val_loss: 223.8256\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 196.3863 - val_loss: 195.6082\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 161.6782 - val_loss: 162.6550\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.6659 - val_loss: 161.7507\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.6557 - val_loss: 224.0449\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.4102 - val_loss: 153.3231\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.7615 - val_loss: 197.5669\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4231 - val_loss: 179.5535\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0932 - val_loss: 157.0977\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.2366 - val_loss: 166.3098\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.7299 - val_loss: 153.3621\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.8673 - val_loss: 276.8286\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.6320 - val_loss: 152.1410\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7877 - val_loss: 153.9585\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.7141 - val_loss: 311.5525\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 271.5963 - val_loss: 218.8284\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.4136 - val_loss: 161.5557\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.1753 - val_loss: 178.8973\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.4135 - val_loss: 157.4792\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.8820 - val_loss: 155.4109\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.2897 - val_loss: 172.7982\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 207.0154 - val_loss: 182.6057\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.2922 - val_loss: 155.9588\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.1665 - val_loss: 422.3700\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.2225 - val_loss: 172.9313\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.4605 - val_loss: 257.4789\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 561.3419 - val_loss: 551.8847\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.4604 - val_loss: 167.3300\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 202.6821 - val_loss: 241.6845\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.0410 - val_loss: 188.4950\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4007 - val_loss: 190.4795\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.6191 - val_loss: 149.2099\n",
      "Epoch 439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.6316 - val_loss: 151.7667\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.2491 - val_loss: 162.1544\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.8406 - val_loss: 218.2946\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.2201 - val_loss: 163.1119\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.6964 - val_loss: 210.5392\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.8083 - val_loss: 220.5623\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.3300 - val_loss: 180.5514\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.8028 - val_loss: 146.9742\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9987 - val_loss: 231.0121\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.8510 - val_loss: 163.6947\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.2351 - val_loss: 152.0527\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.3197 - val_loss: 151.2185\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.9377 - val_loss: 153.0882\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.6525 - val_loss: 147.5073\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.9461 - val_loss: 169.4116\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 346.6260 - val_loss: 183.6543\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2827 - val_loss: 153.7884\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.0902 - val_loss: 157.8352\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.5080 - val_loss: 162.0272\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.3357 - val_loss: 228.1861\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.5062 - val_loss: 163.5813\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6161 - val_loss: 181.0786\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.2121 - val_loss: 148.2640\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.6551 - val_loss: 154.2013\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1586 - val_loss: 165.3464\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2890 - val_loss: 177.4584\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.2557 - val_loss: 155.6173\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 232.415 - 0s 51us/step - loss: 232.7017 - val_loss: 192.8259\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2258 - val_loss: 165.9124\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.1323 - val_loss: 156.0697\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.2101 - val_loss: 147.3642\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.1060 - val_loss: 157.0469\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 203.0007 - val_loss: 162.4099\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 187.4020 - val_loss: 352.6644\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.3268 - val_loss: 236.1233\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.8819 - val_loss: 313.2518\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.2561 - val_loss: 185.3949\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 443.1422 - val_loss: 310.4934\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 357.4889 - val_loss: 234.6227\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 272.0108 - val_loss: 194.8736\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 229.0339 - val_loss: 181.8847\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 218.8689 - val_loss: 168.8324\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.5755 - val_loss: 210.1179\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.9409 - val_loss: 158.8870\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 343.0038 - val_loss: 197.3859\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.3712 - val_loss: 236.4695\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.9677 - val_loss: 200.7844\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.6006 - val_loss: 192.5142\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.3205 - val_loss: 183.7551\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 202.617 - 0s 50us/step - loss: 203.9891 - val_loss: 181.6208\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 224.2133 - val_loss: 200.3690\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.2100 - val_loss: 158.4652\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.3744 - val_loss: 185.8702\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.7708 - val_loss: 167.8063\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.3897 - val_loss: 165.4022\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7264 - val_loss: 150.8676\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.9534 - val_loss: 236.8874\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 192.9284 - val_loss: 207.9279\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 177.0910 - val_loss: 167.7547\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 168.0047 - val_loss: 192.3755\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 185.1831 - val_loss: 149.4166\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 498.6810 - val_loss: 159.4855\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.6776 - val_loss: 198.1391\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.7396 - val_loss: 151.1926\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.9560 - val_loss: 220.6733\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.9283 - val_loss: 156.9043\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5680 - val_loss: 163.2779\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 171.2164 - val_loss: 156.3191\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.6989 - val_loss: 431.7325\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.1792 - val_loss: 173.7101\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 204.3994 - val_loss: 148.6831\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 167.4402 - val_loss: 152.9053\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 187.8208 - val_loss: 234.5245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5543 - val_loss: 148.1973\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.2038 - val_loss: 558.2176\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.8934 - val_loss: 159.0103\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.8936 - val_loss: 207.1843\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.1444 - val_loss: 176.3829\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.1519 - val_loss: 162.4772\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.4681 - val_loss: 159.3564\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.6097 - val_loss: 186.0617\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 196.2664 - val_loss: 156.5641\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.4337 - val_loss: 152.2126\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5151 - val_loss: 152.9001\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.4753 - val_loss: 174.5222\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.9843 - val_loss: 162.7354\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 273.1281 - val_loss: 151.6329\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.8141 - val_loss: 212.8350\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.2736 - val_loss: 272.1349\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.5156 - val_loss: 153.2767\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.0989 - val_loss: 155.8065\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 194.6760 - val_loss: 146.0976\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.1468 - val_loss: 151.3513\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.0015 - val_loss: 233.3143\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.4896 - val_loss: 366.0498\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.5697 - val_loss: 150.1426\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.4902 - val_loss: 272.3908\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 193.9831 - val_loss: 146.8309\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 191.6134 - val_loss: 149.8539\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3872 - val_loss: 165.4795\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.0104 - val_loss: 150.3458\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9861 - val_loss: 153.9187\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.3807 - val_loss: 150.5070\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.3317 - val_loss: 147.3817\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.6958 - val_loss: 154.4296\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.3955 - val_loss: 151.6453\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.9766 - val_loss: 211.1050\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.4119 - val_loss: 208.3148\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6547 - val_loss: 147.0517\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 241.3923 - val_loss: 249.1931\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0101 - val_loss: 171.0551\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.5450 - val_loss: 175.9294\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.1408 - val_loss: 186.6160\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.4468 - val_loss: 149.6649\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.5110 - val_loss: 223.4833\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.3642 - val_loss: 148.9250\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.1167 - val_loss: 147.5334\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9130 - val_loss: 243.0393\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.8240 - val_loss: 176.4729\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8779 - val_loss: 147.9719\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 171.4060 - val_loss: 249.0061\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 253.1204 - val_loss: 176.7389\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 158.6427 - val_loss: 210.3482\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.2126 - val_loss: 148.0802\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.9812 - val_loss: 162.9160\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.8932 - val_loss: 147.2172\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 145.5388 - val_loss: 146.4043\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.5264 - val_loss: 150.7904\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 174.0261 - val_loss: 207.5412\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.2512 - val_loss: 181.7744\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.6531 - val_loss: 172.1808\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 611.4960 - val_loss: 299.8190\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 319.8651 - val_loss: 315.4013\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 292.0144 - val_loss: 198.1052\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 233.9164 - val_loss: 197.9757\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 217.4944 - val_loss: 178.0422\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 270.1334 - val_loss: 177.3841\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.7190 - val_loss: 338.4849\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 266.7786 - val_loss: 175.7223\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.8084 - val_loss: 237.1482\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.2553 - val_loss: 212.5470\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.0029 - val_loss: 239.0543\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.0450 - val_loss: 165.4460\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.2467 - val_loss: 299.8787\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.4012 - val_loss: 233.7687\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.2856 - val_loss: 157.6507\n",
      "Epoch 585/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.0515 - val_loss: 149.0737\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.7881 - val_loss: 416.6851\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 355.5817 - val_loss: 178.2572\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 283.5470 - val_loss: 205.0567\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.0489 - val_loss: 237.4755\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 229.1617 - val_loss: 252.7168\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.1970 - val_loss: 174.2235\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7664 - val_loss: 156.3329\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 199.4522 - val_loss: 447.6988\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.0015 - val_loss: 269.1961\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.4181 - val_loss: 155.3463\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.2954 - val_loss: 182.3871\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 226.3183 - val_loss: 349.4435\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 205.8294 - val_loss: 159.7178\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.5788 - val_loss: 161.7444\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 352.8785 - val_loss: 270.4096TA: 0s - loss: 413\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 279.5792 - val_loss: 216.5748\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 246.5591 - val_loss: 200.3724\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 221.8403 - val_loss: 215.3800\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.1257 - val_loss: 238.0841\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.0940 - val_loss: 257.3496\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.5147 - val_loss: 178.8648\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.1106 - val_loss: 209.3242\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.9122 - val_loss: 224.4391\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 244.7488 - val_loss: 194.6274\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.8165 - val_loss: 181.9896\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.2096 - val_loss: 179.5258\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 209.7237 - val_loss: 194.2354\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.3858 - val_loss: 218.1911\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.5569 - val_loss: 212.8532\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 230.7154 - val_loss: 194.0426\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 199.3162 - val_loss: 183.5996\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.0620 - val_loss: 178.0601\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.7295 - val_loss: 171.9304\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.4776 - val_loss: 203.2403\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 227.0560 - val_loss: 216.6195\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 193.9507 - val_loss: 176.3582\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 219.3831 - val_loss: 190.1713\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 196.3570 - val_loss: 176.4528\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 193.6731 - val_loss: 166.7592\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.7468 - val_loss: 232.9426\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 198.832 - 0s 51us/step - loss: 197.5577 - val_loss: 162.0761\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.9366 - val_loss: 255.6724\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 203.3311 - val_loss: 281.1774\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.3545 - val_loss: 158.2206\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 211.3468 - val_loss: 229.1191\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 310.9215 - val_loss: 180.6511\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.1334 - val_loss: 176.3845\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.2281 - val_loss: 177.9743\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.7876 - val_loss: 254.3600\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.8736 - val_loss: 162.1649\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.0614 - val_loss: 189.4733\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.5570 - val_loss: 166.3970\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.4783 - val_loss: 198.6239\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.2858 - val_loss: 195.2987\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.3720 - val_loss: 189.2030\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.2589 - val_loss: 166.8955\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.0270 - val_loss: 199.6975\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 232.3265 - val_loss: 238.3650\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 166.0271 - val_loss: 202.7406\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.4090 - val_loss: 179.9626\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 243.7301 - val_loss: 200.9637\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.3119 - val_loss: 274.1199\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.2122 - val_loss: 170.2420\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.3533 - val_loss: 161.1063\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.8800 - val_loss: 303.1923\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.1572 - val_loss: 219.7132\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.3538 - val_loss: 232.5803\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.1676 - val_loss: 264.8513\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.9189 - val_loss: 306.7930\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 174.1099 - val_loss: 181.5350\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.9093 - val_loss: 162.3582\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 214.4291 - val_loss: 189.8256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.9850 - val_loss: 165.5721\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.9365 - val_loss: 185.1791\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.4915 - val_loss: 164.9024\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.3777 - val_loss: 166.6306\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.8655 - val_loss: 162.3072\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.8476 - val_loss: 205.5880\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.3300 - val_loss: 156.2501\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.0567 - val_loss: 265.8195\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.7149 - val_loss: 188.3790\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.4358 - val_loss: 249.9451\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.1658 - val_loss: 155.4089\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.5041 - val_loss: 164.0964\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.9949 - val_loss: 160.1125\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.5803 - val_loss: 179.9689\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9854 - val_loss: 156.9969\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.0616 - val_loss: 166.5769\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.3435 - val_loss: 156.9714\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.7103 - val_loss: 220.5932\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.9107 - val_loss: 187.5723\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.6407 - val_loss: 169.4834\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.7446 - val_loss: 168.9364\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.3204 - val_loss: 199.7336\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5700 - val_loss: 157.0481\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 212.7407 - val_loss: 181.1829\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.3487 - val_loss: 168.7556\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.9807 - val_loss: 169.9710\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.3465 - val_loss: 150.6673\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.3249 - val_loss: 163.2928\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4635 - val_loss: 172.1782\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.2767 - val_loss: 155.0028\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.8269 - val_loss: 178.9653\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.4671 - val_loss: 160.9502\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.1301 - val_loss: 277.3001\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 388.2178 - val_loss: 404.8621\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 296.1329 - val_loss: 167.5837\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 186.5662 - val_loss: 157.0612\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 171.1994 - val_loss: 177.9461\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 173.5475 - val_loss: 217.4093\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 181.4219 - val_loss: 173.4732\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.9020 - val_loss: 159.8132\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.0158 - val_loss: 168.6777\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.7416 - val_loss: 157.6387\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4517 - val_loss: 369.7569\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 223.1163 - val_loss: 184.0720\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.2990 - val_loss: 176.0539\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.0054 - val_loss: 470.4204\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.4167 - val_loss: 166.8678\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.7753 - val_loss: 155.2394\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.7567 - val_loss: 262.7500\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.3975 - val_loss: 165.1282\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.3722 - val_loss: 157.7661\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.5045 - val_loss: 173.2542\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 251.1376 - val_loss: 194.9204\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.3835 - val_loss: 199.0216\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.4226 - val_loss: 159.4204\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.1599 - val_loss: 309.4325\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3211 - val_loss: 155.2788\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.7984 - val_loss: 203.4021\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.6635 - val_loss: 384.6020\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.1052 - val_loss: 176.7525\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.5289 - val_loss: 189.0425\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 210.9538 - val_loss: 214.6549\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.7132 - val_loss: 163.8723\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.8473 - val_loss: 159.7931\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.9341 - val_loss: 177.2222\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.5864 - val_loss: 160.5539\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.9471 - val_loss: 351.1184\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.7086 - val_loss: 154.7369\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.4650 - val_loss: 194.0809\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.2750 - val_loss: 160.7120\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.3532 - val_loss: 157.7517\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.0812 - val_loss: 202.4951\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5181 - val_loss: 216.2405\n",
      "Epoch 731/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.5281 - val_loss: 156.3780\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.7988 - val_loss: 297.4446\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.8921 - val_loss: 174.2644\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.1028 - val_loss: 158.2888\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.5152 - val_loss: 165.4693\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 181.767 - 0s 51us/step - loss: 182.4560 - val_loss: 189.6106\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.0144 - val_loss: 238.6385\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7563 - val_loss: 209.1973\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 181.0069 - val_loss: 244.8380\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.4915 - val_loss: 158.3022\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.5062 - val_loss: 196.7618\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.4428 - val_loss: 640.8251\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 219.2180 - val_loss: 191.8207\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.0104 - val_loss: 161.2376\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.4505 - val_loss: 204.5163\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.8334 - val_loss: 154.6785\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.8104 - val_loss: 171.6698\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0900 - val_loss: 150.2737\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.6050 - val_loss: 190.4743\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.5048 - val_loss: 166.4790\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.6293 - val_loss: 224.8314\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.8168 - val_loss: 169.0813\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.6316 - val_loss: 207.5413\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.0295 - val_loss: 190.9946\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.0564 - val_loss: 171.1264\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.1400 - val_loss: 164.0976\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.1685 - val_loss: 148.7160\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6060 - val_loss: 154.7277\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1838 - val_loss: 162.2171\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.0035 - val_loss: 177.4297\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.1598 - val_loss: 202.5037\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 249.9232 - val_loss: 157.7107\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.1149 - val_loss: 191.7881\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.2300 - val_loss: 209.7758\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 182.4301 - val_loss: 147.9194\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 168.5024 - val_loss: 148.9395\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 173.5134 - val_loss: 154.2578\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 179.1116 - val_loss: 209.0395\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.3410 - val_loss: 149.4246\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.3736 - val_loss: 150.4714\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.2446 - val_loss: 210.5208\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6952 - val_loss: 217.2374\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6611 - val_loss: 187.3753\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.4358 - val_loss: 182.3233\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.7799 - val_loss: 179.5140\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2266 - val_loss: 185.5450\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.1099 - val_loss: 148.6964\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.7493 - val_loss: 156.8307\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.1203 - val_loss: 251.0670\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.2612 - val_loss: 180.5076\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.2300 - val_loss: 152.3761\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4949 - val_loss: 187.4829\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.5065 - val_loss: 180.2484\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.8838 - val_loss: 152.0371\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.5930 - val_loss: 193.5010\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4343 - val_loss: 150.7273\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.2783 - val_loss: 209.3953\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.9560 - val_loss: 185.0991\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.3493 - val_loss: 152.5264\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.5917 - val_loss: 155.5627\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.8270 - val_loss: 207.3328\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.7079 - val_loss: 166.9856\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.9892 - val_loss: 179.2806\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 166.9978 - val_loss: 163.5100\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 197.4364 - val_loss: 225.9440\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.0484 - val_loss: 492.4320\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.8918 - val_loss: 155.7541\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1741 - val_loss: 154.3794\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8593 - val_loss: 154.6590\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.9260 - val_loss: 154.6769\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.3951 - val_loss: 174.4350\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 176.4966 - val_loss: 151.9763\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.2323 - val_loss: 199.7522\n",
      "Epoch 804/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.7605 - val_loss: 242.0930\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.0865 - val_loss: 154.6504\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.9850 - val_loss: 159.9198\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4897 - val_loss: 222.6605\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 410.6561 - val_loss: 177.9926\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.9321 - val_loss: 167.0347\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2006 - val_loss: 251.0763\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.9988 - val_loss: 223.8763\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4614 - val_loss: 162.8033\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.8885 - val_loss: 336.1328\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.3670 - val_loss: 306.8699\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.1854 - val_loss: 154.0632\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.3102 - val_loss: 314.9767\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.4889 - val_loss: 297.3139\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5792 - val_loss: 151.6718\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.6777 - val_loss: 174.9876\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.5625 - val_loss: 160.4270\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.5138 - val_loss: 214.2192\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6632 - val_loss: 155.4436\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3026 - val_loss: 154.1229\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.3911 - val_loss: 153.2535\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 164.3968 - val_loss: 159.1762\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3198 - val_loss: 156.7256\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.9401 - val_loss: 254.7558\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 206.2073 - val_loss: 314.4751\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.7162 - val_loss: 148.7172\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6182 - val_loss: 266.1477\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.6034 - val_loss: 198.9657\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6840 - val_loss: 164.5813\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.2444 - val_loss: 166.1051\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.9684 - val_loss: 160.7553\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.7144 - val_loss: 374.4788\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.7377 - val_loss: 151.8751\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 159.1004 - val_loss: 160.3732\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 172.0229 - val_loss: 151.1674\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 181.4316 - val_loss: 148.8874\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.9966 - val_loss: 207.0520\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.2176 - val_loss: 148.1539\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2149 - val_loss: 226.8452\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0110 - val_loss: 166.6025\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.2944 - val_loss: 228.3582\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 202.0777 - val_loss: 200.1113\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.2421 - val_loss: 178.7654\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.3246 - val_loss: 156.1505\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.8707 - val_loss: 339.1935\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.3144 - val_loss: 166.6922\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 219.079 - 0s 51us/step - loss: 216.8126 - val_loss: 190.2892\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7454 - val_loss: 156.3142\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.0619 - val_loss: 178.1784\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.2020 - val_loss: 165.0476\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1129 - val_loss: 256.7058\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.5412 - val_loss: 196.0898\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3939 - val_loss: 226.4908\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.2469 - val_loss: 180.8774\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5296 - val_loss: 287.3509\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.9204 - val_loss: 164.5498\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 285.9171 - val_loss: 410.4467\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.2802 - val_loss: 155.1663\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.6836 - val_loss: 200.4292\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.0158 - val_loss: 148.2912\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.8007 - val_loss: 177.5293\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.0430 - val_loss: 155.0380\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.1629 - val_loss: 150.1216\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.1920 - val_loss: 146.0711\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.3787 - val_loss: 179.8761\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.3858 - val_loss: 158.1112\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.2061 - val_loss: 314.3786\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.4864 - val_loss: 163.3799\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.3420 - val_loss: 153.8089\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.4368 - val_loss: 149.2100\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5434 - val_loss: 146.6020\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.4366 - val_loss: 153.9329\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8954 - val_loss: 175.5256\n",
      "Epoch 877/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1761 - val_loss: 153.0174\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.0912 - val_loss: 149.5604\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6878 - val_loss: 150.3464\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1300 - val_loss: 164.9574\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.0272 - val_loss: 164.2135\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8524 - val_loss: 158.3994\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5687 - val_loss: 313.9111\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.1097 - val_loss: 150.4977\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.4919 - val_loss: 184.4470\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 214.1912 - val_loss: 165.4130\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.3634 - val_loss: 157.7554\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.4627 - val_loss: 146.9592\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6172 - val_loss: 153.5163\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.6438 - val_loss: 184.3678\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.2901 - val_loss: 175.1653\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 212.1390 - val_loss: 163.7501\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.3949 - val_loss: 151.2285\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4104 - val_loss: 161.2346\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.3612 - val_loss: 250.2137\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.5745 - val_loss: 324.8695\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 267.8363 - val_loss: 153.6867\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.3242 - val_loss: 224.6905\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3556 - val_loss: 162.3678\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.3730 - val_loss: 157.8895\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.1272 - val_loss: 172.0541\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8382 - val_loss: 152.6937\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8223 - val_loss: 176.9566\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.0024 - val_loss: 163.7911\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.2847 - val_loss: 182.0152\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.0877 - val_loss: 168.0040\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.7724 - val_loss: 170.5215\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.8572 - val_loss: 231.8054\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 196.0437 - val_loss: 171.6301\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 170.6731 - val_loss: 167.3207\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 198.7332 - val_loss: 197.7334\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 172.7857 - val_loss: 231.1424\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.8183 - val_loss: 206.6163\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.3795 - val_loss: 150.0759\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7177 - val_loss: 147.6892\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1992 - val_loss: 162.9653\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.4770 - val_loss: 246.7522\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 211.6992 - val_loss: 366.1787\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.0641 - val_loss: 158.4203\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4442 - val_loss: 211.4770\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.9961 - val_loss: 209.9470\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.1148 - val_loss: 151.1283\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.8102 - val_loss: 158.0743\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.1528 - val_loss: 204.6238\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.9672 - val_loss: 147.8834\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8857 - val_loss: 157.5654\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.5851 - val_loss: 174.5702\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2955 - val_loss: 183.5366\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4289 - val_loss: 189.5901\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.8255 - val_loss: 173.2086\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6055 - val_loss: 151.8767\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6971 - val_loss: 245.4926\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8619 - val_loss: 147.7907\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.3908 - val_loss: 252.7936\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1549 - val_loss: 164.9480\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8210 - val_loss: 163.3575\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9814 - val_loss: 223.3644\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.0749 - val_loss: 182.0168\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 156.4049 - val_loss: 191.5005\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3560 - val_loss: 147.4691\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8272 - val_loss: 147.7582\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.8214 - val_loss: 270.9724\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.9870 - val_loss: 263.3416\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.4281 - val_loss: 179.8277\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.2503 - val_loss: 203.6140\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6536 - val_loss: 217.6005\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.8695 - val_loss: 153.6129\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.8962 - val_loss: 162.3483\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 220.1076 - val_loss: 193.0020\n",
      "Epoch 950/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.2633 - val_loss: 193.8816\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.9679 - val_loss: 181.1478\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.2815 - val_loss: 146.7124\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4632 - val_loss: 152.5866\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.0303 - val_loss: 146.9332\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9966 - val_loss: 152.6424\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.4932 - val_loss: 150.1672\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.5393 - val_loss: 169.6516\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6723 - val_loss: 298.6594\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.9853 - val_loss: 192.8905\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2015 - val_loss: 148.5648\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8230 - val_loss: 170.0880\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.6965 - val_loss: 188.9769\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.2142 - val_loss: 156.7764\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.9544 - val_loss: 142.8325\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.4778 - val_loss: 152.0621\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.0989 - val_loss: 227.6038\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.8512 - val_loss: 147.6322\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9522 - val_loss: 151.4615\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.0359 - val_loss: 158.1700\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9111 - val_loss: 161.4017\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.1163 - val_loss: 145.1513\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.7748 - val_loss: 170.0003\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.5120 - val_loss: 152.2853\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8416 - val_loss: 189.7178\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0931 - val_loss: 285.3699\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.6386 - val_loss: 156.5047\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.2451 - val_loss: 152.8132\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.1006 - val_loss: 147.9121\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.6909 - val_loss: 175.6045\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.8124 - val_loss: 144.2999\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.5698 - val_loss: 261.3906\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 158.2916 - val_loss: 149.4770\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 188.4511 - val_loss: 178.6635\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 176.4160 - val_loss: 151.6401\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.8464 - val_loss: 203.6566\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3785 - val_loss: 231.3333\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.5566 - val_loss: 172.0131\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.6195 - val_loss: 146.7822\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.2649 - val_loss: 150.9606\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.6148 - val_loss: 167.3099\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5911 - val_loss: 197.0013\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7276 - val_loss: 165.2160\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.5874 - val_loss: 178.2356\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6364 - val_loss: 180.8767\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.4501 - val_loss: 179.1007\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.4990 - val_loss: 157.1686\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.0413 - val_loss: 255.8619\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.7553 - val_loss: 153.9010\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.5253 - val_loss: 161.8723\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.0222 - val_loss: 197.2466\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4045 - val_loss: 193.6058\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.5452 - val_loss: 254.9569\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0303 - val_loss: 154.6099\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 282.9728 - val_loss: 178.5020\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.7517 - val_loss: 144.4894\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.3676 - val_loss: 150.8244\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2856 - val_loss: 171.5066\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.2960 - val_loss: 149.3945\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.9835 - val_loss: 163.8949\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.5646 - val_loss: 167.8347\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.9591 - val_loss: 254.7046\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2748 - val_loss: 278.1892\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.8721 - val_loss: 159.3837\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7088 - val_loss: 161.2547\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.8654 - val_loss: 149.5499\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.0828 - val_loss: 168.0419\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4131 - val_loss: 148.0968\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.1657 - val_loss: 143.7276\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.1367 - val_loss: 174.9031\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8273 - val_loss: 277.9750\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1080 - val_loss: 148.9185\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.4126 - val_loss: 167.3053\n",
      "Epoch 1023/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.5134 - val_loss: 229.8769\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.2805 - val_loss: 251.3355\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.5958 - val_loss: 149.5626\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.3667 - val_loss: 146.6827\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3713 - val_loss: 150.3016\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.2007 - val_loss: 286.4956\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1129 - val_loss: 195.5946\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.6937 - val_loss: 218.1891\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1947 - val_loss: 151.6433\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.6376 - val_loss: 167.6976\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.9618 - val_loss: 144.4649\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.1004 - val_loss: 152.5199\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4700 - val_loss: 144.7253\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.8879 - val_loss: 144.4384\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.4173 - val_loss: 151.1767\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.0220 - val_loss: 150.2316\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6639 - val_loss: 152.8822\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.7939 - val_loss: 164.6141\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1345 - val_loss: 201.7973\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.3512 - val_loss: 187.8341\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.6358 - val_loss: 255.3079\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.7032 - val_loss: 226.6234\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.5890 - val_loss: 156.8773\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.0132 - val_loss: 160.7301\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.9726 - val_loss: 169.7458\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.7273 - val_loss: 149.4599\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.2070 - val_loss: 145.5263\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.6116 - val_loss: 182.1362\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5864 - val_loss: 317.2668\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.7912 - val_loss: 191.9046\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.6733 - val_loss: 155.1888\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 163.5566 - val_loss: 167.7512\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 180.3320 - val_loss: 152.7575\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 145.5429 - val_loss: 171.4801\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 200.4266 - val_loss: 190.0666\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.0771 - val_loss: 230.0845\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6407 - val_loss: 156.8925\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.0719 - val_loss: 197.0404\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3359 - val_loss: 210.3471\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8460 - val_loss: 269.6400\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.7883 - val_loss: 391.8969\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.7373 - val_loss: 148.1023\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.4901 - val_loss: 156.3880\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.6860 - val_loss: 168.7852\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.4946 - val_loss: 285.4671\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9385 - val_loss: 143.0925\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.2762 - val_loss: 270.1937\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.3369 - val_loss: 196.8296\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8864 - val_loss: 161.8061\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.4110 - val_loss: 383.4706\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5882 - val_loss: 205.5451\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.6493 - val_loss: 148.6767\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.1906 - val_loss: 163.8877\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6866 - val_loss: 170.4811\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.0507 - val_loss: 173.2806\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.8538 - val_loss: 437.7212\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.7771 - val_loss: 162.5067\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7170 - val_loss: 148.4791\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.7905 - val_loss: 222.3807\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.7310 - val_loss: 165.4994\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 197.0474 - val_loss: 347.7089\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 344.5193 - val_loss: 380.8426\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 205.8364 - val_loss: 167.3417\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 174.5046 - val_loss: 149.3630\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.0034 - val_loss: 158.6105\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9843 - val_loss: 148.6552\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2404 - val_loss: 184.4479\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1683 - val_loss: 151.4747\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8524 - val_loss: 144.1935\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.5719 - val_loss: 182.8064\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.2604 - val_loss: 194.6441\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.0654 - val_loss: 177.5680\n",
      "Epoch 1095/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7760 - val_loss: 146.0454\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7491 - val_loss: 170.9433\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6920 - val_loss: 263.6654\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.8132 - val_loss: 156.4555\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.0642 - val_loss: 517.3795\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.8071 - val_loss: 159.7675\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3661 - val_loss: 274.5484\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.6157 - val_loss: 178.7609\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.4445 - val_loss: 152.4968\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.6542 - val_loss: 153.4175\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.4597 - val_loss: 146.1673\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.7664 - val_loss: 440.8499\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.4175 - val_loss: 173.8656\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.7656 - val_loss: 151.0621\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.5048 - val_loss: 144.8853\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.8545 - val_loss: 166.8598\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0647 - val_loss: 159.6469\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3208 - val_loss: 231.5278\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.9743 - val_loss: 166.5147\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5778 - val_loss: 234.4475\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.5923 - val_loss: 143.8849\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.7334 - val_loss: 160.2839\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1622 - val_loss: 222.4912\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.9087 - val_loss: 175.8325\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.2926 - val_loss: 185.7651\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.4436 - val_loss: 231.8867\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.0642 - val_loss: 464.2246\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.7918 - val_loss: 261.0530\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.4436 - val_loss: 325.5391\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2953 - val_loss: 152.8145\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.3737 - val_loss: 237.1724\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.5876 - val_loss: 161.4428\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 148.7385 - val_loss: 156.0845\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 173.4952 - val_loss: 162.6158\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 174.2710 - val_loss: 159.1688\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.9371 - val_loss: 191.5916\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.4898 - val_loss: 208.4709\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.7446 - val_loss: 152.1329\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.2506 - val_loss: 165.8303\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 150.6229 - val_loss: 152.8815\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 154.2596 - val_loss: 167.4808\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 155.2085 - val_loss: 204.6368\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 148.2126 - val_loss: 145.7835\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2858 - val_loss: 146.8552\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.6871 - val_loss: 311.7567\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.6548 - val_loss: 142.8721\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3367 - val_loss: 182.9970\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 179.9699 - val_loss: 226.2686\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.5913 - val_loss: 147.5715\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.7282 - val_loss: 188.6425\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.3756 - val_loss: 157.1962\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1988 - val_loss: 146.0923\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.6755 - val_loss: 151.9309\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.8515 - val_loss: 188.9090\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.6771 - val_loss: 158.2828\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.8246 - val_loss: 153.3907\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7266 - val_loss: 156.8317\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.0877 - val_loss: 145.6448\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9771 - val_loss: 162.2363\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5359 - val_loss: 151.6116\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.0826 - val_loss: 181.5543\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.4282 - val_loss: 176.8120\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.4148 - val_loss: 148.7266\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.8394 - val_loss: 172.8351\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0736 - val_loss: 145.6949\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.9042 - val_loss: 166.4337\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2444 - val_loss: 194.8748\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.0029 - val_loss: 148.6600\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.9205 - val_loss: 153.9772\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.9923 - val_loss: 153.5680\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7677 - val_loss: 271.4797\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.4466 - val_loss: 165.5014\n",
      "Epoch 1167/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.5158 - val_loss: 149.8438\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3791 - val_loss: 162.4978\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.3409 - val_loss: 170.0118\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 158.091 - 0s 51us/step - loss: 161.0862 - val_loss: 162.7687\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.9352 - val_loss: 142.5819\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1566 - val_loss: 151.2059\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.9640 - val_loss: 162.1342\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 208.2096 - val_loss: 152.2108\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.4402 - val_loss: 240.0179\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.8189 - val_loss: 161.5361\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.9546 - val_loss: 153.4346\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4853 - val_loss: 157.8634\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.7619 - val_loss: 171.0611\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 241.9445 - val_loss: 212.9837\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4601 - val_loss: 142.9872\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.6256 - val_loss: 148.8686\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.4285 - val_loss: 157.1015\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.3955 - val_loss: 296.6075\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.6724 - val_loss: 169.9406\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.7880 - val_loss: 143.4724\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.0333 - val_loss: 155.4555\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.7674 - val_loss: 191.3592\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.7426 - val_loss: 143.7988\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.2407 - val_loss: 146.1886\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.1244 - val_loss: 151.4730\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1346 - val_loss: 154.8717\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.8317 - val_loss: 204.7930\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.4212 - val_loss: 196.0198\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.4433 - val_loss: 216.5168\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1437 - val_loss: 154.3857\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6341 - val_loss: 152.1258\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1594 - val_loss: 149.4380\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 172.8310 - val_loss: 250.4802\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 199.1088 - val_loss: 186.9573\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 213.7304 - val_loss: 144.9918\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.8066 - val_loss: 151.5600\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2958 - val_loss: 176.2082\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.1035 - val_loss: 152.1097\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.8417 - val_loss: 192.6437\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.7059 - val_loss: 198.7296\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.2297 - val_loss: 142.3812\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5601 - val_loss: 152.6689\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3294 - val_loss: 150.0099\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9730 - val_loss: 154.2919\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.7986 - val_loss: 164.7825\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 180.7398 - val_loss: 157.8848\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 167.2424 - val_loss: 176.1674\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8137 - val_loss: 142.9558\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.3499 - val_loss: 185.9712\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1527 - val_loss: 153.7109\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.9927 - val_loss: 158.8355\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.4997 - val_loss: 147.6865\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9835 - val_loss: 157.1289\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8822 - val_loss: 148.8856\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.0554 - val_loss: 150.1938\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5679 - val_loss: 144.9764\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.2811 - val_loss: 213.7008\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0998 - val_loss: 146.4124\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3588 - val_loss: 144.7414\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6958 - val_loss: 197.1218\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.7478 - val_loss: 211.4828\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0405 - val_loss: 181.2382\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.5126 - val_loss: 163.7578\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2926 - val_loss: 177.3917\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.5492 - val_loss: 186.7565\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 172.7152 - val_loss: 152.2356\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7433 - val_loss: 187.7906\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9779 - val_loss: 147.0411\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.0963 - val_loss: 164.3482\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.5549 - val_loss: 203.3200\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9821 - val_loss: 154.2252\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7553 - val_loss: 176.8117\n",
      "Epoch 1239/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7799 - val_loss: 156.3445\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.7899 - val_loss: 156.6505\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.8918 - val_loss: 148.4565\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0782 - val_loss: 154.1036\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.4465 - val_loss: 144.8681\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1626 - val_loss: 151.9498\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.2460 - val_loss: 264.1195\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 269.0236 - val_loss: 276.0031\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.7298 - val_loss: 160.4024\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2938 - val_loss: 159.4835\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3331 - val_loss: 193.1530\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3396 - val_loss: 153.0571\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4438 - val_loss: 159.2142\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.7038 - val_loss: 155.3177\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.3430 - val_loss: 152.6129\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6214 - val_loss: 152.1867\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0515 - val_loss: 158.9281\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1129 - val_loss: 145.7953\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7905 - val_loss: 156.7058\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.7351 - val_loss: 147.4201\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.5427 - val_loss: 166.1847\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.0586 - val_loss: 173.4382\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.2157 - val_loss: 188.2543\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.1352 - val_loss: 142.6214\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 168.130 - 0s 51us/step - loss: 166.9930 - val_loss: 143.4602\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.2112 - val_loss: 492.2535\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.5500 - val_loss: 154.6721\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1062 - val_loss: 151.7567\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.7531 - val_loss: 148.4278\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.8682 - val_loss: 227.4732\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2649 - val_loss: 261.5960\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.0406 - val_loss: 154.9813\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.5128 - val_loss: 172.7799\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9126 - val_loss: 155.5157\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.0482 - val_loss: 145.8834\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.4738 - val_loss: 144.9663\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.3069 - val_loss: 245.4349\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 155.8492 - val_loss: 142.0835\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.0713 - val_loss: 144.4794\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.2538 - val_loss: 182.3920\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.4632 - val_loss: 165.9920\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 164.6725 - val_loss: 193.8816\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 150.9860 - val_loss: 160.8570\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 186.4743 - val_loss: 150.2023\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 156.3102 - val_loss: 172.0607\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.5734 - val_loss: 163.4810\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9324 - val_loss: 161.2072\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.8326 - val_loss: 164.3137\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.3233 - val_loss: 169.5366\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.2437 - val_loss: 148.8859\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.7678 - val_loss: 154.6113\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.0541 - val_loss: 159.7808\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.4938 - val_loss: 166.9218\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.1676 - val_loss: 160.0644\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4091 - val_loss: 154.6216\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.8023 - val_loss: 760.3167\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.7966 - val_loss: 150.1231\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.1030 - val_loss: 181.6500\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.6227 - val_loss: 170.0990\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 146.0583 - val_loss: 198.2292\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.3324 - val_loss: 313.5118\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.7846 - val_loss: 149.4722\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.8790 - val_loss: 144.0637\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.6430 - val_loss: 265.9260\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7032 - val_loss: 194.6496\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.9342 - val_loss: 150.9929\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.5118 - val_loss: 156.6948\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.8313 - val_loss: 141.3238\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5715 - val_loss: 162.6466\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4657 - val_loss: 188.2425\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3473 - val_loss: 146.8606\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.1654 - val_loss: 188.5124\n",
      "Epoch 1311/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1109 - val_loss: 168.6547\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.3922 - val_loss: 155.4691\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.2413 - val_loss: 154.5488\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.1153 - val_loss: 290.9480\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.1065 - val_loss: 148.5601\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.2788 - val_loss: 178.2659\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1399 - val_loss: 179.3818\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6154 - val_loss: 158.5597\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.4886 - val_loss: 225.3259\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.0891 - val_loss: 162.2737\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4157 - val_loss: 145.6747\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.7397 - val_loss: 168.5892\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.0650 - val_loss: 178.0734\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.2050 - val_loss: 151.4592\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0950 - val_loss: 162.9633\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3068 - val_loss: 215.0222\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8802 - val_loss: 168.0302\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8754 - val_loss: 150.8527\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0782 - val_loss: 160.1886\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.0985 - val_loss: 158.4316\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8319 - val_loss: 144.0807\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4008 - val_loss: 154.1231\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.9462 - val_loss: 151.4347\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.6149 - val_loss: 160.0991\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.1089 - val_loss: 147.5146\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.7660 - val_loss: 147.8848\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.4647 - val_loss: 163.9598\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.6290 - val_loss: 184.1104\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9426 - val_loss: 145.0369\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.9054 - val_loss: 161.8298\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.3096 - val_loss: 141.8590\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.1077 - val_loss: 201.6874\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 149.5471 - val_loss: 146.0233\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 165.8199 - val_loss: 143.5667\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.7725 - val_loss: 213.8548\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.2718 - val_loss: 202.1843\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.6192 - val_loss: 175.7860\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.1324 - val_loss: 159.3621\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6143 - val_loss: 153.3256\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.7559 - val_loss: 170.7409\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.0663 - val_loss: 232.7184\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3210 - val_loss: 153.2525\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6607 - val_loss: 214.7133\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.7262 - val_loss: 181.5969\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6514 - val_loss: 162.7508\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.0852 - val_loss: 143.9007\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1576 - val_loss: 148.7276\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.6650 - val_loss: 570.7467\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5521 - val_loss: 153.8348\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.2010 - val_loss: 140.7687\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.8867 - val_loss: 144.3156\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8297 - val_loss: 150.1439\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.4181 - val_loss: 148.7061\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0404 - val_loss: 140.7867\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.5517 - val_loss: 159.1248\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6062 - val_loss: 156.0948\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.5996 - val_loss: 218.8529\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0178 - val_loss: 146.3287\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.9257 - val_loss: 202.2678\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.5798 - val_loss: 148.1164\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.7652 - val_loss: 142.5879\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.7419 - val_loss: 158.4035\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1987 - val_loss: 159.8926\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.2536 - val_loss: 189.8667\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9022 - val_loss: 144.1666\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.2561 - val_loss: 152.1352\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.4851 - val_loss: 159.6203\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5801 - val_loss: 159.5942\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5073 - val_loss: 232.7778\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9855 - val_loss: 164.8834\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5763 - val_loss: 157.1025\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8726 - val_loss: 167.7013\n",
      "Epoch 1383/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.5918 - val_loss: 171.6514\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.3359 - val_loss: 139.3806\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6056 - val_loss: 149.8981\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.0250 - val_loss: 212.2990\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3432 - val_loss: 186.4388\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.6176 - val_loss: 149.0559\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.5513 - val_loss: 185.8272\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3968 - val_loss: 155.3521\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.3981 - val_loss: 264.7321\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8767 - val_loss: 142.9583\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 181.0050 - val_loss: 206.3805\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.3687 - val_loss: 151.5070\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5776 - val_loss: 148.7170\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8200 - val_loss: 152.8806\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.4873 - val_loss: 146.4115\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.0452 - val_loss: 154.6773\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 147.284 - 0s 50us/step - loss: 148.4606 - val_loss: 157.5213\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.0653 - val_loss: 177.3208\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.0649 - val_loss: 187.0652\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1859 - val_loss: 200.7556\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.8810 - val_loss: 155.6741\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7391 - val_loss: 198.8725\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.9307 - val_loss: 183.0822\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.5270 - val_loss: 150.5992\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.5015 - val_loss: 218.1309\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8764 - val_loss: 154.8000\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7906 - val_loss: 188.7052\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6136 - val_loss: 226.1855\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.7603 - val_loss: 145.6682\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3320 - val_loss: 156.5194\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.4321 - val_loss: 172.2732\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 155.7931 - val_loss: 137.6502\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 164.1932 - val_loss: 144.3637\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 162.5147 - val_loss: 248.2377\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 206.9645 - val_loss: 181.6502\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3393 - val_loss: 149.8049\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.8977 - val_loss: 148.2891\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1270 - val_loss: 172.1307\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.8593 - val_loss: 145.1499\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8932 - val_loss: 141.9957\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3705 - val_loss: 142.4763\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8191 - val_loss: 142.1610\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.0159 - val_loss: 148.1738\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9203 - val_loss: 141.4630\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.3643 - val_loss: 144.5781\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6990 - val_loss: 157.5475\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3413 - val_loss: 223.3050\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.8168 - val_loss: 153.6701\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5482 - val_loss: 145.2645\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8711 - val_loss: 190.5932\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.5698 - val_loss: 145.6574\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3672 - val_loss: 141.8234\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8625 - val_loss: 188.2050\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.0313 - val_loss: 335.5124\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6874 - val_loss: 139.9996\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1027 - val_loss: 161.5636\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2547 - val_loss: 143.3616\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3565 - val_loss: 218.3123\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.7976 - val_loss: 151.9197\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6016 - val_loss: 141.6055\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.9796 - val_loss: 152.4871\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.6419 - val_loss: 158.8611\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.2127 - val_loss: 446.1733\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.6529 - val_loss: 182.2930\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.0735 - val_loss: 149.1745\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.8178 - val_loss: 186.5000\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4150 - val_loss: 149.9560\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9105 - val_loss: 153.6298\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2568 - val_loss: 142.2259\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1374 - val_loss: 153.6234\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.0891 - val_loss: 177.8759\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1331 - val_loss: 140.9292\n",
      "Epoch 1455/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8223 - val_loss: 157.8833\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.8053 - val_loss: 151.8229\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9027 - val_loss: 148.8435\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2133 - val_loss: 220.6235\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.1993 - val_loss: 141.3948\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0537 - val_loss: 165.3659\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.3105 - val_loss: 148.2625\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9966 - val_loss: 145.3079\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2900 - val_loss: 156.8514\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.6531 - val_loss: 155.4492\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7938 - val_loss: 169.1407\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0332 - val_loss: 142.3139\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.4784 - val_loss: 162.3484\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.7900 - val_loss: 175.8245\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4650 - val_loss: 162.4608\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.7209 - val_loss: 156.4275\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6045 - val_loss: 266.9084\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.1439 - val_loss: 145.2555\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.3779 - val_loss: 139.7147\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.7727 - val_loss: 147.6167\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8028 - val_loss: 161.6228\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6505 - val_loss: 146.7819\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.9217 - val_loss: 158.3083\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7342 - val_loss: 141.8853\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7479 - val_loss: 144.4107\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8483 - val_loss: 155.2179\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0160 - val_loss: 142.2792\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.3801 - val_loss: 168.4090\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.9317 - val_loss: 149.8391\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.6558 - val_loss: 153.7365\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.4761 - val_loss: 199.3501\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6978 - val_loss: 146.3299\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.3283 - val_loss: 163.6427\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 146.3621 - val_loss: 189.6159\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 157.4017 - val_loss: 157.2042\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.6667 - val_loss: 211.4053\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.2776 - val_loss: 156.0803\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8231 - val_loss: 168.5886\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0141 - val_loss: 155.5043\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6471 - val_loss: 150.7765\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.9226 - val_loss: 141.5420\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1001 - val_loss: 253.4658\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.0527 - val_loss: 143.1092\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6068 - val_loss: 146.8567\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.4837 - val_loss: 143.7682\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.3738 - val_loss: 145.4493\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1371 - val_loss: 197.9229\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1312 - val_loss: 168.8400\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.3543 - val_loss: 179.3055\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0754 - val_loss: 156.3971\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4826 - val_loss: 268.4177\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4478 - val_loss: 140.3291\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.4983 - val_loss: 236.0783\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.3254 - val_loss: 166.8196\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1387 - val_loss: 153.0510\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1035 - val_loss: 139.7542\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6623 - val_loss: 148.9028\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.5860 - val_loss: 147.9182\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9268 - val_loss: 164.4534\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.6105 - val_loss: 141.6398\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1326 - val_loss: 152.0753\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1455 - val_loss: 166.1350\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 168.4563 - val_loss: 206.4895\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1614 - val_loss: 171.9830\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9073 - val_loss: 153.3356\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.4679 - val_loss: 168.0457\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2549 - val_loss: 179.1476\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7470 - val_loss: 150.3203\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.5413 - val_loss: 160.7946\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.3429 - val_loss: 212.7291\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 147.0265 - val_loss: 143.8987\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.4057 - val_loss: 151.3414\n",
      "Epoch 1527/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3548 - val_loss: 140.6365\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2744 - val_loss: 146.1524\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7243 - val_loss: 159.5462\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0297 - val_loss: 141.7835\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.6234 - val_loss: 156.1500\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.1457 - val_loss: 154.4050\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4031 - val_loss: 204.4216\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.1600 - val_loss: 172.6398\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3312 - val_loss: 166.1580\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.8837 - val_loss: 168.5756\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.7315 - val_loss: 152.4316\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2539 - val_loss: 189.2326\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9832 - val_loss: 151.8761\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.4561 - val_loss: 143.0916\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.0519 - val_loss: 232.9134\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.1347 - val_loss: 186.5996\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.1034 - val_loss: 179.6537\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.9872 - val_loss: 148.5791\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.2647 - val_loss: 158.3743\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1949 - val_loss: 155.8255\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2989 - val_loss: 148.3111\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1139 - val_loss: 153.2381\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9511 - val_loss: 152.0959\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6807 - val_loss: 158.7797\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7378 - val_loss: 236.1069\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1834 - val_loss: 283.3672\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.5578 - val_loss: 153.0066\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8850 - val_loss: 142.5993\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4435 - val_loss: 173.2665\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.1884 - val_loss: 181.1607\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.6362 - val_loss: 147.8670\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.2136 - val_loss: 140.9792\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.2439 - val_loss: 150.5197\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.7666 - val_loss: 334.1321\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 145.9045 - val_loss: 142.1145\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 138.3799 - val_loss: 157.4373\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2635 - val_loss: 204.6704\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9800 - val_loss: 140.1406\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9387 - val_loss: 156.3680\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.3184 - val_loss: 164.5177\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.0310 - val_loss: 137.8469\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.7182 - val_loss: 172.5599\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9625 - val_loss: 227.0271\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8045 - val_loss: 249.6781\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.7251 - val_loss: 148.9418\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6713 - val_loss: 141.3461\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7208 - val_loss: 143.2261\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.5359 - val_loss: 144.7129\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1571 - val_loss: 148.1291\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5132 - val_loss: 141.0168\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8923 - val_loss: 159.7279\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8307 - val_loss: 141.2251\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6193 - val_loss: 182.2975\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.3469 - val_loss: 222.5599\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9449 - val_loss: 181.6447\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1513 - val_loss: 155.3045\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 163.562 - 0s 51us/step - loss: 165.0222 - val_loss: 167.6138\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.6884 - val_loss: 178.2962\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.5161 - val_loss: 209.7404\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.7899 - val_loss: 146.1070\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8900 - val_loss: 158.6609\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4222 - val_loss: 167.2038\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.4889 - val_loss: 152.4959\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0448 - val_loss: 152.8022\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5529 - val_loss: 144.3965\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8158 - val_loss: 167.2812\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5371 - val_loss: 142.1029\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2731 - val_loss: 152.4667\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8445 - val_loss: 177.8462\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.6461 - val_loss: 142.8094\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4411 - val_loss: 156.9840\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1740 - val_loss: 181.2127\n",
      "Epoch 1599/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7036 - val_loss: 155.0508\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4979 - val_loss: 215.4047\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9846 - val_loss: 150.5109\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.7272 - val_loss: 240.0820\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.9692 - val_loss: 154.7038\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9558 - val_loss: 147.5074\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2817 - val_loss: 143.4425\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2297 - val_loss: 170.3823\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.8362 - val_loss: 138.6582\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1587 - val_loss: 218.6794\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.2234 - val_loss: 192.7945\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0390 - val_loss: 150.9476\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8644 - val_loss: 160.2035\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1546 - val_loss: 157.6536\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.2668 - val_loss: 146.4579\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4987 - val_loss: 208.8299\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0399 - val_loss: 141.7225\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2717 - val_loss: 160.5210\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0148 - val_loss: 170.6589\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2358 - val_loss: 156.1733\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.9210 - val_loss: 190.4072\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5290 - val_loss: 231.7252\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.2273 - val_loss: 177.6305\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.5664 - val_loss: 150.7790\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0451 - val_loss: 168.2175\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7566 - val_loss: 150.1680\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.3729 - val_loss: 163.2522\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.9858 - val_loss: 141.3847\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.4513 - val_loss: 145.3446\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6131 - val_loss: 151.4801\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6739 - val_loss: 147.9005\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2052 - val_loss: 171.2835\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.9865 - val_loss: 160.5686\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 163.0933 - val_loss: 173.6879\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 149.0571 - val_loss: 140.1436\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.7351 - val_loss: 207.7776\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 151.7137 - val_loss: 199.4304\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.3250 - val_loss: 155.8256\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8315 - val_loss: 247.6146\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.5612 - val_loss: 141.4426\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.9416 - val_loss: 141.1187\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.7330 - val_loss: 172.9547\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5508 - val_loss: 161.4596\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2891 - val_loss: 148.1329\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.0013 - val_loss: 150.2271\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.8114 - val_loss: 205.0125\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.3625 - val_loss: 136.5793\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4874 - val_loss: 144.0379\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5904 - val_loss: 250.1429\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2269 - val_loss: 155.9018\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6700 - val_loss: 151.9273\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5654 - val_loss: 224.0299\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.7348 - val_loss: 150.1895\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2774 - val_loss: 172.5663\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.1108 - val_loss: 177.6780\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 137.228 - 0s 51us/step - loss: 138.2619 - val_loss: 156.0189\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5427 - val_loss: 158.3965\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6765 - val_loss: 140.5737\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5105 - val_loss: 142.2878\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5196 - val_loss: 145.3098\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0618 - val_loss: 275.6028\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.5490 - val_loss: 148.3133\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.5204 - val_loss: 156.2472\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.7100 - val_loss: 179.5547\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1589 - val_loss: 178.9771\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.9502 - val_loss: 190.4087\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0698 - val_loss: 147.5274\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.4971 - val_loss: 147.9191\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.0484 - val_loss: 143.3522\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9759 - val_loss: 179.0483\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.7070 - val_loss: 145.1794\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1636 - val_loss: 149.6462\n",
      "Epoch 1671/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0566 - val_loss: 153.1890\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1338 - val_loss: 145.6599\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2579 - val_loss: 198.3566\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.8717 - val_loss: 168.6499\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5028 - val_loss: 195.1059\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.6400 - val_loss: 161.0145\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1393 - val_loss: 225.2919\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.9746 - val_loss: 160.5027\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.4999 - val_loss: 143.2331\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.4848 - val_loss: 150.6332\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 151.1832 - val_loss: 194.0540\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2972 - val_loss: 161.7550\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0759 - val_loss: 137.6003\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6916 - val_loss: 262.9642\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8270 - val_loss: 178.6813\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.2155 - val_loss: 143.7152\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.1307 - val_loss: 137.1268\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2764 - val_loss: 141.2180\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4078 - val_loss: 143.4786\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5379 - val_loss: 147.3111\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5303 - val_loss: 143.7972\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8619 - val_loss: 169.1339\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1056 - val_loss: 147.2848\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.8393 - val_loss: 139.0852\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8834 - val_loss: 251.8162\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.8689 - val_loss: 141.1784\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1336 - val_loss: 202.7905\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0200 - val_loss: 187.4117\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.5211 - val_loss: 203.5989\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3878 - val_loss: 144.9050\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.8732 - val_loss: 140.1434\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1262 - val_loss: 149.4286\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4390 - val_loss: 173.4246\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0085 - val_loss: 158.2264\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 143.8594 - val_loss: 141.0128\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 133.5847 - val_loss: 221.2395\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.3252 - val_loss: 148.1290\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4061 - val_loss: 147.6222\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8379 - val_loss: 170.8136\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6052 - val_loss: 140.7443\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.3077 - val_loss: 154.4763\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0970 - val_loss: 144.2377\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.6699 - val_loss: 168.0187\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.5506 - val_loss: 228.4709\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.6951 - val_loss: 143.8112\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4819 - val_loss: 140.4408\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8879 - val_loss: 148.2643\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.9540 - val_loss: 142.4941\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.0669 - val_loss: 172.0840\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.8322 - val_loss: 150.9320\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.9575 - val_loss: 330.0522\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 172.6936 - val_loss: 174.9694\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.6926 - val_loss: 148.3180\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9814 - val_loss: 147.5352\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5618 - val_loss: 142.7479\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7388 - val_loss: 145.1337\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4440 - val_loss: 144.0701\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8590 - val_loss: 211.6306\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3606 - val_loss: 139.6129\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7018 - val_loss: 147.5298\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.5886 - val_loss: 140.4039\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.6063 - val_loss: 138.3515\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.3111 - val_loss: 188.9501\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1198 - val_loss: 156.9935\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6366 - val_loss: 139.9751\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5525 - val_loss: 150.1735\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.6894 - val_loss: 188.4668\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6019 - val_loss: 241.3320\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3086 - val_loss: 205.3739\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3736 - val_loss: 170.8751\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 147.279 - 0s 51us/step - loss: 146.6335 - val_loss: 141.6632\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6466 - val_loss: 188.7313\n",
      "Epoch 1743/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.5225 - val_loss: 300.8203\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7446 - val_loss: 147.1197\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.4720 - val_loss: 139.4983\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2124 - val_loss: 243.9670\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.1543 - val_loss: 298.9875\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5519 - val_loss: 160.6133\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6028 - val_loss: 141.3172\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0251 - val_loss: 146.7271\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7543 - val_loss: 168.6104\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.6548 - val_loss: 229.2044\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.1096 - val_loss: 174.4091\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0649 - val_loss: 139.8236\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.1917 - val_loss: 138.4790\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.2681 - val_loss: 209.5233\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9972 - val_loss: 150.7685\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.5686 - val_loss: 136.5596\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1936 - val_loss: 190.2572\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.7478 - val_loss: 137.1574\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.1884 - val_loss: 162.0609\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4629 - val_loss: 161.3434\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 196.4937 - val_loss: 149.4895\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3549 - val_loss: 386.2045\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.9317 - val_loss: 180.6186\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.0923 - val_loss: 135.7265\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2473 - val_loss: 161.7778\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.3666 - val_loss: 139.3281\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.9328 - val_loss: 223.6228\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5633 - val_loss: 170.9454\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1380 - val_loss: 292.0454\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1701 - val_loss: 203.6925\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2579 - val_loss: 152.9865\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5924 - val_loss: 146.5437\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7217 - val_loss: 146.9952\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3376 - val_loss: 138.1928\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 188.5207 - val_loss: 213.5213\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 158.0517 - val_loss: 182.0025\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 158.6403 - val_loss: 151.3649\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.7702 - val_loss: 150.7353\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4495 - val_loss: 177.5960\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.9158 - val_loss: 176.1998\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4412 - val_loss: 233.9633\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.2963 - val_loss: 158.3640\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4122 - val_loss: 159.4116\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.8639 - val_loss: 144.8168\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.5290 - val_loss: 154.4919\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6305 - val_loss: 143.1147\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.2132 - val_loss: 155.3283\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 196.5893 - val_loss: 256.1499\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.2501 - val_loss: 151.6599\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.8833 - val_loss: 150.8534\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2473 - val_loss: 162.1552\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.7295 - val_loss: 162.5060\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8253 - val_loss: 189.2824\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.3790 - val_loss: 257.3227\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0029 - val_loss: 178.5009\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.4089 - val_loss: 159.2303\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0531 - val_loss: 197.1536\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8771 - val_loss: 250.0502\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.8237 - val_loss: 155.3243\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.6547 - val_loss: 180.3094\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3463 - val_loss: 138.8731\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2952 - val_loss: 147.8628\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8776 - val_loss: 215.3169\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 148.8561 - val_loss: 143.6211\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0776 - val_loss: 169.0017\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0669 - val_loss: 152.3289\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0818 - val_loss: 148.0026\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.4022 - val_loss: 138.0450\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5776 - val_loss: 148.2747\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7929 - val_loss: 136.9828\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2091 - val_loss: 144.0358\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.1635 - val_loss: 142.7790\n",
      "Epoch 1815/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2682 - val_loss: 149.0314\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9761 - val_loss: 145.9796\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4245 - val_loss: 140.2223\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8859 - val_loss: 196.9854\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.4828 - val_loss: 169.1615\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1469 - val_loss: 192.5809\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5501 - val_loss: 200.4264\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6603 - val_loss: 216.6619\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4653 - val_loss: 189.8730\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7280 - val_loss: 143.5295\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8489 - val_loss: 160.5500\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5177 - val_loss: 144.1679\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4570 - val_loss: 176.1728\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.6891 - val_loss: 134.6164\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4850 - val_loss: 195.9648\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4613 - val_loss: 153.7253\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7554 - val_loss: 154.5384\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.2326 - val_loss: 141.1783\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9893 - val_loss: 222.5807\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.7412 - val_loss: 184.9806\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2193 - val_loss: 136.0526\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5052 - val_loss: 142.3816\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.8204 - val_loss: 147.0205\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 166.1358 - val_loss: 213.6258\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8244 - val_loss: 273.4295\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5248 - val_loss: 145.3052\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4446 - val_loss: 146.1283\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.7675 - val_loss: 187.9347\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5946 - val_loss: 152.6901\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8271 - val_loss: 139.5981\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.7088 - val_loss: 148.2866\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3501 - val_loss: 146.9821\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4478 - val_loss: 173.1678\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9777 - val_loss: 166.4564\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.7315 - val_loss: 158.0805\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 148.7649 - val_loss: 148.4906\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 143.9059 - val_loss: 145.8096\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.3510 - val_loss: 138.2608\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0292 - val_loss: 141.1838\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0002 - val_loss: 179.1866\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2916 - val_loss: 146.4159\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3514 - val_loss: 163.0764\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.9982 - val_loss: 144.0821\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5701 - val_loss: 157.1629\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4695 - val_loss: 214.5859\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.3334 - val_loss: 158.2451\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.0610 - val_loss: 154.3047\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.4159 - val_loss: 151.7910\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.9219 - val_loss: 165.8798\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9897 - val_loss: 137.0779\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.8947 - val_loss: 167.7801\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.3682 - val_loss: 219.9790\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.8261 - val_loss: 143.4796\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2649 - val_loss: 212.3010\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5907 - val_loss: 149.2194\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.2924 - val_loss: 150.7308\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0350 - val_loss: 145.1341\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0110 - val_loss: 144.8594\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.0683 - val_loss: 175.1615\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 157.931 - 0s 51us/step - loss: 160.4947 - val_loss: 145.6214\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1964 - val_loss: 180.2440\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9949 - val_loss: 150.2099\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5588 - val_loss: 157.2430\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.8772 - val_loss: 140.2497\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.0124 - val_loss: 140.3253\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2619 - val_loss: 145.0574\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8512 - val_loss: 152.5742\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4055 - val_loss: 150.2659\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3764 - val_loss: 147.0821\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2201 - val_loss: 146.2844\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1270 - val_loss: 155.2589\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.2982 - val_loss: 160.7511\n",
      "Epoch 1887/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2357 - val_loss: 152.9241\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.0213 - val_loss: 138.9667\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0555 - val_loss: 140.2113\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.4350 - val_loss: 150.9070\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9236 - val_loss: 143.4808\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.7978 - val_loss: 152.1791\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4962 - val_loss: 151.1581\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7049 - val_loss: 193.0181\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7465 - val_loss: 136.4809\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0557 - val_loss: 352.4891\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 291.7717 - val_loss: 189.0883\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.8592 - val_loss: 223.5809\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3692 - val_loss: 166.6001\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.9897 - val_loss: 152.3080\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.5174 - val_loss: 166.7452\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.2950 - val_loss: 261.7449\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.3349 - val_loss: 172.9197\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0367 - val_loss: 176.3108\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1397 - val_loss: 194.9968\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4666 - val_loss: 148.6424\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.9477 - val_loss: 187.3608\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9240 - val_loss: 241.0957\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.8378 - val_loss: 147.8359\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.5382 - val_loss: 183.8521\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.8944 - val_loss: 168.8161\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3683 - val_loss: 153.2147\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6462 - val_loss: 187.1001\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2438 - val_loss: 150.2138\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.6730 - val_loss: 171.9488\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.8422 - val_loss: 139.3246\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2095 - val_loss: 177.9839\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1649 - val_loss: 150.5538\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8135 - val_loss: 175.6732\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.2376 - val_loss: 170.6388\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7706 - val_loss: 150.3922\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.0894 - val_loss: 155.2128\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 149.3613 - val_loss: 145.7712\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 153.4318 - val_loss: 179.0682\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 183.8158 - val_loss: 261.7501\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 158.651 - 0s 51us/step - loss: 157.0897 - val_loss: 159.1505\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5536 - val_loss: 150.3767\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2303 - val_loss: 166.9413\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1946 - val_loss: 140.6387\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.7789 - val_loss: 136.8537\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1355 - val_loss: 147.1800\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1798 - val_loss: 145.7885\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0133 - val_loss: 142.4373\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6506 - val_loss: 260.8674\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1458 - val_loss: 151.6595\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8389 - val_loss: 174.3130\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7083 - val_loss: 151.6346\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2162 - val_loss: 189.3489\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.9650 - val_loss: 293.1579\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.9554 - val_loss: 148.7879\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.2743 - val_loss: 154.6511\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6953 - val_loss: 140.3824\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.2734 - val_loss: 155.0659\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9431 - val_loss: 147.5876\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.4917 - val_loss: 353.6583\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3232 - val_loss: 143.2739\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.5067 - val_loss: 140.5147\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.0860 - val_loss: 185.4088\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9672 - val_loss: 138.9833\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1996 - val_loss: 190.8062\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.2678 - val_loss: 151.5604\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.2178 - val_loss: 148.3125\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5313 - val_loss: 144.8561\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.0972 - val_loss: 144.3265\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6910 - val_loss: 186.5717\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3223 - val_loss: 192.2284\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6653 - val_loss: 193.5245\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.2309 - val_loss: 184.2114\n",
      "Epoch 1959/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.3159 - val_loss: 149.8659\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1922 - val_loss: 138.6173\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1243 - val_loss: 143.4264\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6661 - val_loss: 142.7854\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 223.1828 - val_loss: 153.8593\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.8718 - val_loss: 152.7462\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.5738 - val_loss: 156.3168\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.6089 - val_loss: 165.8476\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9847 - val_loss: 142.6813\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4490 - val_loss: 148.6988\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5574 - val_loss: 210.1686\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 178.4130 - val_loss: 152.6475\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8934 - val_loss: 145.7106\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5958 - val_loss: 187.6105\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7343 - val_loss: 190.3556\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2230 - val_loss: 139.6583\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.7917 - val_loss: 139.0789\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8744 - val_loss: 173.7528\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1051 - val_loss: 151.4662\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5575 - val_loss: 228.3532\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3617 - val_loss: 275.6149\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6120 - val_loss: 142.8037\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2856 - val_loss: 214.0982\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4576 - val_loss: 190.7538\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9802 - val_loss: 165.2064\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.0986 - val_loss: 148.7140\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.6608 - val_loss: 296.1518\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.7053 - val_loss: 175.0069\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7443 - val_loss: 146.9435\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0412 - val_loss: 142.9511\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1173 - val_loss: 178.6241\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0522 - val_loss: 147.9093\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6350 - val_loss: 158.2382\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.9136 - val_loss: 157.6595\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6471 - val_loss: 140.6596\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2670 - val_loss: 162.9017\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4729 - val_loss: 144.1340\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6424 - val_loss: 194.1530\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3868 - val_loss: 164.7326\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4534 - val_loss: 178.3068\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5171 - val_loss: 209.8959\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6962 - val_loss: 149.5080\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0206 - val_loss: 166.3743\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1692 - val_loss: 140.9574\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9948 - val_loss: 137.2561\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2842 - val_loss: 210.9009\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.1448 - val_loss: 143.1421\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 144.8460 - val_loss: 151.0027\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.4406 - val_loss: 257.6588\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 158.0161 - val_loss: 152.2722\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8668 - val_loss: 144.4196\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7763 - val_loss: 173.9815\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.9809 - val_loss: 134.3297\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5123 - val_loss: 147.5725\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2239 - val_loss: 138.5586\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.7182 - val_loss: 149.0385\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6327 - val_loss: 241.9678\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3344 - val_loss: 143.5621\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1123 - val_loss: 156.6107\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.4316 - val_loss: 156.2147\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2657 - val_loss: 160.9705\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8570 - val_loss: 135.7761\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4614 - val_loss: 147.9154\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 143.309 - 0s 51us/step - loss: 142.6141 - val_loss: 149.7719\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0662 - val_loss: 179.0646\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.8630 - val_loss: 150.2620\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9650 - val_loss: 161.1897\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.5259 - val_loss: 143.4384\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5977 - val_loss: 150.9905\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3133 - val_loss: 234.5068\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.5707 - val_loss: 157.2953\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.1775 - val_loss: 141.2568\n",
      "Epoch 2031/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.5627 - val_loss: 177.7111\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2143 - val_loss: 142.8798\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1166 - val_loss: 136.1801\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9612 - val_loss: 170.3518\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4929 - val_loss: 142.4561\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3972 - val_loss: 155.7372\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6015 - val_loss: 192.6048\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6154 - val_loss: 143.0507\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4264 - val_loss: 172.2420\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.4659 - val_loss: 138.4172\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8396 - val_loss: 182.0622\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4992 - val_loss: 140.5493\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6487 - val_loss: 139.9139\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.5299 - val_loss: 151.8757\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1643 - val_loss: 142.0762\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7992 - val_loss: 138.2920\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8108 - val_loss: 155.6733\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.2311 - val_loss: 141.5820\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.1095 - val_loss: 185.0959\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4817 - val_loss: 141.8406\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.5584 - val_loss: 142.0507\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5201 - val_loss: 184.6801\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.0813 - val_loss: 146.0845\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5543 - val_loss: 174.0439\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3322 - val_loss: 277.2634\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0179 - val_loss: 138.5865\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4016 - val_loss: 141.6826\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4936 - val_loss: 143.7312\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9845 - val_loss: 159.0752\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3680 - val_loss: 277.7438\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.7958 - val_loss: 152.1922\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5319 - val_loss: 141.4582\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7020 - val_loss: 172.7800\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8996 - val_loss: 138.0725\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8480 - val_loss: 150.2614\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.0592 - val_loss: 172.1692\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.1884 - val_loss: 155.0058\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.6065 - val_loss: 156.4023\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 143.1602 - val_loss: 147.4177\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 153.4483 - val_loss: 141.3948\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.9904 - val_loss: 141.8138\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.7448 - val_loss: 140.2714\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5793 - val_loss: 139.5387\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8342 - val_loss: 184.2065\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8945 - val_loss: 137.7959\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3732 - val_loss: 147.3662\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8373 - val_loss: 147.2352\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7761 - val_loss: 215.4249\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.3370 - val_loss: 165.6738\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6356 - val_loss: 138.0292\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1215 - val_loss: 239.9589\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.3885 - val_loss: 192.8351\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6817 - val_loss: 175.6555\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4381 - val_loss: 136.2757\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.2026 - val_loss: 138.5926\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6242 - val_loss: 172.4281\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1228 - val_loss: 143.8163\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7931 - val_loss: 176.4285\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.7836 - val_loss: 188.6870\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9282 - val_loss: 166.3126\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7541 - val_loss: 138.2446\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.2382 - val_loss: 141.3636\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9591 - val_loss: 140.7979\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.4859 - val_loss: 191.3742\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4761 - val_loss: 134.5056\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8169 - val_loss: 168.1711\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7331 - val_loss: 137.5406\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.8814 - val_loss: 133.6548\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1218 - val_loss: 148.7479\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6312 - val_loss: 137.6414\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4795 - val_loss: 139.7662\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.5068 - val_loss: 261.8910\n",
      "Epoch 2103/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.2618 - val_loss: 143.1261\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7802 - val_loss: 148.8082\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5044 - val_loss: 145.1956\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0217 - val_loss: 151.9809\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.5961 - val_loss: 162.7650\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3853 - val_loss: 139.2360\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.2119 - val_loss: 149.7165\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.8916 - val_loss: 168.6397\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4505 - val_loss: 163.3703\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4701 - val_loss: 140.8498\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2009 - val_loss: 135.9606\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.4516 - val_loss: 144.4127\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3443 - val_loss: 231.2075\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.5884 - val_loss: 160.5200\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7344 - val_loss: 148.4611\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6339 - val_loss: 148.4816\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9179 - val_loss: 146.0757\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3811 - val_loss: 224.7957\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0466 - val_loss: 186.7414\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.2902 - val_loss: 155.9423\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.1827 - val_loss: 134.8118\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5735 - val_loss: 205.9319\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7542 - val_loss: 139.2281\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3197 - val_loss: 177.8439\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4651 - val_loss: 144.0923\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9977 - val_loss: 196.8494\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4377 - val_loss: 178.8664\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.7768 - val_loss: 190.2381\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.1994 - val_loss: 257.2161\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.2000 - val_loss: 150.1888\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.1510 - val_loss: 151.5457\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6362 - val_loss: 142.9621\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7852 - val_loss: 149.7529\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5637 - val_loss: 173.8538\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4152 - val_loss: 156.4876\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9207 - val_loss: 147.0529\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2654 - val_loss: 170.2870\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.5161 - val_loss: 142.6999\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 149.9772 - val_loss: 211.6294\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 153.6331 - val_loss: 142.4727\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.1251 - val_loss: 143.6739\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5476 - val_loss: 150.4929\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.5085 - val_loss: 148.5620\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1886 - val_loss: 140.1553\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4848 - val_loss: 186.8457\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.0164 - val_loss: 185.4867\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8063 - val_loss: 149.1620\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7838 - val_loss: 160.9739\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7312 - val_loss: 161.3812\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2890 - val_loss: 230.8861\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2060 - val_loss: 152.2787\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.6332 - val_loss: 172.6055\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9469 - val_loss: 202.6094\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.9113 - val_loss: 163.3761\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6128 - val_loss: 176.9320\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3900 - val_loss: 146.6928\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3722 - val_loss: 144.4119\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4290 - val_loss: 145.3644\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6634 - val_loss: 179.9366\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3032 - val_loss: 152.6110\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.1969 - val_loss: 150.3510\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8938 - val_loss: 140.1079\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4473 - val_loss: 154.2619\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2866 - val_loss: 177.3343\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.7579 - val_loss: 156.1632\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9220 - val_loss: 219.3854\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6796 - val_loss: 163.0342\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.2362 - val_loss: 148.4249\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7230 - val_loss: 172.7486\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4566 - val_loss: 145.9025\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6859 - val_loss: 161.3431\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3866 - val_loss: 151.2973\n",
      "Epoch 2175/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0981 - val_loss: 246.5181\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.0443 - val_loss: 189.8757\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1474 - val_loss: 172.4452\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1930 - val_loss: 149.6536\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6593 - val_loss: 135.6360\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1376 - val_loss: 155.2024\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7235 - val_loss: 136.9517\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1622 - val_loss: 176.4607\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5292 - val_loss: 221.5050\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3707 - val_loss: 141.1676\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.6344 - val_loss: 138.4638\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.7573 - val_loss: 181.8590\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7238 - val_loss: 318.0669\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7338 - val_loss: 202.3644\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8519 - val_loss: 176.6271\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8654 - val_loss: 142.5271\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4956 - val_loss: 140.6873\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3123 - val_loss: 137.4248\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6531 - val_loss: 177.5697\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7757 - val_loss: 143.1254\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.2390 - val_loss: 163.3862\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7600 - val_loss: 161.1337\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0616 - val_loss: 142.4445\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0272 - val_loss: 164.4718\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.3541 - val_loss: 141.7994\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.5995 - val_loss: 139.6070\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9151 - val_loss: 143.3965\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8119 - val_loss: 167.3953\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.2597 - val_loss: 150.4335\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0903 - val_loss: 140.5706\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.4767 - val_loss: 203.1039\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.8948 - val_loss: 146.5573\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8403 - val_loss: 149.4449\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1847 - val_loss: 147.0559\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2632 - val_loss: 174.8474\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7015 - val_loss: 154.0546\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7563 - val_loss: 145.8591\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1002 - val_loss: 154.0455\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 151.5045 - val_loss: 158.1530\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 161.2169 - val_loss: 140.0449\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 142.6598 - val_loss: 199.5934\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 148.1340 - val_loss: 134.3652\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8250 - val_loss: 140.0891\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.5753 - val_loss: 145.2329\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4029 - val_loss: 230.3767\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7499 - val_loss: 164.0262\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6038 - val_loss: 140.1881\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7611 - val_loss: 138.4701\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.6212 - val_loss: 169.5282\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7948 - val_loss: 187.9888\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.6028 - val_loss: 143.7810\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8956 - val_loss: 173.9783\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.3688 - val_loss: 233.3748\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8338 - val_loss: 142.3783\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3841 - val_loss: 138.1977\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6469 - val_loss: 184.8403\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2388 - val_loss: 152.5741\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1122 - val_loss: 173.2885\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5979 - val_loss: 137.8901\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8873 - val_loss: 187.8693\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.6470 - val_loss: 145.8061\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9741 - val_loss: 187.0645\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.8986 - val_loss: 142.4747\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.7092 - val_loss: 142.7485\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.4914 - val_loss: 157.9816\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3666 - val_loss: 138.8571\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.2035 - val_loss: 141.9134\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.3060 - val_loss: 138.9367\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.7234 - val_loss: 182.7541\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0290 - val_loss: 149.8784\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.0522 - val_loss: 151.3923\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.4617 - val_loss: 141.3362\n",
      "Epoch 2247/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7903 - val_loss: 140.9464\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.3784 - val_loss: 146.8692\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9006 - val_loss: 185.8157\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9215 - val_loss: 180.3662\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.7219 - val_loss: 139.8680\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.1597 - val_loss: 209.6540\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.2016 - val_loss: 133.2825\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6528 - val_loss: 174.0323\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9490 - val_loss: 201.7127\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4950 - val_loss: 149.8057\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8147 - val_loss: 147.8858\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 185.4041 - val_loss: 138.6033\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.3645 - val_loss: 140.4254\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.1115 - val_loss: 137.4944\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7855 - val_loss: 173.6531\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.4610 - val_loss: 164.8162\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.1407 - val_loss: 136.4694\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7647 - val_loss: 159.3415\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7493 - val_loss: 136.4343\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0366 - val_loss: 154.4555\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2050 - val_loss: 141.2558\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.6659 - val_loss: 142.9096\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3761 - val_loss: 157.6355\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.8448 - val_loss: 149.8427\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0678 - val_loss: 142.0956\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0848 - val_loss: 177.2386\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0921 - val_loss: 147.3704\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.0949 - val_loss: 166.6712\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6720 - val_loss: 139.1644\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 136.7259 - val_loss: 253.4522\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.9845 - val_loss: 167.0386\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5895 - val_loss: 146.7392\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8448 - val_loss: 151.6088\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0876 - val_loss: 146.6683\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.4751 - val_loss: 224.4347\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5046 - val_loss: 164.4821\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.9180 - val_loss: 201.8826\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6162 - val_loss: 158.2469\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.4919 - val_loss: 138.9929\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.6846 - val_loss: 237.3089\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.6801 - val_loss: 154.9051\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.6614 - val_loss: 231.8437\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.2844 - val_loss: 187.5879\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2502 - val_loss: 146.2832\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0448 - val_loss: 140.1300\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 147.9730 - val_loss: 152.8356\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6565 - val_loss: 147.2399\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9807 - val_loss: 191.9902\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.3982 - val_loss: 174.2590\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6048 - val_loss: 139.9781\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.6742 - val_loss: 149.1848\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8052 - val_loss: 155.8994\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.6348 - val_loss: 196.2462\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7350 - val_loss: 147.8116\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5133 - val_loss: 143.5126\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.6847 - val_loss: 137.4890\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0436 - val_loss: 144.0275\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8781 - val_loss: 138.0998\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.5584 - val_loss: 165.5567\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1986 - val_loss: 146.0238\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7983 - val_loss: 148.0214\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.8458 - val_loss: 231.5860\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 210.9617 - val_loss: 154.7564\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2757 - val_loss: 140.2086\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.8484 - val_loss: 147.1071\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0259 - val_loss: 153.7968\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7824 - val_loss: 143.2955\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3138 - val_loss: 141.7873\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3553 - val_loss: 137.8656\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9266 - val_loss: 157.5010\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.1005 - val_loss: 148.4757\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5691 - val_loss: 139.8292\n",
      "Epoch 2319/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.6090 - val_loss: 137.2726\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6831 - val_loss: 138.1608\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7575 - val_loss: 144.9463\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5604 - val_loss: 151.4694\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6656 - val_loss: 151.9554\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8902 - val_loss: 182.2693\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6630 - val_loss: 161.5007\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1851 - val_loss: 137.3371\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4026 - val_loss: 151.0351\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7640 - val_loss: 159.4346\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.5351 - val_loss: 156.3261\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8400 - val_loss: 139.2147\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2881 - val_loss: 189.9871\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.8766 - val_loss: 143.9616\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5148 - val_loss: 142.5167\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4116 - val_loss: 140.9607\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3307 - val_loss: 164.2388\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9203 - val_loss: 207.8775\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9702 - val_loss: 185.3702\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0382 - val_loss: 153.7659\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4100 - val_loss: 137.5512\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1415 - val_loss: 144.5360\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8586 - val_loss: 206.0307\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.0049 - val_loss: 143.1213\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.3059 - val_loss: 140.3961\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.2026 - val_loss: 140.7733\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6507 - val_loss: 134.1268\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7061 - val_loss: 148.9015\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1325 - val_loss: 151.9138 ETA: 0s - loss: 139\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0255 - val_loss: 150.5879\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.8718 - val_loss: 136.3608\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4274 - val_loss: 209.5420\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2646 - val_loss: 175.7962\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.2931 - val_loss: 155.6044\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4583 - val_loss: 138.6893\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.4846 - val_loss: 164.2315\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5427 - val_loss: 135.3430\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.1102 - val_loss: 163.2096\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.2867 - val_loss: 146.2244\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.8299 - val_loss: 152.8735\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.5206 - val_loss: 182.6831\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 134.4259 - val_loss: 150.1903\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 141.9521 - val_loss: 145.3109\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7767 - val_loss: 140.9327\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.5390 - val_loss: 154.8229\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.9069 - val_loss: 152.8383\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0455 - val_loss: 160.3702\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1337 - val_loss: 141.0299\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4786 - val_loss: 169.5662\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.6344 - val_loss: 152.4982\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4000 - val_loss: 147.2250\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1421 - val_loss: 228.7864\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5738 - val_loss: 188.5397\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.8206 - val_loss: 246.5350\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.1031 - val_loss: 143.3466\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1797 - val_loss: 155.0407\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5792 - val_loss: 181.6270\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4030 - val_loss: 136.1358\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.8305 - val_loss: 142.9393\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5438 - val_loss: 139.7762\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3254 - val_loss: 144.6669\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8973 - val_loss: 177.7267\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6738 - val_loss: 154.2506\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7626 - val_loss: 177.6133\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7954 - val_loss: 173.8175\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.2399 - val_loss: 173.8552\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5466 - val_loss: 181.0837\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4222 - val_loss: 139.1536\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.3226 - val_loss: 195.1895\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.7546 - val_loss: 166.0404\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1201 - val_loss: 143.9767\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4101 - val_loss: 152.3594\n",
      "Epoch 2391/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6157 - val_loss: 178.1498\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3081 - val_loss: 148.3726\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0735 - val_loss: 165.2142\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1129 - val_loss: 184.8967\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1967 - val_loss: 164.2469\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0046 - val_loss: 137.9085\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.3917 - val_loss: 149.7398\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9470 - val_loss: 230.9380\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0595 - val_loss: 146.1245\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3348 - val_loss: 165.5447\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7955 - val_loss: 175.6443\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 140.935 - 0s 50us/step - loss: 140.0464 - val_loss: 147.9888\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.6254 - val_loss: 152.1116\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.7437 - val_loss: 138.7982\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7694 - val_loss: 149.6039\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.2168 - val_loss: 148.6745\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6032 - val_loss: 225.4197\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.6948 - val_loss: 136.5210\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4469 - val_loss: 140.5645\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3564 - val_loss: 148.2923\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.9345 - val_loss: 145.4632\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.2043 - val_loss: 137.0112\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7943 - val_loss: 153.3124\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0703 - val_loss: 139.9123\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7883 - val_loss: 139.1870\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 130.9783 - val_loss: 206.6440\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.9507 - val_loss: 142.4358\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5077 - val_loss: 149.9589\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9527 - val_loss: 143.9927\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1698 - val_loss: 138.6422\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1861 - val_loss: 148.4610\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7340 - val_loss: 164.3224\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7696 - val_loss: 135.9367\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.4074 - val_loss: 213.6301\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.7522 - val_loss: 169.6980\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8813 - val_loss: 142.9705\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8839 - val_loss: 166.9630\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8004 - val_loss: 134.1170\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7712 - val_loss: 144.3665\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.1780 - val_loss: 143.4893\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.2513 - val_loss: 140.9377\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.7719 - val_loss: 169.0101\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 225.9206 - val_loss: 142.0581\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 133.4216 - val_loss: 142.9715\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8082 - val_loss: 143.2177\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4329 - val_loss: 250.9420\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2364 - val_loss: 139.2391\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6842 - val_loss: 134.8777\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7776 - val_loss: 142.3447\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.9024 - val_loss: 227.0918\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3277 - val_loss: 144.2017\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.6290 - val_loss: 180.0171\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6126 - val_loss: 172.0463\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7463 - val_loss: 143.6945\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3177 - val_loss: 163.2042\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.8332 - val_loss: 324.2305\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5971 - val_loss: 137.3035\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 153.386 - 0s 51us/step - loss: 152.5810 - val_loss: 175.8259\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9335 - val_loss: 148.5160\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9981 - val_loss: 144.3588\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.0016 - val_loss: 165.5868\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6855 - val_loss: 185.4318\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9746 - val_loss: 157.8458\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7701 - val_loss: 136.9512\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0230 - val_loss: 143.3612\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1673 - val_loss: 139.0863\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.3085 - val_loss: 136.0754\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 133.2583 - val_loss: 137.3340\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.6178 - val_loss: 147.0360\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 139.8278 - val_loss: 136.5847\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.0656 - val_loss: 188.5144\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.9096 - val_loss: 151.8188\n",
      "Epoch 2463/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5208 - val_loss: 157.1736\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8659 - val_loss: 156.9324\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.1552 - val_loss: 153.8069\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5563 - val_loss: 161.0767\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2947 - val_loss: 144.7293\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6707 - val_loss: 159.5206\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9535 - val_loss: 145.3443\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6719 - val_loss: 204.1939\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4556 - val_loss: 139.7733\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.8365 - val_loss: 144.6164\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1449 - val_loss: 136.5833\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6184 - val_loss: 156.0613\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5547 - val_loss: 141.0048\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.1045 - val_loss: 222.6139\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.1023 - val_loss: 147.5497\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3686 - val_loss: 134.8685\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6596 - val_loss: 162.2674\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.1808 - val_loss: 143.3412\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6823 - val_loss: 143.9324\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.1004 - val_loss: 149.5873\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9456 - val_loss: 134.1808\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0919 - val_loss: 223.2030\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9322 - val_loss: 239.4606\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3013 - val_loss: 172.6550\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.2698 - val_loss: 134.6899\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7198 - val_loss: 148.5178\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.8228 - val_loss: 161.0416\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8997 - val_loss: 220.1059\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3996 - val_loss: 189.2649\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3904 - val_loss: 146.7190\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.2912 - val_loss: 142.5259\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.0762 - val_loss: 167.5963\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.2201 - val_loss: 144.5196\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5076 - val_loss: 136.1420\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9951 - val_loss: 145.8506\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2105 - val_loss: 150.5732\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.2604 - val_loss: 148.0280\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4648 - val_loss: 136.8494\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.4122 - val_loss: 143.5816\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.9777 - val_loss: 167.4905\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 154.8156 - val_loss: 184.7846\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 142.8657 - val_loss: 155.6286\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.3949 - val_loss: 146.8914\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.9821 - val_loss: 164.9469\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1659 - val_loss: 155.0252\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1003 - val_loss: 142.9102\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4513 - val_loss: 177.3038\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6472 - val_loss: 137.0495\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.8303 - val_loss: 142.0875\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5472 - val_loss: 166.2806\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5359 - val_loss: 157.6901\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0031 - val_loss: 139.8289\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7256 - val_loss: 138.3746\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.7144 - val_loss: 155.5616\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5747 - val_loss: 160.3380\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 140.2880 - val_loss: 141.4619\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7868 - val_loss: 261.4965\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2733 - val_loss: 139.3129\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.1225 - val_loss: 141.7415\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2466 - val_loss: 141.9044\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.4977 - val_loss: 138.4659\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3583 - val_loss: 141.5610\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7717 - val_loss: 134.0904\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2898 - val_loss: 134.7403\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.2123 - val_loss: 144.2294\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7723 - val_loss: 137.6715\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8929 - val_loss: 136.3584\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5522 - val_loss: 172.9835\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.2051 - val_loss: 174.8076\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7123 - val_loss: 184.3403\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.8239 - val_loss: 234.9317\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6716 - val_loss: 155.3849\n",
      "Epoch 2535/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8847 - val_loss: 151.0617\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1851 - val_loss: 138.1300\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.2935 - val_loss: 141.5601\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.2295 - val_loss: 139.4794\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0941 - val_loss: 145.6720\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9287 - val_loss: 143.9341\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.1104 - val_loss: 137.8377\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5740 - val_loss: 150.0492\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9054 - val_loss: 181.6844\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.6398 - val_loss: 139.1946\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1470 - val_loss: 175.1886\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6476 - val_loss: 141.7369\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1865 - val_loss: 141.3271\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6478 - val_loss: 146.3872\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 129.6888 - val_loss: 148.5420\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9693 - val_loss: 138.5967\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.9291 - val_loss: 154.4990\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.3887 - val_loss: 138.1154\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6845 - val_loss: 141.4205\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.1378 - val_loss: 148.4948\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3952 - val_loss: 158.3632\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6257 - val_loss: 142.6023\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.0453 - val_loss: 156.0565\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.9091 - val_loss: 139.3677\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0667 - val_loss: 162.8052\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0130 - val_loss: 141.4441\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4089 - val_loss: 134.0601\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9050 - val_loss: 192.5561\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5406 - val_loss: 140.2234\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8944 - val_loss: 156.6726\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2102 - val_loss: 170.5935\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2706 - val_loss: 137.6401\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3781 - val_loss: 190.8294\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.1549 - val_loss: 187.4278\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6442 - val_loss: 140.5101\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5874 - val_loss: 168.7652\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3659 - val_loss: 153.2567\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8802 - val_loss: 183.1194\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1822 - val_loss: 262.9388\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1682 - val_loss: 172.1181\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.7002 - val_loss: 145.0170\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 134.6144 - val_loss: 138.8587\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.3226 - val_loss: 148.6408\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 133.3277 - val_loss: 148.0277\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.6882 - val_loss: 151.3177\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5987 - val_loss: 134.3039\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2000 - val_loss: 140.7801\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.9171 - val_loss: 139.5265\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9108 - val_loss: 161.6492\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4946 - val_loss: 137.7835\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0047 - val_loss: 150.5848\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3024 - val_loss: 159.9392\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.9711 - val_loss: 158.8375\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.5554 - val_loss: 164.1284\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1073 - val_loss: 331.7091\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.4740 - val_loss: 152.3446\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7545 - val_loss: 171.6361\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.2506 - val_loss: 169.8263\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9569 - val_loss: 150.2098\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4596 - val_loss: 141.2704\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7185 - val_loss: 149.0905\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1705 - val_loss: 141.9231\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9233 - val_loss: 187.6023\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1344 - val_loss: 144.4478\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7083 - val_loss: 194.0633\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5616 - val_loss: 139.2228\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.9835 - val_loss: 152.9224\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.4594 - val_loss: 144.1803\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.9698 - val_loss: 143.3913\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2767 - val_loss: 152.7592\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.1799 - val_loss: 135.4378\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9686 - val_loss: 195.9233\n",
      "Epoch 2607/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0737 - val_loss: 157.0525\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1113 - val_loss: 137.2207\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0268 - val_loss: 151.6881\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1769 - val_loss: 146.4959\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2369 - val_loss: 231.5560\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2948 - val_loss: 149.3189\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2483 - val_loss: 150.0322\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.1441 - val_loss: 192.9148\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0391 - val_loss: 138.0552\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4779 - val_loss: 136.8371\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7832 - val_loss: 181.7981\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9714 - val_loss: 146.7846\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4527 - val_loss: 154.9910\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.4055 - val_loss: 138.2817\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6881 - val_loss: 134.6308\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6982 - val_loss: 138.9910\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.5899 - val_loss: 159.7494\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0753 - val_loss: 170.8973\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.8525 - val_loss: 153.7275\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9480 - val_loss: 273.3154\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3861 - val_loss: 174.0381\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7177 - val_loss: 161.3538\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.5107 - val_loss: 146.4758\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4738 - val_loss: 134.1145\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6997 - val_loss: 147.8417\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.6397 - val_loss: 141.3193\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.7488 - val_loss: 139.4906\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.3021 - val_loss: 151.0422\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2623 - val_loss: 135.5214\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.1939 - val_loss: 234.5353\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4246 - val_loss: 135.0654\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.2505 - val_loss: 137.4047\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6155 - val_loss: 154.2167\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.1826 - val_loss: 175.1160\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9711 - val_loss: 139.8379\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5079 - val_loss: 149.6644\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.8884 - val_loss: 142.0546\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6278 - val_loss: 142.0404\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.0998 - val_loss: 145.3738\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2042 - val_loss: 138.9261\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.2406 - val_loss: 145.1292\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.3288 - val_loss: 155.7693\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 179.9456 - val_loss: 142.5354\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.7357 - val_loss: 150.0824\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7324 - val_loss: 163.7868\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9467 - val_loss: 145.7582\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0431 - val_loss: 142.4307\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0876 - val_loss: 144.4943\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.0429 - val_loss: 159.5156\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1600 - val_loss: 145.6997\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9152 - val_loss: 168.0468\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7256 - val_loss: 142.9219\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1413 - val_loss: 143.8517\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6584 - val_loss: 141.4376\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8087 - val_loss: 150.3741\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0323 - val_loss: 159.8044\n",
      "Epoch 2663/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5645 - val_loss: 139.6328\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8651 - val_loss: 142.6667\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9148 - val_loss: 141.4714\n",
      "Epoch 2666/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.9876 - val_loss: 173.1797\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.5550 - val_loss: 146.0780\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8461 - val_loss: 165.7305\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1635 - val_loss: 155.8341\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6898 - val_loss: 140.5056\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.0085 - val_loss: 133.0699\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7515 - val_loss: 170.9867\n",
      "Epoch 2673/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1774 - val_loss: 149.6396\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2572 - val_loss: 151.3117\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7940 - val_loss: 135.2436\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8573 - val_loss: 181.8569\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.7525 - val_loss: 145.7447\n",
      "Epoch 2678/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0438 - val_loss: 137.9089\n",
      "Epoch 2679/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.4406 - val_loss: 156.5435\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0876 - val_loss: 136.9380\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6431 - val_loss: 155.1892\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8742 - val_loss: 140.0858\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5939 - val_loss: 164.6543\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4745 - val_loss: 152.5293\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7475 - val_loss: 139.2626\n",
      "Epoch 2686/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3959 - val_loss: 145.2084\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.8319 - val_loss: 155.6160\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.4415 - val_loss: 169.6018\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7059 - val_loss: 142.2178\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3276 - val_loss: 144.3416\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.9781 - val_loss: 143.7495\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.4608 - val_loss: 147.9403\n",
      "Epoch 2693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2516 - val_loss: 141.2504\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5045 - val_loss: 228.7444\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9462 - val_loss: 144.1073\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0884 - val_loss: 194.5964\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9792 - val_loss: 150.1906\n",
      "Epoch 2698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1816 - val_loss: 241.9382\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6335 - val_loss: 174.7527\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3121 - val_loss: 144.6243\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9862 - val_loss: 137.2827\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0326 - val_loss: 136.1092\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2135 - val_loss: 146.4219\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7479 - val_loss: 144.9675\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.8389 - val_loss: 153.3649\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9556 - val_loss: 144.7795\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2186 - val_loss: 184.3240\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2558 - val_loss: 215.9837\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5999 - val_loss: 135.1858\n",
      "Epoch 2710/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.0372 - val_loss: 138.5258\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.4072 - val_loss: 148.1185\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3157 - val_loss: 142.3999\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.9984 - val_loss: 182.4474\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.7048 - val_loss: 141.2632\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2342 - val_loss: 138.6894\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5535 - val_loss: 135.9497\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0094 - val_loss: 155.3496\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9920 - val_loss: 137.2316\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5182 - val_loss: 138.7878\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6400 - val_loss: 188.4966\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.5362 - val_loss: 192.2883\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.2440 - val_loss: 167.8399\n",
      "Epoch 2723/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.3325 - val_loss: 140.8997\n",
      "Epoch 2724/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4701 - val_loss: 168.1674\n",
      "Epoch 2725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6059 - val_loss: 191.1445\n",
      "Epoch 2726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5011 - val_loss: 164.3811\n",
      "Epoch 2727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8618 - val_loss: 166.7419\n",
      "Epoch 2728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6983 - val_loss: 191.6524\n",
      "Epoch 2729/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.0267 - val_loss: 137.5611\n",
      "Epoch 2730/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.9356 - val_loss: 140.1207\n",
      "Epoch 2731/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 139.1383 - val_loss: 169.4157\n",
      "Epoch 2732/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 136.4252 - val_loss: 156.9031\n",
      "Epoch 2733/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 132.1596 - val_loss: 139.3020\n",
      "Epoch 2734/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8882 - val_loss: 151.8652\n",
      "Epoch 2735/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4583 - val_loss: 190.0625\n",
      "Epoch 2736/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.3652 - val_loss: 134.8952\n",
      "Epoch 2737/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.2367 - val_loss: 160.1826\n",
      "Epoch 2738/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.2507 - val_loss: 146.3416\n",
      "Epoch 2739/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7747 - val_loss: 156.5329\n",
      "Epoch 2740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4059 - val_loss: 173.0903\n",
      "Epoch 2741/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6449 - val_loss: 154.3146\n",
      "Epoch 2742/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 192.1095 - val_loss: 171.1795\n",
      "Epoch 2743/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1605 - val_loss: 218.8869\n",
      "Epoch 2744/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.2285 - val_loss: 153.1590\n",
      "Epoch 2745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4690 - val_loss: 353.9704\n",
      "Epoch 2746/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.6714 - val_loss: 136.4032\n",
      "Epoch 2747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7509 - val_loss: 134.6096\n",
      "Epoch 2748/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8438 - val_loss: 151.2626\n",
      "Epoch 2749/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6115 - val_loss: 144.1929\n",
      "Epoch 2750/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7810 - val_loss: 137.3334\n",
      "Epoch 2751/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9743 - val_loss: 138.0846\n",
      "Epoch 2752/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.2954 - val_loss: 186.6105\n",
      "Epoch 2753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2118 - val_loss: 136.6557\n",
      "Epoch 2754/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.9330 - val_loss: 137.1596\n",
      "Epoch 2755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6529 - val_loss: 139.1630\n",
      "Epoch 2756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0749 - val_loss: 173.1857\n",
      "Epoch 2757/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3857 - val_loss: 182.7243\n",
      "Epoch 2758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7754 - val_loss: 140.8880\n",
      "Epoch 2759/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.1171 - val_loss: 207.6834\n",
      "Epoch 2760/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4907 - val_loss: 140.3296\n",
      "Epoch 2761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3485 - val_loss: 136.9029\n",
      "Epoch 2762/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9250 - val_loss: 139.7637\n",
      "Epoch 2763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4569 - val_loss: 141.9771\n",
      "Epoch 2764/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8560 - val_loss: 136.0113\n",
      "Epoch 2765/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.4265 - val_loss: 139.9673\n",
      "Epoch 2766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5573 - val_loss: 146.0869\n",
      "Epoch 2767/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4150 - val_loss: 144.6334\n",
      "Epoch 2768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9795 - val_loss: 150.7070\n",
      "Epoch 2769/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1067 - val_loss: 141.4854\n",
      "Epoch 2770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0551 - val_loss: 180.3072\n",
      "Epoch 2771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6838 - val_loss: 151.0532\n",
      "Epoch 2772/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5237 - val_loss: 164.4152\n",
      "Epoch 2773/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.2139 - val_loss: 139.3363\n",
      "Epoch 2774/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7442 - val_loss: 142.8054\n",
      "Epoch 2775/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7196 - val_loss: 166.1551\n",
      "Epoch 2776/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.9995 - val_loss: 148.3874\n",
      "Epoch 2777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4297 - val_loss: 176.2716\n",
      "Epoch 2778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2362 - val_loss: 173.0017\n",
      "Epoch 2779/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.8731 - val_loss: 134.9434\n",
      "Epoch 2780/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.7748 - val_loss: 155.0593\n",
      "Epoch 2781/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1732 - val_loss: 140.7913\n",
      "Epoch 2782/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7736 - val_loss: 151.5932\n",
      "Epoch 2783/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.0593 - val_loss: 149.4659\n",
      "Epoch 2784/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7406 - val_loss: 142.7016\n",
      "Epoch 2785/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9026 - val_loss: 139.5639\n",
      "Epoch 2786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7223 - val_loss: 140.5783\n",
      "Epoch 2787/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.2845 - val_loss: 145.8785\n",
      "Epoch 2788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5187 - val_loss: 163.9245\n",
      "Epoch 2789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3099 - val_loss: 151.0271\n",
      "Epoch 2790/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8371 - val_loss: 168.6614\n",
      "Epoch 2791/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8840 - val_loss: 148.8806\n",
      "Epoch 2792/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0097 - val_loss: 135.2749\n",
      "Epoch 2793/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 155.7332 - val_loss: 227.2468\n",
      "Epoch 2794/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 158.3871 - val_loss: 144.4976\n",
      "Epoch 2795/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 129.4427 - val_loss: 144.8472\n",
      "Epoch 2796/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.5384 - val_loss: 189.4986\n",
      "Epoch 2797/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5208 - val_loss: 181.4904\n",
      "Epoch 2798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3396 - val_loss: 142.5749\n",
      "Epoch 2799/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6331 - val_loss: 142.6862\n",
      "Epoch 2800/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5724 - val_loss: 135.6448\n",
      "Epoch 2801/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0534 - val_loss: 264.0385\n",
      "Epoch 2802/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.0137 - val_loss: 138.1460\n",
      "Epoch 2803/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.6838 - val_loss: 144.6412\n",
      "Epoch 2804/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4772 - val_loss: 143.7086\n",
      "Epoch 2805/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6724 - val_loss: 165.3513\n",
      "Epoch 2806/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1824 - val_loss: 138.9801\n",
      "Epoch 2807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3103 - val_loss: 176.7401\n",
      "Epoch 2808/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.2836 - val_loss: 147.4398\n",
      "Epoch 2809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1826 - val_loss: 146.1942\n",
      "Epoch 2810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4341 - val_loss: 150.7198\n",
      "Epoch 2811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5124 - val_loss: 160.3681\n",
      "Epoch 2812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1813 - val_loss: 143.1093\n",
      "Epoch 2813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7655 - val_loss: 153.5672\n",
      "Epoch 2814/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0527 - val_loss: 163.8059\n",
      "Epoch 2815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5785 - val_loss: 221.7049\n",
      "Epoch 2816/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8004 - val_loss: 220.2801\n",
      "Epoch 2817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5634 - val_loss: 204.6332\n",
      "Epoch 2818/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2609 - val_loss: 163.4453\n",
      "Epoch 2819/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6108 - val_loss: 144.3701\n",
      "Epoch 2820/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9889 - val_loss: 157.1444\n",
      "Epoch 2821/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6275 - val_loss: 138.5177\n",
      "Epoch 2822/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0889 - val_loss: 141.7602\n",
      "Epoch 2823/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5019 - val_loss: 161.0294\n",
      "Epoch 2824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2172 - val_loss: 163.0413\n",
      "Epoch 2825/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2451 - val_loss: 145.9162\n",
      "Epoch 2826/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6061 - val_loss: 142.2105\n",
      "Epoch 2827/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1172 - val_loss: 143.9189\n",
      "Epoch 2828/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.0718 - val_loss: 155.1316\n",
      "Epoch 2829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9073 - val_loss: 149.4238\n",
      "Epoch 2830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5273 - val_loss: 140.0458\n",
      "Epoch 2831/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6254 - val_loss: 307.4571\n",
      "Epoch 2832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5170 - val_loss: 142.3489\n",
      "Epoch 2833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3819 - val_loss: 184.2130\n",
      "Epoch 2834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1533 - val_loss: 134.8320\n",
      "Epoch 2835/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4430 - val_loss: 140.0254\n",
      "Epoch 2836/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4208 - val_loss: 144.1562\n",
      "Epoch 2837/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4682 - val_loss: 145.7260\n",
      "Epoch 2838/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5425 - val_loss: 209.9968\n",
      "Epoch 2839/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4029 - val_loss: 140.1300\n",
      "Epoch 2840/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8024 - val_loss: 163.0364\n",
      "Epoch 2841/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.8007 - val_loss: 141.9144\n",
      "Epoch 2842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2234 - val_loss: 162.7323\n",
      "Epoch 2843/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.2316 - val_loss: 147.7904\n",
      "Epoch 2844/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6259 - val_loss: 146.8606\n",
      "Epoch 2845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.3582 - val_loss: 235.1333\n",
      "Epoch 2846/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.8702 - val_loss: 151.6861\n",
      "Epoch 2847/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.4735 - val_loss: 140.1356\n",
      "Epoch 2848/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.9424 - val_loss: 189.9309\n",
      "Epoch 2849/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.9804 - val_loss: 163.3281\n",
      "Epoch 2850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5764 - val_loss: 185.3487\n",
      "Epoch 2851/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.9400 - val_loss: 141.2173\n",
      "Epoch 2852/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0249 - val_loss: 187.4027\n",
      "Epoch 2853/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.2766 - val_loss: 152.5560\n",
      "Epoch 2854/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.2858 - val_loss: 156.7398\n",
      "Epoch 2855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9540 - val_loss: 137.8453\n",
      "Epoch 2856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9899 - val_loss: 200.9987\n",
      "Epoch 2857/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.4026 - val_loss: 154.5409\n",
      "Epoch 2858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0238 - val_loss: 179.8472\n",
      "Epoch 2859/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8503 - val_loss: 142.3858\n",
      "Epoch 2860/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3005 - val_loss: 142.3177\n",
      "Epoch 2861/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7459 - val_loss: 145.0333\n",
      "Epoch 2862/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.2667 - val_loss: 142.8955\n",
      "Epoch 2863/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6393 - val_loss: 137.7083\n",
      "Epoch 2864/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3259 - val_loss: 161.6073\n",
      "Epoch 2865/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 137.9122 - val_loss: 154.6531\n",
      "Epoch 2866/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.0304 - val_loss: 206.4395\n",
      "Epoch 2867/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 133.5016 - val_loss: 169.9788\n",
      "Epoch 2868/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9801 - val_loss: 147.0842\n",
      "Epoch 2869/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.6312 - val_loss: 136.8785\n",
      "Epoch 2870/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0874 - val_loss: 147.8473\n",
      "Epoch 2871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2966 - val_loss: 141.8276\n",
      "Epoch 2872/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9650 - val_loss: 152.2786\n",
      "Epoch 2873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6257 - val_loss: 139.6530\n",
      "Epoch 2874/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4967 - val_loss: 144.8224\n",
      "Epoch 2875/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.5930 - val_loss: 148.8491\n",
      "Epoch 2876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3752 - val_loss: 162.6249\n",
      "Epoch 2877/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2084 - val_loss: 163.2015\n",
      "Epoch 2878/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6373 - val_loss: 180.2381\n",
      "Epoch 2879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3425 - val_loss: 183.4675\n",
      "Epoch 2880/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.3080 - val_loss: 134.6281\n",
      "Epoch 2881/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.2995 - val_loss: 150.3060\n",
      "Epoch 2882/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6945 - val_loss: 142.3067\n",
      "Epoch 2883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6302 - val_loss: 138.5737\n",
      "Epoch 2884/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0471 - val_loss: 145.7908\n",
      "Epoch 2885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9921 - val_loss: 155.1373\n",
      "Epoch 2886/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7783 - val_loss: 154.8517\n",
      "Epoch 2887/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8278 - val_loss: 153.3645\n",
      "Epoch 2888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7381 - val_loss: 152.2897\n",
      "Epoch 2889/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0477 - val_loss: 141.0332\n",
      "Epoch 2890/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.9106 - val_loss: 140.4553\n",
      "Epoch 2891/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5411 - val_loss: 135.5691\n",
      "Epoch 2892/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9332 - val_loss: 157.3841\n",
      "Epoch 2893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1688 - val_loss: 140.9369\n",
      "Epoch 2894/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.2260 - val_loss: 145.3449\n",
      "Epoch 2895/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.9057 - val_loss: 143.8269\n",
      "Epoch 2896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0008 - val_loss: 213.7079\n",
      "Epoch 2897/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7708 - val_loss: 143.4251\n",
      "Epoch 2898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9378 - val_loss: 175.6629\n",
      "Epoch 2899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.1484 - val_loss: 143.8298\n",
      "Epoch 2900/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8274 - val_loss: 692.6089\n",
      "Epoch 2901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7391 - val_loss: 139.5763\n",
      "Epoch 2902/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.2794 - val_loss: 164.8249\n",
      "Epoch 2903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6202 - val_loss: 147.5739\n",
      "Epoch 2904/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2047 - val_loss: 150.7398\n",
      "Epoch 2905/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 132.233 - 0s 51us/step - loss: 131.7049 - val_loss: 151.3530\n",
      "Epoch 2906/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4447 - val_loss: 139.6377\n",
      "Epoch 2907/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.1220 - val_loss: 176.5193\n",
      "Epoch 2908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5356 - val_loss: 145.1255\n",
      "Epoch 2909/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.0152 - val_loss: 173.9745\n",
      "Epoch 2910/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0661 - val_loss: 153.6532\n",
      "Epoch 2911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7375 - val_loss: 149.0639\n",
      "Epoch 2912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8952 - val_loss: 150.3737\n",
      "Epoch 2913/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3462 - val_loss: 144.7098\n",
      "Epoch 2914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5380 - val_loss: 142.2473\n",
      "Epoch 2915/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.0222 - val_loss: 139.6168\n",
      "Epoch 2916/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9057 - val_loss: 193.2312\n",
      "Epoch 2917/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.6520 - val_loss: 142.0281\n",
      "Epoch 2918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0004 - val_loss: 180.6200\n",
      "Epoch 2919/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5764 - val_loss: 163.0505\n",
      "Epoch 2920/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.8000 - val_loss: 156.6733\n",
      "Epoch 2921/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9152 - val_loss: 159.2639\n",
      "Epoch 2922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9567 - val_loss: 193.8928\n",
      "Epoch 2923/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.324 - 0s 50us/step - loss: 143.9066 - val_loss: 174.3609\n",
      "Epoch 2924/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6091 - val_loss: 229.1049\n",
      "Epoch 2925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7227 - val_loss: 145.0567\n",
      "Epoch 2926/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.3671 - val_loss: 133.5952\n",
      "Epoch 2927/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7881 - val_loss: 186.1670\n",
      "Epoch 2928/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1170 - val_loss: 136.9432\n",
      "Epoch 2929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4888 - val_loss: 147.0253\n",
      "Epoch 2930/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.9529 - val_loss: 137.4793\n",
      "Epoch 2931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6820 - val_loss: 151.6252\n",
      "Epoch 2932/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.1548 - val_loss: 142.9860\n",
      "Epoch 2933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.4276 - val_loss: 139.2183\n",
      "Epoch 2934/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1133 - val_loss: 138.7615\n",
      "Epoch 2935/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.5906 - val_loss: 188.8818\n",
      "Epoch 2936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9534 - val_loss: 142.4942\n",
      "Epoch 2937/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.5738 - val_loss: 179.7062\n",
      "Epoch 2938/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 145.8632 - val_loss: 160.9099\n",
      "Epoch 2939/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 134.6789 - val_loss: 161.7247\n",
      "Epoch 2940/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 137.4543 - val_loss: 141.9313\n",
      "Epoch 2941/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.2393 - val_loss: 164.7590\n",
      "Epoch 2942/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6669 - val_loss: 182.0071\n",
      "Epoch 2943/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0742 - val_loss: 182.1453\n",
      "Epoch 2944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1007 - val_loss: 143.4485\n",
      "Epoch 2945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.3378 - val_loss: 133.2756\n",
      "Epoch 2946/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.6676 - val_loss: 139.7695\n",
      "Epoch 2947/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.9281 - val_loss: 151.7265\n",
      "Epoch 2948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2961 - val_loss: 147.5215\n",
      "Epoch 2949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.7248 - val_loss: 143.5663\n",
      "Epoch 2950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7942 - val_loss: 178.2272\n",
      "Epoch 2951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2779 - val_loss: 188.7657\n",
      "Epoch 2952/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8229 - val_loss: 168.5125\n",
      "Epoch 2953/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3734 - val_loss: 170.4129\n",
      "Epoch 2954/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4234 - val_loss: 138.6087\n",
      "Epoch 2955/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0069 - val_loss: 172.4499\n",
      "Epoch 2956/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6576 - val_loss: 198.6249\n",
      "Epoch 2957/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2667 - val_loss: 190.7493\n",
      "Epoch 2958/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7032 - val_loss: 145.5373\n",
      "Epoch 2959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6685 - val_loss: 143.1945\n",
      "Epoch 2960/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2452 - val_loss: 206.7752\n",
      "Epoch 2961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4393 - val_loss: 185.8499\n",
      "Epoch 2962/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0792 - val_loss: 159.7044\n",
      "Epoch 2963/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3244 - val_loss: 154.6585\n",
      "Epoch 2964/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.0444 - val_loss: 157.0174\n",
      "Epoch 2965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4959 - val_loss: 209.2531\n",
      "Epoch 2966/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6429 - val_loss: 137.7872\n",
      "Epoch 2967/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7378 - val_loss: 159.4969\n",
      "Epoch 2968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6414 - val_loss: 152.1245\n",
      "Epoch 2969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1973 - val_loss: 141.3754\n",
      "Epoch 2970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9734 - val_loss: 143.6463\n",
      "Epoch 2971/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4560 - val_loss: 150.7175\n",
      "Epoch 2972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7527 - val_loss: 207.3924\n",
      "Epoch 2973/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.8149 - val_loss: 201.4463\n",
      "Epoch 2974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9344 - val_loss: 162.6236\n",
      "Epoch 2975/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0303 - val_loss: 181.6415\n",
      "Epoch 2976/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0391 - val_loss: 152.3698\n",
      "Epoch 2977/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7881 - val_loss: 158.3004\n",
      "Epoch 2978/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5349 - val_loss: 175.6351\n",
      "Epoch 2979/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4547 - val_loss: 154.4117\n",
      "Epoch 2980/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7934 - val_loss: 138.4015\n",
      "Epoch 2981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5626 - val_loss: 188.7821\n",
      "Epoch 2982/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.1436 - val_loss: 135.7256\n",
      "Epoch 2983/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2650 - val_loss: 137.5263\n",
      "Epoch 2984/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.7593 - val_loss: 138.7630\n",
      "Epoch 2985/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7535 - val_loss: 141.6928\n",
      "Epoch 2986/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.9156 - val_loss: 148.2195\n",
      "Epoch 2987/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4876 - val_loss: 165.7071\n",
      "Epoch 2988/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3842 - val_loss: 138.1842\n",
      "Epoch 2989/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0995 - val_loss: 155.0289\n",
      "Epoch 2990/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9096 - val_loss: 146.8244\n",
      "Epoch 2991/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 128.7406 - val_loss: 145.3303\n",
      "Epoch 2992/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 129.7049 - val_loss: 165.3111\n",
      "Epoch 2993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7917 - val_loss: 145.1610\n",
      "Epoch 2994/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.6145 - val_loss: 152.6693\n",
      "Epoch 2995/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4026 - val_loss: 141.5315\n",
      "Epoch 2996/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1229 - val_loss: 136.5827\n",
      "Epoch 2997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0178 - val_loss: 141.9647\n",
      "Epoch 2998/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3370 - val_loss: 151.6420\n",
      "Epoch 2999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3494 - val_loss: 175.7361\n",
      "Epoch 3000/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 149.4339 - val_loss: 322.6348\n",
      "Epoch 3001/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 183.1741 - val_loss: 172.7320\n",
      "Epoch 3002/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9857 - val_loss: 146.0203\n",
      "Epoch 3003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6404 - val_loss: 142.6065\n",
      "Epoch 3004/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.2578 - val_loss: 141.8503\n",
      "Epoch 3005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8451 - val_loss: 138.9456\n",
      "Epoch 3006/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.7304 - val_loss: 141.5594\n",
      "Epoch 3007/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0412 - val_loss: 187.3256\n",
      "Epoch 3008/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.9293 - val_loss: 195.6171\n",
      "Epoch 3009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8136 - val_loss: 142.0053\n",
      "Epoch 3010/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.5790 - val_loss: 140.8303\n",
      "Epoch 3011/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 145.0649 - val_loss: 231.7579\n",
      "Epoch 3012/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 171.2277 - val_loss: 210.6045\n",
      "Epoch 3013/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 147.4073 - val_loss: 143.4686\n",
      "Epoch 3014/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6876 - val_loss: 146.3474\n",
      "Epoch 3015/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7293 - val_loss: 153.4648\n",
      "Epoch 3016/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0464 - val_loss: 163.4364\n",
      "Epoch 3017/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5001 - val_loss: 153.8062\n",
      "Epoch 3018/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.4625 - val_loss: 159.4114\n",
      "Epoch 3019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5150 - val_loss: 205.2696\n",
      "Epoch 3020/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2047 - val_loss: 174.6595\n",
      "Epoch 3021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9067 - val_loss: 173.7150\n",
      "Epoch 3022/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.9441 - val_loss: 187.2719\n",
      "Epoch 3023/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0038 - val_loss: 151.8682\n",
      "Epoch 3024/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.5236 - val_loss: 137.7493\n",
      "Epoch 3025/10000\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 142.4021 - val_loss: 249.9529\n",
      "Epoch 3026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7831 - val_loss: 172.7360\n",
      "Epoch 3027/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5843 - val_loss: 137.4896\n",
      "Epoch 3028/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4823 - val_loss: 134.9401\n",
      "Epoch 3029/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1811 - val_loss: 154.2254\n",
      "Epoch 3030/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5454 - val_loss: 147.9968\n",
      "Epoch 3031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8993 - val_loss: 149.4219\n",
      "Epoch 3032/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.8806 - val_loss: 153.0468\n",
      "Epoch 3033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7403 - val_loss: 144.3818\n",
      "Epoch 3034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6556 - val_loss: 135.2593\n",
      "Epoch 3035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3806 - val_loss: 144.4726\n",
      "Epoch 3036/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.1363 - val_loss: 137.7656\n",
      "Epoch 3037/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.0706 - val_loss: 154.0715\n",
      "Epoch 3038/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2641 - val_loss: 140.0672\n",
      "Epoch 3039/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0654 - val_loss: 141.9147\n",
      "Epoch 3040/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2082 - val_loss: 153.8862\n",
      "Epoch 3041/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3344 - val_loss: 137.5600\n",
      "Epoch 3042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9256 - val_loss: 184.9023\n",
      "Epoch 3043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5065 - val_loss: 133.7417\n",
      "Epoch 3044/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1960 - val_loss: 152.2471\n",
      "Epoch 3045/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.7827 - val_loss: 172.2063\n",
      "Epoch 3046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2859 - val_loss: 184.6338\n",
      "Epoch 3047/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5710 - val_loss: 153.7331\n",
      "Epoch 3048/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1433 - val_loss: 146.6573\n",
      "Epoch 3049/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4565 - val_loss: 143.3854\n",
      "Epoch 3050/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.1678 - val_loss: 189.0499\n",
      "Epoch 3051/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1326 - val_loss: 138.7662\n",
      "Epoch 3052/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.0247 - val_loss: 165.8149\n",
      "Epoch 3053/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9929 - val_loss: 163.7375\n",
      "Epoch 3054/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9424 - val_loss: 179.6993\n",
      "Epoch 3055/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6168 - val_loss: 165.1569\n",
      "Epoch 3056/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9956 - val_loss: 137.5651\n",
      "Epoch 3057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4434 - val_loss: 141.2973\n",
      "Epoch 3058/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.4877 - val_loss: 143.2720\n",
      "Epoch 3059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.4805 - val_loss: 166.5979\n",
      "Epoch 3060/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1768 - val_loss: 140.2961\n",
      "Epoch 3061/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3955 - val_loss: 300.4895\n",
      "Epoch 3062/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.2295 - val_loss: 179.8940\n",
      "Epoch 3063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3111 - val_loss: 142.2757\n",
      "Epoch 3064/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.1486 - val_loss: 180.9595\n",
      "Epoch 3065/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.8414 - val_loss: 178.3244\n",
      "Epoch 3066/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.8879 - val_loss: 147.8950\n",
      "Epoch 3067/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.8975 - val_loss: 151.5790\n",
      "Epoch 3068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3616 - val_loss: 154.6030\n",
      "Epoch 3069/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5251 - val_loss: 158.0758\n",
      "Epoch 3070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9978 - val_loss: 137.4474\n",
      "Epoch 3071/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8889 - val_loss: 134.6088\n",
      "Epoch 3072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4621 - val_loss: 138.5802\n",
      "Epoch 3073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.7005 - val_loss: 164.5061\n",
      "Epoch 3074/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.2114 - val_loss: 159.6321\n",
      "Epoch 3075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5099 - val_loss: 142.2617\n",
      "Epoch 3076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.8717 - val_loss: 280.6059\n",
      "Epoch 3077/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5778 - val_loss: 150.4043\n",
      "Epoch 3078/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.0599 - val_loss: 175.4541\n",
      "Epoch 3079/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.2142 - val_loss: 144.3738\n",
      "Epoch 3080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4798 - val_loss: 140.1473\n",
      "Epoch 3081/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2849 - val_loss: 177.7468\n",
      "Epoch 3082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0333 - val_loss: 143.4092\n",
      "Epoch 3083/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 132.8085 - val_loss: 137.1182\n",
      "Epoch 3084/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.5192 - val_loss: 165.5365\n",
      "Epoch 3085/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 136.3036 - val_loss: 152.5128\n",
      "Epoch 3086/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 137.5908 - val_loss: 141.3439\n",
      "Epoch 3087/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8206 - val_loss: 148.9051\n",
      "Epoch 3088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5133 - val_loss: 207.8817\n",
      "Epoch 3089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7369 - val_loss: 140.9946\n",
      "Epoch 3090/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.3553 - val_loss: 148.7796\n",
      "Epoch 3091/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.0508 - val_loss: 155.0869\n",
      "Epoch 3092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5088 - val_loss: 178.7779\n",
      "Epoch 3093/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1924 - val_loss: 158.8686\n",
      "Epoch 3094/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9253 - val_loss: 162.5138\n",
      "Epoch 3095/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4155 - val_loss: 147.2987\n",
      "Epoch 3096/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7336 - val_loss: 140.3916\n",
      "Epoch 3097/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8386 - val_loss: 142.8728\n",
      "Epoch 3098/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7726 - val_loss: 147.2181\n",
      "Epoch 3099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5487 - val_loss: 136.0388\n",
      "Epoch 3100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7982 - val_loss: 147.4209\n",
      "Epoch 3101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8574 - val_loss: 153.9674\n",
      "Epoch 3102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4007 - val_loss: 154.4010\n",
      "Epoch 3103/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6874 - val_loss: 146.1399\n",
      "Epoch 3104/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.2022 - val_loss: 141.2937\n",
      "Epoch 3105/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1217 - val_loss: 172.6271\n",
      "Epoch 3106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6296 - val_loss: 146.5302\n",
      "Epoch 3107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.1609 - val_loss: 212.3610\n",
      "Epoch 3108/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.7157 - val_loss: 161.8552\n",
      "Epoch 3109/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2289 - val_loss: 148.4076\n",
      "Epoch 3110/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3934 - val_loss: 136.1243\n",
      "Epoch 3111/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9111 - val_loss: 141.6984\n",
      "Epoch 3112/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1721 - val_loss: 146.9797\n",
      "Epoch 3113/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4307 - val_loss: 256.0707\n",
      "Epoch 3114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3804 - val_loss: 176.5474\n",
      "Epoch 3115/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3021 - val_loss: 140.0999\n",
      "Epoch 3116/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8133 - val_loss: 161.1847\n",
      "Epoch 3117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4459 - val_loss: 135.1561\n",
      "Epoch 3118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.0887 - val_loss: 199.4200\n",
      "Epoch 3119/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.3557 - val_loss: 142.1628\n",
      "Epoch 3120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1102 - val_loss: 149.8986\n",
      "Epoch 3121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5272 - val_loss: 146.9104\n",
      "Epoch 3122/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3008 - val_loss: 137.4475\n",
      "Epoch 3123/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5232 - val_loss: 194.8729\n",
      "Epoch 3124/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9983 - val_loss: 176.8356\n",
      "Epoch 3125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3434 - val_loss: 141.9136\n",
      "Epoch 3126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9956 - val_loss: 148.8795\n",
      "Epoch 3127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.6823 - val_loss: 137.9561\n",
      "Epoch 3128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4610 - val_loss: 151.0270\n",
      "Epoch 3129/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4070 - val_loss: 140.4546\n",
      "Epoch 3130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3678 - val_loss: 152.3741\n",
      "Epoch 3131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.6237 - val_loss: 145.7087\n",
      "Epoch 3132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4789 - val_loss: 137.3310\n",
      "Epoch 3133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7649 - val_loss: 159.1577\n",
      "Epoch 3134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3490 - val_loss: 168.1971\n",
      "Epoch 3135/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2200 - val_loss: 142.1727\n",
      "Epoch 3136/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.3935 - val_loss: 187.9211\n",
      "Epoch 3137/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.4762 - val_loss: 137.0878\n",
      "Epoch 3138/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1418 - val_loss: 136.4957\n",
      "Epoch 3139/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9990 - val_loss: 139.7404\n",
      "Epoch 3140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8014 - val_loss: 143.5296\n",
      "Epoch 3141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5687 - val_loss: 153.0487\n",
      "Epoch 3142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6608 - val_loss: 145.8568\n",
      "Epoch 3143/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.4063 - val_loss: 148.2073\n",
      "Epoch 3144/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.9610 - val_loss: 170.0386\n",
      "Epoch 3145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6095 - val_loss: 201.0035\n",
      "Epoch 3146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.8795 - val_loss: 243.3684\n",
      "Epoch 3147/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.7390 - val_loss: 159.3824\n",
      "Epoch 3148/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.6989 - val_loss: 145.9702\n",
      "Epoch 3149/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.8934 - val_loss: 142.9274\n",
      "Epoch 3150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7412 - val_loss: 163.0940\n",
      "Epoch 3151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6797 - val_loss: 141.2550\n",
      "Epoch 3152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9244 - val_loss: 172.5837\n",
      "Epoch 3153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2041 - val_loss: 153.4582\n",
      "Epoch 3154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2500 - val_loss: 315.1084\n",
      "Epoch 3155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8861 - val_loss: 150.2892\n",
      "Epoch 3156/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 133.7399 - val_loss: 152.3800\n",
      "Epoch 3157/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 132.0633 - val_loss: 151.9505\n",
      "Epoch 3158/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 136.5458 - val_loss: 156.2622\n",
      "Epoch 3159/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.3195 - val_loss: 139.5882\n",
      "Epoch 3160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8382 - val_loss: 149.9760\n",
      "Epoch 3161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3742 - val_loss: 145.1689\n",
      "Epoch 3162/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5395 - val_loss: 140.4668\n",
      "Epoch 3163/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.8533 - val_loss: 158.7150\n",
      "Epoch 3164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.9217 - val_loss: 194.0818\n",
      "Epoch 3165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6555 - val_loss: 150.4967\n",
      "Epoch 3166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0474 - val_loss: 136.8298\n",
      "Epoch 3167/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.9443 - val_loss: 146.3127\n",
      "Epoch 3168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6857 - val_loss: 157.1341\n",
      "Epoch 3169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7398 - val_loss: 254.5102\n",
      "Epoch 3170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0494 - val_loss: 238.2684\n",
      "Epoch 3171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.0734 - val_loss: 189.2705\n",
      "Epoch 3172/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0832 - val_loss: 166.6587\n",
      "Epoch 3173/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 134.138 - 0s 51us/step - loss: 134.1337 - val_loss: 222.4452\n",
      "Epoch 3174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4163 - val_loss: 151.5353\n",
      "Epoch 3175/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7189 - val_loss: 149.1274\n",
      "Epoch 3176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9324 - val_loss: 196.8327\n",
      "Epoch 3177/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6559 - val_loss: 154.0075\n",
      "Epoch 3178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.3911 - val_loss: 149.0091\n",
      "Epoch 3179/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.0894 - val_loss: 153.9722\n",
      "Epoch 3180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6488 - val_loss: 172.7540\n",
      "Epoch 3181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6459 - val_loss: 138.7199\n",
      "Epoch 3182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.0417 - val_loss: 160.6408\n",
      "Epoch 3183/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8570 - val_loss: 144.1507\n",
      "Epoch 3184/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.1645 - val_loss: 149.8477\n",
      "Epoch 3185/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.1671 - val_loss: 152.8664\n",
      "Epoch 3186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2732 - val_loss: 140.4122\n",
      "Epoch 3187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5551 - val_loss: 174.3468\n",
      "Epoch 3188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0211 - val_loss: 149.6083\n",
      "Epoch 3189/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.8438 - val_loss: 147.8086\n",
      "Epoch 3190/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7055 - val_loss: 145.1286\n",
      "Epoch 3191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1034 - val_loss: 155.3910\n",
      "Epoch 3192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7038 - val_loss: 138.4971\n",
      "Epoch 3193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6193 - val_loss: 140.2342\n",
      "Epoch 3194/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7856 - val_loss: 142.0568\n",
      "Epoch 3195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2617 - val_loss: 212.9467\n",
      "Epoch 3196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1417 - val_loss: 140.3537\n",
      "Epoch 3197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6015 - val_loss: 220.5048\n",
      "Epoch 3198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0905 - val_loss: 210.7019\n",
      "Epoch 3199/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4931 - val_loss: 140.5041\n",
      "Epoch 3200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3531 - val_loss: 144.2215\n",
      "Epoch 3201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0097 - val_loss: 139.4194\n",
      "Epoch 3202/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8110 - val_loss: 162.1306\n",
      "Epoch 3203/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5556 - val_loss: 147.1983\n",
      "Epoch 3204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4135 - val_loss: 170.2707\n",
      "Epoch 3205/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3275 - val_loss: 142.0131\n",
      "Epoch 3206/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9884 - val_loss: 144.0306\n",
      "Epoch 3207/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.4356 - val_loss: 185.8729\n",
      "Epoch 3208/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.5589 - val_loss: 150.1172\n",
      "Epoch 3209/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6275 - val_loss: 162.6659\n",
      "Epoch 3210/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7001 - val_loss: 142.9612\n",
      "Epoch 3211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.4405 - val_loss: 170.9752\n",
      "Epoch 3212/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.2716 - val_loss: 139.7347\n",
      "Epoch 3213/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8616 - val_loss: 164.8670\n",
      "Epoch 3214/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2690 - val_loss: 162.7443\n",
      "Epoch 3215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5325 - val_loss: 172.8457\n",
      "Epoch 3216/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.4706 - val_loss: 276.9979\n",
      "Epoch 3217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0248 - val_loss: 147.1883\n",
      "Epoch 3218/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1065 - val_loss: 166.1537\n",
      "Epoch 3219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6766 - val_loss: 162.5228\n",
      "Epoch 3220/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8429 - val_loss: 148.1514\n",
      "Epoch 3221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9478 - val_loss: 144.6297\n",
      "Epoch 3222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4288 - val_loss: 149.5765\n",
      "Epoch 3223/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.3742 - val_loss: 156.4337\n",
      "Epoch 3224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6250 - val_loss: 140.2117\n",
      "Epoch 3225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5870 - val_loss: 143.2814\n",
      "Epoch 3226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2671 - val_loss: 152.3407\n",
      "Epoch 3227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7342 - val_loss: 192.0423\n",
      "Epoch 3228/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.8207 - val_loss: 160.7786\n",
      "Epoch 3229/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.3628 - val_loss: 285.0407\n",
      "Epoch 3230/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.5064 - val_loss: 157.3821\n",
      "Epoch 3231/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 130.0449 - val_loss: 141.5368\n",
      "Epoch 3232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8207 - val_loss: 139.4647\n",
      "Epoch 3233/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 128.7632 - val_loss: 139.7060\n",
      "Epoch 3234/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0303 - val_loss: 146.7160\n",
      "Epoch 3235/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.1934 - val_loss: 145.9821\n",
      "Epoch 3236/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.1033 - val_loss: 144.8662\n",
      "Epoch 3237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.7931 - val_loss: 175.2332\n",
      "Epoch 3238/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2886 - val_loss: 138.2631\n",
      "Epoch 3239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4297 - val_loss: 169.5741\n",
      "Epoch 3240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0428 - val_loss: 163.7181\n",
      "Epoch 3241/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7672 - val_loss: 148.3443\n",
      "Epoch 3242/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3591 - val_loss: 141.1156\n",
      "Epoch 3243/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2692 - val_loss: 154.9591\n",
      "Epoch 3244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.6892 - val_loss: 141.4112\n",
      "Epoch 3245/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6140 - val_loss: 137.1840\n",
      "Epoch 3246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4288 - val_loss: 157.9253\n",
      "Epoch 3247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2902 - val_loss: 205.0902\n",
      "Epoch 3248/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.3175 - val_loss: 149.1706\n",
      "Epoch 3249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1786 - val_loss: 174.2151\n",
      "Epoch 3250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.0835 - val_loss: 167.0262\n",
      "Epoch 3251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7050 - val_loss: 160.0493\n",
      "Epoch 3252/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 151.535 - 0s 51us/step - loss: 151.1446 - val_loss: 170.1204\n",
      "Epoch 3253/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 152.7139 - val_loss: 164.1034\n",
      "Epoch 3254/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.3812 - val_loss: 163.0746\n",
      "Epoch 3255/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.1468 - val_loss: 167.2088\n",
      "Epoch 3256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0281 - val_loss: 146.1145\n",
      "Epoch 3257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5211 - val_loss: 173.6329\n",
      "Epoch 3258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.7969 - val_loss: 244.9150\n",
      "Epoch 3259/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.9621 - val_loss: 190.7970\n",
      "Epoch 3260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7636 - val_loss: 221.0132\n",
      "Epoch 3261/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1864 - val_loss: 177.3379\n",
      "Epoch 3262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7701 - val_loss: 151.9128\n",
      "Epoch 3263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2368 - val_loss: 167.7022\n",
      "Epoch 3264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3635 - val_loss: 156.0342\n",
      "Epoch 3265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8392 - val_loss: 142.2528\n",
      "Epoch 3266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9096 - val_loss: 145.6321\n",
      "Epoch 3267/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 134.087 - 0s 51us/step - loss: 133.8302 - val_loss: 145.8105\n",
      "Epoch 3268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2041 - val_loss: 152.5775\n",
      "Epoch 3269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9690 - val_loss: 153.2021\n",
      "Epoch 3270/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5682 - val_loss: 142.3312\n",
      "Epoch 3271/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.6039 - val_loss: 181.8465\n",
      "Epoch 3272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4074 - val_loss: 150.7182\n",
      "Epoch 3273/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5255 - val_loss: 139.5710\n",
      "Epoch 3274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5398 - val_loss: 176.2595\n",
      "Epoch 3275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8354 - val_loss: 168.1902\n",
      "Epoch 3276/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.1236 - val_loss: 136.7265\n",
      "Epoch 3277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9072 - val_loss: 140.4819\n",
      "Epoch 3278/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2836 - val_loss: 141.1439\n",
      "Epoch 3279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1551 - val_loss: 143.6817\n",
      "Epoch 3280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9570 - val_loss: 140.2319\n",
      "Epoch 3281/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.2598 - val_loss: 154.4121\n",
      "Epoch 3282/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.0500 - val_loss: 181.0611\n",
      "Epoch 3283/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8572 - val_loss: 146.8482\n",
      "Epoch 3284/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1682 - val_loss: 145.7583\n",
      "Epoch 3285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5680 - val_loss: 136.8884\n",
      "Epoch 3286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0671 - val_loss: 215.4311\n",
      "Epoch 3287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7294 - val_loss: 157.4677\n",
      "Epoch 3288/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4678 - val_loss: 143.4215\n",
      "Epoch 3289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2572 - val_loss: 142.8722\n",
      "Epoch 3290/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 128.5221 - val_loss: 160.4763\n",
      "Epoch 3291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9011 - val_loss: 175.8249\n",
      "Epoch 3292/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.4302 - val_loss: 140.7774\n",
      "Epoch 3293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2013 - val_loss: 143.7652\n",
      "Epoch 3294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0695 - val_loss: 139.4036\n",
      "Epoch 3295/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6482 - val_loss: 154.2624\n",
      "Epoch 3296/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5503 - val_loss: 145.9852\n",
      "Epoch 3297/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.2564 - val_loss: 137.9526\n",
      "Epoch 3298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0878 - val_loss: 195.0808\n",
      "Epoch 3299/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.6824 - val_loss: 155.1332\n",
      "Epoch 3300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4160 - val_loss: 138.8675\n",
      "Epoch 3301/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.7386 - val_loss: 157.9747\n",
      "Epoch 3302/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 153.8642 - val_loss: 139.4530\n",
      "Epoch 3303/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 132.1879 - val_loss: 156.7051\n",
      "Epoch 3304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6465 - val_loss: 191.6411\n",
      "Epoch 3305/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2544 - val_loss: 162.6097\n",
      "Epoch 3306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3124 - val_loss: 233.6095\n",
      "Epoch 3307/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.4598 - val_loss: 135.9864\n",
      "Epoch 3308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5868 - val_loss: 163.6020\n",
      "Epoch 3309/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1121 - val_loss: 135.7137\n",
      "Epoch 3310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7091 - val_loss: 144.3166\n",
      "Epoch 3311/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6957 - val_loss: 215.6916\n",
      "Epoch 3312/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.6604 - val_loss: 171.6218\n",
      "Epoch 3313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7243 - val_loss: 139.8272\n",
      "Epoch 3314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4573 - val_loss: 140.0637\n",
      "Epoch 3315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1724 - val_loss: 156.7264\n",
      "Epoch 3316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3028 - val_loss: 225.7913\n",
      "Epoch 3317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7052 - val_loss: 147.0621\n",
      "Epoch 3318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1839 - val_loss: 175.3511\n",
      "Epoch 3319/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.8604 - val_loss: 156.8771\n",
      "Epoch 3320/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4452 - val_loss: 146.2918\n",
      "Epoch 3321/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0020 - val_loss: 278.7590\n",
      "Epoch 3322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6507 - val_loss: 144.2489\n",
      "Epoch 3323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7554 - val_loss: 141.9796\n",
      "Epoch 3324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.9040 - val_loss: 142.6631\n",
      "Epoch 3325/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6462 - val_loss: 140.9528\n",
      "Epoch 3326/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.2258 - val_loss: 147.0359\n",
      "Epoch 3327/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.2757 - val_loss: 167.8250\n",
      "Epoch 3328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7909 - val_loss: 164.0174\n",
      "Epoch 3329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8092 - val_loss: 262.0414\n",
      "Epoch 3330/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.7128 - val_loss: 156.2249\n",
      "Epoch 3331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.9268 - val_loss: 144.1677\n",
      "Epoch 3332/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0584 - val_loss: 163.1326\n",
      "Epoch 3333/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7749 - val_loss: 170.4483\n",
      "Epoch 3334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2983 - val_loss: 191.6932\n",
      "Epoch 3335/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5991 - val_loss: 139.5562\n",
      "Epoch 3336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6010 - val_loss: 136.9406\n",
      "Epoch 3337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3224 - val_loss: 136.0711\n",
      "Epoch 3338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0060 - val_loss: 160.4680\n",
      "Epoch 3339/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.3029 - val_loss: 148.1338\n",
      "Epoch 3340/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5086 - val_loss: 166.5399\n",
      "Epoch 3341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1532 - val_loss: 160.2191\n",
      "Epoch 3342/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9593 - val_loss: 139.2345\n",
      "Epoch 3343/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.8620 - val_loss: 161.0642\n",
      "Epoch 3344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.5570 - val_loss: 145.2632\n",
      "Epoch 3345/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6521 - val_loss: 145.4822\n",
      "Epoch 3346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9054 - val_loss: 142.7197\n",
      "Epoch 3347/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7839 - val_loss: 146.4185\n",
      "Epoch 3348/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4334 - val_loss: 152.9033\n",
      "Epoch 3349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.6195 - val_loss: 455.8066\n",
      "Epoch 3350/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4807 - val_loss: 159.7352\n",
      "Epoch 3351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4575 - val_loss: 146.9368\n",
      "Epoch 3352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.6331 - val_loss: 171.5683\n",
      "Epoch 3353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8049 - val_loss: 143.8163\n",
      "Epoch 3354/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.2165 - val_loss: 199.6228\n",
      "Epoch 3355/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7827 - val_loss: 147.4157\n",
      "Epoch 3356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9089 - val_loss: 141.3513\n",
      "Epoch 3357/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.9966 - val_loss: 148.6010\n",
      "Epoch 3358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4624 - val_loss: 151.2071\n",
      "Epoch 3359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.2960 - val_loss: 140.3130\n",
      "Epoch 3360/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9807 - val_loss: 140.4703\n",
      "Epoch 3361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7553 - val_loss: 163.3893\n",
      "Epoch 3362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.6330 - val_loss: 190.6908\n",
      "Epoch 3363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7402 - val_loss: 142.4865\n",
      "Epoch 3364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2959 - val_loss: 159.8262\n",
      "Epoch 3365/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3066 - val_loss: 150.8802\n",
      "Epoch 3366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4745 - val_loss: 161.5055\n",
      "Epoch 3367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5729 - val_loss: 178.0034\n",
      "Epoch 3368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8335 - val_loss: 146.3586\n",
      "Epoch 3369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3527 - val_loss: 139.8640\n",
      "Epoch 3370/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.8664 - val_loss: 154.1067\n",
      "Epoch 3371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2270 - val_loss: 172.2628\n",
      "Epoch 3372/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.9859 - val_loss: 147.9875\n",
      "Epoch 3373/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.6601 - val_loss: 149.7183\n",
      "Epoch 3374/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.2179 - val_loss: 145.5038\n",
      "Epoch 3375/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 126.5804 - val_loss: 149.7304\n",
      "Epoch 3376/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.7396 - val_loss: 151.4685\n",
      "Epoch 3377/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.6002 - val_loss: 136.7505\n",
      "Epoch 3378/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3991 - val_loss: 220.3559\n",
      "Epoch 3379/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.3275 - val_loss: 143.5929\n",
      "Epoch 3380/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.4111 - val_loss: 138.6092\n",
      "Epoch 3381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6147 - val_loss: 168.7213\n",
      "Epoch 3382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1042 - val_loss: 150.2186\n",
      "Epoch 3383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6700 - val_loss: 186.1175\n",
      "Epoch 3384/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.1842 - val_loss: 138.9322\n",
      "Epoch 3385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0781 - val_loss: 140.4929\n",
      "Epoch 3386/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.6922 - val_loss: 155.0150\n",
      "Epoch 3387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7852 - val_loss: 143.9731\n",
      "Epoch 3388/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8331 - val_loss: 147.8547\n",
      "Epoch 3389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9014 - val_loss: 151.9392\n",
      "Epoch 3390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7329 - val_loss: 159.4146\n",
      "Epoch 3391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0192 - val_loss: 179.2136\n",
      "Epoch 3392/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6916 - val_loss: 148.2919\n",
      "Epoch 3393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6189 - val_loss: 183.2718\n",
      "Epoch 3394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9345 - val_loss: 175.3750\n",
      "Epoch 3395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5887 - val_loss: 145.1015\n",
      "Epoch 3396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2186 - val_loss: 139.2483\n",
      "Epoch 3397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4865 - val_loss: 202.6257\n",
      "Epoch 3398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0025 - val_loss: 144.9802\n",
      "Epoch 3399/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5118 - val_loss: 157.2781\n",
      "Epoch 3400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8339 - val_loss: 138.9101\n",
      "Epoch 3401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2766 - val_loss: 145.1503\n",
      "Epoch 3402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2610 - val_loss: 150.3379\n",
      "Epoch 3403/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1090 - val_loss: 152.4243\n",
      "Epoch 3404/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5600 - val_loss: 152.2577\n",
      "Epoch 3405/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.7458 - val_loss: 160.4921\n",
      "Epoch 3406/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.8847 - val_loss: 242.8632\n",
      "Epoch 3407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0813 - val_loss: 159.4646\n",
      "Epoch 3408/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4321 - val_loss: 153.6778\n",
      "Epoch 3409/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.8629 - val_loss: 210.8020\n",
      "Epoch 3410/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.4311 - val_loss: 142.2886\n",
      "Epoch 3411/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.6692 - val_loss: 181.4816\n",
      "Epoch 3412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5993 - val_loss: 184.7893\n",
      "Epoch 3413/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1419 - val_loss: 177.0578\n",
      "Epoch 3414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9658 - val_loss: 144.4378\n",
      "Epoch 3415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3148 - val_loss: 175.3294\n",
      "Epoch 3416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.3011 - val_loss: 141.7117\n",
      "Epoch 3417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5902 - val_loss: 144.6637\n",
      "Epoch 3418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5008 - val_loss: 142.8492\n",
      "Epoch 3419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.2592 - val_loss: 176.6591\n",
      "Epoch 3420/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.7986 - val_loss: 158.0382\n",
      "Epoch 3421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1772 - val_loss: 150.9656\n",
      "Epoch 3422/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3281 - val_loss: 192.7864\n",
      "Epoch 3423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3332 - val_loss: 143.5926\n",
      "Epoch 3424/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.0473 - val_loss: 314.6920\n",
      "Epoch 3425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4044 - val_loss: 147.4629\n",
      "Epoch 3426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.1401 - val_loss: 158.2357\n",
      "Epoch 3427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0625 - val_loss: 159.2025\n",
      "Epoch 3428/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 173.7906 - val_loss: 144.8187\n",
      "Epoch 3429/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0297 - val_loss: 143.8440\n",
      "Epoch 3430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1715 - val_loss: 162.8975\n",
      "Epoch 3431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4893 - val_loss: 173.3822\n",
      "Epoch 3432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0121 - val_loss: 149.0281\n",
      "Epoch 3433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0513 - val_loss: 148.3570\n",
      "Epoch 3434/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.3851 - val_loss: 143.9167\n",
      "Epoch 3435/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6603 - val_loss: 155.6228\n",
      "Epoch 3436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2843 - val_loss: 168.9399\n",
      "Epoch 3437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0356 - val_loss: 140.0343\n",
      "Epoch 3438/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 128.0839 - val_loss: 147.8059\n",
      "Epoch 3439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8220 - val_loss: 167.9850\n",
      "Epoch 3440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7727 - val_loss: 184.9310\n",
      "Epoch 3441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2878 - val_loss: 139.0821\n",
      "Epoch 3442/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9177 - val_loss: 139.9379\n",
      "Epoch 3443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3894 - val_loss: 140.1929\n",
      "Epoch 3444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8426 - val_loss: 169.2945\n",
      "Epoch 3445/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8579 - val_loss: 136.4225\n",
      "Epoch 3446/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7282 - val_loss: 168.5491\n",
      "Epoch 3447/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.4985 - val_loss: 188.3901\n",
      "Epoch 3448/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4696 - val_loss: 158.0955\n",
      "Epoch 3449/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.4811 - val_loss: 145.8372\n",
      "Epoch 3450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4761 - val_loss: 170.3355\n",
      "Epoch 3451/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9791 - val_loss: 164.6408\n",
      "Epoch 3452/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4380 - val_loss: 138.1442\n",
      "Epoch 3453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6520 - val_loss: 147.7072\n",
      "Epoch 3454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1954 - val_loss: 141.5396\n",
      "Epoch 3455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1251 - val_loss: 156.4823\n",
      "Epoch 3456/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.2858 - val_loss: 154.0195\n",
      "Epoch 3457/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 135.2062 - val_loss: 142.0430\n",
      "Epoch 3458/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 150.8644 - val_loss: 142.7460\n",
      "Epoch 3459/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 139.6038 - val_loss: 143.4762\n",
      "Epoch 3460/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.4229 - val_loss: 139.0875\n",
      "Epoch 3461/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7577 - val_loss: 140.5872\n",
      "Epoch 3462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7342 - val_loss: 135.4442\n",
      "Epoch 3463/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8224 - val_loss: 187.7332\n",
      "Epoch 3464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5706 - val_loss: 150.5771\n",
      "Epoch 3465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2283 - val_loss: 146.2146\n",
      "Epoch 3466/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5451 - val_loss: 215.8840\n",
      "Epoch 3467/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9030 - val_loss: 153.2047\n",
      "Epoch 3468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8359 - val_loss: 147.6127\n",
      "Epoch 3469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2201 - val_loss: 163.5319\n",
      "Epoch 3470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2471 - val_loss: 143.5946\n",
      "Epoch 3471/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0625 - val_loss: 169.2279\n",
      "Epoch 3472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6940 - val_loss: 141.7942\n",
      "Epoch 3473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5885 - val_loss: 207.5609\n",
      "Epoch 3474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7765 - val_loss: 149.7293\n",
      "Epoch 3475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0869 - val_loss: 186.5794\n",
      "Epoch 3476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.0707 - val_loss: 163.5273\n",
      "Epoch 3477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3727 - val_loss: 195.3090\n",
      "Epoch 3478/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.5879 - val_loss: 142.1563\n",
      "Epoch 3479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2786 - val_loss: 175.3090\n",
      "Epoch 3480/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4119 - val_loss: 142.9439\n",
      "Epoch 3481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7415 - val_loss: 212.2348\n",
      "Epoch 3482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1926 - val_loss: 147.3639\n",
      "Epoch 3483/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.6105 - val_loss: 153.3453\n",
      "Epoch 3484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7063 - val_loss: 171.7335\n",
      "Epoch 3485/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2197 - val_loss: 139.6961\n",
      "Epoch 3486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7624 - val_loss: 146.9536\n",
      "Epoch 3487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9996 - val_loss: 139.0715\n",
      "Epoch 3488/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7605 - val_loss: 141.0858\n",
      "Epoch 3489/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9755 - val_loss: 144.8241\n",
      "Epoch 3490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8644 - val_loss: 201.7075\n",
      "Epoch 3491/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.2278 - val_loss: 145.5654\n",
      "Epoch 3492/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9446 - val_loss: 173.2710\n",
      "Epoch 3493/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7221 - val_loss: 145.6188\n",
      "Epoch 3494/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1116 - val_loss: 146.1710\n",
      "Epoch 3495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2066 - val_loss: 151.0203\n",
      "Epoch 3496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4229 - val_loss: 141.6439\n",
      "Epoch 3497/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5873 - val_loss: 147.0534\n",
      "Epoch 3498/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.1886 - val_loss: 151.6245\n",
      "Epoch 3499/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2053 - val_loss: 178.4711\n",
      "Epoch 3500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5995 - val_loss: 152.3779\n",
      "Epoch 3501/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6405 - val_loss: 157.2653\n",
      "Epoch 3502/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3010 - val_loss: 202.9333\n",
      "Epoch 3503/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.9156 - val_loss: 165.9696\n",
      "Epoch 3504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5507 - val_loss: 149.6736\n",
      "Epoch 3505/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7338 - val_loss: 165.0917\n",
      "Epoch 3506/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 151.918 - 0s 51us/step - loss: 159.1903 - val_loss: 292.5415\n",
      "Epoch 3507/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.7277 - val_loss: 146.3732\n",
      "Epoch 3508/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3808 - val_loss: 166.9305\n",
      "Epoch 3509/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.2982 - val_loss: 139.5569\n",
      "Epoch 3510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6197 - val_loss: 142.0598\n",
      "Epoch 3511/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6923 - val_loss: 147.7741\n",
      "Epoch 3512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1381 - val_loss: 147.6435\n",
      "Epoch 3513/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9546 - val_loss: 146.1055\n",
      "Epoch 3514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0852 - val_loss: 140.0491\n",
      "Epoch 3515/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.2620 - val_loss: 139.5033\n",
      "Epoch 3516/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8990 - val_loss: 161.5924\n",
      "Epoch 3517/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7711 - val_loss: 139.2346\n",
      "Epoch 3518/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4269 - val_loss: 183.3284\n",
      "Epoch 3519/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.5398 - val_loss: 147.3158\n",
      "Epoch 3520/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 151.9845 - val_loss: 141.9568\n",
      "Epoch 3521/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 124.6667 - val_loss: 145.7684\n",
      "Epoch 3522/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8923 - val_loss: 157.2482\n",
      "Epoch 3523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3058 - val_loss: 145.7093\n",
      "Epoch 3524/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.9900 - val_loss: 156.0098\n",
      "Epoch 3525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7947 - val_loss: 153.9581\n",
      "Epoch 3526/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0450 - val_loss: 146.6115\n",
      "Epoch 3527/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5592 - val_loss: 152.4230\n",
      "Epoch 3528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0607 - val_loss: 150.5252\n",
      "Epoch 3529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4779 - val_loss: 154.6427\n",
      "Epoch 3530/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5228 - val_loss: 154.1718\n",
      "Epoch 3531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9885 - val_loss: 153.9215\n",
      "Epoch 3532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9466 - val_loss: 147.7108\n",
      "Epoch 3533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6100 - val_loss: 135.6004\n",
      "Epoch 3534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5700 - val_loss: 157.3008\n",
      "Epoch 3535/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7134 - val_loss: 164.0144\n",
      "Epoch 3536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0053 - val_loss: 143.3536\n",
      "Epoch 3537/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6954 - val_loss: 156.0408\n",
      "Epoch 3538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3437 - val_loss: 182.8360\n",
      "Epoch 3539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.1141 - val_loss: 148.3682\n",
      "Epoch 3540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8704 - val_loss: 191.6573\n",
      "Epoch 3541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.4854 - val_loss: 153.0464\n",
      "Epoch 3542/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0851 - val_loss: 150.4497\n",
      "Epoch 3543/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6726 - val_loss: 146.3651\n",
      "Epoch 3544/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4058 - val_loss: 159.7141\n",
      "Epoch 3545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7102 - val_loss: 141.7515\n",
      "Epoch 3546/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8660 - val_loss: 158.9170\n",
      "Epoch 3547/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8293 - val_loss: 228.5603\n",
      "Epoch 3548/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.8307 - val_loss: 157.0928\n",
      "Epoch 3549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4436 - val_loss: 185.8089\n",
      "Epoch 3550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4846 - val_loss: 155.3945\n",
      "Epoch 3551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8407 - val_loss: 144.8578\n",
      "Epoch 3552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6839 - val_loss: 171.7918\n",
      "Epoch 3553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6974 - val_loss: 138.7420\n",
      "Epoch 3554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8185 - val_loss: 141.0000\n",
      "Epoch 3555/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.9439 - val_loss: 142.0332\n",
      "Epoch 3556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7095 - val_loss: 141.7466\n",
      "Epoch 3557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7755 - val_loss: 136.7043\n",
      "Epoch 3558/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5138 - val_loss: 137.0552\n",
      "Epoch 3559/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7044 - val_loss: 196.1834\n",
      "Epoch 3560/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0966 - val_loss: 164.7964\n",
      "Epoch 3561/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.2281 - val_loss: 140.4654\n",
      "Epoch 3562/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9452 - val_loss: 146.7873\n",
      "Epoch 3563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1861 - val_loss: 139.9910\n",
      "Epoch 3564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5900 - val_loss: 314.7879\n",
      "Epoch 3565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2368 - val_loss: 188.5189\n",
      "Epoch 3566/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8877 - val_loss: 141.3226\n",
      "Epoch 3567/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.7704 - val_loss: 138.1403\n",
      "Epoch 3568/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.7609 - val_loss: 145.5607\n",
      "Epoch 3569/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9053 - val_loss: 216.9107\n",
      "Epoch 3570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0140 - val_loss: 143.0584\n",
      "Epoch 3571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6801 - val_loss: 156.7076\n",
      "Epoch 3572/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6013 - val_loss: 216.9130\n",
      "Epoch 3573/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9719 - val_loss: 139.2834\n",
      "Epoch 3574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2514 - val_loss: 140.9082\n",
      "Epoch 3575/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0694 - val_loss: 197.8292\n",
      "Epoch 3576/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9485 - val_loss: 150.5011\n",
      "Epoch 3577/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4154 - val_loss: 181.3759\n",
      "Epoch 3578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5778 - val_loss: 195.6466\n",
      "Epoch 3579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7563 - val_loss: 150.7889\n",
      "Epoch 3580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9860 - val_loss: 254.3348\n",
      "Epoch 3581/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7428 - val_loss: 148.2133\n",
      "Epoch 3582/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3955 - val_loss: 139.0091\n",
      "Epoch 3583/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.5910 - val_loss: 150.4260\n",
      "Epoch 3584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5731 - val_loss: 140.9493\n",
      "Epoch 3585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.4466 - val_loss: 153.8494\n",
      "Epoch 3586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5542 - val_loss: 160.0318\n",
      "Epoch 3587/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9786 - val_loss: 142.4343\n",
      "Epoch 3588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7838 - val_loss: 155.2064\n",
      "Epoch 3589/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9255 - val_loss: 145.9004\n",
      "Epoch 3590/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.5830 - val_loss: 142.6994\n",
      "Epoch 3591/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0484 - val_loss: 144.3828\n",
      "Epoch 3592/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 130.2966 - val_loss: 176.1867\n",
      "Epoch 3593/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.0442 - val_loss: 143.0304\n",
      "Epoch 3594/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.2498 - val_loss: 159.4020\n",
      "Epoch 3595/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6762 - val_loss: 140.9343\n",
      "Epoch 3596/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.4089 - val_loss: 156.9669\n",
      "Epoch 3597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.3752 - val_loss: 170.4966\n",
      "Epoch 3598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4579 - val_loss: 140.1761\n",
      "Epoch 3599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4209 - val_loss: 136.7475\n",
      "Epoch 3600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6262 - val_loss: 196.9406\n",
      "Epoch 3601/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.2914 - val_loss: 148.7775\n",
      "Epoch 3602/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8220 - val_loss: 148.5099\n",
      "Epoch 3603/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2297 - val_loss: 194.6848\n",
      "Epoch 3604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8616 - val_loss: 139.2105\n",
      "Epoch 3605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6204 - val_loss: 170.1543\n",
      "Epoch 3606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8183 - val_loss: 223.1578\n",
      "Epoch 3607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4793 - val_loss: 173.3487\n",
      "Epoch 3608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6378 - val_loss: 156.0133\n",
      "Epoch 3609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6874 - val_loss: 141.0049\n",
      "Epoch 3610/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.3944 - val_loss: 140.6957\n",
      "Epoch 3611/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8878 - val_loss: 141.9513\n",
      "Epoch 3612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5261 - val_loss: 221.3507\n",
      "Epoch 3613/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7537 - val_loss: 154.3955\n",
      "Epoch 3614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4273 - val_loss: 144.5167\n",
      "Epoch 3615/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.7128 - val_loss: 168.5471\n",
      "Epoch 3616/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.7627 - val_loss: 312.1716\n",
      "Epoch 3617/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3583 - val_loss: 139.3891\n",
      "Epoch 3618/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1932 - val_loss: 143.5582\n",
      "Epoch 3619/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.5406 - val_loss: 141.8267\n",
      "Epoch 3620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3490 - val_loss: 218.1240\n",
      "Epoch 3621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.6090 - val_loss: 147.6848\n",
      "Epoch 3622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0851 - val_loss: 137.0476\n",
      "Epoch 3623/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3157 - val_loss: 173.7298\n",
      "Epoch 3624/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4744 - val_loss: 151.4318\n",
      "Epoch 3625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1452 - val_loss: 149.8097\n",
      "Epoch 3626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1800 - val_loss: 142.5310\n",
      "Epoch 3627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7124 - val_loss: 164.2442\n",
      "Epoch 3628/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.3097 - val_loss: 140.7816\n",
      "Epoch 3629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8209 - val_loss: 206.1444\n",
      "Epoch 3630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3466 - val_loss: 140.5060\n",
      "Epoch 3631/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.6274 - val_loss: 138.2500\n",
      "Epoch 3632/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.9189 - val_loss: 137.5985\n",
      "Epoch 3633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5465 - val_loss: 148.2573\n",
      "Epoch 3634/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.1125 - val_loss: 137.9956\n",
      "Epoch 3635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3524 - val_loss: 155.0577\n",
      "Epoch 3636/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.9185 - val_loss: 171.9602\n",
      "Epoch 3637/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.1334 - val_loss: 258.4534\n",
      "Epoch 3638/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 142.394 - 0s 51us/step - loss: 140.7811 - val_loss: 145.0498\n",
      "Epoch 3639/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.7964 - val_loss: 137.8660\n",
      "Epoch 3640/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 134.713 - 0s 51us/step - loss: 134.5336 - val_loss: 152.7533\n",
      "Epoch 3641/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.0396 - val_loss: 158.7790\n",
      "Epoch 3642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1104 - val_loss: 198.8159\n",
      "Epoch 3643/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7252 - val_loss: 146.2583\n",
      "Epoch 3644/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2732 - val_loss: 138.5297\n",
      "Epoch 3645/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9017 - val_loss: 152.5184\n",
      "Epoch 3646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2053 - val_loss: 145.3170\n",
      "Epoch 3647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5878 - val_loss: 147.8422\n",
      "Epoch 3648/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0311 - val_loss: 145.4783\n",
      "Epoch 3649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.4939 - val_loss: 155.4695\n",
      "Epoch 3650/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7099 - val_loss: 353.2083\n",
      "Epoch 3651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0095 - val_loss: 147.8105\n",
      "Epoch 3652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9069 - val_loss: 325.3986\n",
      "Epoch 3653/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9416 - val_loss: 144.3360\n",
      "Epoch 3654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6303 - val_loss: 170.4784\n",
      "Epoch 3655/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4495 - val_loss: 159.4011\n",
      "Epoch 3656/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.2603 - val_loss: 137.5321\n",
      "Epoch 3657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.3879 - val_loss: 237.0189\n",
      "Epoch 3658/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3020 - val_loss: 152.7451\n",
      "Epoch 3659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0848 - val_loss: 142.4859\n",
      "Epoch 3660/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0473 - val_loss: 149.4478\n",
      "Epoch 3661/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.9568 - val_loss: 159.6663\n",
      "Epoch 3662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1397 - val_loss: 217.3551\n",
      "Epoch 3663/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4365 - val_loss: 153.1697\n",
      "Epoch 3664/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9593 - val_loss: 143.0996\n",
      "Epoch 3665/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.8685 - val_loss: 157.2071\n",
      "Epoch 3666/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.0044 - val_loss: 147.0909\n",
      "Epoch 3667/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.6960 - val_loss: 134.7034\n",
      "Epoch 3668/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.5108 - val_loss: 184.1182\n",
      "Epoch 3669/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2086 - val_loss: 145.0315\n",
      "Epoch 3670/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7391 - val_loss: 142.8986\n",
      "Epoch 3671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2651 - val_loss: 162.2695\n",
      "Epoch 03671: early stopping\n",
      "Fold score (RMSE): 12.50809383392334\n",
      "Fold #2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 7980.4315 - val_loss: 5432.5455\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4715.0950 - val_loss: 4961.1167\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 4368.2300 - val_loss: 4558.4142\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4265.1165 - val_loss: 4633.8906\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 4180.2302 - val_loss: 4593.9931\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 4098.6005 - val_loss: 4385.0999\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4084.9001 - val_loss: 4355.0151\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 4037.4743 - val_loss: 4770.2225\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3934.0919 - val_loss: 4162.5703\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3795.9191 - val_loss: 6098.9017\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3884.8783 - val_loss: 4011.9127\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3569.6333 - val_loss: 3870.6855\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 3417.7474 - val_loss: 3449.3249\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3252.7613 - val_loss: 4354.3934\n",
      "Epoch 15/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 2932.6478 - val_loss: 3595.3918\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 2768.3590 - val_loss: 2617.3199\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2459.5943 - val_loss: 2035.1077\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 2495.1550 - val_loss: 2163.7456\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1997.7413 - val_loss: 1625.0526\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 1705.8727 - val_loss: 1221.8094\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 1404.8471 - val_loss: 1592.0824\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1157.7930 - val_loss: 930.8080\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 1060.5005 - val_loss: 1183.6343\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 877.9275 - val_loss: 850.4139\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 800.5973 - val_loss: 521.8610\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 864.5729 - val_loss: 559.0336\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 719.8987 - val_loss: 1478.7891\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 726.1998 - val_loss: 515.1021\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 629.4358 - val_loss: 499.7961\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 585.0881 - val_loss: 585.7181\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 586.1368 - val_loss: 898.3118\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 611.6918 - val_loss: 934.1715\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 585.6398 - val_loss: 474.9003\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 503.7748 - val_loss: 393.2992\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 533.7693 - val_loss: 532.9402\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 556.5746 - val_loss: 392.6008\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 552.8960 - val_loss: 415.2696\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 462.7530 - val_loss: 465.0444\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 516.4687 - val_loss: 365.3747\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 576.0319 - val_loss: 346.9303\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 468.2352 - val_loss: 380.8486\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 441.6287 - val_loss: 761.4365\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 435.0827 - val_loss: 396.1574\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 459.4057 - val_loss: 372.3296\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 527.8587 - val_loss: 442.2633\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 461.8851 - val_loss: 355.6942\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 454.5956 - val_loss: 368.9027\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 422.5639 - val_loss: 602.0492\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 488.6007 - val_loss: 424.8400\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 475.2155 - val_loss: 415.5035\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 554.4068 - val_loss: 643.1386\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 530.2219 - val_loss: 347.3779\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 432.4410 - val_loss: 893.7038\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 440.2551 - val_loss: 868.0716\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 382.0407 - val_loss: 288.5349\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 489.8815 - val_loss: 538.9923\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 374.7622 - val_loss: 347.1814\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 431.1027 - val_loss: 373.6777\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 468.3294 - val_loss: 1720.6791\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 434.0522 - val_loss: 303.7629\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 404.9495 - val_loss: 1837.1744\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 365.6549 - val_loss: 320.9005\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 392.8889 - val_loss: 501.9893\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 418.6585 - val_loss: 967.4368\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 540.8579 - val_loss: 434.0385\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 358.4287 - val_loss: 414.4159\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 382.1955 - val_loss: 342.1804\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 365.5992 - val_loss: 293.9081\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 375.7220 - val_loss: 492.5978\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 408.7472 - val_loss: 374.2298\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 318.7124 - val_loss: 1035.9834\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 417.4368 - val_loss: 297.1641\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 332.3551 - val_loss: 265.8736\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 381.8872 - val_loss: 341.0605\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 378.5593 - val_loss: 301.1199\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 369.8991 - val_loss: 270.0822\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 321.7448 - val_loss: 290.1726\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 356.0117 - val_loss: 346.2156\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 368.8151 - val_loss: 254.6291\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 356.5293 - val_loss: 313.4678\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 317.6972 - val_loss: 253.3548\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 382.5572 - val_loss: 328.0253\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 302.6401 - val_loss: 382.2746\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 408.0874 - val_loss: 325.9303\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 309.7072 - val_loss: 285.4589\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 317.0417 - val_loss: 353.2475\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 308.6691 - val_loss: 489.4327\n",
      "Epoch 88/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 362.4789 - val_loss: 395.0924\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 489.3388 - val_loss: 255.5420\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 315.6401 - val_loss: 293.4612\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 333.8379 - val_loss: 409.8123\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 532.5518 - val_loss: 491.9534\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 356.5316 - val_loss: 302.9985\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 281.3862 - val_loss: 242.4098\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 287.3319 - val_loss: 301.2928\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 303.6803 - val_loss: 343.2424\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 356.809 - 0s 51us/step - loss: 354.0205 - val_loss: 278.3284\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 291.4561 - val_loss: 631.4965\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 331.1329 - val_loss: 263.7617\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 283.9641 - val_loss: 369.6871\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 291.5730 - val_loss: 293.9956\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 303.9128 - val_loss: 226.2099\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 328.0665 - val_loss: 309.4621\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 303.2631 - val_loss: 396.9785\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 363.2465 - val_loss: 273.4364\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 297.1720 - val_loss: 242.4023\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 289.1199 - val_loss: 507.1829\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 368.3407 - val_loss: 1715.4279\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 335.9680 - val_loss: 321.9222\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 324.8252 - val_loss: 236.7055\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 301.9442 - val_loss: 266.2207\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 380.3291 - val_loss: 415.9355\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.7689 - val_loss: 226.9324\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 315.0108 - val_loss: 261.4922\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.7618 - val_loss: 743.0744\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 316.7235 - val_loss: 268.3505\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 303.2168 - val_loss: 539.5182\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 327.1361 - val_loss: 340.4903\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 293.3728 - val_loss: 234.6678\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.4392 - val_loss: 320.7787\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 339.2400 - val_loss: 317.4412\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 347.4170 - val_loss: 251.6237\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 293.0891 - val_loss: 256.9250\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 272.9592 - val_loss: 238.5674\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 312.7975 - val_loss: 314.0863\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 257.1919 - val_loss: 254.2045\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 306.4389 - val_loss: 243.9010\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 254.9486 - val_loss: 448.5818\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 285.4031 - val_loss: 379.2532\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 286.5415 - val_loss: 321.2221\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 294.8109 - val_loss: 263.2327\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 322.9524 - val_loss: 215.4115\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 242.7004 - val_loss: 216.1201\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 269.1028 - val_loss: 240.1512\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 247.8324 - val_loss: 330.6528\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 392.9342 - val_loss: 303.9296\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 270.2437 - val_loss: 285.6029\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 384.7018 - val_loss: 220.1921\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 243.6197 - val_loss: 357.3216\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 287.1265 - val_loss: 488.3855\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 315.1245 - val_loss: 202.9544\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 300.6653 - val_loss: 267.7130\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 282.7512 - val_loss: 213.7580\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.7916 - val_loss: 276.4216\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 257.8837 - val_loss: 235.2721\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.4639 - val_loss: 253.0533\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 266.3219 - val_loss: 240.0796\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.8141 - val_loss: 210.4620\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 396.6281 - val_loss: 241.4684\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.0633 - val_loss: 241.0843\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 285.2033 - val_loss: 389.2398\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 270.0566 - val_loss: 658.9711\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 273.3501 - val_loss: 2043.2196\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 657.6294 - val_loss: 253.3437\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 284.4313 - val_loss: 205.8818\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.1100 - val_loss: 201.8571\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 258.0825 - val_loss: 212.0715\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 331.5237 - val_loss: 229.2430\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 270.5379 - val_loss: 230.7444\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 248.3784 - val_loss: 285.0787\n",
      "Epoch 161/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 332.4305 - val_loss: 276.0174\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 239.2201 - val_loss: 253.1784\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.3488 - val_loss: 269.2207\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 242.1403 - val_loss: 238.3123\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 301.6631 - val_loss: 229.4060\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.0012 - val_loss: 197.9595\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 261.1811 - val_loss: 295.0118\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.2325 - val_loss: 217.4825\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 227.7303 - val_loss: 232.7883\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 352.1233 - val_loss: 279.8386\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.9953 - val_loss: 214.3383\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 282.3617 - val_loss: 189.2793\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 215.7696 - val_loss: 202.8012\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 278.2827 - val_loss: 1069.6184\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 272.7661 - val_loss: 194.7293\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 239.8431 - val_loss: 444.2291\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.5398 - val_loss: 271.3664\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.9477 - val_loss: 205.0005\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.6075 - val_loss: 501.8171\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 294.0781 - val_loss: 261.6776\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.1169 - val_loss: 1128.6185\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 225.0920 - val_loss: 242.8639\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.2021 - val_loss: 311.3476\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.6543 - val_loss: 306.3636\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.3884 - val_loss: 243.2044\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 270.0481 - val_loss: 229.5790\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 236.9763 - val_loss: 1022.0129\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 319.7903 - val_loss: 210.4653\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.2534 - val_loss: 233.7408\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.4632 - val_loss: 280.4420\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.2024 - val_loss: 205.4111\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 222.1786 - val_loss: 205.0680\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 231.9970 - val_loss: 212.1114\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 268.7585 - val_loss: 177.8732\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 252.4098 - val_loss: 212.2255\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.5458 - val_loss: 187.6544\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.5735 - val_loss: 199.0737\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.3239 - val_loss: 297.2988\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.9659 - val_loss: 394.3331\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.7737 - val_loss: 217.0767\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 264.1479 - val_loss: 297.6273\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 375.1365 - val_loss: 408.6694\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 342.6299 - val_loss: 226.6347\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 251.8202 - val_loss: 188.3298\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 206.1670 - val_loss: 262.5497\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.9347 - val_loss: 469.1765\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 234.1950 - val_loss: 177.5226\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 224.9853 - val_loss: 287.8496\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 238.6004 - val_loss: 241.6286\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 237.9250 - val_loss: 446.4767\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 258.0805 - val_loss: 257.2736\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 230.3076 - val_loss: 347.4366\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 260.5539 - val_loss: 379.4821\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 274.0179 - val_loss: 172.4340\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.0211 - val_loss: 469.0996\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 265.5000 - val_loss: 204.0357\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.8229 - val_loss: 177.6842\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.9070 - val_loss: 1712.4879\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 277.9160 - val_loss: 185.6408\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.8850 - val_loss: 283.0506\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.4272 - val_loss: 200.6580\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.1869 - val_loss: 324.5752\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.4634 - val_loss: 215.7157\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.4492 - val_loss: 265.3233\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 354.4705 - val_loss: 284.1745\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.9453 - val_loss: 332.7826\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.7840 - val_loss: 171.7287\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.2886 - val_loss: 255.7666\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.0939 - val_loss: 234.2524\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 248.9870 - val_loss: 193.5818\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 346.5958 - val_loss: 199.9853\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 217.4726 - val_loss: 178.8771\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.5792 - val_loss: 166.0539\n",
      "Epoch 234/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.8076 - val_loss: 213.0173\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.9470 - val_loss: 220.0097\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 295.6401 - val_loss: 447.5375\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.2491 - val_loss: 244.4728\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 280.7222 - val_loss: 360.7907\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.8378 - val_loss: 179.7947\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.2066 - val_loss: 197.7127\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.5198 - val_loss: 261.3910\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.5861 - val_loss: 185.1465\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 282.5973 - val_loss: 382.5792\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 206.1714 - val_loss: 165.6785\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 263.2189 - val_loss: 200.6314\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 197.2709 - val_loss: 364.4603\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 276.0301 - val_loss: 190.6168\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.9062 - val_loss: 317.3332\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.6589 - val_loss: 235.1617\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.8021 - val_loss: 229.6275\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 663.1072 - val_loss: 1105.3819\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 406.7149 - val_loss: 263.9954\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 325.1803 - val_loss: 246.8761\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 286.5998 - val_loss: 264.9166\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 273.2188 - val_loss: 179.5470\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.8217 - val_loss: 308.3834\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 214.7075 - val_loss: 230.5660\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.5001 - val_loss: 250.2712\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.2523 - val_loss: 410.9300\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.2794 - val_loss: 211.3569\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 268.7464 - val_loss: 187.4750\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.5145 - val_loss: 166.8643\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.4041 - val_loss: 229.9891\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.9248 - val_loss: 214.0815\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.1209 - val_loss: 193.1273\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 269.9955 - val_loss: 209.7197\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.1361 - val_loss: 178.9747\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.8179 - val_loss: 187.8853\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.4650 - val_loss: 192.1046\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 279.0708 - val_loss: 218.0353\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.7700 - val_loss: 278.0811\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.8934 - val_loss: 225.4481\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 430.6577 - val_loss: 189.3159\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 220.5511 - val_loss: 186.7264\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.7531 - val_loss: 191.2129\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.2573 - val_loss: 198.2138\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.0763 - val_loss: 245.5933\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.0700 - val_loss: 264.4159\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.9528 - val_loss: 194.8062\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 244.9698 - val_loss: 189.6645\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 225.9213 - val_loss: 175.3481\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 189.8804 - val_loss: 166.4462\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 197.1563 - val_loss: 167.4353\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 181.8928 - val_loss: 167.8611\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.8363 - val_loss: 193.4681\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.0185 - val_loss: 258.5605\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.3484 - val_loss: 709.4917\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.6762 - val_loss: 188.2520\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9405 - val_loss: 288.2147\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.2655 - val_loss: 170.5388\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.3996 - val_loss: 249.8453\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 280.3007 - val_loss: 193.4758\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.9206 - val_loss: 189.2132\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.9879 - val_loss: 256.0358\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.1181 - val_loss: 181.4027\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.2439 - val_loss: 344.4037\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 298.683 - 0s 51us/step - loss: 295.1280 - val_loss: 253.7715\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 321.3336 - val_loss: 506.2230\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 290.5271 - val_loss: 173.3962\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 196.3262 - val_loss: 183.7153\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.4407 - val_loss: 163.8114\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.9028 - val_loss: 179.9116\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.9993 - val_loss: 171.4317\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.1518 - val_loss: 199.4185\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.9914 - val_loss: 173.0142\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.0513 - val_loss: 191.2078\n",
      "Epoch 307/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.0769 - val_loss: 168.8848\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.5762 - val_loss: 259.1424\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.8451 - val_loss: 193.3732\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 289.5574 - val_loss: 366.2515\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.6446 - val_loss: 164.1906\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0648 - val_loss: 163.2316\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.5456 - val_loss: 177.9757\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.5762 - val_loss: 158.2699\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3873 - val_loss: 224.0941\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.6979 - val_loss: 177.1277\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 266.0454 - val_loss: 477.3760\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.7496 - val_loss: 296.7600\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.1578 - val_loss: 402.1770\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.7281 - val_loss: 153.1754\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.4286 - val_loss: 161.4811\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 217.0576 - val_loss: 284.5246\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.3734 - val_loss: 199.9346\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.9793 - val_loss: 162.6554\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 630.6428 - val_loss: 681.9318\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 386.2358 - val_loss: 334.4463\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 376.8246 - val_loss: 258.0250\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 310.3323 - val_loss: 243.7630\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 308.0210 - val_loss: 510.4253\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 282.1902 - val_loss: 332.4502\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 241.3751 - val_loss: 237.5125\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.1126 - val_loss: 223.2871\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 240.6100 - val_loss: 286.7159\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 209.7518 - val_loss: 193.8506\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.9384 - val_loss: 181.2892\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.6463 - val_loss: 352.3554\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.8473 - val_loss: 435.9028\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.6226 - val_loss: 201.5821\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.8417 - val_loss: 191.9554\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.5390 - val_loss: 207.8305\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.3895 - val_loss: 186.0129\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.2104 - val_loss: 170.2988\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.3898 - val_loss: 176.4392\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.5957 - val_loss: 237.2687\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.9494 - val_loss: 438.5471\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.5700 - val_loss: 174.5374\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.5260 - val_loss: 493.6656\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.7615 - val_loss: 378.4016\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 245.9770 - val_loss: 183.1859\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.9056 - val_loss: 202.4724\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 200.0402 - val_loss: 165.8908\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 216.9290 - val_loss: 179.9311\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 206.5804 - val_loss: 355.2646\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 204.8880 - val_loss: 181.5367\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 241.7094 - val_loss: 268.7978\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.4560 - val_loss: 184.7894\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.4269 - val_loss: 204.2135\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.4996 - val_loss: 172.2230\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.5283 - val_loss: 205.2515\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5029 - val_loss: 167.4666\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.7805 - val_loss: 222.8033\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.9873 - val_loss: 481.7384\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.2108 - val_loss: 237.8486\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 220.9834 - val_loss: 166.2296\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.6186 - val_loss: 194.1778\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.5453 - val_loss: 173.6588\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.2240 - val_loss: 159.2563\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.3622 - val_loss: 192.7377\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.4687 - val_loss: 210.0092\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.7111 - val_loss: 192.0507\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.7909 - val_loss: 169.2960\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.7784 - val_loss: 162.0793\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.8930 - val_loss: 207.2078\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.9986 - val_loss: 204.1444\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.9516 - val_loss: 160.8635\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.9630 - val_loss: 265.1308\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.6374 - val_loss: 180.4726\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.0826 - val_loss: 230.9183\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.5962 - val_loss: 217.6165\n",
      "Epoch 380/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.4226 - val_loss: 258.9962\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.0638 - val_loss: 182.5437\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.7894 - val_loss: 193.8566\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.2218 - val_loss: 180.2657\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.1886 - val_loss: 189.2942\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.1982 - val_loss: 230.2104\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5683 - val_loss: 159.4411\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.0079 - val_loss: 284.8484\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.5469 - val_loss: 158.9396\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.3968 - val_loss: 214.6411\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.1253 - val_loss: 215.2343\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.1970 - val_loss: 200.7543\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.3771 - val_loss: 257.7509\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.4591 - val_loss: 202.1839\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 261.3303 - val_loss: 202.2900\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.0961 - val_loss: 184.0377\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.2827 - val_loss: 209.8265\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.5063 - val_loss: 190.8635\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.1819 - val_loss: 163.5393\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.2958 - val_loss: 210.1299\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.0284 - val_loss: 230.2987\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1458 - val_loss: 225.1022\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.6757 - val_loss: 173.3280\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.8397 - val_loss: 296.5400\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.9099 - val_loss: 215.0551\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 225.9881 - val_loss: 199.9329\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 351.5572 - val_loss: 204.4462\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.7488 - val_loss: 167.3775\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.3736 - val_loss: 243.5485\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.6813 - val_loss: 469.4336\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.4120 - val_loss: 159.3856\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.6710 - val_loss: 181.0197\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.9808 - val_loss: 179.8729\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8176 - val_loss: 152.0340\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 283.9670 - val_loss: 175.8562\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.6922 - val_loss: 170.0384\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.7156 - val_loss: 361.1151\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.9002 - val_loss: 204.2204\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.3014 - val_loss: 185.5344\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.3732 - val_loss: 391.9441\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 228.9555 - val_loss: 156.6143\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.7499 - val_loss: 180.2133\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3343 - val_loss: 200.1045\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 163.8153 - val_loss: 189.9924\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 188.3582 - val_loss: 168.4798\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 180.3247 - val_loss: 246.0868\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 179.5142 - val_loss: 160.0038\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.4282 - val_loss: 403.2557\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 198.0871 - val_loss: 158.9522\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.7561 - val_loss: 169.2603\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.7661 - val_loss: 167.2632\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.6467 - val_loss: 242.9326\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.8913 - val_loss: 167.5279\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.1227 - val_loss: 184.8495\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.4455 - val_loss: 189.4495\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.4366 - val_loss: 156.9864\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.6685 - val_loss: 159.8919\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.3033 - val_loss: 156.6598\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.9690 - val_loss: 166.8292\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.7230 - val_loss: 174.8057\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.4906 - val_loss: 158.0215\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.0598 - val_loss: 339.6798\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.9967 - val_loss: 175.4665\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.9137 - val_loss: 210.0819\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.0797 - val_loss: 166.4347\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2454 - val_loss: 220.3541\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.9741 - val_loss: 156.2359\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9026 - val_loss: 170.2799\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.6222 - val_loss: 173.2866\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8259 - val_loss: 199.0262\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.4965 - val_loss: 218.4005\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.3091 - val_loss: 247.0266\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.5252 - val_loss: 253.9858\n",
      "Epoch 453/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.7249 - val_loss: 822.9954\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 347.3136 - val_loss: 195.8807\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.3836 - val_loss: 157.7915\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.4344 - val_loss: 166.8298\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.5061 - val_loss: 186.3915\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.2548 - val_loss: 197.0469\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.6822 - val_loss: 161.3748\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.3535 - val_loss: 214.9164\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.5625 - val_loss: 316.9874\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 196.1903 - val_loss: 188.2977\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9017 - val_loss: 195.7874\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 171.7260 - val_loss: 153.4486\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.4497 - val_loss: 154.2533\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 191.5965 - val_loss: 212.1884\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.3498 - val_loss: 209.2103\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.8520 - val_loss: 154.0671\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.4382 - val_loss: 172.5155\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.2649 - val_loss: 235.8826\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.4552 - val_loss: 156.8122\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.7672 - val_loss: 175.7286\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.2329 - val_loss: 208.2425\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.7634 - val_loss: 158.7318\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.9281 - val_loss: 229.7262\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.5616 - val_loss: 199.4403\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6474 - val_loss: 156.2143\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.3884 - val_loss: 209.5446\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.8670 - val_loss: 283.0810\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 196.9834 - val_loss: 151.3520\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.3221 - val_loss: 335.8454\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.6697 - val_loss: 164.7349\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 194.1954 - val_loss: 226.8439\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.2099 - val_loss: 170.2778\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3327 - val_loss: 246.7659\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3127 - val_loss: 197.7437\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.9596 - val_loss: 152.5813\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.3112 - val_loss: 153.2549\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.1283 - val_loss: 161.5310\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.8807 - val_loss: 171.1211\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.7433 - val_loss: 191.6353\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.9841 - val_loss: 176.5374\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 170.5881 - val_loss: 159.0114\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.1294 - val_loss: 260.1429\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.7267 - val_loss: 160.9244\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1036 - val_loss: 214.2649\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.7728 - val_loss: 168.0790\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3965 - val_loss: 188.3382\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.7605 - val_loss: 182.6524\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.9085 - val_loss: 158.3645\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.0410 - val_loss: 161.4034\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.8399 - val_loss: 198.4906\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5466 - val_loss: 179.5906\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 185.0234 - val_loss: 170.8365\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 181.5522 - val_loss: 151.5837\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 181.2681 - val_loss: 164.6094\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 155.3739 - val_loss: 235.3262\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.9576 - val_loss: 165.1157\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4095 - val_loss: 181.7339\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.2628 - val_loss: 179.0789\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.9813 - val_loss: 534.1614\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.1220 - val_loss: 318.6081\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 180.0008 - val_loss: 193.0517\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 185.4302 - val_loss: 283.5290\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.5622 - val_loss: 159.5900\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.3975 - val_loss: 156.3211\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.1558 - val_loss: 153.8604\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3470 - val_loss: 212.3826\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.7565 - val_loss: 218.7083\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 190.4557 - val_loss: 163.1402\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 184.9405 - val_loss: 174.7720\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 208.7576 - val_loss: 284.4143\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 183.4265 - val_loss: 229.9168\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 160.6383 - val_loss: 172.6011\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 160.8596 - val_loss: 172.8704\n",
      "Epoch 526/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 59us/step - loss: 169.9640 - val_loss: 191.3784\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 179.1370 - val_loss: 408.1078\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 260.1386 - val_loss: 155.0276\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 172.5654 - val_loss: 152.7542\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 158.3114 - val_loss: 196.2057\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 162.8412 - val_loss: 190.2336\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 157.2623 - val_loss: 149.5322\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 257.5266 - val_loss: 222.0116\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 155.1994 - val_loss: 177.7124\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 159.9956 - val_loss: 216.1081\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 167.0267 - val_loss: 215.0093\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 194.3298 - val_loss: 181.2186\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 158.4058 - val_loss: 201.4625\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 160.1909 - val_loss: 187.6913\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 167.2602 - val_loss: 152.3927\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.3146 - val_loss: 151.7051\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 171.1707 - val_loss: 194.5683\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.2835 - val_loss: 326.9114\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 174.4464 - val_loss: 162.8306\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.7018 - val_loss: 188.0154\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 182.7569 - val_loss: 231.8974\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.1794 - val_loss: 151.3652\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 174.7637 - val_loss: 232.6757\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 179.4313 - val_loss: 193.9569\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 247.9926 - val_loss: 240.1101\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 189.3492 - val_loss: 198.7853\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 177.5334 - val_loss: 148.2564\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 173.9082 - val_loss: 159.5267\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.6886 - val_loss: 154.1416\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.8502 - val_loss: 295.4072\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 166.3522 - val_loss: 223.3824\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 165.9587 - val_loss: 188.9227\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.4276 - val_loss: 161.9748\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 191.4605 - val_loss: 165.7054\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 178.9562 - val_loss: 186.7304\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 186.5951 - val_loss: 454.6026\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 197.6337 - val_loss: 216.5816- ETA: 0s - loss: \n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 158.1082 - val_loss: 267.6458\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 211.7420 - val_loss: 192.3043\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 159.6784 - val_loss: 159.1973\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 180.6425 - val_loss: 197.6559\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 278.5444 - val_loss: 158.6406\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 169.8528 - val_loss: 152.5487\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 159.5432 - val_loss: 301.3739\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 152.5944 - val_loss: 149.2812\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 194.7307 - val_loss: 345.6556\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.1930 - val_loss: 200.8830\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.3016 - val_loss: 219.7460\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.0709 - val_loss: 190.3492\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.8654 - val_loss: 200.2189\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.9055 - val_loss: 178.5966\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 211.4642 - val_loss: 222.1580\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.5737 - val_loss: 252.0306\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.4470 - val_loss: 163.9563\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.7937 - val_loss: 169.2116\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.6608 - val_loss: 175.9410\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.0060 - val_loss: 341.9663\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.7190 - val_loss: 183.3562\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.7096 - val_loss: 158.0753\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 209.4153 - val_loss: 198.9810\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.6519 - val_loss: 183.4486\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.2373 - val_loss: 227.1226\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.8260 - val_loss: 197.2535\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.5014 - val_loss: 160.5091\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.4113 - val_loss: 157.0176\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4310 - val_loss: 197.7107\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 507.1246 - val_loss: 294.3089\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.9437 - val_loss: 162.9004\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.7217 - val_loss: 164.1460\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.6496 - val_loss: 168.0391\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2029 - val_loss: 185.1368\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.7426 - val_loss: 188.4906\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.2766 - val_loss: 197.8682\n",
      "Epoch 599/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.3224 - val_loss: 209.1947\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.7680 - val_loss: 166.3277\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.0921 - val_loss: 155.6001\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.9179 - val_loss: 177.2102\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.2879 - val_loss: 185.4053\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.3231 - val_loss: 167.6671\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.6222 - val_loss: 242.3182\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 261.5719 - val_loss: 180.1683\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.1699 - val_loss: 178.4284\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.5432 - val_loss: 149.7593\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.5562 - val_loss: 216.7731\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.5320 - val_loss: 163.2649\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.7767 - val_loss: 212.9070\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.5225 - val_loss: 162.8307\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.1432 - val_loss: 154.1227\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 243.8809 - val_loss: 217.7041\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.2671 - val_loss: 175.4522\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.1412 - val_loss: 159.1146\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.7079 - val_loss: 152.2097\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.7171 - val_loss: 151.2958\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.0341 - val_loss: 182.9353\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.0219 - val_loss: 164.6316\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.2685 - val_loss: 180.4442\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.4657 - val_loss: 315.6917\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.9010 - val_loss: 176.1368\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7626 - val_loss: 184.8122\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.1846 - val_loss: 152.8934\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1176 - val_loss: 161.7536\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.6061 - val_loss: 149.0432\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 162.4223 - val_loss: 158.7875\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 157.9689 - val_loss: 205.3615\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.7241 - val_loss: 165.2189\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 250.9494 - val_loss: 173.7988\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.4687 - val_loss: 172.7354\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 237.6974 - val_loss: 289.4410\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.6883 - val_loss: 172.6375\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.7503 - val_loss: 163.9841\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.9473 - val_loss: 239.0331\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5951 - val_loss: 165.3171\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.8852 - val_loss: 232.9941\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.9391 - val_loss: 154.7846\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4262 - val_loss: 149.9771\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.5713 - val_loss: 170.1598\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.5366 - val_loss: 151.5503\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.5561 - val_loss: 219.5769\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.8347 - val_loss: 165.7361\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3270 - val_loss: 163.0280\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.8542 - val_loss: 188.2219\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.0753 - val_loss: 168.7045\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.7664 - val_loss: 162.6844\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.6848 - val_loss: 177.3004\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.4054 - val_loss: 163.1974\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.6587 - val_loss: 190.2872\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.9319 - val_loss: 171.8666\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0616 - val_loss: 222.3783\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.8599 - val_loss: 199.2762\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.7330 - val_loss: 194.1529\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.9482 - val_loss: 211.4818\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.1222 - val_loss: 153.5359\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.3338 - val_loss: 385.5482\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.0941 - val_loss: 238.3568\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.8447 - val_loss: 184.8593\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.2390 - val_loss: 169.6134\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.5832 - val_loss: 159.7744\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7300 - val_loss: 227.9370\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 373.7353 - val_loss: 209.2867\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5158 - val_loss: 165.2325\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9303 - val_loss: 177.9001\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.6661 - val_loss: 256.4110\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.1792 - val_loss: 169.5310\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.4351 - val_loss: 318.1221\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.2610 - val_loss: 241.1398\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.7949 - val_loss: 154.9287\n",
      "Epoch 672/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.0046 - val_loss: 193.9778\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.0285 - val_loss: 148.2415\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.9138 - val_loss: 157.4730\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.1253 - val_loss: 191.3914\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4022 - val_loss: 150.6898\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.0704 - val_loss: 187.8839\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.6306 - val_loss: 157.8891\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2839 - val_loss: 182.5297\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.3822 - val_loss: 149.0569\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9226 - val_loss: 208.0230\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.6130 - val_loss: 154.2819\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.1183 - val_loss: 354.3654\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.4840 - val_loss: 229.3659\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3363 - val_loss: 156.3816\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.4639 - val_loss: 192.1281\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.1151 - val_loss: 162.3447\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0390 - val_loss: 208.1391\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.9556 - val_loss: 199.3022\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6057 - val_loss: 173.0894\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.7003 - val_loss: 269.6519\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.2133 - val_loss: 191.2862\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4224 - val_loss: 259.2963\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.4659 - val_loss: 153.0324\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8857 - val_loss: 159.2581\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.7299 - val_loss: 159.7162\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.9820 - val_loss: 156.5550\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.4807 - val_loss: 195.7577\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.3355 - val_loss: 165.1797\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 184.5679 - val_loss: 188.2673\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 186.2955 - val_loss: 149.1935\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 158.0239 - val_loss: 172.9283\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 156.6418 - val_loss: 154.5316\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.2548 - val_loss: 156.5153\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.1572 - val_loss: 154.3459\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.0464 - val_loss: 300.9377\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.7183 - val_loss: 242.1056\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.3796 - val_loss: 177.0931\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.0892 - val_loss: 163.4746\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.8834 - val_loss: 143.8029\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.5271 - val_loss: 213.8507\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0761 - val_loss: 172.4839\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.2734 - val_loss: 203.8499\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.7546 - val_loss: 165.5909\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.2726 - val_loss: 151.9138\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.8320 - val_loss: 150.8478\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.2688 - val_loss: 214.6979\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.0086 - val_loss: 164.9346\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.5444 - val_loss: 163.5131\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.2727 - val_loss: 155.7772\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.0268 - val_loss: 260.6590\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0233 - val_loss: 167.5002\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6455 - val_loss: 171.9633\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.9087 - val_loss: 152.7656\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7009 - val_loss: 198.8808\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.1163 - val_loss: 151.5693\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.5137 - val_loss: 152.9575\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7382 - val_loss: 193.1746\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6286 - val_loss: 250.8076\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.4399 - val_loss: 157.1158\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.9844 - val_loss: 197.4093\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2840 - val_loss: 186.8195\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.0913 - val_loss: 152.2145\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9811 - val_loss: 190.6102\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.4198 - val_loss: 184.9585\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.8898 - val_loss: 227.3117\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.9413 - val_loss: 162.8385\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.1937 - val_loss: 158.0857\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5430 - val_loss: 227.3892\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.3658 - val_loss: 168.7062\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2443 - val_loss: 158.2077\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6736 - val_loss: 153.0995\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.6668 - val_loss: 210.4924\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.7062 - val_loss: 189.1117\n",
      "Epoch 745/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2125 - val_loss: 146.9533\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.5837 - val_loss: 211.3170\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5348 - val_loss: 182.9988\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.8628 - val_loss: 244.8452\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.4718 - val_loss: 165.9428\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3399 - val_loss: 146.6556\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4367 - val_loss: 153.8681\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.5134 - val_loss: 177.6945\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 157.8601 - val_loss: 466.2167\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.9028 - val_loss: 169.2576\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.1748 - val_loss: 158.7391\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9038 - val_loss: 300.6820\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.7177 - val_loss: 166.0976\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5768 - val_loss: 268.6207\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.7391 - val_loss: 204.3603\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0287 - val_loss: 347.7189\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.5834 - val_loss: 149.9122\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8691 - val_loss: 211.7031\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.8110 - val_loss: 153.3326\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.1894 - val_loss: 246.0524\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 181.2965 - val_loss: 151.7283\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 154.5886 - val_loss: 167.2117\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8092 - val_loss: 154.0316\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0314 - val_loss: 226.7203\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.4635 - val_loss: 155.5702\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5019 - val_loss: 149.2478\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.8725 - val_loss: 178.7942\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.0394 - val_loss: 154.7164\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 203.7244 - val_loss: 216.6647\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 190.1562 - val_loss: 159.6342\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 141.1237 - val_loss: 203.9919\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.9998 - val_loss: 317.2884\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.1231 - val_loss: 158.7246\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.7883 - val_loss: 192.8857\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.3248 - val_loss: 209.6185\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.2080 - val_loss: 145.4267\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.9235 - val_loss: 153.4812\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.6901 - val_loss: 145.5621\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.3045 - val_loss: 218.3321\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9226 - val_loss: 235.9588\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 189.3032 - val_loss: 161.7745\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3281 - val_loss: 169.2758\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.8864 - val_loss: 358.2440\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.5226 - val_loss: 170.2730\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.0517 - val_loss: 210.0639\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.9407 - val_loss: 177.7715\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2520 - val_loss: 168.9188\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0477 - val_loss: 181.7690\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2331 - val_loss: 159.5842\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.0352 - val_loss: 152.0740\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.6508 - val_loss: 157.4399\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8875 - val_loss: 191.5150\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9613 - val_loss: 146.6213\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.1997 - val_loss: 182.1003\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4275 - val_loss: 146.0951\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.5811 - val_loss: 148.2528\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2172 - val_loss: 165.2214\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.1532 - val_loss: 150.4942\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.8985 - val_loss: 243.7588\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6842 - val_loss: 148.9139\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3340 - val_loss: 176.4014\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3227 - val_loss: 145.5553\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.8948 - val_loss: 164.7170\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9353 - val_loss: 154.2130\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7859 - val_loss: 188.3373\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9139 - val_loss: 240.2800\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.4110 - val_loss: 353.2222\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.8590 - val_loss: 168.6932\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5490 - val_loss: 149.3226\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5111 - val_loss: 167.6044\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.1562 - val_loss: 148.1926\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2092 - val_loss: 152.5441\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.9608 - val_loss: 204.2521\n",
      "Epoch 818/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.1645 - val_loss: 165.6611\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0054 - val_loss: 161.9665\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.7250 - val_loss: 151.6841\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.6548 - val_loss: 158.6106\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7673 - val_loss: 209.2327\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.7934 - val_loss: 208.3501\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8174 - val_loss: 189.4579\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.4679 - val_loss: 172.0331\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7482 - val_loss: 154.6549\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 206.0533 - val_loss: 212.9664\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.6116 - val_loss: 156.6137\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.2858 - val_loss: 145.6481\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1867 - val_loss: 192.4347\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.4732 - val_loss: 151.7928\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8574 - val_loss: 174.7832\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.9000 - val_loss: 164.0526\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3553 - val_loss: 159.6690\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.5526 - val_loss: 164.6507\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.9506 - val_loss: 183.1587\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2521 - val_loss: 157.5474\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0764 - val_loss: 225.0216\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2346 - val_loss: 165.4178\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8811 - val_loss: 272.9779\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.0713 - val_loss: 207.9339\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1592 - val_loss: 233.5815\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.4828 - val_loss: 208.8789\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4558 - val_loss: 146.7266\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 155.0755 - val_loss: 151.6763\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 146.3532 - val_loss: 222.3237\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 165.6794 - val_loss: 180.2219\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.7688 - val_loss: 187.5556\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.7894 - val_loss: 330.0228\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.0410 - val_loss: 173.0273\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.4978 - val_loss: 184.3959\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1313 - val_loss: 179.7949\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2752 - val_loss: 164.9246\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.4156 - val_loss: 215.3260\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7699 - val_loss: 164.5354\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.2729 - val_loss: 254.9635\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4467 - val_loss: 150.7547\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2338 - val_loss: 250.0875\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.7495 - val_loss: 205.7211\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 262.4613 - val_loss: 158.3289\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.4766 - val_loss: 203.9971\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6181 - val_loss: 199.4537\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0616 - val_loss: 234.0532\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.2550 - val_loss: 198.5189\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.4229 - val_loss: 159.5098\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6155 - val_loss: 189.0960\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.3017 - val_loss: 254.8063\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1952 - val_loss: 152.8455\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8680 - val_loss: 213.7517\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4090 - val_loss: 175.7399\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.8616 - val_loss: 152.3043\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3597 - val_loss: 157.6664\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0075 - val_loss: 181.5952\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.2631 - val_loss: 280.5223\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.9814 - val_loss: 158.9955\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.4875 - val_loss: 337.5218\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0960 - val_loss: 178.8084\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2105 - val_loss: 174.6804\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.9569 - val_loss: 164.5698\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8387 - val_loss: 153.9574\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3576 - val_loss: 160.1733\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.0966 - val_loss: 172.2370\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6097 - val_loss: 430.4723\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9483 - val_loss: 151.3807\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.6866 - val_loss: 164.7866\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.2885 - val_loss: 149.9218\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 246.7500 - val_loss: 239.0076\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.2078 - val_loss: 171.3362\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.9383 - val_loss: 175.3876\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.9566 - val_loss: 266.3092\n",
      "Epoch 891/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.0608 - val_loss: 165.8345\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.3834 - val_loss: 182.7173\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8046 - val_loss: 148.7471\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.2804 - val_loss: 401.0953\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.0837 - val_loss: 154.7344\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2526 - val_loss: 159.7122\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.2246 - val_loss: 183.3911\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.8228 - val_loss: 192.2810\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2266 - val_loss: 173.4353\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.6374 - val_loss: 158.6003\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6627 - val_loss: 220.8445\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.8000 - val_loss: 150.7424\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8400 - val_loss: 158.7142\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7341 - val_loss: 188.6686\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3077 - val_loss: 162.8817\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1023 - val_loss: 176.6577\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.0382 - val_loss: 143.5396\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6891 - val_loss: 164.4112\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.7946 - val_loss: 155.8308\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.2155 - val_loss: 154.1670\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.6343 - val_loss: 146.7989\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6887 - val_loss: 155.5332\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.3114 - val_loss: 149.6498\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9193 - val_loss: 166.2958\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.9043 - val_loss: 160.6318\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7399 - val_loss: 212.5541\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.3847 - val_loss: 164.2190\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 165.1190 - val_loss: 167.8787\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 150.4173 - val_loss: 163.3601\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 169.3914 - val_loss: 152.3436\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.0972 - val_loss: 183.1729\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6245 - val_loss: 167.3548\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.4971 - val_loss: 147.2577\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5174 - val_loss: 214.0376\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0660 - val_loss: 221.0534\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.6078 - val_loss: 160.6088\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0303 - val_loss: 268.0247\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8820 - val_loss: 149.5781\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5080 - val_loss: 240.5888\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1122 - val_loss: 209.6656\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6894 - val_loss: 152.5677\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2800 - val_loss: 152.0047\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.5927 - val_loss: 163.0704\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.2796 - val_loss: 244.0429\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.9545 - val_loss: 156.8212\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3363 - val_loss: 162.4917\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9429 - val_loss: 153.5294\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4399 - val_loss: 171.9987\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.6880 - val_loss: 160.1225\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2584 - val_loss: 145.7567\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.7410 - val_loss: 208.5361\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.3279 - val_loss: 159.2337\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5626 - val_loss: 167.0010\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.6596 - val_loss: 193.6825\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.2004 - val_loss: 193.1448\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.5523 - val_loss: 144.7096\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.6359 - val_loss: 171.2806\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4034 - val_loss: 182.2119\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.4289 - val_loss: 157.4678\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6860 - val_loss: 362.0893\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1221 - val_loss: 154.4769\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.8402 - val_loss: 188.2970\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.8599 - val_loss: 211.8426\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8463 - val_loss: 145.8084\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9366 - val_loss: 156.2374\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.1414 - val_loss: 162.0637\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.8795 - val_loss: 154.4487\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.2542 - val_loss: 144.6930\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.6136 - val_loss: 170.1121\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1789 - val_loss: 144.6351\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 162.0532 - val_loss: 159.8259\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3222 - val_loss: 294.9456\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.5401 - val_loss: 157.8784\n",
      "Epoch 964/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8266 - val_loss: 146.3438\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8958 - val_loss: 175.3786\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6431 - val_loss: 178.6184\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2956 - val_loss: 157.3766\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.6976 - val_loss: 153.9310\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4264 - val_loss: 170.7484\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 241.6143 - val_loss: 186.2627\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3148 - val_loss: 191.1177\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.9234 - val_loss: 167.9739\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1030 - val_loss: 170.3770\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6225 - val_loss: 170.6616\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3601 - val_loss: 190.0677\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.0979 - val_loss: 152.9071\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.6955 - val_loss: 149.2208\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8009 - val_loss: 142.2297\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4205 - val_loss: 147.3426\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.1353 - val_loss: 156.9154\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.0184 - val_loss: 240.7365\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.5030 - val_loss: 149.6370\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1312 - val_loss: 166.0130\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3940 - val_loss: 158.8983\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.1745 - val_loss: 206.5145\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2278 - val_loss: 239.3575\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 236.1951 - val_loss: 323.2626\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9609 - val_loss: 161.3104\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 160.8549 - val_loss: 152.9327\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 143.8418 - val_loss: 148.2749\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.9966 - val_loss: 153.3066\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.6554 - val_loss: 154.9204\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0715 - val_loss: 167.5881\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9708 - val_loss: 181.4022\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.6030 - val_loss: 208.4874\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.9287 - val_loss: 207.1421\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2518 - val_loss: 190.8472\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5486 - val_loss: 147.1874\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4531 - val_loss: 167.6335\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.3886 - val_loss: 168.7038\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.4605 - val_loss: 167.2406\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7832 - val_loss: 149.9379\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3232 - val_loss: 174.6509\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7819 - val_loss: 221.0681\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 168.3930 - val_loss: 161.9841\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4935 - val_loss: 148.7295\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.8384 - val_loss: 178.4723\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0331 - val_loss: 154.5362\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0875 - val_loss: 191.0086\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5266 - val_loss: 151.0723\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3505 - val_loss: 144.5173\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.7956 - val_loss: 183.3984\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.8769 - val_loss: 882.4576\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.2299 - val_loss: 182.3577\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.4323 - val_loss: 159.7207\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.9980 - val_loss: 156.7846\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8992 - val_loss: 155.3790\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.6086 - val_loss: 220.0342\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1970 - val_loss: 147.7303\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5458 - val_loss: 296.4720\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 201.6151 - val_loss: 145.8989\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3475 - val_loss: 155.8864\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.9226 - val_loss: 150.0033\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6766 - val_loss: 160.8162\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8164 - val_loss: 226.2330\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5999 - val_loss: 167.3588\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6455 - val_loss: 166.0487\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 144.0893 - val_loss: 158.1629\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5758 - val_loss: 183.2786\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.8782 - val_loss: 161.4357\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3554 - val_loss: 264.1724\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8576 - val_loss: 163.3217\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9375 - val_loss: 155.5479\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0220 - val_loss: 148.2781\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0058 - val_loss: 162.8476\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.4564 - val_loss: 148.6646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2175 - val_loss: 170.1085\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7620 - val_loss: 144.1059\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.9060 - val_loss: 175.0543\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9847 - val_loss: 149.1011\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8555 - val_loss: 160.1915\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.3635 - val_loss: 173.7083\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.7808 - val_loss: 154.8097\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.7727 - val_loss: 154.1082\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4620 - val_loss: 241.9327\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.6308 - val_loss: 153.2209\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9682 - val_loss: 142.5562\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3246 - val_loss: 170.1684\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0028 - val_loss: 156.2136\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.7021 - val_loss: 163.1299\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9049 - val_loss: 162.1755\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9178 - val_loss: 158.9746\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.4444 - val_loss: 212.8962\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.6295 - val_loss: 147.2053\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.0304 - val_loss: 144.9017\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6428 - val_loss: 178.3651\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9745 - val_loss: 196.6023\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.0554 - val_loss: 362.9184\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 210.4042 - val_loss: 184.4486\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.3605 - val_loss: 175.3975\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 177.9698 - val_loss: 173.2580\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 185.3318 - val_loss: 166.2027\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 183.8985 - val_loss: 158.2877\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 189.0983 - val_loss: 190.1861\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.6136 - val_loss: 189.8409\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.1949 - val_loss: 180.7982\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.6646 - val_loss: 172.4067\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.9932 - val_loss: 170.9980\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8561 - val_loss: 208.5758\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.5876 - val_loss: 236.7156\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4362 - val_loss: 152.3728\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2267 - val_loss: 160.5705\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.6351 - val_loss: 158.6265\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3920 - val_loss: 150.5285\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.4442 - val_loss: 186.6712\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8008 - val_loss: 163.9411\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.7043 - val_loss: 144.0101\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5653 - val_loss: 168.0057\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.7111 - val_loss: 169.5877\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 234.0400 - val_loss: 258.7805\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6983 - val_loss: 156.6418\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.8219 - val_loss: 234.6906\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2387 - val_loss: 177.4113\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4133 - val_loss: 168.5030\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6114 - val_loss: 214.4066\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3519 - val_loss: 163.6050\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.7480 - val_loss: 177.5036\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.9455 - val_loss: 152.1183\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9181 - val_loss: 150.7708\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4241 - val_loss: 190.3373\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.2026 - val_loss: 168.7800\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9030 - val_loss: 158.8463\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4508 - val_loss: 202.1407\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 139.560 - 0s 51us/step - loss: 138.8860 - val_loss: 236.7496\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1787 - val_loss: 177.7638\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5253 - val_loss: 206.6979\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8394 - val_loss: 183.8142\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.1846 - val_loss: 149.0125\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3035 - val_loss: 157.1975\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4325 - val_loss: 168.9285\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.3762 - val_loss: 181.4260\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2969 - val_loss: 156.0673\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5232 - val_loss: 146.6444\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.5387 - val_loss: 158.7382\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.1530 - val_loss: 153.1197\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2386 - val_loss: 197.7556\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5959 - val_loss: 509.9665\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.4705 - val_loss: 257.5228\n",
      "Epoch 1109/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5464 - val_loss: 167.6104\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.3234 - val_loss: 181.9408\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0713 - val_loss: 171.5612\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 204.5805- ETA: 0s - loss: 147 - 0s 50us/step - loss: 204.2961 - val_loss: 263.7532\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3236 - val_loss: 187.8245\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3032 - val_loss: 143.8009\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5409 - val_loss: 294.2831\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.3256 - val_loss: 182.0684\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.4883 - val_loss: 242.1212\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6312 - val_loss: 165.3972\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1934 - val_loss: 151.5222\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1289 - val_loss: 151.2377\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3536 - val_loss: 144.1207\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7315 - val_loss: 175.6249\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.8679 - val_loss: 175.2313\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8773 - val_loss: 154.6918\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9979 - val_loss: 182.4362\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.7760 - val_loss: 167.6295\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0011 - val_loss: 173.0430\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0389 - val_loss: 177.7139\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7696 - val_loss: 161.7001\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.1581 - val_loss: 175.2654\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1430 - val_loss: 151.3089\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6854 - val_loss: 189.8987\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0769 - val_loss: 149.7538\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 151.4372 - val_loss: 190.4818\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.2639 - val_loss: 209.2014\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 152.5832 - val_loss: 171.8063\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5121 - val_loss: 156.1090\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.0229 - val_loss: 243.1608\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8706 - val_loss: 169.4830\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2389 - val_loss: 188.5625\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7443 - val_loss: 163.0619\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0088 - val_loss: 186.9978\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9199 - val_loss: 267.7998\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6861 - val_loss: 153.8193\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8251 - val_loss: 248.1926\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.9365 - val_loss: 146.6661\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6655 - val_loss: 142.4100\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.0075 - val_loss: 232.3379\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1515 - val_loss: 183.6126\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5246 - val_loss: 259.3780\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4748 - val_loss: 191.6621\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.4981 - val_loss: 161.1716\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9280 - val_loss: 160.4942\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5774 - val_loss: 149.9426\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9155 - val_loss: 147.0029\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2649 - val_loss: 175.0928\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.2198 - val_loss: 155.2957\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6612 - val_loss: 161.9948\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8816 - val_loss: 146.6141\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5726 - val_loss: 159.9514\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.8174 - val_loss: 169.9879\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.3273 - val_loss: 169.7135\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.4940 - val_loss: 202.7406\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0477 - val_loss: 150.0435\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.4376 - val_loss: 152.1221\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.5766 - val_loss: 154.5472\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9661 - val_loss: 149.6060\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1449 - val_loss: 195.2773\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.7590 - val_loss: 169.9963\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1871 - val_loss: 152.3182\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3876 - val_loss: 153.5419\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 209.1511 - val_loss: 170.2684\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2617 - val_loss: 175.4467\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.9440 - val_loss: 155.8149\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.4427 - val_loss: 154.9212\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.4396 - val_loss: 226.0445\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3501 - val_loss: 388.9447\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5642 - val_loss: 164.7323\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1645 - val_loss: 216.8033\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2297 - val_loss: 165.6189\n",
      "Epoch 1181/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0700 - val_loss: 171.8549\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.5870 - val_loss: 163.7790\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.8981 - val_loss: 165.8111\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5462 - val_loss: 174.1693\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5887 - val_loss: 161.7138\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1664 - val_loss: 173.8659\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1287 - val_loss: 171.7001\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.5123 - val_loss: 164.6313\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0323 - val_loss: 170.8448\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2468 - val_loss: 151.1679\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6910 - val_loss: 148.7041\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1287 - val_loss: 151.0749\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6589 - val_loss: 170.0598\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1091 - val_loss: 153.6562\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.6039 - val_loss: 153.4854\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.4681 - val_loss: 168.2779\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.8361 - val_loss: 146.5208\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4618 - val_loss: 149.3054\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 242.2052 - val_loss: 483.1798\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.2778 - val_loss: 174.1202\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8808 - val_loss: 168.0591\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.8540 - val_loss: 156.3950\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 167.5725 - val_loss: 232.8474\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 139.4665 - val_loss: 150.6690\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 159.1037 - val_loss: 156.4362\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 154.4382 - val_loss: 148.2035\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.1146 - val_loss: 145.8524\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 150.8231 - val_loss: 142.9491\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 137.0602 - val_loss: 256.6274\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 154.8490 - val_loss: 171.4286\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 200.8423 - val_loss: 179.4036\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 179.0487 - val_loss: 159.7032\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 149.7383 - val_loss: 195.5661\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 146.5696 - val_loss: 147.1009\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 136.5183 - val_loss: 155.0302\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 147.8259 - val_loss: 145.9571\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 156.8909 - val_loss: 141.7473\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 208.4627 - val_loss: 178.7952\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 154.1737 - val_loss: 158.2530\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.9134 - val_loss: 148.4094\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 152.8461 - val_loss: 149.3617\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 145.0540 - val_loss: 143.6802\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 179.0337 - val_loss: 171.9346\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 140.5002 - val_loss: 193.8732\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 148.6306 - val_loss: 159.5493\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.3958 - val_loss: 150.4771\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 156.7855 - val_loss: 143.4446\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 142.9919 - val_loss: 175.0738\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.3889 - val_loss: 152.3738\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 142.8449 - val_loss: 143.6849\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.2277 - val_loss: 148.8404\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.9733 - val_loss: 155.1887\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.6166 - val_loss: 156.4694\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 149.1984 - val_loss: 146.9613\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.9340 - val_loss: 145.3319\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.9809 - val_loss: 1660.3700\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 259.8835 - val_loss: 155.7097\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 138.1459 - val_loss: 164.6774\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.9162 - val_loss: 149.2428\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 177.2652 - val_loss: 182.0526\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 142.4573 - val_loss: 194.7463\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 149.4773 - val_loss: 207.2734\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 159.0336 - val_loss: 151.3119\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 141.9176 - val_loss: 156.9813\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.1657 - val_loss: 145.3683\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 162.8860 - val_loss: 156.0846\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 136.3533 - val_loss: 153.7088\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 154.4249 - val_loss: 142.8088\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.6939 - val_loss: 155.6287\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.2402 - val_loss: 143.3420\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 156.4417 - val_loss: 146.1600\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.4251 - val_loss: 172.8140\n",
      "Epoch 1253/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.0696 - val_loss: 154.1705\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.4227 - val_loss: 169.5287\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0169 - val_loss: 242.2238\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.3359 - val_loss: 153.1875\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0774 - val_loss: 148.4707\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8683 - val_loss: 150.7692\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2520 - val_loss: 143.8154\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6339 - val_loss: 154.1084\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9418 - val_loss: 141.5191\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7802 - val_loss: 146.7304\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.5841 - val_loss: 312.2987\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.7296 - val_loss: 184.9748\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1661 - val_loss: 161.3188\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5918 - val_loss: 201.4238\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1158 - val_loss: 187.0414\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.5021 - val_loss: 165.2780\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 146.5105 - val_loss: 150.6651\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 173.0534 - val_loss: 149.5192\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 129.5467 - val_loss: 163.7031\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6439 - val_loss: 185.3833\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.7661 - val_loss: 176.2308\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8014 - val_loss: 177.1563\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5309 - val_loss: 231.6448\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5654 - val_loss: 154.3147\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.0704 - val_loss: 224.1374\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1144 - val_loss: 176.5765\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.9528 - val_loss: 161.9993\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0079 - val_loss: 169.9608\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7498 - val_loss: 154.6879\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6619 - val_loss: 157.6972\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9968 - val_loss: 150.6589\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3586 - val_loss: 173.0174\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8927 - val_loss: 143.5170\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9018 - val_loss: 147.2733\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.5988 - val_loss: 164.8990\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6980 - val_loss: 154.0603\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.5529 - val_loss: 148.5601\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3777 - val_loss: 239.3710\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.6551 - val_loss: 172.0648\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1213 - val_loss: 147.6546\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9639 - val_loss: 172.0468\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1025 - val_loss: 159.7462\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9224 - val_loss: 193.7830\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7135 - val_loss: 220.0970\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8213 - val_loss: 165.1274\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2385 - val_loss: 151.0596\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8069 - val_loss: 155.7271\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5834 - val_loss: 164.3923\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0664 - val_loss: 149.8178\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.5976 - val_loss: 151.1482\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8077 - val_loss: 176.7707\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6903 - val_loss: 159.4783\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7530 - val_loss: 175.6068\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0259 - val_loss: 153.9033\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9051 - val_loss: 169.0600\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.6060 - val_loss: 143.6439\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2534 - val_loss: 147.9837\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1432 - val_loss: 177.1371\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7326 - val_loss: 187.1612\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7973 - val_loss: 145.3592\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8004 - val_loss: 174.9455\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.9171 - val_loss: 157.2441\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.0853 - val_loss: 176.4769\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9092 - val_loss: 142.3571\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6005 - val_loss: 216.2777\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1154 - val_loss: 145.6538\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8557 - val_loss: 232.4794\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.0938 - val_loss: 142.2812\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5258 - val_loss: 159.5550\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2279 - val_loss: 159.7507\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8023 - val_loss: 956.8417\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4676 - val_loss: 148.1088\n",
      "Epoch 1325/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.6373 - val_loss: 145.0560\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9512 - val_loss: 164.4509\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.4388 - val_loss: 210.6072\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.6606 - val_loss: 224.9153\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9751 - val_loss: 152.2030\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.6394 - val_loss: 143.2709\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1052 - val_loss: 277.1345\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9577 - val_loss: 149.2905\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1932 - val_loss: 149.0647\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3012 - val_loss: 156.4594\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.1144 - val_loss: 189.3669\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5846 - val_loss: 146.6531\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2660 - val_loss: 144.6264\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0824 - val_loss: 146.3704\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 137.2545 - val_loss: 150.7323\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 157.0094 - val_loss: 177.2135\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 153.6164 - val_loss: 145.8862\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 143.6385 - val_loss: 146.8362\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 168.6909 - val_loss: 191.9686\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 257.646 - 0s 50us/step - loss: 257.1362 - val_loss: 175.0314\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9979 - val_loss: 156.8173\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8082 - val_loss: 166.2973\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.4015 - val_loss: 217.6123\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6396 - val_loss: 167.9798\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7526 - val_loss: 169.2624\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2720 - val_loss: 181.7098\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1544 - val_loss: 156.8331\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1994 - val_loss: 142.9070\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8578 - val_loss: 145.3822\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4365 - val_loss: 160.6043\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9832 - val_loss: 154.8230\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.8926 - val_loss: 166.4509\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4971 - val_loss: 157.5759\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7014 - val_loss: 648.2426\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0899 - val_loss: 289.0333\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.9023 - val_loss: 165.7380\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7825 - val_loss: 268.6087\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2700 - val_loss: 155.1229\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9145 - val_loss: 237.4995\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2946 - val_loss: 149.6610\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9933 - val_loss: 162.5857\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7609 - val_loss: 149.3919\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.7300 - val_loss: 160.0848\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.0083 - val_loss: 173.0889\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0210 - val_loss: 145.8819\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.6314 - val_loss: 145.3910\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8641 - val_loss: 159.8359\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4783 - val_loss: 153.2156\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6864 - val_loss: 184.2008\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6435 - val_loss: 140.6279\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9542 - val_loss: 162.7692\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2022 - val_loss: 160.7797\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5321 - val_loss: 156.4890\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4827 - val_loss: 150.5089\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5160 - val_loss: 140.6410\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7981 - val_loss: 146.3264\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4330 - val_loss: 143.0967\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3352 - val_loss: 165.3273\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.1748 - val_loss: 162.4637\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3068 - val_loss: 145.5121\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8401 - val_loss: 149.9811- ETA: 0s - loss: 171\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0078 - val_loss: 161.0106\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.8093 - val_loss: 143.2272\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7857 - val_loss: 161.7197\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.4293 - val_loss: 142.5916\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3772 - val_loss: 152.5892\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.0577 - val_loss: 160.5263\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0832 - val_loss: 155.3858\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3292 - val_loss: 151.8055\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2330 - val_loss: 145.1721\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1947 - val_loss: 188.9151\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7661 - val_loss: 154.2645\n",
      "Epoch 1397/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.9811 - val_loss: 145.7836\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.2399 - val_loss: 161.7759\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2365 - val_loss: 174.3727\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6746 - val_loss: 196.9879\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8875 - val_loss: 146.2043\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2594 - val_loss: 238.0282\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0530 - val_loss: 142.8435\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.9795 - val_loss: 143.7599\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.7620 - val_loss: 268.3445\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6871 - val_loss: 144.8076\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8802 - val_loss: 155.5034\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6367 - val_loss: 214.1759\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.9710 - val_loss: 178.7757\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9592 - val_loss: 218.2190\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2169 - val_loss: 143.3904\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4660 - val_loss: 151.1313\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 138.6819 - val_loss: 176.5058\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 152.1159 - val_loss: 158.0921\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 159.8398 - val_loss: 146.5290\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.3724 - val_loss: 142.5905\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.7790 - val_loss: 141.5652\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9237 - val_loss: 144.0980\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9240 - val_loss: 151.3383\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2097 - val_loss: 147.2818\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2569 - val_loss: 204.7495\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6511 - val_loss: 210.8198\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5883 - val_loss: 141.7627\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2177 - val_loss: 146.1649\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7138 - val_loss: 161.1725\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.4953 - val_loss: 272.1220\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.7360 - val_loss: 153.3499\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2315 - val_loss: 145.9189\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7411 - val_loss: 148.8853\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2412 - val_loss: 175.8047\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7733 - val_loss: 154.4456\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.3048 - val_loss: 152.0576\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.7713 - val_loss: 144.8627\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.5356 - val_loss: 168.8214\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0311 - val_loss: 249.2270\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3106 - val_loss: 177.7536\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0164 - val_loss: 140.7978\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8053 - val_loss: 158.5188\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.4042 - val_loss: 144.9839\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2391 - val_loss: 158.6785\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0583 - val_loss: 161.5476\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.6335 - val_loss: 149.9431\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1613 - val_loss: 143.4067\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.0360 - val_loss: 153.3252\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7516 - val_loss: 153.0728\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5558 - val_loss: 171.8422\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6071 - val_loss: 159.8886\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9629 - val_loss: 145.0935\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8766 - val_loss: 144.6810\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3335 - val_loss: 275.1520\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5169 - val_loss: 231.8598\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2657 - val_loss: 208.0271\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7599 - val_loss: 178.7925\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3744 - val_loss: 149.0568\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3765 - val_loss: 141.2137\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.5028 - val_loss: 143.9512\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2090 - val_loss: 151.8130\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.2560 - val_loss: 150.1837\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.1533 - val_loss: 150.6210\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.4318 - val_loss: 224.7074\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.5927 - val_loss: 186.8419\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4475 - val_loss: 174.7795\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2107 - val_loss: 152.7489\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.3588 - val_loss: 153.7432\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3451 - val_loss: 160.4102\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.8301 - val_loss: 192.7766\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1102 - val_loss: 193.1144\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1203 - val_loss: 214.2203\n",
      "Epoch 1469/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7846 - val_loss: 194.2281\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9698 - val_loss: 141.0107\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7800 - val_loss: 160.2705\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8634 - val_loss: 162.1323\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.5900 - val_loss: 144.8326\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4324 - val_loss: 151.9023\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5583 - val_loss: 150.6468\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3109 - val_loss: 149.6551\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.1592 - val_loss: 193.1936\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.2494 - val_loss: 179.8781\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1511 - val_loss: 171.6582\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1767 - val_loss: 143.0253\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8310 - val_loss: 180.9154\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.6854 - val_loss: 142.3847\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.8383 - val_loss: 143.7736\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.5901 - val_loss: 176.2662\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 140.8205 - val_loss: 151.1185\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 143.4459 - val_loss: 160.3438\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.6920 - val_loss: 262.3749\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.6801 - val_loss: 140.3093\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.9841 - val_loss: 153.9844\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2988 - val_loss: 273.3151\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8959 - val_loss: 161.6762\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.6000 - val_loss: 149.4083\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4692 - val_loss: 142.2619\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0150 - val_loss: 143.4074\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5663 - val_loss: 187.1511\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.4234 - val_loss: 157.4042\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7855 - val_loss: 146.6597\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1384 - val_loss: 149.8334\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.6229 - val_loss: 177.5783\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.9082 - val_loss: 144.5170\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8738 - val_loss: 181.7515\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5267 - val_loss: 144.6512\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1024 - val_loss: 148.8054\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4063 - val_loss: 153.9703\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.5223 - val_loss: 152.9740\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5831 - val_loss: 154.7415\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4597 - val_loss: 162.1535\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1858 - val_loss: 169.0691\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6559 - val_loss: 220.4637\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5755 - val_loss: 149.9722\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8877 - val_loss: 145.6248 ETA: 0s - loss: 145\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.8796 - val_loss: 166.0400\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 198.2486 - val_loss: 254.9029\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.5982 - val_loss: 154.9817\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2317 - val_loss: 144.7140\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 130.6547 - val_loss: 155.0968\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5601 - val_loss: 159.3716\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.6353 - val_loss: 160.5796\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1191 - val_loss: 171.2734\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6390 - val_loss: 147.2960\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2894 - val_loss: 177.8714\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5611 - val_loss: 149.0040\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.5032 - val_loss: 209.7720\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0134 - val_loss: 312.9432\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4004 - val_loss: 164.3806\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9965 - val_loss: 143.9866\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7511 - val_loss: 138.5054\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7144 - val_loss: 167.2833\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4492 - val_loss: 181.9249\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.4440 - val_loss: 267.0343\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8395 - val_loss: 151.5141\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5485 - val_loss: 162.2170\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.9706 - val_loss: 157.3816\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5687 - val_loss: 164.3823\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.2722 - val_loss: 146.9183\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.0253 - val_loss: 162.6042\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.2970 - val_loss: 149.0022\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6366 - val_loss: 141.8246\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9431 - val_loss: 188.0970\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.2036 - val_loss: 144.6104\n",
      "Epoch 1541/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2529 - val_loss: 155.9846\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.1374 - val_loss: 181.3656\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6362 - val_loss: 176.7116\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9302 - val_loss: 151.4779\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0707 - val_loss: 175.5791\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2977 - val_loss: 168.9775\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9859 - val_loss: 141.5796\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1460 - val_loss: 162.4283\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2309 - val_loss: 176.5779\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4200 - val_loss: 149.4211\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.1498 - val_loss: 155.2028\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7253 - val_loss: 145.5677\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1860 - val_loss: 156.5681\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5250 - val_loss: 143.6029\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0803 - val_loss: 149.5666\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 133.6957 - val_loss: 147.6800\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 142.5963 - val_loss: 146.6371\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 191.3094 - val_loss: 227.2135\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 231.9626 - val_loss: 172.5750\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9403 - val_loss: 146.0545\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1399 - val_loss: 171.4337\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0238 - val_loss: 159.9340\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4229 - val_loss: 153.6922\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.2068 - val_loss: 148.2161\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7552 - val_loss: 164.1337\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6742 - val_loss: 151.7201\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0177 - val_loss: 150.1609\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8704 - val_loss: 509.8130\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.0970 - val_loss: 160.7196\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7086 - val_loss: 146.0409\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5003 - val_loss: 163.9824\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1524 - val_loss: 151.3736\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5386 - val_loss: 175.5997\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8786 - val_loss: 173.4573\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7137 - val_loss: 141.8287\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6994 - val_loss: 148.6259\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.8962 - val_loss: 210.6296\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8913 - val_loss: 144.3722\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2707 - val_loss: 163.8850\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0072 - val_loss: 144.3215\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3632 - val_loss: 155.8382\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7946 - val_loss: 144.2037\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4237 - val_loss: 345.2760\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9302 - val_loss: 156.0032\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3503 - val_loss: 147.3060\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1421 - val_loss: 155.6718\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1003 - val_loss: 144.6303\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.2615 - val_loss: 144.8225\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6346 - val_loss: 166.9364\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0774 - val_loss: 142.4899\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0910 - val_loss: 176.2110\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0735 - val_loss: 180.4292\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3813 - val_loss: 193.8885\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.9937 - val_loss: 184.6445\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2356 - val_loss: 158.7466\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9841 - val_loss: 229.1105\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5476 - val_loss: 178.3423\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1847 - val_loss: 140.8102\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7852 - val_loss: 160.8035\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5620 - val_loss: 182.0666\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.7091 - val_loss: 173.2366\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.3079 - val_loss: 168.6905\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.9692 - val_loss: 148.4496\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.0837 - val_loss: 157.3484\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8098 - val_loss: 146.4565\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4113 - val_loss: 146.8344\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4876 - val_loss: 193.7605\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6390 - val_loss: 139.4630\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0894 - val_loss: 163.3789\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7698 - val_loss: 157.3993\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8097 - val_loss: 141.9109\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8733 - val_loss: 158.1352\n",
      "Epoch 1613/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.3104 - val_loss: 150.1801\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2828 - val_loss: 171.7612\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 137.2537 - val_loss: 142.5790\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.3141 - val_loss: 154.3770\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.5687 - val_loss: 267.0121\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.0232 - val_loss: 152.2027\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4519 - val_loss: 158.7184\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.2277 - val_loss: 145.4260\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7759 - val_loss: 152.2836\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1079 - val_loss: 150.2597\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5369 - val_loss: 146.0687\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0234 - val_loss: 152.9910\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.0205 - val_loss: 146.8914\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3875 - val_loss: 204.4657\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5127 - val_loss: 201.2433\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.0009 - val_loss: 145.7276\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 143.5467 - val_loss: 141.0841\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 128.7482 - val_loss: 143.6245\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.2620 - val_loss: 148.2982\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7880 - val_loss: 152.9154\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7196 - val_loss: 181.1820\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5611 - val_loss: 174.8863\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.8182 - val_loss: 150.2796\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7021 - val_loss: 151.0481\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.7912 - val_loss: 139.3934\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.0585 - val_loss: 155.9575\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0948 - val_loss: 150.7310\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9529 - val_loss: 150.3739\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5863 - val_loss: 513.2646\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4417 - val_loss: 177.7338\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3438 - val_loss: 155.8351\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9839 - val_loss: 174.8460\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.9791 - val_loss: 142.1694\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5427 - val_loss: 149.5923\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.4533 - val_loss: 141.4845\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6174 - val_loss: 163.3804\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7115 - val_loss: 174.0504\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 197.3151 - val_loss: 159.7411\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7287 - val_loss: 139.9415\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2242 - val_loss: 145.3598\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0012 - val_loss: 214.8470\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0315 - val_loss: 246.3759\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.4559 - val_loss: 153.4922\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0921 - val_loss: 160.2331\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.9470 - val_loss: 145.4726\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6096 - val_loss: 150.3759\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9382 - val_loss: 155.6145\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.2351 - val_loss: 221.7957\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 155.5573 - val_loss: 199.3123\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.0576 - val_loss: 144.7114\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9530 - val_loss: 182.4458\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.7713 - val_loss: 193.4664\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5280 - val_loss: 156.7872\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.5865 - val_loss: 144.5746\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.6907 - val_loss: 147.8568\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.4272 - val_loss: 572.6443\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.9188 - val_loss: 168.8896\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6799 - val_loss: 164.0935\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8285 - val_loss: 149.9575\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5933 - val_loss: 176.2661\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2705 - val_loss: 152.0844\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6457 - val_loss: 150.8033\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1821 - val_loss: 142.6187\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1075 - val_loss: 181.6596\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4182 - val_loss: 144.8724\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4884 - val_loss: 146.3245\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9625 - val_loss: 147.9606\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8185 - val_loss: 142.1252\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2011 - val_loss: 157.6982\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1551 - val_loss: 153.0944\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.1291 - val_loss: 139.9523\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.0371 - val_loss: 168.1644\n",
      "Epoch 1685/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8256 - val_loss: 170.1605\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6196 - val_loss: 169.9709\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3936 - val_loss: 140.8206\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.1323 - val_loss: 140.9068\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.6038 - val_loss: 161.3581\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1703 - val_loss: 143.5949\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2599 - val_loss: 164.6179\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9812 - val_loss: 171.0072\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8397 - val_loss: 148.4888\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7983 - val_loss: 162.6922\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3177 - val_loss: 146.0639\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4704 - val_loss: 141.9958\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6824 - val_loss: 148.4883\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.7369 - val_loss: 141.3067\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4771 - val_loss: 150.9717\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 155.5853 - val_loss: 217.5989\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 141.0874 - val_loss: 177.2915\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.6083 - val_loss: 147.4736\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 162.3839 - val_loss: 180.2036\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2651 - val_loss: 146.1853\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.9487 - val_loss: 148.6801\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7335 - val_loss: 148.5266\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1800 - val_loss: 166.4257\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.8449 - val_loss: 198.3137\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0153 - val_loss: 144.1559\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7561 - val_loss: 143.8721\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7302 - val_loss: 155.2976\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6712 - val_loss: 176.8765\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7372 - val_loss: 173.1536\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.4864 - val_loss: 240.2043\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1046 - val_loss: 140.2982\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1162 - val_loss: 148.4118\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3563 - val_loss: 180.0594\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0622 - val_loss: 186.4670\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 280.6941 - val_loss: 161.0385\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6549 - val_loss: 144.7517\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5374 - val_loss: 145.0876\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0237 - val_loss: 199.3945\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1418 - val_loss: 149.1264\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.4949 - val_loss: 194.0962\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4998 - val_loss: 146.5120\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8121 - val_loss: 165.7610\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4998 - val_loss: 156.4787\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6643 - val_loss: 142.7052\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.9486 - val_loss: 200.7957\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.2869 - val_loss: 151.8820\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4061 - val_loss: 182.2655\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4401 - val_loss: 144.3336\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.8639 - val_loss: 162.3906\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8775 - val_loss: 144.7790\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7781 - val_loss: 150.7503\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7765 - val_loss: 157.0909\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2113 - val_loss: 222.7401\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.7855 - val_loss: 163.8851\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0258 - val_loss: 143.6961\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.5291 - val_loss: 158.4234\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0734 - val_loss: 147.7014\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4088 - val_loss: 145.3713\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6809 - val_loss: 203.9759\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.9630 - val_loss: 141.8826\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3620 - val_loss: 158.2082\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.3942 - val_loss: 159.5778\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.8295 - val_loss: 196.7171\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 170.3872 - val_loss: 188.7620\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9891 - val_loss: 142.7722\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 152.314 - 0s 50us/step - loss: 152.1074 - val_loss: 225.0363\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2309 - val_loss: 141.6625\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.7487 - val_loss: 143.8388\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4353 - val_loss: 159.6696\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3755 - val_loss: 146.6384\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5108 - val_loss: 159.9026\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.9804 - val_loss: 156.3343\n",
      "Epoch 1757/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9035 - val_loss: 163.9741\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6019 - val_loss: 165.2447\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6707 - val_loss: 148.1097\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.2566 - val_loss: 458.3836\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.6102 - val_loss: 147.4521\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 137.8025 - val_loss: 168.7069\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.4409 - val_loss: 207.2522\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.6678 - val_loss: 181.0063\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.3441 - val_loss: 183.0969\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4791 - val_loss: 155.3112\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4337 - val_loss: 163.2846\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2601 - val_loss: 163.5097\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5527 - val_loss: 150.2313\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7406 - val_loss: 144.5336\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8761 - val_loss: 162.8800\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.4316 - val_loss: 141.8673\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 134.7451 - val_loss: 157.8552\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.3072 - val_loss: 144.6720\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 138.1651 - val_loss: 146.1163\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2054 - val_loss: 142.9289\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0345 - val_loss: 153.0925\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7755 - val_loss: 200.0690\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.6311 - val_loss: 149.4170\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2105 - val_loss: 159.3798\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6509 - val_loss: 203.5026\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2454 - val_loss: 164.6268\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8925 - val_loss: 140.7815\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.7260 - val_loss: 199.3945\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5629 - val_loss: 192.2993\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7498 - val_loss: 145.2623\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7677 - val_loss: 163.2424\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.6329 - val_loss: 151.9580\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3587 - val_loss: 147.1744\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7242 - val_loss: 141.5795\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.5682 - val_loss: 172.6810\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9696 - val_loss: 166.9148\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1143 - val_loss: 148.0672\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.8995 - val_loss: 146.1403\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4128 - val_loss: 146.5436\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0805 - val_loss: 149.0260\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7088 - val_loss: 146.0888\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9592 - val_loss: 150.4281\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9004 - val_loss: 153.9887\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3228 - val_loss: 191.7480\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 248.9585 - val_loss: 149.8353\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1504 - val_loss: 155.9596\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9869 - val_loss: 195.4182\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3743 - val_loss: 204.1212\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.2233 - val_loss: 144.0788\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2538 - val_loss: 146.9559\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6059 - val_loss: 154.5915\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8297 - val_loss: 150.5573\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2221 - val_loss: 151.5840\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4869 - val_loss: 195.5648\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.0798 - val_loss: 147.9930\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6355 - val_loss: 164.0589\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8550 - val_loss: 147.1136\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8199 - val_loss: 150.3524\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3380 - val_loss: 217.0192\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.1243 - val_loss: 150.8368\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9820 - val_loss: 142.9407\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7260 - val_loss: 197.8080\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9313 - val_loss: 155.1979\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2665 - val_loss: 155.1117\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0560 - val_loss: 147.7603\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5276 - val_loss: 145.6943\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1693 - val_loss: 153.6908\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5620 - val_loss: 229.0968\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.9188 - val_loss: 168.5833\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1272 - val_loss: 165.1080\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 271.5034 - val_loss: 238.5591\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.9507 - val_loss: 150.3771\n",
      "Epoch 1829/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6709 - val_loss: 241.3845\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0433 - val_loss: 153.1702\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6842 - val_loss: 179.3942\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7176 - val_loss: 148.9178\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2740 - val_loss: 162.8609\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.4376 - val_loss: 138.8696\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0557 - val_loss: 143.3508\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0332 - val_loss: 168.4379\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9695 - val_loss: 195.9430\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.6205 - val_loss: 148.3202\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.0885 - val_loss: 150.5450\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2647 - val_loss: 227.2819\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9666 - val_loss: 169.1250\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8230 - val_loss: 139.4370\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.8466 - val_loss: 152.9481\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.0441 - val_loss: 142.7837\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.8507 - val_loss: 159.3800\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 133.0825 - val_loss: 173.4646\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 155.5096 - val_loss: 161.4966\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.6866 - val_loss: 157.6326\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6593 - val_loss: 165.8656\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3171 - val_loss: 197.9328\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5141 - val_loss: 172.5747\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.6666 - val_loss: 148.5814\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8347 - val_loss: 169.9578\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.2948 - val_loss: 218.3280\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.6093 - val_loss: 148.3904\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1060 - val_loss: 156.9423\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.3694 - val_loss: 145.8521\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9387 - val_loss: 188.8647\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5814 - val_loss: 148.1798\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4105 - val_loss: 145.5371\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6101 - val_loss: 153.4797\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1607 - val_loss: 166.7468\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3105 - val_loss: 151.1822\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6398 - val_loss: 149.0282\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3253 - val_loss: 220.9494\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1102 - val_loss: 153.0684\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6195 - val_loss: 143.5382\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 138.619 - 0s 51us/step - loss: 137.9451 - val_loss: 143.1378\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7713 - val_loss: 155.6481\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2111 - val_loss: 145.5010\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0178 - val_loss: 141.1178\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5639 - val_loss: 177.9720\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7971 - val_loss: 150.1051\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 214.2424 - val_loss: 142.6483\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5284 - val_loss: 146.0507\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.2724 - val_loss: 143.5428\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0612 - val_loss: 144.0165\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8305 - val_loss: 183.8702\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.0900 - val_loss: 215.0173\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1764 - val_loss: 150.4038\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8724 - val_loss: 151.0123\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.9772 - val_loss: 174.0357\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7363 - val_loss: 153.5839\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5519 - val_loss: 155.3253\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.1892 - val_loss: 142.2199\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0892 - val_loss: 143.9775\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.9889 - val_loss: 162.5197\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.4174 - val_loss: 155.8211\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2114 - val_loss: 154.6777\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2839 - val_loss: 192.2660\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4899 - val_loss: 140.3924\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6217 - val_loss: 142.8038\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2375 - val_loss: 197.3379\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.3099 - val_loss: 140.7017\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.9629 - val_loss: 240.4781\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0385 - val_loss: 185.3947\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.1977 - val_loss: 197.0225\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.9918 - val_loss: 143.0669\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.8235 - val_loss: 159.3633\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.0675 - val_loss: 151.8865\n",
      "Epoch 1901/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 129.5398 - val_loss: 143.4812\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.2858 - val_loss: 216.7258\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.6375 - val_loss: 144.6576\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 132.2605 - val_loss: 165.8077\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2705 - val_loss: 139.2568\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.9345 - val_loss: 190.2236\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.6762 - val_loss: 259.2941\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.2081 - val_loss: 155.5243\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8470 - val_loss: 151.7187\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.1366 - val_loss: 471.5335\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5670 - val_loss: 141.2659\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4622 - val_loss: 242.8796\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.8673 - val_loss: 183.9491\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4247 - val_loss: 162.9824\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0280 - val_loss: 191.3560\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1464 - val_loss: 179.4101\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 368.9616 - val_loss: 210.5758\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 182.8170 - val_loss: 181.0196\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.4277 - val_loss: 164.0105\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.7079 - val_loss: 157.5718\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 197.2391 - val_loss: 191.4587\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.8987 - val_loss: 165.7473\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8761 - val_loss: 157.9103\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5298 - val_loss: 144.5519\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.0733 - val_loss: 150.0947\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.1473 - val_loss: 140.4093\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 131.3994 - val_loss: 140.6250\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 140.1687 - val_loss: 147.4652\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.2441 - val_loss: 145.8630\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8993 - val_loss: 169.6015\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6975 - val_loss: 149.0774\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4528 - val_loss: 209.0152\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 136.8176 - val_loss: 186.2801\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.5023 - val_loss: 144.4009\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.9237 - val_loss: 146.4803\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0798 - val_loss: 183.3267\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.6839 - val_loss: 175.7713\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2816 - val_loss: 199.6739\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3312 - val_loss: 159.2436\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9556 - val_loss: 148.0069\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4777 - val_loss: 139.0388\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0280 - val_loss: 146.1505\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.5114 - val_loss: 153.5388\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7534 - val_loss: 158.8591\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3817 - val_loss: 144.1646\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1455 - val_loss: 152.8859\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1661 - val_loss: 147.2072\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.1341 - val_loss: 175.4769\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.9487 - val_loss: 177.6195\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7195 - val_loss: 260.6925\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 207.9462 - val_loss: 160.0852\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9043 - val_loss: 188.8622\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0771 - val_loss: 142.4903\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1234 - val_loss: 147.8946\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5874 - val_loss: 149.9523\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7542 - val_loss: 149.1110\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0144 - val_loss: 142.4104\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.5943 - val_loss: 145.2742\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2371 - val_loss: 255.5270\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.7354 - val_loss: 158.1498\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2750 - val_loss: 209.5817\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6414 - val_loss: 193.0147\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7003 - val_loss: 146.0534\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.3676 - val_loss: 164.2625\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2154 - val_loss: 192.2568\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4984 - val_loss: 163.1070\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.5944 - val_loss: 149.1212\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.8830 - val_loss: 142.7821\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.7376 - val_loss: 157.8948\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.5351 - val_loss: 145.9008\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3976 - val_loss: 141.7198\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.1850 - val_loss: 146.4215\n",
      "Epoch 1973/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8935 - val_loss: 163.8579\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2946 - val_loss: 184.6913\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9933 - val_loss: 142.1533\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3363 - val_loss: 155.0986\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3268 - val_loss: 166.7950\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3058 - val_loss: 143.6169\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3673 - val_loss: 148.9957\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4088 - val_loss: 200.2087\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1194 - val_loss: 159.0004\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.1562 - val_loss: 153.2599\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2851 - val_loss: 149.4766\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7870 - val_loss: 141.8687\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2434 - val_loss: 162.2576\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 158.3407 - val_loss: 158.3776\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.3122 - val_loss: 145.4082\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.0336 - val_loss: 146.6764\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.6165 - val_loss: 141.8757\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.4853 - val_loss: 179.1497\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0547 - val_loss: 179.4032\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4423 - val_loss: 186.3072\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7237 - val_loss: 146.0350\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7849 - val_loss: 156.4976\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.3697 - val_loss: 146.9177\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.2149 - val_loss: 174.0375\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.0767 - val_loss: 154.3004\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7650 - val_loss: 152.9328\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8312 - val_loss: 151.0094\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0106 - val_loss: 200.2820\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0551 - val_loss: 182.2291\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8955 - val_loss: 262.4576\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0130 - val_loss: 140.9721\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7893 - val_loss: 177.1631\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.2013 - val_loss: 152.9818\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7551 - val_loss: 148.3292\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6578 - val_loss: 137.7160\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6593 - val_loss: 142.3573\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2300 - val_loss: 177.6336\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 369.0690 - val_loss: 160.8699\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.6533 - val_loss: 177.4284\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5037 - val_loss: 144.1311\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7856 - val_loss: 149.3273\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1856 - val_loss: 154.9451\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.0504 - val_loss: 162.5786\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6561 - val_loss: 159.1256\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5752 - val_loss: 144.1658\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.6301 - val_loss: 183.2881\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9666 - val_loss: 158.1904\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 260.1750 - val_loss: 149.0658\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6331 - val_loss: 147.2951\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.6249 - val_loss: 141.0184\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0996 - val_loss: 145.9089\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9064 - val_loss: 153.4371\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4097 - val_loss: 163.6431\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.1965 - val_loss: 151.4139\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2584 - val_loss: 182.0919\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.1562 - val_loss: 160.1082\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9935 - val_loss: 144.2405\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.8501 - val_loss: 198.6735\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.3587 - val_loss: 192.1592\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9247 - val_loss: 182.9547\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5601 - val_loss: 148.3124\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0920 - val_loss: 173.9661\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.0525 - val_loss: 157.2703\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7572 - val_loss: 149.0329\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3566 - val_loss: 156.4073\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3298 - val_loss: 172.9326\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2021 - val_loss: 149.3392\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.1407 - val_loss: 164.6866\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3570 - val_loss: 143.8833\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7868 - val_loss: 250.4420\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.0301 - val_loss: 185.0428\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6583 - val_loss: 171.1945\n",
      "Epoch 2045/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8087 - val_loss: 140.4654\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5093 - val_loss: 140.5223\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1424 - val_loss: 191.4270\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.1135 - val_loss: 179.3967\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0355 - val_loss: 163.2233\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6021 - val_loss: 150.0602\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8598 - val_loss: 147.0555\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7521 - val_loss: 152.2297\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3581 - val_loss: 153.8757\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0319 - val_loss: 184.9595\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7294 - val_loss: 206.7627\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4337 - val_loss: 143.1358\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2429 - val_loss: 144.9830\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.6817 - val_loss: 228.8663\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.9397 - val_loss: 146.6230\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 151.5426 - val_loss: 155.6639\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0489 - val_loss: 146.3389\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.9753 - val_loss: 149.2741\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8648 - val_loss: 145.1067\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8025 - val_loss: 139.3212\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4681 - val_loss: 145.2664\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9741 - val_loss: 152.0821\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6204 - val_loss: 151.7462\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9241 - val_loss: 143.6851\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5538 - val_loss: 140.8433\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.6607 - val_loss: 148.1773\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.6372 - val_loss: 172.3421\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3142 - val_loss: 231.4708\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9890 - val_loss: 154.7532\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1659 - val_loss: 184.1132\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0104 - val_loss: 140.4894\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.7651 - val_loss: 193.4736\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7641 - val_loss: 164.2343\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3540 - val_loss: 234.8971\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7974 - val_loss: 152.5774\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 137.028 - 0s 51us/step - loss: 137.0703 - val_loss: 147.4805\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9835 - val_loss: 177.0012\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.9281 - val_loss: 141.6992\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1785 - val_loss: 188.4644\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3195 - val_loss: 149.1454\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4800 - val_loss: 155.7473\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1324 - val_loss: 168.9360\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.7512 - val_loss: 153.5805\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6650 - val_loss: 143.0355\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7574 - val_loss: 164.9039\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.4851 - val_loss: 161.7096\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4640 - val_loss: 169.9739\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6103 - val_loss: 155.4032\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6674 - val_loss: 157.9874\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1681 - val_loss: 183.7203\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3359 - val_loss: 161.4370\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4307 - val_loss: 167.4975\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3278 - val_loss: 187.8917\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5224 - val_loss: 164.9069\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1423 - val_loss: 163.5059\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 132.1748 - val_loss: 148.6558\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 161.2463 - val_loss: 281.3934\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.3410 - val_loss: 148.1080\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.3743 - val_loss: 171.0321\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1118 - val_loss: 139.7752\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.9945 - val_loss: 143.8313\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4312 - val_loss: 154.4861\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2718 - val_loss: 146.7490\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8367 - val_loss: 175.0920\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6966 - val_loss: 380.0064\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5465 - val_loss: 138.7665\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.9141 - val_loss: 150.4779\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.9957 - val_loss: 156.4582\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4896 - val_loss: 170.9055\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5801 - val_loss: 201.8386\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1763 - val_loss: 140.5858\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0841 - val_loss: 396.5295\n",
      "Epoch 2117/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.4955 - val_loss: 895.7471\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.4999 - val_loss: 206.7584\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.3603 - val_loss: 159.8751\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.8765 - val_loss: 229.6946\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8851 - val_loss: 151.9412\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.2122 - val_loss: 176.2051\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5091 - val_loss: 172.4477\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0451 - val_loss: 169.1572\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8318 - val_loss: 175.6248\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.6625 - val_loss: 147.4397\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.3458 - val_loss: 150.1457\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5510 - val_loss: 146.6089\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8632 - val_loss: 144.4950\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.9978 - val_loss: 152.0967\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.4657 - val_loss: 143.1950\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.9797 - val_loss: 141.0458\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.2014 - val_loss: 166.9474\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3147 - val_loss: 164.2214\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3067 - val_loss: 170.2419\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.9971 - val_loss: 173.5835\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1054 - val_loss: 186.0815\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9824 - val_loss: 149.4372\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3397 - val_loss: 160.8229\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0293 - val_loss: 148.7565\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0544 - val_loss: 146.5802\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7998 - val_loss: 172.9828\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5334 - val_loss: 177.6949\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0103 - val_loss: 155.5438\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4872 - val_loss: 204.0612\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.5671 - val_loss: 148.2299\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6958 - val_loss: 145.0136\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5698 - val_loss: 177.8332\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.2737 - val_loss: 170.5447\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.3240 - val_loss: 151.6554\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9878 - val_loss: 174.8145\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2418 - val_loss: 159.2815\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0570 - val_loss: 175.5108\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1023 - val_loss: 140.7963\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8524 - val_loss: 160.3606\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9457 - val_loss: 161.4284\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3689 - val_loss: 146.7774\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.6875 - val_loss: 256.8037\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.6933 - val_loss: 229.6225\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4609 - val_loss: 157.6464\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8618 - val_loss: 142.2112\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0145 - val_loss: 163.8554\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.8056 - val_loss: 218.8520\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8588 - val_loss: 150.3820\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6523 - val_loss: 181.9666\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4893 - val_loss: 163.1408\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.3343 - val_loss: 160.1951\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0189 - val_loss: 143.6270\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0963 - val_loss: 140.6800\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.7290 - val_loss: 146.8117\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6270 - val_loss: 143.9982\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2724 - val_loss: 182.8640\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4692 - val_loss: 199.1483\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0254 - val_loss: 160.1979\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8389 - val_loss: 148.5785\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.3132 - val_loss: 145.0627\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3318 - val_loss: 147.7867\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7438 - val_loss: 216.5773\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7178 - val_loss: 154.4075\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.6594 - val_loss: 155.4390\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7371 - val_loss: 145.5537\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6799 - val_loss: 143.9290\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6677 - val_loss: 144.1216\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2231 - val_loss: 145.3504\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.7436 - val_loss: 151.4475\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9541 - val_loss: 179.1809\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1006 - val_loss: 185.5647\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5595 - val_loss: 157.6995\n",
      "Epoch 2189/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0733 - val_loss: 155.2937\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7140 - val_loss: 149.3604\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1199 - val_loss: 150.3915\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.6967 - val_loss: 152.8975\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3368 - val_loss: 145.5780\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0457 - val_loss: 159.0110\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2913 - val_loss: 161.2513\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.9135 - val_loss: 239.9793\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.9818 - val_loss: 145.0281\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2445 - val_loss: 157.1713\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5371 - val_loss: 161.8891\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.8247 - val_loss: 140.1023\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.5768 - val_loss: 155.6503\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 141.0014 - val_loss: 243.3235\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 127.4731 - val_loss: 146.7028\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 155.4491 - val_loss: 148.1770\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.0645 - val_loss: 156.8889\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5706 - val_loss: 149.9998\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1211 - val_loss: 157.7783\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1375 - val_loss: 165.8445\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1606 - val_loss: 162.2221\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1999 - val_loss: 146.7083\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5934 - val_loss: 159.2419\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3630 - val_loss: 154.0688\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6660 - val_loss: 142.1583\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6729 - val_loss: 218.3166\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5405 - val_loss: 147.7270\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.3418 - val_loss: 169.6876\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1878 - val_loss: 154.8129\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5570 - val_loss: 148.2557\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.3354 - val_loss: 154.1672\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 192.4289 - val_loss: 211.5682\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8450 - val_loss: 144.1244\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0029 - val_loss: 180.0500\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1234 - val_loss: 162.0436\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5719 - val_loss: 145.0557\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7730 - val_loss: 172.7815\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8446 - val_loss: 190.3940\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4030 - val_loss: 145.5623\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.3739 - val_loss: 315.7912\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.3270 - val_loss: 161.0555\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.1791 - val_loss: 209.6785\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6581 - val_loss: 145.2552\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6366 - val_loss: 159.8309\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5825 - val_loss: 144.3960\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5605 - val_loss: 147.9116\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8664 - val_loss: 164.0516\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.1617 - val_loss: 155.1697\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.4703 - val_loss: 194.7966\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8405 - val_loss: 162.5304\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0707 - val_loss: 155.7116\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7903 - val_loss: 182.3001\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6585 - val_loss: 184.4223\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.9779 - val_loss: 181.8331\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.4381 - val_loss: 155.8439\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1573 - val_loss: 170.1228\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7821 - val_loss: 157.8700\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0035 - val_loss: 150.5256\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5439 - val_loss: 147.8421\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1690 - val_loss: 141.7527\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 175.7983 - val_loss: 144.5179\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.8637 - val_loss: 141.7773\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.8675 - val_loss: 141.0759\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6400 - val_loss: 151.1118\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2806 - val_loss: 148.1165\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.6239 - val_loss: 174.1591\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8860 - val_loss: 143.9445\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3023 - val_loss: 208.9858\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4166 - val_loss: 160.5998\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.1103 - val_loss: 175.4660\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7699 - val_loss: 172.4097\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1890 - val_loss: 173.2813\n",
      "Epoch 2261/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3935 - val_loss: 146.2604\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2380 - val_loss: 160.8510\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3668 - val_loss: 186.2088\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8362 - val_loss: 147.0567\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2533 - val_loss: 155.8639\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5412 - val_loss: 193.3533\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2366 - val_loss: 157.4271\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0327 - val_loss: 172.9704\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.6891 - val_loss: 447.2332\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0176 - val_loss: 144.3186\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.0827 - val_loss: 163.3111\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 137.939 - 0s 51us/step - loss: 138.9975 - val_loss: 175.8932\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 136.1152 - val_loss: 141.2247\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 170.5887 - val_loss: 152.9700\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 142.1008 - val_loss: 149.5176\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5679 - val_loss: 171.4094\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8020 - val_loss: 749.3956\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.8084 - val_loss: 182.0400\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2211 - val_loss: 188.5942\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9288 - val_loss: 142.0351\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1304 - val_loss: 163.5900\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3089 - val_loss: 146.3840\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.7148 - val_loss: 151.2676\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0971 - val_loss: 150.8347\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0908 - val_loss: 145.8924\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6023 - val_loss: 148.7363\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4066 - val_loss: 165.4702\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.3544 - val_loss: 137.9167\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7018 - val_loss: 175.5176\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 304.4065 - val_loss: 1512.2997\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 285.4858 - val_loss: 183.5665\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.0696 - val_loss: 194.8108\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2758 - val_loss: 159.6557\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.8428 - val_loss: 162.7145\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3316 - val_loss: 170.7776\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6862 - val_loss: 222.2302\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6585 - val_loss: 158.5052\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4576 - val_loss: 183.8914\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.3056 - val_loss: 226.0056\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1024 - val_loss: 164.7606\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 236.3929 - val_loss: 212.5440\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.1920 - val_loss: 147.8146\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9427 - val_loss: 142.8733\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8739 - val_loss: 190.3876\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4710 - val_loss: 165.8690\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3720 - val_loss: 158.2643\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1048 - val_loss: 167.7152\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6927 - val_loss: 192.2205\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5914 - val_loss: 148.3441\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3326 - val_loss: 145.9431\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0936 - val_loss: 167.7132\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1917 - val_loss: 163.4370\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1779 - val_loss: 174.5495\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1740 - val_loss: 150.8593\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9701 - val_loss: 142.1677\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3428 - val_loss: 164.2272\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8632 - val_loss: 153.5096\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3851 - val_loss: 160.8082\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3311 - val_loss: 170.2247\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.7918 - val_loss: 179.6704\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2548 - val_loss: 200.2906\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0634 - val_loss: 150.6193\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2919 - val_loss: 146.3421\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.6368 - val_loss: 155.8414\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2361 - val_loss: 155.0525\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5800 - val_loss: 152.5598\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6772 - val_loss: 149.9109\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.5438 - val_loss: 155.3929\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0633 - val_loss: 144.2596\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1065 - val_loss: 143.8487\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0028 - val_loss: 146.3615\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1182 - val_loss: 139.5515\n",
      "Epoch 2333/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.6839 - val_loss: 147.5022\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6137 - val_loss: 162.1454\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8913 - val_loss: 174.2790\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7176 - val_loss: 142.3519\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.1335 - val_loss: 181.8476\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3657 - val_loss: 157.7670\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9998 - val_loss: 147.9909\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7994 - val_loss: 162.3080\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7465 - val_loss: 154.8316\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3271 - val_loss: 169.4372\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3619 - val_loss: 160.4368\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7114 - val_loss: 170.8901\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 165.0582 - val_loss: 341.1889\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 148.8994 - val_loss: 138.8508\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 129.8587 - val_loss: 175.7370\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.1043 - val_loss: 189.5212\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3173 - val_loss: 165.7159\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.6255 - val_loss: 146.8284\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4128 - val_loss: 188.4029\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1986 - val_loss: 142.7716\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.8206 - val_loss: 220.5354\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.3014 - val_loss: 151.6377\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9559 - val_loss: 151.4257\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.0864 - val_loss: 180.3831\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.7382 - val_loss: 156.9327\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8001 - val_loss: 182.6275\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2602 - val_loss: 147.1876\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5661 - val_loss: 213.0883\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1411 - val_loss: 157.3193\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.9748 - val_loss: 143.1709\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.8880 - val_loss: 152.5048\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5191 - val_loss: 148.1052\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9034 - val_loss: 139.6072\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.5008 - val_loss: 143.4691\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6978 - val_loss: 161.6379\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.5889 - val_loss: 165.8644\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6008 - val_loss: 156.2091\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.7202 - val_loss: 159.3609\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7435 - val_loss: 141.0797\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9068 - val_loss: 160.8165\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5732 - val_loss: 228.2320\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.0661 - val_loss: 178.9049\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1515 - val_loss: 154.1285\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3139 - val_loss: 157.2058\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4216 - val_loss: 208.0685\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2143 - val_loss: 144.3676\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.1224 - val_loss: 164.7307TA: 0s - loss: 127\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5013 - val_loss: 155.1241\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3219 - val_loss: 155.8498\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8990 - val_loss: 146.8470\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7642 - val_loss: 152.1837\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0857 - val_loss: 163.3006\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4971 - val_loss: 175.8154\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.3050 - val_loss: 178.6931\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 349.3726 - val_loss: 242.0392\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.4030 - val_loss: 165.4028\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.5718 - val_loss: 166.6920\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.4823 - val_loss: 164.0104\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.0033 - val_loss: 154.5473\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.3875 - val_loss: 168.7182\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.2973 - val_loss: 159.2609\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 174.0048 - val_loss: 252.4210\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 238.1426 - val_loss: 185.8460\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.1883 - val_loss: 154.3657\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2821 - val_loss: 215.8382\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0639 - val_loss: 160.3703\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.4730 - val_loss: 142.1147\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5255 - val_loss: 152.4547\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0571 - val_loss: 162.4069\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7473 - val_loss: 149.8626\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7265 - val_loss: 151.9403\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.4324 - val_loss: 162.9659\n",
      "Epoch 2405/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0236 - val_loss: 154.0781\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9955 - val_loss: 146.9685\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7384 - val_loss: 187.4324\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3487 - val_loss: 166.0598\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0864 - val_loss: 154.8050\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8933 - val_loss: 182.3697\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 204.4727 - val_loss: 147.4808\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9984 - val_loss: 154.0596\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8282 - val_loss: 141.5172\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2418 - val_loss: 159.1898\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5438 - val_loss: 147.6269\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.3631 - val_loss: 158.9740\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 130.3857 - val_loss: 159.3514\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.0365 - val_loss: 142.3695\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.4471 - val_loss: 277.3453\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.9764 - val_loss: 147.3051\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7013 - val_loss: 148.8806\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.1512 - val_loss: 153.3671\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.5337 - val_loss: 161.7914\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7356 - val_loss: 142.6131\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9098 - val_loss: 152.0988\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6767 - val_loss: 142.9501\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9052 - val_loss: 145.1453\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3307 - val_loss: 178.0192\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2183 - val_loss: 143.0355\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1271 - val_loss: 158.9688\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7492 - val_loss: 153.8204\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6694 - val_loss: 161.3650\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9027 - val_loss: 226.9933\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6252 - val_loss: 162.5249\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.2986 - val_loss: 148.6307\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6265 - val_loss: 153.9519\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0947 - val_loss: 143.5450\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.5811 - val_loss: 161.8874\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1230 - val_loss: 144.5963\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1118 - val_loss: 144.3919\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2317 - val_loss: 157.2408\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.4465 - val_loss: 178.0209\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.5398 - val_loss: 154.4711\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2944 - val_loss: 159.3122\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0663 - val_loss: 181.9506\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3599 - val_loss: 153.1744\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1931 - val_loss: 143.8997\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5025 - val_loss: 140.8067\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3072 - val_loss: 180.1459\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2218 - val_loss: 143.6435\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9100 - val_loss: 142.1251\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9526 - val_loss: 399.4239\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6118 - val_loss: 142.7445\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9737 - val_loss: 142.1759\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6328 - val_loss: 144.5676\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3838 - val_loss: 185.7422\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1485 - val_loss: 148.1377\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.6830 - val_loss: 142.6002\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0603 - val_loss: 148.6010\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7751 - val_loss: 140.0972\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.3363 - val_loss: 166.4526\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5906 - val_loss: 332.3603\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.0648 - val_loss: 157.6049\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9243 - val_loss: 192.2343\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.1118 - val_loss: 145.4933\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2136 - val_loss: 179.9437\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4189 - val_loss: 149.3232\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0211 - val_loss: 187.9826\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4369 - val_loss: 141.4795\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.4049 - val_loss: 189.9508\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0198 - val_loss: 148.1784\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5010 - val_loss: 147.1107\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 136.958 - 0s 51us/step - loss: 137.9550 - val_loss: 217.9524\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5345 - val_loss: 159.6769\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.5394 - val_loss: 307.3698\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.4950 - val_loss: 224.3166\n",
      "Epoch 2477/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.4005 - val_loss: 151.7775\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.5557 - val_loss: 222.1564\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2533 - val_loss: 202.4611\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.7284 - val_loss: 155.6977\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1649 - val_loss: 199.7805\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5510 - val_loss: 170.3308\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.9927 - val_loss: 178.2161\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8912 - val_loss: 151.1738\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.5168 - val_loss: 177.8223\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8621 - val_loss: 152.0139\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4962 - val_loss: 152.7211\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1996 - val_loss: 155.3354\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 190.9068 - val_loss: 157.0981\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 247.3090 - val_loss: 161.9066\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 153.0268 - val_loss: 156.2930\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 150.0594 - val_loss: 171.6386\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.9272 - val_loss: 152.5736\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.7897 - val_loss: 145.2802\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2222 - val_loss: 158.6742\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4250 - val_loss: 171.1532\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6792 - val_loss: 142.9044\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.4054 - val_loss: 153.6334\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5551 - val_loss: 150.7051\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4431 - val_loss: 161.3970\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5685 - val_loss: 156.3340\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6632 - val_loss: 165.9034\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6855 - val_loss: 147.8568\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6472 - val_loss: 218.3270\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1066 - val_loss: 159.1994\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2847 - val_loss: 143.0284\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6199 - val_loss: 146.8024\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4757 - val_loss: 140.4954\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7511 - val_loss: 196.4579\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0941 - val_loss: 181.7690\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9054 - val_loss: 173.5952\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0872 - val_loss: 178.1908\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9686 - val_loss: 175.4689\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1789 - val_loss: 174.7303\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6898 - val_loss: 176.1391\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.1451 - val_loss: 149.5689\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8409 - val_loss: 170.1479\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 134.1977 - val_loss: 145.9823\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.5601 - val_loss: 146.2309\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2640 - val_loss: 165.7364\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8963 - val_loss: 192.6968\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7878 - val_loss: 176.9965\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2421 - val_loss: 384.1440\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.8498 - val_loss: 181.4777\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.5639 - val_loss: 154.0080\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5002 - val_loss: 185.5276\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3826 - val_loss: 186.9764\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4918 - val_loss: 160.5426\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0495 - val_loss: 151.5932\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2731 - val_loss: 152.3232\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4913 - val_loss: 140.5872\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8421 - val_loss: 163.1074\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5566 - val_loss: 146.3381\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9416 - val_loss: 146.8448\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2823 - val_loss: 150.3499\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0794 - val_loss: 152.5965\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.9619 - val_loss: 167.6089\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0215 - val_loss: 144.7428\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5223 - val_loss: 150.1722\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2933 - val_loss: 185.5768\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2273 - val_loss: 146.7664\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.3405 - val_loss: 142.1610\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2797 - val_loss: 143.0692\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2367 - val_loss: 139.1177\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3911 - val_loss: 144.7892\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4835 - val_loss: 142.4874\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5858 - val_loss: 163.5352\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9965 - val_loss: 146.5967\n",
      "Epoch 2549/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2035 - val_loss: 155.2197\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3162 - val_loss: 138.2381\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4130 - val_loss: 1356.6828\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.0412 - val_loss: 164.0070\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0837 - val_loss: 141.2280\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.7728 - val_loss: 148.5012\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3940 - val_loss: 145.2676\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.0546 - val_loss: 142.7733\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1624 - val_loss: 202.9001\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8459 - val_loss: 184.5920\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1326 - val_loss: 174.4724\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.5038 - val_loss: 144.1403\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 127.1231 - val_loss: 147.3289\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 129.4460 - val_loss: 169.6893\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 155.4466 - val_loss: 194.5707\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.4752 - val_loss: 185.1690\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8651 - val_loss: 170.4617\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7368 - val_loss: 155.0058\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.6437 - val_loss: 206.3423\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.1778 - val_loss: 185.7586\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1171 - val_loss: 154.4197\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.2706 - val_loss: 194.5317\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.3039 - val_loss: 152.2341\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1328 - val_loss: 144.8987\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5037 - val_loss: 150.9629\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2245 - val_loss: 147.3051\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7103 - val_loss: 142.4806\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.2310 - val_loss: 155.2923\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3969 - val_loss: 142.3708\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.8451 - val_loss: 201.0470\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1227 - val_loss: 202.0551\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2498 - val_loss: 159.0966\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.6453 - val_loss: 152.7419\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4040 - val_loss: 137.9954\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1371 - val_loss: 143.5842\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4860 - val_loss: 155.5900\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0749 - val_loss: 147.2062\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5451 - val_loss: 165.8866\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5222 - val_loss: 144.7781\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7556 - val_loss: 140.9234\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.4969 - val_loss: 253.3661\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.3420 - val_loss: 155.1041\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8742 - val_loss: 180.3265\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.9163 - val_loss: 153.6473\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8347 - val_loss: 143.9460\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1630 - val_loss: 139.8202\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0264 - val_loss: 141.8324\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.7860 - val_loss: 154.3619\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8199 - val_loss: 210.3492\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0529 - val_loss: 153.6116\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.2754 - val_loss: 141.6428\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.4810 - val_loss: 149.8417\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8645 - val_loss: 142.1044\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0663 - val_loss: 170.2909\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2126 - val_loss: 154.5682\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.1666 - val_loss: 152.8666\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6110 - val_loss: 142.0068\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5427 - val_loss: 156.5170\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2273 - val_loss: 149.4020\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.1675 - val_loss: 142.7734\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7112 - val_loss: 147.7352\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2016 - val_loss: 187.2800\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 235.1448 - val_loss: 150.4365\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.4613 - val_loss: 149.1939\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3792 - val_loss: 167.8913\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5511 - val_loss: 151.9893\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1788 - val_loss: 171.6947\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.2392 - val_loss: 146.9219\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7416 - val_loss: 142.6963\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.1152 - val_loss: 209.9284\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.4649 - val_loss: 175.5684\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.4789 - val_loss: 156.1471\n",
      "Epoch 2621/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.8672 - val_loss: 143.5803\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.4452 - val_loss: 139.1533\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.5882 - val_loss: 175.1998\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5310 - val_loss: 159.8762\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.2941 - val_loss: 147.1704\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.8196 - val_loss: 151.9372\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.9907 - val_loss: 143.5082\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7268 - val_loss: 314.6246\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7034 - val_loss: 160.6604\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9179 - val_loss: 138.3095\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4856 - val_loss: 279.2448\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.4997 - val_loss: 182.2516\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1358 - val_loss: 149.5311\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0369 - val_loss: 164.6524\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4039 - val_loss: 149.0386\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9088 - val_loss: 138.2325\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2849 - val_loss: 147.7093\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3159 - val_loss: 193.4918\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0231 - val_loss: 181.2374\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3262 - val_loss: 157.0176\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9452 - val_loss: 170.1293\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.0133 - val_loss: 158.0735\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 165.2144 - val_loss: 149.4591\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.1492 - val_loss: 147.0452\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.5866 - val_loss: 144.9360\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9000 - val_loss: 137.7202\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3551 - val_loss: 144.8742\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9212 - val_loss: 164.2116\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.4484 - val_loss: 156.1653\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4707 - val_loss: 170.2521\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9233 - val_loss: 166.5340\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2032 - val_loss: 236.6608\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7311 - val_loss: 221.1051\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3965 - val_loss: 155.4751\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1172 - val_loss: 141.0297\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.8510 - val_loss: 176.2642\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.9602 - val_loss: 176.1462\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8851 - val_loss: 148.9708\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4428 - val_loss: 180.7008\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5752 - val_loss: 168.6408\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4965 - val_loss: 165.8834\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.4625 - val_loss: 157.0286\n",
      "Epoch 2663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8178 - val_loss: 145.0257\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9028 - val_loss: 148.6391\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.1327 - val_loss: 140.8882\n",
      "Epoch 2666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2800 - val_loss: 202.0988\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4776 - val_loss: 156.5877\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3976 - val_loss: 159.8988\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7558 - val_loss: 149.6360\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.6052 - val_loss: 145.9017\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.9367 - val_loss: 170.8305\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2555 - val_loss: 172.2024\n",
      "Epoch 2673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8664 - val_loss: 151.2445\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3353 - val_loss: 146.0800\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7343 - val_loss: 150.5176\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.1054 - val_loss: 190.2808\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9932 - val_loss: 143.2094\n",
      "Epoch 2678/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2246 - val_loss: 158.3702\n",
      "Epoch 2679/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0409 - val_loss: 165.5053\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.0400 - val_loss: 178.0861\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8985 - val_loss: 151.7849\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.1209 - val_loss: 146.9054\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4264 - val_loss: 162.8526\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7428 - val_loss: 159.2387\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 360.4690 - val_loss: 156.7420\n",
      "Epoch 2686/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.5282 - val_loss: 155.9893\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7000 - val_loss: 142.2149\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5661 - val_loss: 167.1291\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6636 - val_loss: 158.2564\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.0823 - val_loss: 174.4237\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7319 - val_loss: 145.5176\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5582 - val_loss: 144.0237\n",
      "Epoch 2693/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5494 - val_loss: 153.5430\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1984 - val_loss: 155.0099\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0658 - val_loss: 146.9433\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6327 - val_loss: 152.9482\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.5130 - val_loss: 164.5614\n",
      "Epoch 2698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2039 - val_loss: 153.1359\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0944 - val_loss: 153.7886\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5424 - val_loss: 150.6358\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2798 - val_loss: 138.5679\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2136 - val_loss: 183.9863\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4981 - val_loss: 147.0871\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.9330 - val_loss: 147.2112\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 131.3769 - val_loss: 157.8081\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.2675 - val_loss: 279.2205\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.1523 - val_loss: 142.3521\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7904 - val_loss: 193.1832\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.3229 - val_loss: 174.9063\n",
      "Epoch 2710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8050 - val_loss: 139.4761\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5298 - val_loss: 168.8271\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5810 - val_loss: 163.8827\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4200 - val_loss: 227.0687\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.0327 - val_loss: 165.9130\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2160 - val_loss: 233.3742\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8582 - val_loss: 144.0848\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9554 - val_loss: 164.6760\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9130 - val_loss: 188.2889\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.4595 - val_loss: 186.5368\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.2915 - val_loss: 148.9060\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.3919 - val_loss: 164.8508\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9014 - val_loss: 178.7053\n",
      "Epoch 2723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.5111 - val_loss: 151.7642\n",
      "Epoch 2724/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 247.4185 - val_loss: 739.0132\n",
      "Epoch 2725/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 249.2620 - val_loss: 188.5403\n",
      "Epoch 2726/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.2009 - val_loss: 197.8234\n",
      "Epoch 2727/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.8332 - val_loss: 157.9310\n",
      "Epoch 2728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1209 - val_loss: 151.9028\n",
      "Epoch 2729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.4398 - val_loss: 154.4743\n",
      "Epoch 2730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7026 - val_loss: 150.1847\n",
      "Epoch 2731/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6778 - val_loss: 155.9044\n",
      "Epoch 2732/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9070 - val_loss: 204.9307\n",
      "Epoch 2733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7063 - val_loss: 191.3508\n",
      "Epoch 2734/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2198 - val_loss: 147.0967\n",
      "Epoch 2735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6234 - val_loss: 139.9952\n",
      "Epoch 2736/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3013 - val_loss: 142.2041\n",
      "Epoch 2737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6165 - val_loss: 186.0692\n",
      "Epoch 2738/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.4471 - val_loss: 145.4075\n",
      "Epoch 2739/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.2212 - val_loss: 156.1198\n",
      "Epoch 2740/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.3627 - val_loss: 157.6395\n",
      "Epoch 2741/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7260 - val_loss: 203.8718\n",
      "Epoch 2742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1359 - val_loss: 146.1595\n",
      "Epoch 2743/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6151 - val_loss: 146.7142\n",
      "Epoch 2744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.1767 - val_loss: 218.2326\n",
      "Epoch 2745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9736 - val_loss: 148.2737\n",
      "Epoch 2746/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.4026 - val_loss: 167.9284\n",
      "Epoch 2747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9526 - val_loss: 219.8311\n",
      "Epoch 2748/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.4725 - val_loss: 155.1658\n",
      "Epoch 2749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.5442 - val_loss: 144.8946\n",
      "Epoch 2750/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5061 - val_loss: 182.9471\n",
      "Epoch 2751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4911 - val_loss: 171.1679\n",
      "Epoch 2752/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8216 - val_loss: 146.6050\n",
      "Epoch 2753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5332 - val_loss: 147.5418\n",
      "Epoch 2754/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.6247 - val_loss: 146.7758\n",
      "Epoch 2755/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0404 - val_loss: 146.9917\n",
      "Epoch 2756/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1862 - val_loss: 176.4287\n",
      "Epoch 2757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3990 - val_loss: 154.9558\n",
      "Epoch 2758/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0639 - val_loss: 146.9845\n",
      "Epoch 2759/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2708 - val_loss: 147.9532\n",
      "Epoch 2760/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0313 - val_loss: 157.4774\n",
      "Epoch 2761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.3586 - val_loss: 145.3762\n",
      "Epoch 2762/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7155 - val_loss: 145.0802\n",
      "Epoch 2763/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.2057 - val_loss: 141.9727\n",
      "Epoch 2764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.5342 - val_loss: 1284.2638\n",
      "Epoch 2765/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 496.5001 - val_loss: 262.5482\n",
      "Epoch 2766/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 301.8750 - val_loss: 219.8457\n",
      "Epoch 2767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 331.1181 - val_loss: 257.5254\n",
      "Epoch 2768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.4718 - val_loss: 266.2158\n",
      "Epoch 2769/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 254.7312 - val_loss: 217.8766\n",
      "Epoch 2770/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 232.2323 - val_loss: 363.1577\n",
      "Epoch 2771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.2839 - val_loss: 171.8988\n",
      "Epoch 2772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.3462 - val_loss: 165.6157\n",
      "Epoch 2773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 268.4686 - val_loss: 164.6796\n",
      "Epoch 2774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.8986 - val_loss: 177.7659\n",
      "Epoch 2775/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.5636 - val_loss: 206.4609\n",
      "Epoch 2776/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.1281 - val_loss: 268.0841\n",
      "Epoch 2777/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 157.5990 - val_loss: 169.5378\n",
      "Epoch 2778/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.6117 - val_loss: 149.1326\n",
      "Epoch 2779/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 143.9584 - val_loss: 174.5261\n",
      "Epoch 2780/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.5088 - val_loss: 158.2694\n",
      "Epoch 2781/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2566 - val_loss: 149.6859\n",
      "Epoch 2782/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.8839 - val_loss: 299.4635\n",
      "Epoch 2783/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7432 - val_loss: 153.6676\n",
      "Epoch 2784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4905 - val_loss: 193.2828\n",
      "Epoch 2785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9024 - val_loss: 146.5960\n",
      "Epoch 2786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.9028 - val_loss: 159.9445\n",
      "Epoch 2787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6566 - val_loss: 149.8312\n",
      "Epoch 2788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2210 - val_loss: 160.7571\n",
      "Epoch 2789/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6639 - val_loss: 146.9593\n",
      "Epoch 2790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0249 - val_loss: 141.5444\n",
      "Epoch 2791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6506 - val_loss: 165.1400\n",
      "Epoch 2792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3354 - val_loss: 166.3991\n",
      "Epoch 2793/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0424 - val_loss: 148.0143\n",
      "Epoch 2794/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7654 - val_loss: 160.0997\n",
      "Epoch 2795/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3657 - val_loss: 149.7216\n",
      "Epoch 2796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0476 - val_loss: 150.8153\n",
      "Epoch 2797/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6859 - val_loss: 154.2404\n",
      "Epoch 2798/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6201 - val_loss: 151.7698\n",
      "Epoch 2799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1406 - val_loss: 167.9592\n",
      "Epoch 2800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0452 - val_loss: 164.6896\n",
      "Epoch 2801/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6780 - val_loss: 150.7714\n",
      "Epoch 2802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3026 - val_loss: 143.7955\n",
      "Epoch 2803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8535 - val_loss: 220.5525\n",
      "Epoch 2804/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.9789 - val_loss: 143.8137\n",
      "Epoch 2805/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1159 - val_loss: 145.3032\n",
      "Epoch 2806/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.2008 - val_loss: 187.7468\n",
      "Epoch 2807/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7734 - val_loss: 151.0026\n",
      "Epoch 2808/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.9937 - val_loss: 156.6935\n",
      "Epoch 2809/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.9023 - val_loss: 151.9129\n",
      "Epoch 2810/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3656 - val_loss: 143.3059\n",
      "Epoch 2811/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.3553 - val_loss: 183.1322\n",
      "Epoch 2812/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4334 - val_loss: 141.7397\n",
      "Epoch 2813/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0605 - val_loss: 237.0160\n",
      "Epoch 2814/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7004 - val_loss: 147.6737\n",
      "Epoch 2815/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9581 - val_loss: 150.7796\n",
      "Epoch 2816/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4642 - val_loss: 176.3840\n",
      "Epoch 2817/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.9917 - val_loss: 157.0078\n",
      "Epoch 2818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6715 - val_loss: 149.1029\n",
      "Epoch 2819/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.6012 - val_loss: 177.4502\n",
      "Epoch 2820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.3790 - val_loss: 162.8147\n",
      "Epoch 2821/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4260 - val_loss: 154.0496\n",
      "Epoch 2822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4967 - val_loss: 181.6346\n",
      "Epoch 2823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1690 - val_loss: 147.6260\n",
      "Epoch 2824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5624 - val_loss: 152.4688\n",
      "Epoch 2825/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8515 - val_loss: 140.9650\n",
      "Epoch 2826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9838 - val_loss: 203.7939\n",
      "Epoch 2827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1443 - val_loss: 171.1500\n",
      "Epoch 2828/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8461 - val_loss: 196.9377\n",
      "Epoch 2829/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0125 - val_loss: 161.7144\n",
      "Epoch 2830/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.8847 - val_loss: 145.4736\n",
      "Epoch 2831/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.8302 - val_loss: 151.5601\n",
      "Epoch 2832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5480 - val_loss: 154.1723\n",
      "Epoch 2833/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0156 - val_loss: 158.0374\n",
      "Epoch 2834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6251 - val_loss: 181.9695\n",
      "Epoch 2835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7097 - val_loss: 146.7186\n",
      "Epoch 2836/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 299.4857 - val_loss: 253.6240\n",
      "Epoch 2837/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.4687 - val_loss: 215.6375\n",
      "Epoch 2838/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.4255 - val_loss: 284.4673\n",
      "Epoch 2839/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.2010 - val_loss: 208.0592\n",
      "Epoch 2840/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.9025 - val_loss: 302.3597\n",
      "Epoch 2841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.4303 - val_loss: 169.0776\n",
      "Epoch 2842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2691 - val_loss: 159.6487\n",
      "Epoch 2843/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6616 - val_loss: 296.0070\n",
      "Epoch 2844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6351 - val_loss: 155.8192\n",
      "Epoch 2845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2337 - val_loss: 165.7634\n",
      "Epoch 2846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8164 - val_loss: 162.6443\n",
      "Epoch 2847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.9071 - val_loss: 160.8621\n",
      "Epoch 2848/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6063 - val_loss: 218.7489\n",
      "Epoch 2849/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 163.6778 - val_loss: 168.4164\n",
      "Epoch 2850/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 145.2263 - val_loss: 155.3251\n",
      "Epoch 2851/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 157.0339 - val_loss: 184.5596\n",
      "Epoch 2852/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.8574 - val_loss: 161.4612\n",
      "Epoch 2853/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8738 - val_loss: 172.9417\n",
      "Epoch 2854/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.8679 - val_loss: 150.6241\n",
      "Epoch 2855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6969 - val_loss: 159.8726\n",
      "Epoch 2856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7850 - val_loss: 196.9969\n",
      "Epoch 2857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9565 - val_loss: 154.0198\n",
      "Epoch 2858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8206 - val_loss: 156.0959\n",
      "Epoch 2859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4261 - val_loss: 167.5130\n",
      "Epoch 2860/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.2732 - val_loss: 206.9337\n",
      "Epoch 2861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.4313 - val_loss: 156.3081\n",
      "Epoch 2862/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8264 - val_loss: 375.1660\n",
      "Epoch 2863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7814 - val_loss: 155.1769\n",
      "Epoch 2864/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.2282 - val_loss: 161.1230\n",
      "Epoch 2865/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5760 - val_loss: 174.8478\n",
      "Epoch 2866/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0783 - val_loss: 234.0155\n",
      "Epoch 2867/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1097 - val_loss: 156.6513\n",
      "Epoch 2868/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0089 - val_loss: 184.6064\n",
      "Epoch 2869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9184 - val_loss: 155.4570\n",
      "Epoch 2870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2114 - val_loss: 167.1699\n",
      "Epoch 2871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.1261 - val_loss: 202.6171\n",
      "Epoch 2872/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2337 - val_loss: 162.6750\n",
      "Epoch 2873/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.6731 - val_loss: 157.0825\n",
      "Epoch 2874/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4037 - val_loss: 158.9373\n",
      "Epoch 2875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4749 - val_loss: 208.7185\n",
      "Epoch 2876/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.1226 - val_loss: 147.4534\n",
      "Epoch 2877/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0568 - val_loss: 173.2963\n",
      "Epoch 2878/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9412 - val_loss: 151.2601\n",
      "Epoch 2879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6347 - val_loss: 155.3707\n",
      "Epoch 2880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7284 - val_loss: 153.4006\n",
      "Epoch 2881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7195 - val_loss: 161.6481\n",
      "Epoch 2882/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9110 - val_loss: 156.9463\n",
      "Epoch 2883/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.6484 - val_loss: 163.8585\n",
      "Epoch 2884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7231 - val_loss: 162.5583\n",
      "Epoch 2885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.4485 - val_loss: 188.1299\n",
      "Epoch 2886/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.7078 - val_loss: 148.9283\n",
      "Epoch 2887/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5669 - val_loss: 159.5336\n",
      "Epoch 2888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5525 - val_loss: 154.1656\n",
      "Epoch 2889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9352 - val_loss: 163.9409\n",
      "Epoch 2890/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.8171 - val_loss: 152.3785\n",
      "Epoch 2891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2008 - val_loss: 203.4801\n",
      "Epoch 2892/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7681 - val_loss: 175.4199\n",
      "Epoch 2893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.4237 - val_loss: 164.0887\n",
      "Epoch 2894/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9649 - val_loss: 176.3954\n",
      "Epoch 2895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7420 - val_loss: 180.5570\n",
      "Epoch 2896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.4665 - val_loss: 195.7732\n",
      "Epoch 2897/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7847 - val_loss: 161.6535\n",
      "Epoch 2898/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.3760 - val_loss: 156.8508\n",
      "Epoch 2899/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.2799 - val_loss: 146.8049\n",
      "Epoch 2900/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4979 - val_loss: 141.3744\n",
      "Epoch 2901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6621 - val_loss: 146.5359\n",
      "Epoch 2902/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 140.9180 - val_loss: 163.6315\n",
      "Epoch 2903/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0596 - val_loss: 307.4513\n",
      "Epoch 2904/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7827 - val_loss: 161.4697\n",
      "Epoch 2905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6569 - val_loss: 159.0815\n",
      "Epoch 2906/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7041 - val_loss: 152.1048\n",
      "Epoch 2907/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3275 - val_loss: 142.9220\n",
      "Epoch 2908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9726 - val_loss: 196.0923\n",
      "Epoch 2909/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8264 - val_loss: 236.4867\n",
      "Epoch 2910/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 167.9121 - val_loss: 142.2084\n",
      "Epoch 2911/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.3450 - val_loss: 183.1202\n",
      "Epoch 2912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4294 - val_loss: 149.9393\n",
      "Epoch 2913/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6648 - val_loss: 169.6367\n",
      "Epoch 2914/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.7675 - val_loss: 152.2665\n",
      "Epoch 2915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.4948 - val_loss: 247.7370- ETA: 0s - loss: 144\n",
      "Epoch 2916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1888 - val_loss: 147.9740\n",
      "Epoch 2917/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6054 - val_loss: 154.5589\n",
      "Epoch 2918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9744 - val_loss: 235.2243\n",
      "Epoch 2919/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0052 - val_loss: 183.5056\n",
      "Epoch 2920/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4898 - val_loss: 154.6794\n",
      "Epoch 2921/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.6831 - val_loss: 167.7277\n",
      "Epoch 2922/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 148.4768 - val_loss: 178.4935\n",
      "Epoch 2923/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.9462 - val_loss: 157.0183\n",
      "Epoch 2924/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 139.1314 - val_loss: 142.8449\n",
      "Epoch 2925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8676 - val_loss: 151.8778\n",
      "Epoch 2926/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5229 - val_loss: 149.9228\n",
      "Epoch 2927/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.6677 - val_loss: 405.8396\n",
      "Epoch 2928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2347 - val_loss: 171.5164\n",
      "Epoch 2929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3625 - val_loss: 158.4459\n",
      "Epoch 2930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4089 - val_loss: 149.6473\n",
      "Epoch 2931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0028 - val_loss: 164.2261\n",
      "Epoch 2932/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5202 - val_loss: 150.1197\n",
      "Epoch 2933/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9538 - val_loss: 154.9824\n",
      "Epoch 2934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0595 - val_loss: 290.3157\n",
      "Epoch 2935/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3714 - val_loss: 198.1185\n",
      "Epoch 2936/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4552 - val_loss: 145.9472\n",
      "Epoch 2937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7904 - val_loss: 154.3066\n",
      "Epoch 2938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1539 - val_loss: 181.9846\n",
      "Epoch 2939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7377 - val_loss: 185.6238\n",
      "Epoch 2940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7074 - val_loss: 154.7295\n",
      "Epoch 2941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7808 - val_loss: 212.2147\n",
      "Epoch 2942/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9940 - val_loss: 185.9694\n",
      "Epoch 2943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0448 - val_loss: 244.4875\n",
      "Epoch 2944/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3151 - val_loss: 194.5362\n",
      "Epoch 2945/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.5975 - val_loss: 160.6292\n",
      "Epoch 2946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9711 - val_loss: 170.3923\n",
      "Epoch 2947/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1728 - val_loss: 155.8007\n",
      "Epoch 2948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1006 - val_loss: 150.7748\n",
      "Epoch 2949/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3517 - val_loss: 153.9987\n",
      "Epoch 2950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0268 - val_loss: 145.1316\n",
      "Epoch 2951/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.4564 - val_loss: 164.6859\n",
      "Epoch 2952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4585 - val_loss: 142.1572\n",
      "Epoch 2953/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1985 - val_loss: 155.5832\n",
      "Epoch 2954/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.1521 - val_loss: 155.5831\n",
      "Epoch 2955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.9122 - val_loss: 193.5564\n",
      "Epoch 2956/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.6733 - val_loss: 147.1264\n",
      "Epoch 2957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2230 - val_loss: 163.3460\n",
      "Epoch 2958/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4897 - val_loss: 149.3584\n",
      "Epoch 2959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4921 - val_loss: 142.4358\n",
      "Epoch 2960/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0197 - val_loss: 150.3878\n",
      "Epoch 2961/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.4616 - val_loss: 220.3419\n",
      "Epoch 2962/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.6398 - val_loss: 213.7008\n",
      "Epoch 2963/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.2338 - val_loss: 149.4408\n",
      "Epoch 2964/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3135 - val_loss: 146.9779\n",
      "Epoch 2965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4024 - val_loss: 149.9371\n",
      "Epoch 2966/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.4911 - val_loss: 188.1736\n",
      "Epoch 2967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5430 - val_loss: 230.3352\n",
      "Epoch 2968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.3393 - val_loss: 195.9359\n",
      "Epoch 2969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5034 - val_loss: 161.1851\n",
      "Epoch 2970/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5809 - val_loss: 183.3696\n",
      "Epoch 2971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4006 - val_loss: 169.4665\n",
      "Epoch 2972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5527 - val_loss: 151.1652\n",
      "Epoch 2973/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4265 - val_loss: 151.1409\n",
      "Epoch 2974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4156 - val_loss: 184.3407\n",
      "Epoch 2975/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.8952 - val_loss: 165.2341\n",
      "Epoch 2976/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5929 - val_loss: 145.2396\n",
      "Epoch 2977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7712 - val_loss: 191.9355\n",
      "Epoch 2978/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8115 - val_loss: 176.1619\n",
      "Epoch 2979/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.2665 - val_loss: 142.0349\n",
      "Epoch 2980/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1377 - val_loss: 165.0244\n",
      "Epoch 2981/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5922 - val_loss: 163.8385\n",
      "Epoch 2982/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1775 - val_loss: 182.7281\n",
      "Epoch 2983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4186 - val_loss: 148.8972\n",
      "Epoch 2984/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3468 - val_loss: 154.4696\n",
      "Epoch 2985/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3992 - val_loss: 165.8475\n",
      "Epoch 2986/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3983 - val_loss: 178.3917\n",
      "Epoch 2987/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6099 - val_loss: 185.4536\n",
      "Epoch 2988/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7739 - val_loss: 150.7175\n",
      "Epoch 2989/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9680 - val_loss: 155.0278\n",
      "Epoch 2990/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1588 - val_loss: 163.5819\n",
      "Epoch 2991/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2753 - val_loss: 198.8369\n",
      "Epoch 2992/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6282 - val_loss: 216.4660\n",
      "Epoch 2993/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 158.2316 - val_loss: 191.0103\n",
      "Epoch 2994/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.8027 - val_loss: 153.7882\n",
      "Epoch 2995/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 137.5415 - val_loss: 152.4359\n",
      "Epoch 2996/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 143.6589 - val_loss: 162.4147\n",
      "Epoch 2997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6530 - val_loss: 152.9258\n",
      "Epoch 2998/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1547 - val_loss: 179.0088\n",
      "Epoch 2999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7794 - val_loss: 163.5760\n",
      "Epoch 3000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9860 - val_loss: 177.7059\n",
      "Epoch 3001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.4839 - val_loss: 157.1953\n",
      "Epoch 3002/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6154 - val_loss: 149.3339\n",
      "Epoch 3003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1214 - val_loss: 196.8950\n",
      "Epoch 3004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9246 - val_loss: 174.0391\n",
      "Epoch 3005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0508 - val_loss: 150.4988\n",
      "Epoch 3006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0612 - val_loss: 156.5278\n",
      "Epoch 3007/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4812 - val_loss: 149.9544\n",
      "Epoch 03007: early stopping\n",
      "Fold score (RMSE): 11.925237655639648\n",
      "Fold #3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 5674.5373 - val_loss: 5314.5866\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 4842.0372 - val_loss: 4655.6169\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4562.7635 - val_loss: 4904.4263\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4307.1385 - val_loss: 4351.7795\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4259.3323 - val_loss: 4290.9561\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4203.7214 - val_loss: 4359.5683\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4027.3878 - val_loss: 4315.3191\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4017.9713 - val_loss: 4311.5211\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3868.7393 - val_loss: 4065.2762\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3906.4158 - val_loss: 3866.7830\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3850.4772 - val_loss: 3665.3416\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 3528.9772 - val_loss: 3658.2666\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3361.5868 - val_loss: 2791.7284\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 2808.1471 - val_loss: 3521.6367\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2633.3856 - val_loss: 2448.7967\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 2018.6249 - val_loss: 1665.6681\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2057.4112 - val_loss: 1970.8050\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1514.2690 - val_loss: 965.3596\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1090.9101 - val_loss: 826.3597\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1048.0177 - val_loss: 2809.4535\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1023.0688 - val_loss: 1127.2003\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 1164.7368 - val_loss: 638.5816\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 759.7034 - val_loss: 588.5108\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 661.5763 - val_loss: 649.9753\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 646.5435 - val_loss: 689.6418\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 595.2332 - val_loss: 624.7543\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 636.3999 - val_loss: 377.1748\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 658.1627 - val_loss: 542.9642\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 489.4381 - val_loss: 467.6200\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 772.9331 - val_loss: 420.5918\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 479.0612 - val_loss: 387.0386\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 468.1503 - val_loss: 501.5872\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 478.8598 - val_loss: 577.8348\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 493.2630 - val_loss: 471.0332\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 682.1602 - val_loss: 531.7287\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 430.3010 - val_loss: 426.0031\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 471.2605 - val_loss: 464.4332\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 422.9268 - val_loss: 677.5377\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 476.5227 - val_loss: 310.7381\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 416.9080 - val_loss: 325.6829\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 377.8392 - val_loss: 382.4433\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 499.4031 - val_loss: 1042.7955\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 465.0871 - val_loss: 1905.8834\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 571.3924 - val_loss: 394.4386\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 466.4818 - val_loss: 315.0638\n",
      "Epoch 46/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 436.4666 - val_loss: 303.3786\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 412.9127 - val_loss: 907.7310\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 378.255 - 0s 57us/step - loss: 370.4768 - val_loss: 315.5675\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 448.5671 - val_loss: 529.4706\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 419.5094 - val_loss: 386.5019\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 391.3295 - val_loss: 306.2925\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 385.5351 - val_loss: 349.8705\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 354.5860 - val_loss: 406.8679\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 426.0168 - val_loss: 274.7510\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 402.7684 - val_loss: 302.5387\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 411.6910 - val_loss: 326.4396\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 352.7070 - val_loss: 472.9630\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 403.1926 - val_loss: 264.0401\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 380.3626 - val_loss: 393.7253\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 828.1886 - val_loss: 381.7033\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 427.5479 - val_loss: 294.0330\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 397.3025 - val_loss: 315.6917\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 441.9835 - val_loss: 1270.9633\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 493.5975 - val_loss: 378.0818\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 389.4126 - val_loss: 1023.5399\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 378.7718 - val_loss: 413.8435\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 363.7798 - val_loss: 274.2383\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 385.1459 - val_loss: 348.1636\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 360.9042 - val_loss: 337.8021\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 441.9614 - val_loss: 259.4809\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 352.5614 - val_loss: 288.5064\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 345.0783 - val_loss: 402.4351\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 322.7702 - val_loss: 316.5188\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 362.8164 - val_loss: 366.2483\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 363.5164 - val_loss: 337.9275\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 588.6537 - val_loss: 365.2290\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 318.9385 - val_loss: 262.5737\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 373.9902 - val_loss: 997.6600\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 483.971 - 0s 51us/step - loss: 482.1228 - val_loss: 275.6728\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 277.7402 - val_loss: 265.9015\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 312.2702 - val_loss: 587.4003\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 358.4275 - val_loss: 509.3072\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 309.9200 - val_loss: 542.0360\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 492.7403 - val_loss: 278.2046\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 407.9139 - val_loss: 505.6223\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 371.3586 - val_loss: 1747.8020\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 468.4196 - val_loss: 262.8051\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 308.4220 - val_loss: 276.0425\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 316.3111 - val_loss: 239.1205\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 350.5545 - val_loss: 242.2367\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 322.0930 - val_loss: 250.0483\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 338.5780 - val_loss: 238.5029\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 292.7031 - val_loss: 236.7042\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 330.1546 - val_loss: 319.0127\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 350.4671 - val_loss: 506.4030\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 314.0117 - val_loss: 250.6252\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 414.2829 - val_loss: 300.9462\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 329.5909 - val_loss: 249.6882\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 334.6945 - val_loss: 244.0505\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 294.6525 - val_loss: 256.5669\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 320.4772 - val_loss: 326.3090\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 316.3269 - val_loss: 250.6594\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 287.6513 - val_loss: 321.8038\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 334.8146 - val_loss: 301.2751\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 318.2575 - val_loss: 391.2905\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 262.2111 - val_loss: 201.4735\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 341.0688 - val_loss: 210.3315\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 267.4509 - val_loss: 239.3562\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 319.9469 - val_loss: 285.2976\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 325.0875 - val_loss: 259.0076\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 365.8150 - val_loss: 287.5325\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 387.9376 - val_loss: 350.4820\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 339.5501 - val_loss: 475.0045\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 277.9524 - val_loss: 230.5927\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.3168 - val_loss: 208.2947\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 351.5756 - val_loss: 213.2748\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.9782 - val_loss: 239.9061\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 311.6780 - val_loss: 205.2372\n",
      "Epoch 119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.4744 - val_loss: 209.5485\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.5661 - val_loss: 252.0688\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 271.5478 - val_loss: 202.4422\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.8032 - val_loss: 219.8630\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 281.7660 - val_loss: 296.1254\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.0108 - val_loss: 217.1157\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 228.7671 - val_loss: 205.8202\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 316.0546 - val_loss: 217.6598\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 367.5362 - val_loss: 302.8608\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 305.1524 - val_loss: 245.8429\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.1634 - val_loss: 193.6077\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 225.0605 - val_loss: 226.4175\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 268.9688 - val_loss: 191.1498\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 285.1795 - val_loss: 285.1131\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 397.2910 - val_loss: 623.9469\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 264.0594 - val_loss: 274.1165\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 261.0705 - val_loss: 221.7974\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.0849 - val_loss: 208.0582\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 274.2917 - val_loss: 233.0680\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.6839 - val_loss: 214.2478\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 258.6160 - val_loss: 207.2709\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 290.5842 - val_loss: 184.1600\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.7729 - val_loss: 231.0492\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 303.7082 - val_loss: 241.7466\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 245.5140 - val_loss: 211.9540\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 336.3295 - val_loss: 257.4222\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 325.3751 - val_loss: 222.0851\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 314.0979 - val_loss: 212.1402\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.9715 - val_loss: 479.0895\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.7321 - val_loss: 514.4728\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.1544 - val_loss: 178.3290\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.6321 - val_loss: 175.4046\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.0087 - val_loss: 238.0393\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 234.7745 - val_loss: 573.6851\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 268.5938 - val_loss: 225.6186\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 231.3763 - val_loss: 188.2998\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.0412 - val_loss: 286.6270\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 343.5150 - val_loss: 381.8061\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.1375 - val_loss: 188.8682\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.2463 - val_loss: 180.2419\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.5965 - val_loss: 245.3727\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.8980 - val_loss: 233.7984\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.7499 - val_loss: 197.9018\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.5641 - val_loss: 227.5016\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.8534 - val_loss: 204.3721\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.4248 - val_loss: 224.0004\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 289.1248 - val_loss: 361.8162\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.6591 - val_loss: 407.4109\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.5092 - val_loss: 366.8939\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.7106 - val_loss: 185.4790\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 314.1775 - val_loss: 172.5618\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.3087 - val_loss: 172.2413\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 281.1416 - val_loss: 217.5742\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.4059 - val_loss: 174.7059\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.6974 - val_loss: 201.0170\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.8464 - val_loss: 224.0861\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 361.7311 - val_loss: 192.5488\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 297.1192 - val_loss: 1593.8068\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 351.5465 - val_loss: 323.6557\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 248.1515 - val_loss: 238.9803\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 340.4467 - val_loss: 163.5356\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.1065 - val_loss: 185.5392\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 258.7988 - val_loss: 177.0796\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.6517 - val_loss: 187.7672\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.1737 - val_loss: 175.9999\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.1357 - val_loss: 258.8438\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 218.8001 - val_loss: 372.2294\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.0795 - val_loss: 263.9320\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.3032 - val_loss: 158.9279\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.9056 - val_loss: 247.8648\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 384.4604 - val_loss: 442.8222\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.0788 - val_loss: 195.3863\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 274.5135 - val_loss: 199.1364\n",
      "Epoch 192/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 205.5647 - val_loss: 227.9559\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.7124 - val_loss: 178.0578\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.8336 - val_loss: 164.7757\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.4917 - val_loss: 320.5412\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 296.5194 - val_loss: 223.6236\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 308.1632 - val_loss: 339.3006\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 232.6721 - val_loss: 230.0030\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 218.8463 - val_loss: 227.5683\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.3951 - val_loss: 163.6743\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.6490 - val_loss: 203.2566\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.3958 - val_loss: 236.3075\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 283.1894 - val_loss: 243.3446\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1705 - val_loss: 189.5674\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.2014 - val_loss: 179.0867\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.6365 - val_loss: 321.2450\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.2926 - val_loss: 182.9620\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.5769 - val_loss: 240.8252\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.2139 - val_loss: 339.4125\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 293.4721 - val_loss: 242.3044\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 260.6191 - val_loss: 160.7918\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 224.8812 - val_loss: 240.7582\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.3391 - val_loss: 159.2128\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 278.3267 - val_loss: 233.1357\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 244.2426 - val_loss: 171.5709\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.4707 - val_loss: 253.2212\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.3276 - val_loss: 172.9532\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.9959 - val_loss: 191.3099\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 300.4371 - val_loss: 205.0936\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.4724 - val_loss: 290.1028\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.9188 - val_loss: 181.0995\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.1477 - val_loss: 163.7637\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.0606 - val_loss: 177.0697\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.9159 - val_loss: 155.7001\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.7018 - val_loss: 247.6279\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.5720 - val_loss: 213.1021\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.7340 - val_loss: 211.0026\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.1813 - val_loss: 371.1393\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 268.7840 - val_loss: 208.6469\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.3124 - val_loss: 180.9635\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.5316 - val_loss: 205.0079\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.3928 - val_loss: 165.5712\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.0901 - val_loss: 369.1545\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.4564 - val_loss: 197.4729\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.5672 - val_loss: 180.0247\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.6436 - val_loss: 231.2856\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 240.4105 - val_loss: 255.9680\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.5812 - val_loss: 184.0036\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.8178 - val_loss: 251.7343\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 379.1565 - val_loss: 173.9054\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.8295 - val_loss: 161.6202\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.9157 - val_loss: 162.9662\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 185.2898 - val_loss: 150.5872\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 288.0772 - val_loss: 346.7076\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 206.4396 - val_loss: 155.6494\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 187.5154 - val_loss: 162.9970\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 247.3542 - val_loss: 210.4098\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.2658 - val_loss: 157.8326\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.8694 - val_loss: 1064.3499\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 246.7615 - val_loss: 163.8968\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.9926 - val_loss: 205.7019\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 260.7375 - val_loss: 170.1823\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.0307 - val_loss: 323.9175\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.1501 - val_loss: 194.2843\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.4486 - val_loss: 155.3960\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 274.5028 - val_loss: 220.7351\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.6343 - val_loss: 224.6966\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 279.9535 - val_loss: 174.6582\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.7922 - val_loss: 169.8721\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.4099 - val_loss: 165.5851\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.8897 - val_loss: 177.3484\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.4390 - val_loss: 205.2781\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.4304 - val_loss: 897.9559\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 230.2944 - val_loss: 152.7366\n",
      "Epoch 265/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 57us/step - loss: 191.9688 - val_loss: 170.3794\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 185.8250 - val_loss: 195.9344\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 190.5349 - val_loss: 196.4511\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 197.8140 - val_loss: 167.2070\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 196.8345 - val_loss: 197.7740\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 213.9491 - val_loss: 168.2068\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.6465 - val_loss: 159.6090\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.0371 - val_loss: 152.0321\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.5332 - val_loss: 378.0506\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 240.0174 - val_loss: 207.5354\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.4604 - val_loss: 223.7425\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.0612 - val_loss: 406.2357\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.1215 - val_loss: 157.8930\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.1377 - val_loss: 158.2782\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.8228 - val_loss: 156.4131\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.3763 - val_loss: 160.0861\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 202.1705 - val_loss: 178.6061\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.7367 - val_loss: 272.2496\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 204.1850 - val_loss: 153.5432\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 244.1142 - val_loss: 178.4703\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.0653 - val_loss: 298.9560\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 250.2106 - val_loss: 247.6512\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 284.5794 - val_loss: 206.6694\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 200.7874 - val_loss: 157.1001\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 182.4517 - val_loss: 196.3909\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.2884 - val_loss: 154.4767\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.8990 - val_loss: 282.2590\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 242.9025 - val_loss: 147.6608\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.9767 - val_loss: 154.3157\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 221.2992 - val_loss: 612.5209\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.1854 - val_loss: 244.9790\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.4901 - val_loss: 167.9730\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.0732 - val_loss: 163.1169\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 204.0440 - val_loss: 206.4912\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.1103 - val_loss: 168.0712\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.6694 - val_loss: 401.9506\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.7564 - val_loss: 168.7690\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 254.0449 - val_loss: 170.3435\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.7600 - val_loss: 347.9119\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.6155 - val_loss: 153.7194\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 204.1964 - val_loss: 161.9409\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 236.2805 - val_loss: 372.6165\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.9773 - val_loss: 201.5937\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 252.1817 - val_loss: 281.5095\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.1807 - val_loss: 227.7434\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.4255 - val_loss: 152.5309\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.1968 - val_loss: 248.4464\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 199.8060 - val_loss: 155.9375\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 206.3917 - val_loss: 162.3951\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.5282 - val_loss: 210.9036\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 199.5587 - val_loss: 195.1872\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 185.3524 - val_loss: 166.5826\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 182.7844 - val_loss: 174.4170\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 423.1686 - val_loss: 182.7160\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 225.7552 - val_loss: 175.9131\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.7502 - val_loss: 211.8299\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 240.5287 - val_loss: 266.5177\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.6408 - val_loss: 150.3134\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.4305 - val_loss: 154.8284\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 275.4921 - val_loss: 238.6649\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.5875 - val_loss: 213.2995\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.8865 - val_loss: 146.4111\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.1145 - val_loss: 204.7761\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.9261 - val_loss: 144.5193\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 185.5452 - val_loss: 158.9781\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 359.3840 - val_loss: 1000.4373\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 339.3492 - val_loss: 186.0774\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 286.0235 - val_loss: 304.2301\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 219.4706 - val_loss: 198.0051\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 200.1225 - val_loss: 167.9685\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 191.9165 - val_loss: 167.4110\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.7234 - val_loss: 181.2030\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.9673 - val_loss: 484.7484\n",
      "Epoch 338/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 254.2089 - val_loss: 233.0258\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 220.7912 - val_loss: 156.4695\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 227.8204 - val_loss: 169.8763\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.4617 - val_loss: 216.9185\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.2045 - val_loss: 215.5968\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.0708 - val_loss: 176.3387\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.6442 - val_loss: 158.5657\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 197.8283 - val_loss: 176.1613\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 173.6007 - val_loss: 219.4535\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 210.5096 - val_loss: 184.8673\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.7028 - val_loss: 180.6686\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 238.7780 - val_loss: 373.4790\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 318.1519 - val_loss: 154.7786\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.3059 - val_loss: 169.5726\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.0238 - val_loss: 325.2410\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.1566 - val_loss: 211.5500\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.4911 - val_loss: 164.7999\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.5154 - val_loss: 149.0403\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.0764 - val_loss: 309.7404\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.2628 - val_loss: 257.7712\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.7506 - val_loss: 163.3761\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.8148 - val_loss: 156.4675\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.1339 - val_loss: 160.9270\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 181.2736 - val_loss: 196.6349\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.9534 - val_loss: 164.7750\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.3305 - val_loss: 260.2881\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.3928 - val_loss: 179.4784\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.5390 - val_loss: 496.2378\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.5460 - val_loss: 166.0958\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.0944 - val_loss: 150.8651\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.2744 - val_loss: 162.7047\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.1573 - val_loss: 193.1044\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 194.9850 - val_loss: 186.4818\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.6274 - val_loss: 172.6553\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 278.3303 - val_loss: 398.3933\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 195.9929 - val_loss: 162.1802\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.9876 - val_loss: 154.3064\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.5066 - val_loss: 368.1564\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.1329 - val_loss: 148.9250\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.3611 - val_loss: 178.5943\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.5112 - val_loss: 210.0474\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.7205 - val_loss: 155.1710\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.6353 - val_loss: 155.6114\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 175.2027 - val_loss: 167.4502\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.2798 - val_loss: 142.6655\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 231.0782 - val_loss: 207.3831\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 201.4470 - val_loss: 310.0489\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 234.9213 - val_loss: 177.0143\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 180.8411 - val_loss: 154.7552\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.0191 - val_loss: 178.9424\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.4454 - val_loss: 144.9981\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.3110 - val_loss: 140.1157\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.4868 - val_loss: 271.4887\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.0986 - val_loss: 147.1140\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.8518 - val_loss: 212.8041\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.5314 - val_loss: 181.7246\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 235.7689 - val_loss: 155.6412\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.8456 - val_loss: 200.3003\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.5195 - val_loss: 210.7748\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 198.7767 - val_loss: 167.0523\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 241.5181 - val_loss: 245.0431\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 226.5275 - val_loss: 179.6743\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.3288 - val_loss: 166.1223\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.0784 - val_loss: 159.6457\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.1533 - val_loss: 260.0242\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.5461 - val_loss: 159.2138\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 214.9297 - val_loss: 234.8331\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 175.6617 - val_loss: 140.0397\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 264.2839 - val_loss: 176.6043\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.6366 - val_loss: 194.5622\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.9619 - val_loss: 161.0110\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.3574 - val_loss: 149.6363\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.3628 - val_loss: 197.3093\n",
      "Epoch 411/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.1037 - val_loss: 173.9303\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.3909 - val_loss: 173.9249\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.9551 - val_loss: 172.0035\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.1402 - val_loss: 161.5390\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 244.3999 - val_loss: 198.3009\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.7572 - val_loss: 211.5663\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.1725 - val_loss: 167.2427\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.3960 - val_loss: 210.2765\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.4466 - val_loss: 171.0356\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.1255 - val_loss: 207.0898\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.1206 - val_loss: 167.9994\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.0645 - val_loss: 141.4286\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.1951 - val_loss: 147.7821\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.8529 - val_loss: 164.0307\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.0000 - val_loss: 145.9436\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 272.6150 - val_loss: 152.6302\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.5301 - val_loss: 164.4059\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 174.8607 - val_loss: 159.9577\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 215.3330 - val_loss: 198.4963\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.1192 - val_loss: 181.8089\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.4411 - val_loss: 139.5110\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 161.5215 - val_loss: 174.0752\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.9141 - val_loss: 160.2753\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.7067 - val_loss: 198.5106\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.8211 - val_loss: 271.0093\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 388.7995 - val_loss: 194.5997\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.3771 - val_loss: 163.1632\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 280.6327 - val_loss: 266.1305\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 302.6154 - val_loss: 248.0145\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.1426 - val_loss: 154.0559\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.7911 - val_loss: 159.0112\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.6379 - val_loss: 160.1207\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.4760 - val_loss: 173.3304\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.1179 - val_loss: 163.2764\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.1643 - val_loss: 162.6451\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.7902 - val_loss: 235.3988\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.2608 - val_loss: 194.0088\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 267.2968 - val_loss: 169.2177\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.4379 - val_loss: 291.3742\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3908 - val_loss: 202.4278\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.8110 - val_loss: 184.6844\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.2349 - val_loss: 152.3582\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.3648 - val_loss: 151.1539\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 218.4393 - val_loss: 164.9391\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.3967 - val_loss: 181.3357\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.0914 - val_loss: 139.7397\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.4494 - val_loss: 141.2135\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.8840 - val_loss: 145.3234\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.9097 - val_loss: 152.8313\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.9016 - val_loss: 151.0950\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.9560 - val_loss: 173.7969\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.1064 - val_loss: 150.6535\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.0572 - val_loss: 157.6050\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5420 - val_loss: 150.0599\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.3945 - val_loss: 246.7425\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.0686 - val_loss: 162.7203\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7831 - val_loss: 154.4353\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.2062 - val_loss: 151.9439\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4935 - val_loss: 156.6100\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.6745 - val_loss: 153.6679\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.2526 - val_loss: 172.2724\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 275.9326 - val_loss: 164.2191\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.1842 - val_loss: 172.2144\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 162.6904 - val_loss: 253.3167\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 195.5327 - val_loss: 268.7324\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 172.2564 - val_loss: 136.7891\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.2039 - val_loss: 135.8861\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.0061 - val_loss: 160.9662\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.8119 - val_loss: 135.4839\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.3027 - val_loss: 157.7391\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.6541 - val_loss: 164.6097\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.3805 - val_loss: 198.6095\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.6138 - val_loss: 232.2513\n",
      "Epoch 484/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.7009 - val_loss: 146.7292\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 261.4828 - val_loss: 198.2258\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 285.8191 - val_loss: 176.0582\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9540 - val_loss: 145.5261\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.7241 - val_loss: 154.2427\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.1450 - val_loss: 138.0539\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2209 - val_loss: 142.5919\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.7564 - val_loss: 204.5844\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.9034 - val_loss: 139.3771\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8741 - val_loss: 164.8126\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4787 - val_loss: 152.6327\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.4377 - val_loss: 208.8937\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.4205 - val_loss: 170.9017\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4843 - val_loss: 136.1218\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.4123 - val_loss: 155.1044\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 311.8085 - val_loss: 210.7456\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.9579 - val_loss: 151.2934\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.9419 - val_loss: 144.9475\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 165.7681 - val_loss: 151.0204\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7674 - val_loss: 139.6330\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.8444 - val_loss: 142.8659\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7250 - val_loss: 152.8799\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.5512 - val_loss: 167.9667\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.2441 - val_loss: 141.2101\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.8882 - val_loss: 283.8637\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4353 - val_loss: 152.9130\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.6447 - val_loss: 150.7457\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.8721 - val_loss: 287.2883\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.0846 - val_loss: 164.8685\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.4191 - val_loss: 279.8822\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.8039 - val_loss: 138.8561\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.3839 - val_loss: 152.7999\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.7496 - val_loss: 150.2768\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.5439 - val_loss: 165.7503\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.9078 - val_loss: 141.7606\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.9854 - val_loss: 141.9784\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.7027 - val_loss: 171.8941\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9838 - val_loss: 176.0086\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.7187 - val_loss: 135.2710\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.3613 - val_loss: 140.7281\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.9138 - val_loss: 210.4669\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.5708 - val_loss: 186.9189\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.5255 - val_loss: 142.8460\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 210.8705 - val_loss: 143.0510\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2433 - val_loss: 140.5434\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 305.6584 - val_loss: 232.2288\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.6742 - val_loss: 175.1718\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9482 - val_loss: 134.1718\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5860 - val_loss: 169.8014\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4784 - val_loss: 150.7443\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.3503 - val_loss: 188.3844\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.6004 - val_loss: 135.9830\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.9257 - val_loss: 174.0343\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.5999 - val_loss: 139.7338\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.5170 - val_loss: 142.7846\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7745 - val_loss: 175.1701\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.6259 - val_loss: 346.4821\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.1872 - val_loss: 178.7992\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.0392 - val_loss: 143.4307\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0089 - val_loss: 169.0417\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 164.1403 - val_loss: 170.6399\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 181.4849 - val_loss: 735.2831\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 182.8046 - val_loss: 145.7381\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 162.6386 - val_loss: 151.2836\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2747 - val_loss: 138.0362\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.0607 - val_loss: 179.5478\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.1931 - val_loss: 143.5043\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.3500 - val_loss: 265.3291\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.0556 - val_loss: 142.5310\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.2135 - val_loss: 150.1318\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.5728 - val_loss: 183.3210\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.6772 - val_loss: 141.6775\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7291 - val_loss: 145.4615\n",
      "Epoch 557/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.7650 - val_loss: 163.9571\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.1191 - val_loss: 174.1699\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.6071 - val_loss: 175.9515\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7476 - val_loss: 158.3642\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.4129 - val_loss: 140.2213\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 315.3884 - val_loss: 166.2167\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.1423 - val_loss: 157.0668\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.4043 - val_loss: 176.7629\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.9353 - val_loss: 155.7128\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.7460 - val_loss: 180.4096\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.2249 - val_loss: 167.5290\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1162 - val_loss: 162.7258\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.8263 - val_loss: 167.0167\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.0649 - val_loss: 212.4493\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1995 - val_loss: 156.8957\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4705 - val_loss: 275.8928\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2824 - val_loss: 171.0846\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.8798 - val_loss: 188.4028\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.1708 - val_loss: 147.8435\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.7392 - val_loss: 178.2241\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.9286 - val_loss: 144.7486\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.6888 - val_loss: 159.4280\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8686 - val_loss: 140.8487\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4820 - val_loss: 140.6581\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.4427 - val_loss: 370.3729\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 262.9256 - val_loss: 212.0133\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8152 - val_loss: 155.0001\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.9228 - val_loss: 182.0945\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 276.0413 - val_loss: 173.7557\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9086 - val_loss: 142.5333\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.0331 - val_loss: 142.4299\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.2862 - val_loss: 157.3611\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.3871 - val_loss: 358.9213\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3420 - val_loss: 135.9330\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.6750 - val_loss: 187.4610\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.6851 - val_loss: 280.2265\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0569 - val_loss: 140.4575\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7365 - val_loss: 159.2869\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 208.1877 - val_loss: 144.0201\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.0751 - val_loss: 141.9518\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.8735 - val_loss: 148.1801\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1074 - val_loss: 138.6849\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.2314 - val_loss: 253.9715\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.7704 - val_loss: 199.0693\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.3118 - val_loss: 149.1965\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.6740 - val_loss: 152.6789\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4385 - val_loss: 233.5749\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.6380 - val_loss: 228.0454\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.1760 - val_loss: 165.9529\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.9611 - val_loss: 178.0504\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.9635 - val_loss: 178.2227\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0489 - val_loss: 225.8426\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.0255 - val_loss: 222.5513\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 187.0249 - val_loss: 196.0885\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 169.9988 - val_loss: 132.7544\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.1249 - val_loss: 152.8215\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.7401 - val_loss: 164.5105\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.0782 - val_loss: 157.9124\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 151.5401 - val_loss: 133.7331\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 185.9298 - val_loss: 148.7458\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 208.1048 - val_loss: 221.5615\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.6151 - val_loss: 136.6714\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.3363 - val_loss: 136.3584\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.4598 - val_loss: 199.6990\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.5424 - val_loss: 341.0108\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.8725 - val_loss: 155.6973\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.9590 - val_loss: 143.3253\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.4020 - val_loss: 170.1500\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9075 - val_loss: 151.1947\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.1234 - val_loss: 154.8257\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1013 - val_loss: 157.8569\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0046 - val_loss: 169.5433\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.3008 - val_loss: 749.7525\n",
      "Epoch 630/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 255.5390 - val_loss: 143.1440\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9010 - val_loss: 196.2998\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.7049 - val_loss: 170.3545\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.4811 - val_loss: 170.8994\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7443 - val_loss: 235.4943\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1988 - val_loss: 153.8827\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7133 - val_loss: 160.6073\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.6492 - val_loss: 485.9338\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 426.1136 - val_loss: 192.9877\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2700 - val_loss: 154.4666\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.4004 - val_loss: 191.5122\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.8387 - val_loss: 184.6400\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.6982 - val_loss: 155.7024\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6405 - val_loss: 195.5173\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.5038 - val_loss: 169.5965\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.6213 - val_loss: 149.6453\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.9138 - val_loss: 138.4842\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.6687 - val_loss: 150.2453\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.3512 - val_loss: 194.9468\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.1206 - val_loss: 164.7892\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.4321 - val_loss: 136.4693\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1600 - val_loss: 165.7855\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.4886 - val_loss: 155.0849\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.2931 - val_loss: 154.9245\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.5809 - val_loss: 158.9642\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.6116 - val_loss: 160.1371\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4929 - val_loss: 156.7850\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2915 - val_loss: 156.5527\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7235 - val_loss: 325.8678\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 294.9606 - val_loss: 154.4794\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9796 - val_loss: 157.1346\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.8654 - val_loss: 146.4541\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6487 - val_loss: 151.4701\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3375 - val_loss: 189.7415\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.3833 - val_loss: 197.0796\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.4527 - val_loss: 161.6589\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.0739 - val_loss: 143.9024\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 165.9033 - val_loss: 154.4377\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 172.9916 - val_loss: 132.2769\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.4866 - val_loss: 144.5246\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.9705 - val_loss: 150.2330\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4693 - val_loss: 133.5427\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2205 - val_loss: 164.6971\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2799 - val_loss: 143.3149\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.2665 - val_loss: 219.7675\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.3456 - val_loss: 426.4765\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.6496 - val_loss: 143.0462\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.6437 - val_loss: 225.2923\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.9900 - val_loss: 194.7504\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.2000 - val_loss: 237.7036\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5842 - val_loss: 166.7214\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7302 - val_loss: 204.5698\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9158 - val_loss: 520.3485\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.4498 - val_loss: 159.5581\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.9997 - val_loss: 139.6561\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.9013 - val_loss: 143.1441\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 178.8965 - val_loss: 303.0810\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 284.6224 - val_loss: 157.1551\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 154.5869 - val_loss: 143.7081\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.8525 - val_loss: 223.8107\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.8208 - val_loss: 250.5308\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.8371 - val_loss: 145.2437\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1433 - val_loss: 153.0044\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.5621 - val_loss: 141.4196\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2409 - val_loss: 176.0395\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.0585 - val_loss: 162.7598\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.1995 - val_loss: 162.9241\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4553 - val_loss: 157.2109\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.5745 - val_loss: 152.4846\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.3132 - val_loss: 240.0231\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 247.6854 - val_loss: 295.4893\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.2197 - val_loss: 146.7865\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7400 - val_loss: 283.5085\n",
      "Epoch 703/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.5244 - val_loss: 144.7985\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5350 - val_loss: 153.1252\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7299 - val_loss: 141.3276\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.2389 - val_loss: 137.2645\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8578 - val_loss: 217.8661\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.8834 - val_loss: 146.0105\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.2232 - val_loss: 130.1181\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.1299 - val_loss: 187.3228\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.7390 - val_loss: 154.2391\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.8088 - val_loss: 151.3903\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2345 - val_loss: 168.2513\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.0491 - val_loss: 172.1477\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.6931 - val_loss: 354.4928\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.9143 - val_loss: 142.4143\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.1320 - val_loss: 151.6577\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.0828 - val_loss: 203.2909\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.5029 - val_loss: 142.0395\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.7201 - val_loss: 143.5307\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1148 - val_loss: 136.3411\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.1799 - val_loss: 200.4706\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.1306 - val_loss: 141.6506\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2245 - val_loss: 168.8914\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.2694 - val_loss: 142.6692\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.7486 - val_loss: 159.1244\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1502 - val_loss: 166.1421\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.7736 - val_loss: 148.5720\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 336.8195 - val_loss: 270.1844\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.9059 - val_loss: 141.9858\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6966 - val_loss: 163.7175\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9224 - val_loss: 177.9783\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1126 - val_loss: 137.2132\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1183 - val_loss: 171.4145\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5319 - val_loss: 156.7428\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.7457 - val_loss: 138.3878\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.9190 - val_loss: 148.6592\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.9750 - val_loss: 132.9872\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.3138 - val_loss: 171.2827\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3649 - val_loss: 263.4663\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.4150 - val_loss: 143.1797\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7858 - val_loss: 133.0937\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.6454 - val_loss: 144.2087\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 285.7664 - val_loss: 241.9149\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.6499 - val_loss: 185.7681\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.6149 - val_loss: 151.9134\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 293.9847 - val_loss: 687.9007\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.6744 - val_loss: 199.0666\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3842 - val_loss: 150.3368\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.7711 - val_loss: 221.7861\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.7452 - val_loss: 193.4788\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4154 - val_loss: 144.1733\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.3510 - val_loss: 216.8784\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.7579 - val_loss: 155.7900\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.5374 - val_loss: 203.3450\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.9944 - val_loss: 132.9056\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 162.645 - 0s 57us/step - loss: 156.8222 - val_loss: 143.5038\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 154.7823 - val_loss: 174.2607\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 218.5688 - val_loss: 267.5978\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 201.0585 - val_loss: 167.2993\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.8455 - val_loss: 150.7101\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.3897 - val_loss: 150.3607\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9550 - val_loss: 138.6686\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.7801 - val_loss: 154.2707\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3996 - val_loss: 132.7417\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.6947 - val_loss: 266.1783\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.2217 - val_loss: 141.3214\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.6111 - val_loss: 133.5556\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.0425 - val_loss: 128.1530\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5522 - val_loss: 176.0494\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.8656 - val_loss: 173.2663\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.9118 - val_loss: 156.7750\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.3358 - val_loss: 155.7656\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2614 - val_loss: 218.7809\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.0213 - val_loss: 144.4528\n",
      "Epoch 776/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9906 - val_loss: 338.1530\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2038 - val_loss: 175.2945\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9057 - val_loss: 189.5328\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.7285 - val_loss: 330.0650\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.6367 - val_loss: 890.0884\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 408.1010 - val_loss: 320.7746\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.6678 - val_loss: 157.3173\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.0923 - val_loss: 150.8171\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4904 - val_loss: 165.5429\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.7944 - val_loss: 138.2413\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.8613 - val_loss: 154.7652\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.1744 - val_loss: 233.2955\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.9485 - val_loss: 138.1622\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.5843 - val_loss: 358.8974\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.3575 - val_loss: 144.3597\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.4349 - val_loss: 137.5275\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.0806 - val_loss: 246.2263\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.9984 - val_loss: 146.7927\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.7819 - val_loss: 164.4074\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.6524 - val_loss: 1086.7231\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.9372 - val_loss: 145.6924\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.5489 - val_loss: 313.5833\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.3844 - val_loss: 153.8858\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.4988 - val_loss: 172.8334\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.9623 - val_loss: 160.4757\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5462 - val_loss: 135.2529\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1972 - val_loss: 132.7614\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6849 - val_loss: 226.0322\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.5800 - val_loss: 136.9543\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1230 - val_loss: 153.2374\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.2704 - val_loss: 191.0178\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.6119 - val_loss: 183.5429\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7023 - val_loss: 149.7914\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.8497 - val_loss: 262.6388\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.3538 - val_loss: 133.8876\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.0956 - val_loss: 143.4569\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2443 - val_loss: 151.4362\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6380 - val_loss: 139.9258\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.5688 - val_loss: 174.8443\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6891 - val_loss: 138.7394\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.8782 - val_loss: 244.0334\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.4548 - val_loss: 176.6132\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2565 - val_loss: 136.2388\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.4454 - val_loss: 157.7147\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.3264 - val_loss: 199.8411\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 174.5206 - val_loss: 149.3602\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7193 - val_loss: 140.3740\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0902 - val_loss: 131.1754\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3979 - val_loss: 308.0534\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 287.3778 - val_loss: 154.9088\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 154.762 - 0s 51us/step - loss: 158.0638 - val_loss: 156.9924\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8100 - val_loss: 203.1923\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4198 - val_loss: 155.1017\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 153.2692 - val_loss: 141.6850\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 179.9411 - val_loss: 163.8380\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 158.2768 - val_loss: 170.5895\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.4858 - val_loss: 175.8600\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2436 - val_loss: 168.7051\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.6096 - val_loss: 272.7901\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.4891 - val_loss: 137.0065\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.3191 - val_loss: 144.3155\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.7846 - val_loss: 135.0453\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.1978 - val_loss: 138.5446\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0599 - val_loss: 131.6230\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.0626 - val_loss: 174.5853\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0762 - val_loss: 133.1849\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7821 - val_loss: 140.3348\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9644 - val_loss: 133.2852\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9803 - val_loss: 146.9421\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9002 - val_loss: 249.4045\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.7046 - val_loss: 170.4533\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0820 - val_loss: 150.1545\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9792 - val_loss: 142.8970\n",
      "Epoch 849/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0931 - val_loss: 135.7520\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.3693 - val_loss: 148.6726\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.3078 - val_loss: 221.6282\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1103 - val_loss: 158.1015\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.2324 - val_loss: 135.8902\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.3418 - val_loss: 130.7347\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8886 - val_loss: 169.3928\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.7396 - val_loss: 139.3340\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8755 - val_loss: 134.0644\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.1041 - val_loss: 146.6320\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.8410 - val_loss: 129.5071\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.1465 - val_loss: 137.4673\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.7477 - val_loss: 140.8785\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9442 - val_loss: 163.3649\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8411 - val_loss: 157.5285\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9742 - val_loss: 138.5579\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.9904 - val_loss: 136.2942\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 285.1986 - val_loss: 220.3726\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7957 - val_loss: 153.3160\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5681 - val_loss: 173.4698\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5322 - val_loss: 222.6371\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2042 - val_loss: 174.3356\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6692 - val_loss: 152.5286\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5494 - val_loss: 135.0344\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 237.8634 - val_loss: 542.5022\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.4037 - val_loss: 156.9071\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.6847 - val_loss: 207.4779\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8752 - val_loss: 141.8518\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.051 - 0s 50us/step - loss: 144.7821 - val_loss: 133.6539\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3031 - val_loss: 178.6943\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8441 - val_loss: 149.1041\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4654 - val_loss: 142.0907\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.3361 - val_loss: 251.1709\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7453 - val_loss: 185.6415\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6516 - val_loss: 138.0387\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.6636 - val_loss: 142.6263\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2658 - val_loss: 144.6750\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5859 - val_loss: 132.1764\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0624 - val_loss: 142.2091\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 280.9474 - val_loss: 270.8230\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6692 - val_loss: 142.4918\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8992 - val_loss: 133.4523\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 347.0702 - val_loss: 184.2864\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3899 - val_loss: 141.0943\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.9077 - val_loss: 158.2976\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0747 - val_loss: 135.4727\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.8580 - val_loss: 138.0849\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9296 - val_loss: 159.2519\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.8597 - val_loss: 140.9582\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6762 - val_loss: 141.7192\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4848 - val_loss: 157.4302\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.2235 - val_loss: 144.1782\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 150.0487 - val_loss: 151.2937\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 141.8255 - val_loss: 129.8489\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 157.2299 - val_loss: 150.0667\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0831 - val_loss: 130.6703\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.9174 - val_loss: 159.1395\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3236 - val_loss: 136.4047\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.8027 - val_loss: 204.3682\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.3655 - val_loss: 183.6892\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0522 - val_loss: 138.2004\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7245 - val_loss: 145.6151\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.5970 - val_loss: 214.4585\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.2273 - val_loss: 197.4373\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 288.5625 - val_loss: 133.8622\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.0269 - val_loss: 137.9499\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2964 - val_loss: 216.3794\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9744 - val_loss: 134.0233\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.1057 - val_loss: 145.9398\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4214 - val_loss: 152.1195\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3413 - val_loss: 276.4010\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1888 - val_loss: 165.8947\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6908 - val_loss: 190.8045\n",
      "Epoch 922/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3198 - val_loss: 139.6109\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.4927 - val_loss: 248.6820\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1666 - val_loss: 137.7714\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 156.057 - 0s 50us/step - loss: 156.0845 - val_loss: 135.8864\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7999 - val_loss: 136.3428\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.2601 - val_loss: 143.7818\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.1050 - val_loss: 154.6848\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 159.2922 - val_loss: 174.2735\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.8907 - val_loss: 151.2035\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5674 - val_loss: 147.6626\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5420 - val_loss: 145.8584\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8585 - val_loss: 134.6454\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.1928 - val_loss: 134.9695\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.4310 - val_loss: 139.3948\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3279 - val_loss: 132.1548\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8565 - val_loss: 170.3637\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3679 - val_loss: 136.0222\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0304 - val_loss: 151.5536\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0935 - val_loss: 184.5204\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1769 - val_loss: 135.9681\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9346 - val_loss: 149.7697\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2445 - val_loss: 161.6574\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.1439 - val_loss: 145.5758\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.3881 - val_loss: 168.9607\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.8446 - val_loss: 134.9784\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3825 - val_loss: 182.2253\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.1515 - val_loss: 132.5228\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5402 - val_loss: 141.1797\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.0871 - val_loss: 166.3263\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8988 - val_loss: 156.1314\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 482.8868 - val_loss: 226.4179\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 288.9096 - val_loss: 203.1737\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 243.4574 - val_loss: 228.2576\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.7505 - val_loss: 278.3057\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.5156 - val_loss: 197.0431\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.6758 - val_loss: 181.7957\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.0182 - val_loss: 180.6392\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.7928 - val_loss: 190.7853\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.2452 - val_loss: 210.0227\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 613.4228 - val_loss: 222.3225\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 234.9063 - val_loss: 201.4939\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.9932 - val_loss: 177.3261\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.6970 - val_loss: 163.8122\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5861 - val_loss: 139.5344\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0392 - val_loss: 149.6875\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8674 - val_loss: 168.4638\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.2719 - val_loss: 135.5609\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9796 - val_loss: 165.5850\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1245 - val_loss: 160.3253\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3832 - val_loss: 165.0041\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 157.7392 - val_loss: 134.9533\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 187.0346 - val_loss: 171.5852\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 172.1845 - val_loss: 140.4437\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 147.4106 - val_loss: 165.4028\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8069 - val_loss: 154.4911\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.4504 - val_loss: 147.9150\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5867 - val_loss: 153.0382\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2063 - val_loss: 133.7816\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6278 - val_loss: 135.5731\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.3266 - val_loss: 174.5240\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8103 - val_loss: 135.3846\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6322 - val_loss: 155.2116\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2811 - val_loss: 167.0643\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 292.2536 - val_loss: 135.9392\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0226 - val_loss: 140.5172\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1485 - val_loss: 140.8628\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.6412 - val_loss: 324.2136\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.6576 - val_loss: 137.8087ETA: 0s - loss: 519.944 - ETA: 0s - loss: 410\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0575 - val_loss: 130.0147\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9421 - val_loss: 134.6405\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2350 - val_loss: 237.5107\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6536 - val_loss: 157.9713\n",
      "Epoch 994/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6895 - val_loss: 158.6071\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5469 - val_loss: 142.9916\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6509 - val_loss: 156.7269\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8108 - val_loss: 138.8276\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3923 - val_loss: 148.8561\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 349.4451 - val_loss: 971.4469\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7759 - val_loss: 137.3400\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9518 - val_loss: 140.6479\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4633 - val_loss: 137.7124\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 166.6878 - val_loss: 140.5513\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6416 - val_loss: 159.9958\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.0394 - val_loss: 136.1917\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6993 - val_loss: 211.8060\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2372 - val_loss: 173.3752\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.8056 - val_loss: 284.1799\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.2621 - val_loss: 136.8061\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2848 - val_loss: 134.3844\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6032 - val_loss: 146.7460\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.2504 - val_loss: 199.2731\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2342 - val_loss: 158.7567\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9855 - val_loss: 162.2061\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6705 - val_loss: 158.2234\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.7044 - val_loss: 211.3199\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.0459 - val_loss: 142.7168\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0934 - val_loss: 134.8873\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4195 - val_loss: 141.4824\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.2936 - val_loss: 237.1884\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.7726 - val_loss: 158.0803\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3799 - val_loss: 174.1229\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.9238 - val_loss: 160.8020\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.6535 - val_loss: 145.0575\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5552 - val_loss: 133.1268\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3077 - val_loss: 153.3289\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0726 - val_loss: 156.0797\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.9026 - val_loss: 432.5083\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.3671 - val_loss: 151.1150\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.1763 - val_loss: 294.7354\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.9833 - val_loss: 136.6186\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 156.4485 - val_loss: 181.6395\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9352 - val_loss: 259.8013\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.1696 - val_loss: 139.3033\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8555 - val_loss: 144.7257\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.0797 - val_loss: 181.6291\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.2958 - val_loss: 142.9411\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.6722 - val_loss: 133.7898\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3261 - val_loss: 165.2093\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.2442 - val_loss: 134.6000\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.2009 - val_loss: 138.8324\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.2216 - val_loss: 364.6283\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.5623 - val_loss: 206.9203\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4225 - val_loss: 160.7506\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.4040 - val_loss: 136.0028\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2510 - val_loss: 137.7907\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1815 - val_loss: 155.6446\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7825 - val_loss: 143.1500\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.4474 - val_loss: 133.5004\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4973 - val_loss: 167.8989\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.5215 - val_loss: 380.3155\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9797 - val_loss: 139.6037\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.0541 - val_loss: 146.4738\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 159.9702 - val_loss: 168.4370\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.0666 - val_loss: 161.7501\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 144.6978 - val_loss: 134.1785\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.8333 - val_loss: 267.4577\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.4391 - val_loss: 133.9087\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.0892 - val_loss: 159.3412\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3713 - val_loss: 140.2086\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5936 - val_loss: 184.2089\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.4461 - val_loss: 154.1119\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.5199 - val_loss: 155.4176\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7246 - val_loss: 149.8966\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.4035 - val_loss: 210.7471\n",
      "Epoch 1066/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1756 - val_loss: 144.2810\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2299 - val_loss: 133.7640\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7719 - val_loss: 139.6149\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5540 - val_loss: 175.9809\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.4075 - val_loss: 219.3531\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.3666 - val_loss: 167.3053\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.0377 - val_loss: 129.2358\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0707 - val_loss: 147.2026\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3486 - val_loss: 134.3894\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3972 - val_loss: 185.5694\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3944 - val_loss: 245.9581\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.1456 - val_loss: 149.7557\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8060 - val_loss: 146.6825\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0957 - val_loss: 165.2231\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.0311 - val_loss: 135.1091\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.7396 - val_loss: 160.7873\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8016 - val_loss: 223.3267\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.4966 - val_loss: 180.5614\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.9881 - val_loss: 145.6771\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1841 - val_loss: 152.5090\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3209 - val_loss: 143.6599\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1116 - val_loss: 158.4353\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0759 - val_loss: 264.6362\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9875 - val_loss: 129.6755\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7477 - val_loss: 158.5470\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.0427 - val_loss: 140.8739\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4009 - val_loss: 159.5212\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1930 - val_loss: 148.4389\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2153 - val_loss: 141.0087\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4266 - val_loss: 211.1773\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4815 - val_loss: 144.2470\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4459 - val_loss: 134.8824\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8923 - val_loss: 199.2864\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1315 - val_loss: 137.4400\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.0152 - val_loss: 177.7958\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.0484 - val_loss: 203.7560\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.4089 - val_loss: 140.9342\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3121 - val_loss: 134.7681\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2900 - val_loss: 135.8024\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9769 - val_loss: 136.2892\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 229.3773 - val_loss: 222.1026\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0799 - val_loss: 173.2029\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.6160 - val_loss: 163.3163\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.8143 - val_loss: 141.7533\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.4077 - val_loss: 185.4242\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3536 - val_loss: 180.3178\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.9477 - val_loss: 166.2948\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0864 - val_loss: 137.8960\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.7905 - val_loss: 152.1767\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 194.9041 - val_loss: 141.5970\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 181.2162 - val_loss: 143.6314\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 153.8423 - val_loss: 3402.8773\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 165.5041 - val_loss: 179.2593\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.1686 - val_loss: 135.5368\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.0571 - val_loss: 188.4534\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.9632 - val_loss: 160.3961\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.9829 - val_loss: 140.4353\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.8846 - val_loss: 147.0338\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.9457 - val_loss: 598.9011\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 244.9310 - val_loss: 148.1485\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.4189 - val_loss: 135.3281\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.9022 - val_loss: 159.7194\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.9901 - val_loss: 157.7999\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6259 - val_loss: 151.4164\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4072 - val_loss: 141.8919\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0898 - val_loss: 205.1238\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7198 - val_loss: 136.1810\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.0994 - val_loss: 436.0490\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.7432 - val_loss: 133.8372\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2856 - val_loss: 149.7422\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9529 - val_loss: 174.4743\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.3489 - val_loss: 147.0072\n",
      "Epoch 1138/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.4194 - val_loss: 160.1769\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.8705 - val_loss: 149.2295\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.2559 - val_loss: 141.1105\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8651 - val_loss: 159.1327\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2420 - val_loss: 155.5140\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4077 - val_loss: 150.4027\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.3123 - val_loss: 164.8467\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.5813 - val_loss: 174.7890\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.0314 - val_loss: 138.6636\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.7224 - val_loss: 134.2469\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.5998 - val_loss: 158.7990\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0771 - val_loss: 138.7763\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3387 - val_loss: 162.9295\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.4718 - val_loss: 184.9610\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.1348 - val_loss: 141.1643\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.6053 - val_loss: 380.7489\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.8303 - val_loss: 141.7882\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0691 - val_loss: 132.2331\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3412 - val_loss: 253.0674\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1030 - val_loss: 141.5029\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.2659 - val_loss: 152.4218\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0804 - val_loss: 139.4828\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2062 - val_loss: 165.8211\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6499 - val_loss: 141.7900\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6283 - val_loss: 135.8336\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.1540 - val_loss: 153.1030\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.3693 - val_loss: 174.1403\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.5635 - val_loss: 186.6361\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.8063 - val_loss: 132.1409\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.7070 - val_loss: 144.1880\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.4162 - val_loss: 134.6132\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8629 - val_loss: 142.3488\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6011 - val_loss: 137.3058\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.3268 - val_loss: 149.1427\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 270.8372 - val_loss: 165.6648\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.2170 - val_loss: 149.5844\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7379 - val_loss: 398.7502\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.2846 - val_loss: 193.6176\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.1221 - val_loss: 134.4997\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 196.0290 - val_loss: 139.9339\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5076 - val_loss: 136.1535\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4892 - val_loss: 148.4097\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2936 - val_loss: 183.1503\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6135 - val_loss: 146.6711\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5017 - val_loss: 178.5629\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.9263 - val_loss: 135.1988\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.8692 - val_loss: 153.8404\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3631 - val_loss: 191.5320\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 166.7531 - val_loss: 163.6306\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 163.4580 - val_loss: 139.6974\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 181.5882 - val_loss: 168.1686\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.4673 - val_loss: 141.9270\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7411 - val_loss: 202.8637\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1737 - val_loss: 157.4703\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.7253 - val_loss: 152.5544\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2621 - val_loss: 134.4334\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.1746 - val_loss: 214.4534\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 248.7832 - val_loss: 175.8797\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9120 - val_loss: 147.2803\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.7369 - val_loss: 170.4663\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0389 - val_loss: 173.7053\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7307 - val_loss: 234.4091\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5505 - val_loss: 155.0964\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.6673 - val_loss: 133.6646\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.6468 - val_loss: 149.2360\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.0537 - val_loss: 144.4517\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6129 - val_loss: 163.1162\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.6654 - val_loss: 164.6479\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1256 - val_loss: 154.5046\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8429 - val_loss: 166.9748\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.1980 - val_loss: 155.8149\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3469 - val_loss: 136.6696\n",
      "Epoch 1210/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4595 - val_loss: 157.2078\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.1221 - val_loss: 153.1747\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3014 - val_loss: 130.9230\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 209.5979 - val_loss: 368.5037\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.6141 - val_loss: 150.1399\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 168.4361 - val_loss: 250.6168\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3220 - val_loss: 262.5212\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.6167 - val_loss: 145.9343\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9256 - val_loss: 158.5356\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4870 - val_loss: 158.1020\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5942 - val_loss: 146.8593\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1974 - val_loss: 139.6348\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9438 - val_loss: 164.4840\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0893 - val_loss: 204.5468\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7818 - val_loss: 165.3005\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4033 - val_loss: 220.1434\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.0011 - val_loss: 145.4596\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.4021 - val_loss: 140.7108\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0317 - val_loss: 148.1823\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7751 - val_loss: 137.2206\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8188 - val_loss: 152.8369\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.8483 - val_loss: 193.4581\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6789 - val_loss: 142.7401\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.7907 - val_loss: 144.5583\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.7372 - val_loss: 207.1071\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1333 - val_loss: 151.0040\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3731 - val_loss: 134.5149\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7524 - val_loss: 157.3762\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0574 - val_loss: 134.6648\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6658 - val_loss: 183.1712\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.9208 - val_loss: 151.2282\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.3652 - val_loss: 251.0027\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1300 - val_loss: 212.8524\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1481 - val_loss: 230.1166\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3198 - val_loss: 213.5201\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9649 - val_loss: 157.2856\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.9988 - val_loss: 134.5645\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 258.9821 - val_loss: 832.3289\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.2569 - val_loss: 169.3633\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7806 - val_loss: 132.3602\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6777 - val_loss: 141.4426\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.4995 - val_loss: 173.6100\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.9455 - val_loss: 142.8820\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5355 - val_loss: 261.6166\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4587 - val_loss: 154.3260\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4362 - val_loss: 142.1322\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3946 - val_loss: 151.3084\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 161.4764 - val_loss: 160.8153\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 159.1688 - val_loss: 161.3162\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 148.4765 - val_loss: 197.2706\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.6588 - val_loss: 156.8097\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.5438 - val_loss: 138.5443\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.6277 - val_loss: 138.1026\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.6238 - val_loss: 144.9215\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1071 - val_loss: 178.4205\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9988 - val_loss: 147.8603\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.6987 - val_loss: 233.5219\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0470 - val_loss: 132.1670\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5762 - val_loss: 199.5653\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.2347 - val_loss: 148.1171\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.0739 - val_loss: 203.9198\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.3734 - val_loss: 145.0719\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 325.7586 - val_loss: 172.1630\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.9524 - val_loss: 191.3724\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.8424 - val_loss: 156.6048\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0360 - val_loss: 136.2726\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7054 - val_loss: 138.7017\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5124 - val_loss: 135.1472\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9171 - val_loss: 154.6580\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.4669 - val_loss: 145.4781\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8828 - val_loss: 141.8743\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.6522 - val_loss: 206.5239\n",
      "Epoch 1282/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.3502 - val_loss: 192.3711\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.1648 - val_loss: 201.8359\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7214 - val_loss: 175.8041\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5173 - val_loss: 152.7873\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.2053 - val_loss: 130.3196\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8460 - val_loss: 132.8018\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0610 - val_loss: 698.9002\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 207.0355 - val_loss: 159.3469\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4877 - val_loss: 145.9913\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.6858 - val_loss: 145.7198\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7067 - val_loss: 141.9442\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7777 - val_loss: 132.2039\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1459 - val_loss: 137.6268\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.3635 - val_loss: 275.5979\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7587 - val_loss: 140.9427\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5373 - val_loss: 128.2897\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5951 - val_loss: 162.0134\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.4270 - val_loss: 166.5383\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.5925 - val_loss: 132.0245\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9447 - val_loss: 180.4160\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4585 - val_loss: 164.7478\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.7727 - val_loss: 194.7284\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6764 - val_loss: 265.5241\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9999 - val_loss: 155.0353\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7683 - val_loss: 128.7791\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6111 - val_loss: 222.0371\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.8575 - val_loss: 153.0605\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.5706 - val_loss: 386.7654\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.5268 - val_loss: 137.3043\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3874 - val_loss: 178.2740\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8911 - val_loss: 166.0064\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4710 - val_loss: 144.0947\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.0184 - val_loss: 146.0923\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.9108 - val_loss: 140.0315\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0056 - val_loss: 132.7746\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.2065 - val_loss: 173.7581\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 157.4524 - val_loss: 134.2360\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.4570 - val_loss: 134.2150\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 344.5685 - val_loss: 431.3269\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.8821 - val_loss: 138.9492\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.9682 - val_loss: 139.6556\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5863 - val_loss: 133.2973\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6867 - val_loss: 230.8825\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4874 - val_loss: 133.2447\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.8973 - val_loss: 177.2372\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3769 - val_loss: 136.8270\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.2705 - val_loss: 161.2391\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 142.7505 - val_loss: 155.4051\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 199.8540 - val_loss: 143.3047\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 147.0239 - val_loss: 236.7318\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 347.7086 - val_loss: 150.3424\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 176.3352 - val_loss: 140.4630\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.9333 - val_loss: 136.8430\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5360 - val_loss: 147.6315\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.5699 - val_loss: 133.9623\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.3222 - val_loss: 159.2875\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0189 - val_loss: 189.0647\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 336.9681 - val_loss: 217.6163\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.8024 - val_loss: 168.7038\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.5083 - val_loss: 191.3313\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.9812 - val_loss: 151.8139\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.5125 - val_loss: 160.2251\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.5857 - val_loss: 149.9317\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.7359 - val_loss: 235.6895\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1521 - val_loss: 161.0444\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.0839 - val_loss: 147.8695\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.0619 - val_loss: 163.8049\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.7522 - val_loss: 158.7139\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.2582 - val_loss: 186.1511\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.7916 - val_loss: 161.2345\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.3466 - val_loss: 158.5688\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4267 - val_loss: 146.3751\n",
      "Epoch 1354/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.1140 - val_loss: 412.3946\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.1723 - val_loss: 242.2371\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.9186 - val_loss: 183.6089\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 159.4203 - val_loss: 293.1665\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1208 - val_loss: 163.8726\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.9782 - val_loss: 140.8436\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1172 - val_loss: 141.2517\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9972 - val_loss: 177.3589\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6814 - val_loss: 131.9654\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.0323 - val_loss: 134.4657\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0955 - val_loss: 136.8554\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.9481 - val_loss: 156.2984\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2433 - val_loss: 191.6112\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.2684 - val_loss: 150.2297\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2649 - val_loss: 180.6194\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.6071 - val_loss: 133.8330\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5288 - val_loss: 153.3160\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5162 - val_loss: 135.5315\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8152 - val_loss: 138.3946\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9369 - val_loss: 183.9958\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6867 - val_loss: 307.5399\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 324.6384 - val_loss: 228.6643\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.0110 - val_loss: 226.6281\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.6370 - val_loss: 195.3724\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.5747 - val_loss: 150.4212\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.9922 - val_loss: 140.3860\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.4066 - val_loss: 246.7672\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.9519 - val_loss: 153.8612\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6540 - val_loss: 208.3087\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5258 - val_loss: 208.5456\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.0476 - val_loss: 150.5875\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.1759 - val_loss: 139.6670\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.8287 - val_loss: 152.1576\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.6758 - val_loss: 147.0443\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.0081 - val_loss: 226.2331\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.1599 - val_loss: 193.7649\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.5650 - val_loss: 155.4751\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.3818 - val_loss: 151.5044\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.3250 - val_loss: 162.9875\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8611 - val_loss: 266.7778\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0095 - val_loss: 141.2700\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2869 - val_loss: 147.9644\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3287 - val_loss: 144.9590\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2432 - val_loss: 154.5949\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.3775 - val_loss: 171.4181\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.9197 - val_loss: 138.8128\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 164.7039 - val_loss: 190.4548\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 137.4181 - val_loss: 192.8929\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 154.0773 - val_loss: 198.3613\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.6467 - val_loss: 181.6458\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4160 - val_loss: 145.2591\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8790 - val_loss: 163.7363\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.3339 - val_loss: 168.3053\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3144 - val_loss: 154.6882\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.6632 - val_loss: 204.9117\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.2322 - val_loss: 155.6981\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.5771 - val_loss: 189.6213\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9690 - val_loss: 185.4222\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.3511 - val_loss: 140.5800\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.5463 - val_loss: 163.6316\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.1866 - val_loss: 144.1195\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 204.6688 - val_loss: 172.5834\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4294 - val_loss: 152.1167\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1344 - val_loss: 149.0137\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.3698 - val_loss: 137.3798\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5112 - val_loss: 141.9817\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4029 - val_loss: 158.3866\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4178 - val_loss: 139.9317\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3353 - val_loss: 147.3758\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.8732 - val_loss: 169.2353\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9056 - val_loss: 155.8458\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2065 - val_loss: 135.8145\n",
      "Epoch 1426/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5564 - val_loss: 209.6381\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.3191 - val_loss: 133.0104\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.9701 - val_loss: 134.7092\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5116 - val_loss: 133.4838\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5013 - val_loss: 173.6244\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.3630 - val_loss: 153.9819\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3857 - val_loss: 140.9541\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6879 - val_loss: 209.2548\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6350 - val_loss: 256.7564\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.0558 - val_loss: 200.1591\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9637 - val_loss: 134.9771\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.1011 - val_loss: 154.7215\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.7442 - val_loss: 132.7340\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0519 - val_loss: 146.3218\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.5769 - val_loss: 146.6111\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9613 - val_loss: 141.1643\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0900 - val_loss: 346.3737\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8627 - val_loss: 155.7147\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6113 - val_loss: 148.5028\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.2999 - val_loss: 142.5677\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.0673 - val_loss: 170.5973\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.4924 - val_loss: 165.7918\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7926 - val_loss: 192.2809\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8178 - val_loss: 136.3847\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 143.377 - 0s 51us/step - loss: 141.6739 - val_loss: 173.7551\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9247 - val_loss: 143.7281\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.6708 - val_loss: 155.1157\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0128 - val_loss: 170.4031\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.8122 - val_loss: 133.6174\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.2559 - val_loss: 245.1388\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.7142 - val_loss: 149.3665\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 191.9165 - val_loss: 154.1723\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9656 - val_loss: 218.6008\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3472 - val_loss: 167.4002\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.2259 - val_loss: 166.9122\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.2921 - val_loss: 199.6182\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.4479 - val_loss: 173.2272\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.9254 - val_loss: 188.6413\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.4589 - val_loss: 313.6383\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1548 - val_loss: 143.7977\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9699 - val_loss: 153.9892\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3584 - val_loss: 163.5211\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7910 - val_loss: 136.0190\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.3446 - val_loss: 140.7619\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 201.2708 - val_loss: 145.7663\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 162.1828 - val_loss: 169.7901\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 150.6376 - val_loss: 153.3098\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 159.0382 - val_loss: 145.0417\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.3622 - val_loss: 145.3574\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 220.4164 - val_loss: 192.0707\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.9630 - val_loss: 264.9923\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1241 - val_loss: 145.9224\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7536 - val_loss: 150.7504\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8936 - val_loss: 166.8832\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.4381 - val_loss: 181.0664\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.7176 - val_loss: 208.0758\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.1685 - val_loss: 162.7589\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.6958 - val_loss: 138.5454\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.2109 - val_loss: 160.1111\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2974 - val_loss: 140.4353\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5075 - val_loss: 137.4774\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8137 - val_loss: 132.2848\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3428 - val_loss: 175.4817\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5105 - val_loss: 177.5974\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.8344 - val_loss: 187.6874\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.6591 - val_loss: 185.9053\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7478 - val_loss: 140.0941\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8854 - val_loss: 164.7839\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7928 - val_loss: 166.4522\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.4597 - val_loss: 150.9884\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6319 - val_loss: 148.1679\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 157.3367 - val_loss: 140.5727\n",
      "Epoch 1498/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2329 - val_loss: 189.0836\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 181.8442 - val_loss: 138.2943\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8314 - val_loss: 163.4179\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.9211 - val_loss: 172.5719\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0108 - val_loss: 196.1573\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.1490 - val_loss: 138.4242\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.2240 - val_loss: 170.7792\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5501 - val_loss: 140.7222\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.3959 - val_loss: 164.3787\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 190.505 - 0s 51us/step - loss: 189.9983 - val_loss: 232.0035\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9713 - val_loss: 208.8274\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.7279 - val_loss: 155.6013\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5951 - val_loss: 143.2639\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6908 - val_loss: 137.4765\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6249 - val_loss: 155.4005\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3436 - val_loss: 143.2976\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.5607 - val_loss: 159.8108\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 168.665 - 0s 51us/step - loss: 168.2594 - val_loss: 144.0188\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.7591 - val_loss: 133.0355\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.5873 - val_loss: 148.6925\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7015 - val_loss: 157.2661\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.8555 - val_loss: 154.4886\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.7394 - val_loss: 150.6120\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 181.9985 - val_loss: 228.1016\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5164 - val_loss: 133.0046\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8013 - val_loss: 149.8538\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7980 - val_loss: 137.2947\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.6301 - val_loss: 149.4504\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8466 - val_loss: 150.8052\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.1262 - val_loss: 168.4355\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4423 - val_loss: 144.6906\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.8035 - val_loss: 143.7457\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0565 - val_loss: 188.2095\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3348 - val_loss: 153.4573\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5196 - val_loss: 178.9526\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2900 - val_loss: 135.5157\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.5517 - val_loss: 141.3796\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.6871 - val_loss: 167.6996\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2739 - val_loss: 131.6511\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.1547 - val_loss: 152.1364\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7165 - val_loss: 138.1016\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.3451 - val_loss: 130.8685\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1771 - val_loss: 165.5453\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.2458 - val_loss: 151.6174\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 152.3923 - val_loss: 138.4220\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 159.4058 - val_loss: 147.3078\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.1507 - val_loss: 151.3916\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8509 - val_loss: 142.7913\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7898 - val_loss: 161.5368\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.0006 - val_loss: 146.7859\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0265 - val_loss: 146.6058\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5484 - val_loss: 157.2114\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0367 - val_loss: 131.8836\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6346 - val_loss: 260.3213\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.8085 - val_loss: 134.0720\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4678 - val_loss: 178.4719\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.2195 - val_loss: 162.5106\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 155.7789 - val_loss: 167.3797\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 144.1325 - val_loss: 149.8584\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.4594 - val_loss: 196.1933\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.5664 - val_loss: 202.6039\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5305 - val_loss: 139.7473\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2459 - val_loss: 139.2191\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2027 - val_loss: 169.8221\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1676 - val_loss: 144.4370\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.2782 - val_loss: 153.0746\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3763 - val_loss: 131.7960\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2308 - val_loss: 137.0666\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8012 - val_loss: 169.6159\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 145.1194 - val_loss: 140.1836\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8660 - val_loss: 146.7094\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.4157 - val_loss: 157.6215\n",
      "Epoch 1570/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 187.5225 - val_loss: 167.1032\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7204 - val_loss: 136.7081\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8826 - val_loss: 149.1772\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3739 - val_loss: 186.2877\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.7697 - val_loss: 195.8754\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2604 - val_loss: 188.1130\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.0568 - val_loss: 150.0908\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3287 - val_loss: 137.0682\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.4065 - val_loss: 165.8279\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2170 - val_loss: 229.4308\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2794 - val_loss: 196.4474\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9406 - val_loss: 146.4808\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1006 - val_loss: 149.6930\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.3088 - val_loss: 143.4390\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2281 - val_loss: 172.8727\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8029 - val_loss: 131.0087\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0668 - val_loss: 133.3936\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5994 - val_loss: 243.6711\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.2900 - val_loss: 167.6169\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.6238 - val_loss: 344.3026\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.3844 - val_loss: 145.0136\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0848 - val_loss: 159.1804\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9158 - val_loss: 131.4259\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0564 - val_loss: 191.4638\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6093 - val_loss: 162.6649\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6130 - val_loss: 168.2446\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6907 - val_loss: 132.1073\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9195 - val_loss: 132.6342\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5955 - val_loss: 167.3368\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.2828 - val_loss: 182.1883\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.2887 - val_loss: 174.7771\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9321 - val_loss: 148.4958\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0251 - val_loss: 144.2673\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.4025 - val_loss: 182.9924\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3843 - val_loss: 143.5698\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.2052 - val_loss: 186.6509\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.3234 - val_loss: 169.7297\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.5449 - val_loss: 142.8628\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1951 - val_loss: 148.3394\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0713 - val_loss: 165.1411\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7359 - val_loss: 173.8532\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6451 - val_loss: 228.8142\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.8993 - val_loss: 176.0671\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 154.1161 - val_loss: 153.8337\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 152.4731 - val_loss: 131.4157\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.2757 - val_loss: 137.8854\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6229 - val_loss: 130.8173\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2872 - val_loss: 186.7774\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2896 - val_loss: 148.4776\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3855 - val_loss: 165.2675\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0207 - val_loss: 140.4012\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.6132 - val_loss: 154.9864\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9253 - val_loss: 133.7688\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9602 - val_loss: 161.2560\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4562 - val_loss: 159.5825\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5504 - val_loss: 206.2420\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.6102 - val_loss: 410.0269\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.1419 - val_loss: 714.1275\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8683 - val_loss: 152.6581\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7521 - val_loss: 149.1702\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0982 - val_loss: 185.2918\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9748 - val_loss: 222.7883\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8794 - val_loss: 141.6351\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.9695 - val_loss: 173.5792\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.7919 - val_loss: 151.5422\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1635 - val_loss: 161.0197\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2691 - val_loss: 133.5577\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.5877 - val_loss: 193.6868\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9776 - val_loss: 147.8691\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8338 - val_loss: 184.3443\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5570 - val_loss: 139.7346\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 148.5220 - val_loss: 125.8274\n",
      "Epoch 1642/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 176.7011 - val_loss: 134.9253\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9246 - val_loss: 145.4387\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4423 - val_loss: 136.5178\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.7303 - val_loss: 141.9333\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.2518 - val_loss: 147.6808\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6021 - val_loss: 130.7194\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8651 - val_loss: 142.7203\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.5283 - val_loss: 176.4320\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2958 - val_loss: 129.8585\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3372 - val_loss: 157.6206\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1254 - val_loss: 161.1563\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.9190 - val_loss: 171.1352\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.9826 - val_loss: 183.2942\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9203 - val_loss: 155.2201\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8883 - val_loss: 164.2757\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9322 - val_loss: 134.8022\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.0055 - val_loss: 159.6977\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6483 - val_loss: 132.2158\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.2276 - val_loss: 133.8487\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6416 - val_loss: 142.5247\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3664 - val_loss: 148.6566\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7134 - val_loss: 188.6630\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.8912 - val_loss: 150.2105\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7796 - val_loss: 167.3358\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4584 - val_loss: 147.2767\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.5631 - val_loss: 154.5119\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3123 - val_loss: 139.1383\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.1544 - val_loss: 152.1739\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3657 - val_loss: 133.6845\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.9110 - val_loss: 134.0110\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3963 - val_loss: 135.8051\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1287 - val_loss: 150.9359\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.2978 - val_loss: 134.6950\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0622 - val_loss: 138.3194\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0418 - val_loss: 145.4595\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.7087 - val_loss: 136.7115\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8255 - val_loss: 172.0234\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.8237 - val_loss: 132.8460\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4099 - val_loss: 128.8820\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8690 - val_loss: 131.4814\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9418 - val_loss: 149.9665\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3314 - val_loss: 205.4222\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6806 - val_loss: 163.8523\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 150.8326 - val_loss: 137.2237\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 153.8151 - val_loss: 137.0439\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 149.5925 - val_loss: 237.7720\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 156.0887 - val_loss: 139.0368\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5215 - val_loss: 131.6013\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.3859 - val_loss: 146.5987\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.0150 - val_loss: 168.5831\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.8435 - val_loss: 137.7762\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.9329 - val_loss: 148.6296\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7638 - val_loss: 137.9672\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.9667 - val_loss: 168.8542\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6042 - val_loss: 158.8932\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.6061 - val_loss: 185.8798\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.4502 - val_loss: 254.1073\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2704 - val_loss: 134.4621\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7871 - val_loss: 151.0064\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0306 - val_loss: 168.1508\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6263 - val_loss: 128.2382\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.2498 - val_loss: 186.8759\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1611 - val_loss: 129.9701\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.2061 - val_loss: 145.3782\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0984 - val_loss: 135.4332\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2988 - val_loss: 191.3441\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.4296 - val_loss: 133.6494\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1871 - val_loss: 135.0556\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.5673 - val_loss: 138.5141\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.4225 - val_loss: 151.1236\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.8197 - val_loss: 132.9098\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.2309 - val_loss: 172.8983\n",
      "Epoch 1714/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5645 - val_loss: 227.8955\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 157.549 - 0s 51us/step - loss: 157.0706 - val_loss: 190.2974\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.8290 - val_loss: 146.7835\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7475 - val_loss: 150.6359\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8353 - val_loss: 139.7584\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4902 - val_loss: 171.7341\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.4346 - val_loss: 168.9961\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4258 - val_loss: 196.3580\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9099 - val_loss: 141.2247\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3290 - val_loss: 144.5625\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7368 - val_loss: 143.9471\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7186 - val_loss: 133.6317\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1312 - val_loss: 144.7869\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8512 - val_loss: 240.9513\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.3994 - val_loss: 129.7418\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4932 - val_loss: 134.4535\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1015 - val_loss: 164.7276\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.2636 - val_loss: 166.7193\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4644 - val_loss: 148.1132\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6493 - val_loss: 142.8186\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0078 - val_loss: 138.4712\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9937 - val_loss: 197.3885\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.2890 - val_loss: 162.3583\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5105 - val_loss: 163.8072\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.2518 - val_loss: 159.8519\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3892 - val_loss: 135.5162\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.6660 - val_loss: 138.1904\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.7548 - val_loss: 133.2103\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6126 - val_loss: 139.2115\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4275 - val_loss: 138.3613\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4520 - val_loss: 131.1115\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0878 - val_loss: 184.2785\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.3377 - val_loss: 148.3718\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.2670 - val_loss: 174.3301\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1000 - val_loss: 171.7607\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.4467 - val_loss: 202.7275\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8235 - val_loss: 140.7265\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.0152 - val_loss: 134.5014\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.3784 - val_loss: 137.6044\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.9477 - val_loss: 156.7578\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.4560 - val_loss: 148.8430\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2856 - val_loss: 152.6872\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.4676 - val_loss: 187.7497\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.7066 - val_loss: 145.8742\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4318 - val_loss: 161.4565\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.5644 - val_loss: 151.5213\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3420 - val_loss: 145.9969\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.2759 - val_loss: 146.8249\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.7464 - val_loss: 141.2461\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2443 - val_loss: 143.8307\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4523 - val_loss: 130.5148\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9894 - val_loss: 141.6941\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 145.8827 - val_loss: 145.4234\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 166.7583 - val_loss: 140.0486\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 136.5710 - val_loss: 142.9620\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 161.4446 - val_loss: 178.0180\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9954 - val_loss: 153.3032\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.0286 - val_loss: 137.6155\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.0756 - val_loss: 151.9387\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.6802 - val_loss: 138.5397\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.1430 - val_loss: 157.6781\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9625 - val_loss: 153.7032\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3762 - val_loss: 142.6597\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.0305 - val_loss: 138.5551\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2133 - val_loss: 215.7633\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.4432 - val_loss: 134.2731\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.9153 - val_loss: 169.7884\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.7309 - val_loss: 232.3348\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.0375 - val_loss: 148.4200\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.9690 - val_loss: 178.4944\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.2691 - val_loss: 138.4014\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5601 - val_loss: 144.5930\n",
      "Epoch 1786/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.6460 - val_loss: 140.9444\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3671 - val_loss: 137.8652\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9690 - val_loss: 133.0891\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7548 - val_loss: 159.4258\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3660 - val_loss: 215.0581\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 281.8731 - val_loss: 135.4599\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8106 - val_loss: 129.7576\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1075 - val_loss: 164.1313\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0545 - val_loss: 153.3820\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0093 - val_loss: 138.9594\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8533 - val_loss: 134.7975\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6633 - val_loss: 159.1620\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8307 - val_loss: 159.1611\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5706 - val_loss: 130.9904\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.4186 - val_loss: 231.2807\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.5196 - val_loss: 167.5067\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9569 - val_loss: 137.6295\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6019 - val_loss: 144.0705\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1991 - val_loss: 135.9908\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.0926 - val_loss: 175.0424\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8919 - val_loss: 150.7058\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4586 - val_loss: 135.1837\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1880 - val_loss: 130.6975\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8399 - val_loss: 140.1002\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4652 - val_loss: 139.7172\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.4372 - val_loss: 156.3653\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6916 - val_loss: 186.8379\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6539 - val_loss: 143.3315\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8110 - val_loss: 131.6696\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7663 - val_loss: 197.8992\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3378 - val_loss: 147.9095\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.6668 - val_loss: 153.6335\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4741 - val_loss: 198.9787\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.7058 - val_loss: 141.6372\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1980 - val_loss: 138.0024\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 191.8708 - val_loss: 187.5231\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0663 - val_loss: 139.5916\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2522 - val_loss: 139.0381\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4899 - val_loss: 139.3370\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.3649 - val_loss: 134.1106\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 138.6779 - val_loss: 196.2061\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 143.5714 - val_loss: 139.2403\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 146.5034 - val_loss: 230.3858\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 136.2149 - val_loss: 209.1530\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4245 - val_loss: 139.0870\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0345 - val_loss: 154.5359\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.4994 - val_loss: 174.5975\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5987 - val_loss: 142.2724\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.7503 - val_loss: 153.3797\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.1612 - val_loss: 160.6178\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 214.1131 - val_loss: 185.7790\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2543 - val_loss: 130.9985\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7490 - val_loss: 182.2443\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8952 - val_loss: 146.3500\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.3334 - val_loss: 185.0271\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9886 - val_loss: 138.9800\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6433 - val_loss: 137.3983\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5241 - val_loss: 172.2845\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6765 - val_loss: 130.6099\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2242 - val_loss: 142.6466\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1888 - val_loss: 222.5816\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5713 - val_loss: 146.5598\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7877 - val_loss: 130.8824\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.8015 - val_loss: 195.5503\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.7579 - val_loss: 140.2217\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3513 - val_loss: 150.1594\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1757 - val_loss: 231.6073\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9546 - val_loss: 183.8164\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.2340 - val_loss: 135.3613\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.7466 - val_loss: 136.2433\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0184 - val_loss: 149.6290\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0276 - val_loss: 151.5422\n",
      "Epoch 1858/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9251 - val_loss: 164.1433\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2122 - val_loss: 259.5409\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3711 - val_loss: 164.9864\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3131 - val_loss: 147.1422\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6374 - val_loss: 146.3927\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.1226 - val_loss: 146.3547\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.3420 - val_loss: 172.0507\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.2242 - val_loss: 152.5234\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3137 - val_loss: 163.8372\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7419 - val_loss: 151.6582\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2103 - val_loss: 150.8119\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6499 - val_loss: 185.5362\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.7276 - val_loss: 188.6036\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3255 - val_loss: 194.2905\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.7671 - val_loss: 160.8585\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4597 - val_loss: 128.9670\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5889 - val_loss: 145.4995\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5993 - val_loss: 153.4575\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7159 - val_loss: 182.8423\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9195 - val_loss: 167.5477\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1590 - val_loss: 130.1696\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.6657 - val_loss: 169.3660\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1975 - val_loss: 146.1579\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6513 - val_loss: 139.5896\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.4562 - val_loss: 146.2392\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7869 - val_loss: 162.1805\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0045 - val_loss: 136.6645\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.4881 - val_loss: 228.4301\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.9887 - val_loss: 135.7194\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8400 - val_loss: 130.8687\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4196 - val_loss: 128.8625\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.0831 - val_loss: 341.1930\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3421 - val_loss: 133.2172\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7650 - val_loss: 142.8414\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.9263 - val_loss: 132.9929\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4948 - val_loss: 179.2032\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.7089 - val_loss: 173.6929\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.6830 - val_loss: 159.7402\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0391 - val_loss: 137.8311\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7124 - val_loss: 135.0923\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.3721 - val_loss: 140.6961\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 156.6004 - val_loss: 143.6844\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 165.8695 - val_loss: 152.0027\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 164.6593 - val_loss: 169.8447\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5870 - val_loss: 129.1693\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4879 - val_loss: 139.3553\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7021 - val_loss: 150.5698\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3315 - val_loss: 167.5336\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3937 - val_loss: 130.8693\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7336 - val_loss: 152.0479\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0463 - val_loss: 134.6665\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9310 - val_loss: 184.1102\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0886 - val_loss: 136.3755\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2069 - val_loss: 139.3741\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6769 - val_loss: 156.6012\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3444 - val_loss: 151.4785\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8228 - val_loss: 137.3853\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4797 - val_loss: 151.2676\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4455 - val_loss: 158.9188\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.2587 - val_loss: 169.2768\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1971 - val_loss: 161.3818\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8695 - val_loss: 141.6997\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6000 - val_loss: 132.4351\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4527 - val_loss: 129.7614\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1100 - val_loss: 176.8415\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5040 - val_loss: 152.1391\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0582 - val_loss: 140.2185\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4820 - val_loss: 138.5469\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4324 - val_loss: 150.4524\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.1751 - val_loss: 135.6018\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8362 - val_loss: 150.9284\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9360 - val_loss: 132.7368\n",
      "Epoch 1930/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.7295 - val_loss: 130.3306\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.9557 - val_loss: 134.0188\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2712 - val_loss: 207.8691\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0992 - val_loss: 144.8292\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0107 - val_loss: 144.5138\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.0870 - val_loss: 143.1153\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3282 - val_loss: 145.4865\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4466 - val_loss: 164.4247\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2207 - val_loss: 137.7319\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8725 - val_loss: 131.3607\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2249 - val_loss: 279.7921\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6018 - val_loss: 158.2920\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1074 - val_loss: 151.2326\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.8875 - val_loss: 145.7747\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0511 - val_loss: 154.1612\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9279 - val_loss: 131.2975\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4663 - val_loss: 135.9629\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1980 - val_loss: 132.1229\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3668 - val_loss: 139.6141\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4093 - val_loss: 148.2581\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7532 - val_loss: 158.7242\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2140 - val_loss: 145.3920\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8407 - val_loss: 142.0333\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1711 - val_loss: 140.6379\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6257 - val_loss: 141.9822\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7669 - val_loss: 174.4106\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9731 - val_loss: 140.0092\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6367 - val_loss: 167.0168\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.9526 - val_loss: 250.4227\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.9780 - val_loss: 151.6780\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5483 - val_loss: 134.6401\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.6704 - val_loss: 136.0460\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.7809 - val_loss: 132.0719\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6600 - val_loss: 150.2512\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 231.1865 - val_loss: 130.5431\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8342 - val_loss: 138.8003\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4552 - val_loss: 144.8201\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1339 - val_loss: 134.4172\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6248 - val_loss: 129.1053\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2242 - val_loss: 199.2821\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.7170 - val_loss: 136.2152\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 164.1691 - val_loss: 144.8250\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.7591 - val_loss: 171.5912\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 137.7339 - val_loss: 128.7486\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6826 - val_loss: 139.2583\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2677 - val_loss: 159.0093\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1116 - val_loss: 158.5750\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8340 - val_loss: 135.8672\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.5639 - val_loss: 183.7127\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8953 - val_loss: 175.0270\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3183 - val_loss: 152.9180\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9873 - val_loss: 131.2485\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9705 - val_loss: 156.7997\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4734 - val_loss: 175.0682\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6766 - val_loss: 163.8541\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4535 - val_loss: 137.6913\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4710 - val_loss: 134.7265\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3305 - val_loss: 179.1745\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2579 - val_loss: 139.7565\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6670 - val_loss: 148.2260\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0415 - val_loss: 142.7709\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4964 - val_loss: 134.3714\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7160 - val_loss: 156.5265\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9173 - val_loss: 131.9142\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3372 - val_loss: 148.6317\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0303 - val_loss: 139.5394\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7758 - val_loss: 133.7873\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.8337 - val_loss: 146.0573\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4182 - val_loss: 133.1636\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.3871 - val_loss: 134.1308\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4210 - val_loss: 165.1763\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2934 - val_loss: 140.5677\n",
      "Epoch 2002/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8147 - val_loss: 127.9686\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5689 - val_loss: 167.8700\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9379 - val_loss: 142.7237\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9536 - val_loss: 134.9644\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8338 - val_loss: 129.9273\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4166 - val_loss: 138.7868\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6810 - val_loss: 135.7116\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2628 - val_loss: 143.2552\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7294 - val_loss: 138.2917\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0641 - val_loss: 145.7750\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.9738 - val_loss: 130.4370\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3204 - val_loss: 145.1034\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9369 - val_loss: 157.2455\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2756 - val_loss: 151.0509\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.5372 - val_loss: 130.9413\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5364 - val_loss: 144.4450\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3015 - val_loss: 146.1949\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3176 - val_loss: 127.5442\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6685 - val_loss: 146.8805\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8316 - val_loss: 151.5324\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5948 - val_loss: 131.5903\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3617 - val_loss: 156.1114\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.3500 - val_loss: 204.0745\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.7312 - val_loss: 287.6213\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1489 - val_loss: 141.6028\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5220 - val_loss: 141.6870\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9847 - val_loss: 141.0006\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.3732 - val_loss: 152.3046\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5484 - val_loss: 170.5764\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.3314 - val_loss: 132.8625\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0300 - val_loss: 131.4030\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9464 - val_loss: 149.7410\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0391 - val_loss: 130.5043\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7758 - val_loss: 141.5591\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8442 - val_loss: 132.4538\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.7838 - val_loss: 132.7542\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3802 - val_loss: 132.2620\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6464 - val_loss: 149.4982\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.1484 - val_loss: 143.8309\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8168 - val_loss: 130.5962\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 130.2631 - val_loss: 135.0691\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 143.7930 - val_loss: 145.7941\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 144.3281 - val_loss: 134.2794\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 132.5711 - val_loss: 150.3835\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6039 - val_loss: 176.5039\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9080 - val_loss: 299.0168\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7865 - val_loss: 163.9203\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4258 - val_loss: 137.7050\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.9344 - val_loss: 149.6648\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0085 - val_loss: 132.3231\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.6977 - val_loss: 160.5167\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.9625 - val_loss: 141.1748\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3294 - val_loss: 134.1441\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4103 - val_loss: 173.6224\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 148.858 - 0s 51us/step - loss: 149.3306 - val_loss: 137.2893\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9666 - val_loss: 155.0214\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9098 - val_loss: 136.8633\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2975 - val_loss: 163.2023\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.4264 - val_loss: 137.9099\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6674 - val_loss: 143.3567\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6790 - val_loss: 150.5941\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9774 - val_loss: 131.2875\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1237 - val_loss: 143.4076\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3704 - val_loss: 150.9393\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1756 - val_loss: 170.8325\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3310 - val_loss: 191.2170\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6216 - val_loss: 158.3840\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.9712 - val_loss: 149.3844\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 218.2077 - val_loss: 629.6853\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 301.3825 - val_loss: 169.3536\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.4533 - val_loss: 161.3270\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.2564 - val_loss: 139.4522\n",
      "Epoch 2074/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5851 - val_loss: 147.6899\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.6889 - val_loss: 141.7551\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2108 - val_loss: 137.1251\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5329 - val_loss: 156.8959\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.5496 - val_loss: 178.9131\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.6815 - val_loss: 131.4885\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.1603 - val_loss: 149.2364\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1391 - val_loss: 169.8949\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3036 - val_loss: 145.7791\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5226 - val_loss: 132.9216\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2719 - val_loss: 150.5530\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.4309 - val_loss: 147.2803\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8806 - val_loss: 144.9837\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3516 - val_loss: 186.9294\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.3170 - val_loss: 159.7293\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0750 - val_loss: 219.0608\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6340 - val_loss: 136.5179\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5313 - val_loss: 135.3196\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2961 - val_loss: 143.3658\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6118 - val_loss: 137.0903\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9625 - val_loss: 140.1555\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6934 - val_loss: 143.5993\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0660 - val_loss: 136.1791\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6726 - val_loss: 150.3234\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.2572 - val_loss: 216.8499\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6362 - val_loss: 137.3439\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5470 - val_loss: 133.6568\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9673 - val_loss: 163.6714\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.5026 - val_loss: 167.8183\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7824 - val_loss: 190.0472\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0771 - val_loss: 150.6102\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0733 - val_loss: 139.8872\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4708 - val_loss: 127.7050\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0211 - val_loss: 137.6406\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0083 - val_loss: 186.2416\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8330 - val_loss: 128.8850\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8217 - val_loss: 128.4524\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6714 - val_loss: 129.2564\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4908 - val_loss: 136.9948\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1280 - val_loss: 160.2509\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.1327 - val_loss: 130.9115\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.8803 - val_loss: 132.4531\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 142.6527 - val_loss: 135.7950\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 130.5233 - val_loss: 145.7317\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4175 - val_loss: 162.4665\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0243 - val_loss: 204.6201\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.7421 - val_loss: 136.6156\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1765 - val_loss: 140.4071\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6725 - val_loss: 153.2373\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.8363 - val_loss: 147.4517\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8739 - val_loss: 164.9023\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.6708 - val_loss: 150.6502\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.6720 - val_loss: 356.2478\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8472 - val_loss: 133.3830\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4758 - val_loss: 150.2797\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8962 - val_loss: 158.9481\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4530 - val_loss: 160.0841\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0642 - val_loss: 144.6165\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.7200 - val_loss: 142.4454\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7136 - val_loss: 176.3087\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.8037 - val_loss: 161.9004\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.8165 - val_loss: 138.2244\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9825 - val_loss: 131.1518\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9848 - val_loss: 246.5557\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.2345 - val_loss: 132.5768\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8942 - val_loss: 192.3624\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6262 - val_loss: 157.2631\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8710 - val_loss: 161.4089\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2739 - val_loss: 147.4012\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5467 - val_loss: 151.2682\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6451 - val_loss: 130.5949\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7060 - val_loss: 169.4772\n",
      "Epoch 2146/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.6820 - val_loss: 136.8265\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1748 - val_loss: 138.4562\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.7981 - val_loss: 158.6102\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3352 - val_loss: 133.3389\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.7525 - val_loss: 168.0674\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5323 - val_loss: 136.0283\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2741 - val_loss: 141.8927\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0755 - val_loss: 152.2008\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0838 - val_loss: 133.6564\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4648 - val_loss: 130.9637\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4191 - val_loss: 135.8822\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7584 - val_loss: 129.4540\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1889 - val_loss: 164.7646\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.5061 - val_loss: 136.2424\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.9711 - val_loss: 131.6491\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3235 - val_loss: 143.5791\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6433 - val_loss: 143.6291\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9425 - val_loss: 173.6360\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5812 - val_loss: 136.1091\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6707 - val_loss: 183.9387\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7009 - val_loss: 165.0337\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1287 - val_loss: 168.2345\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9468 - val_loss: 148.3953\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7702 - val_loss: 136.9596\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8828 - val_loss: 149.5779\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4537 - val_loss: 136.5613\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5368 - val_loss: 172.2818\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.3218 - val_loss: 144.5910\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 131.3873 - val_loss: 141.4426\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 128.5461 - val_loss: 156.0160\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.0078 - val_loss: 133.4265\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.9132 - val_loss: 130.9863\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0941 - val_loss: 150.9007\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3735 - val_loss: 144.3237\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2641 - val_loss: 323.3961\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6689 - val_loss: 174.7347\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7556 - val_loss: 273.2389\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6774 - val_loss: 147.2791\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2140 - val_loss: 232.0187TA: 0s - loss: 117\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5613 - val_loss: 149.8560\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.9007 - val_loss: 166.3762\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 165.6573 - val_loss: 188.8010\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.6452 - val_loss: 162.4444\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.4513 - val_loss: 182.7313\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8397 - val_loss: 137.3164\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.3716 - val_loss: 146.9082\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.2307 - val_loss: 195.6258\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5203 - val_loss: 128.4240\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0239 - val_loss: 170.0629\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6511 - val_loss: 145.3483\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8252 - val_loss: 156.1430\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 206.2641 - val_loss: 146.5247\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9866 - val_loss: 147.5145\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8711 - val_loss: 163.3010\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2701 - val_loss: 153.9842\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0155 - val_loss: 142.3962\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7116 - val_loss: 141.9589\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3960 - val_loss: 155.1332\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9335 - val_loss: 163.6621\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3964 - val_loss: 140.3388\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3218 - val_loss: 177.4083\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4496 - val_loss: 156.4254\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.0271 - val_loss: 140.2931\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0173 - val_loss: 140.4261\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4810 - val_loss: 129.0552\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.4102 - val_loss: 142.9061\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4473 - val_loss: 138.6759\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0290 - val_loss: 148.9910\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5809 - val_loss: 133.5968\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.0581 - val_loss: 163.5037\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7599 - val_loss: 141.3728\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5649 - val_loss: 146.6409\n",
      "Epoch 2218/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7632 - val_loss: 131.2765\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9602 - val_loss: 157.3082\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4213 - val_loss: 135.9973\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.1676 - val_loss: 165.1513\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3395 - val_loss: 148.4964\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2915 - val_loss: 183.2084\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3981 - val_loss: 142.6122\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9937 - val_loss: 146.2319\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4046 - val_loss: 130.9571\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4225 - val_loss: 141.5673\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8259 - val_loss: 252.2345\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.1370 - val_loss: 143.8320\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.1383 - val_loss: 173.1290\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7637 - val_loss: 140.6075\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6006 - val_loss: 219.3468\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8807 - val_loss: 141.3998\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.2499 - val_loss: 228.5364\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7812 - val_loss: 127.2489\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9730 - val_loss: 256.2760\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.1731 - val_loss: 151.3450\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.3340 - val_loss: 142.7942\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6498 - val_loss: 143.2149\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.7668 - val_loss: 157.2587\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3905 - val_loss: 132.0538\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9716 - val_loss: 143.0578\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3089 - val_loss: 143.4629\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7589 - val_loss: 217.6713\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 348.6491 - val_loss: 135.9771\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6809 - val_loss: 135.6130\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2654 - val_loss: 140.3708\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.8604 - val_loss: 138.4401\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6205 - val_loss: 133.6230\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4963 - val_loss: 143.8354\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9272 - val_loss: 156.2765\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.8436 - val_loss: 150.4974\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.6261 - val_loss: 148.9085\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9497 - val_loss: 131.7711\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1976 - val_loss: 155.8189\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3925 - val_loss: 146.1512\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4056 - val_loss: 160.8150\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.4791 - val_loss: 133.1895\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.4494 - val_loss: 138.8545\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 155.8539 - val_loss: 167.7910\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 136.7297 - val_loss: 129.6374\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6322 - val_loss: 136.1048\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6250 - val_loss: 161.3100\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1565 - val_loss: 184.2578\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3231 - val_loss: 127.1109\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.1882 - val_loss: 159.9974\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5169 - val_loss: 203.5143\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6111 - val_loss: 136.4390\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.1628 - val_loss: 173.1729\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.8283 - val_loss: 140.5085\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8329 - val_loss: 174.2901\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1872 - val_loss: 128.0680\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6929 - val_loss: 145.1166\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7402 - val_loss: 142.6365\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7922 - val_loss: 148.8562\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2517 - val_loss: 159.9021\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.2008 - val_loss: 206.9640\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1407 - val_loss: 136.4341\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7936 - val_loss: 149.2593\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.9107 - val_loss: 134.5296\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6189 - val_loss: 148.5690\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7549 - val_loss: 133.1642\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9627 - val_loss: 245.4978\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1452 - val_loss: 148.5598\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.3466 - val_loss: 175.5024\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9176 - val_loss: 131.3755\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.3691 - val_loss: 139.1838\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8309 - val_loss: 144.0073\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9270 - val_loss: 142.8627\n",
      "Epoch 2290/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.0103 - val_loss: 174.3654\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9008 - val_loss: 135.3097\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1728 - val_loss: 138.1725\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.6245 - val_loss: 128.9780\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1267 - val_loss: 146.2920\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0765 - val_loss: 212.7026\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7082 - val_loss: 140.6192\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5929 - val_loss: 146.8974\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9595 - val_loss: 140.0263\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9216 - val_loss: 141.0460\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.0044 - val_loss: 180.1711\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7681 - val_loss: 152.4830\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.0918 - val_loss: 143.8671\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1470 - val_loss: 143.9109\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1885 - val_loss: 134.6297\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0735 - val_loss: 132.8887\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 201.930 - 0s 51us/step - loss: 200.9219 - val_loss: 159.9263\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1735 - val_loss: 146.2879\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4246 - val_loss: 132.2327\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.2778 - val_loss: 199.6689\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.5858 - val_loss: 182.8703\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4707 - val_loss: 150.8644\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5054 - val_loss: 129.9511\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8672 - val_loss: 131.6493\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.5438 - val_loss: 133.3229\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4529 - val_loss: 151.1081\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.3930 - val_loss: 155.6082\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6698 - val_loss: 141.7367\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5152 - val_loss: 142.2106\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.3804 - val_loss: 156.6349\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1645 - val_loss: 156.8626\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7331 - val_loss: 149.0238\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8590 - val_loss: 146.9966\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3347 - val_loss: 140.0172\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4016 - val_loss: 151.5283\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0490 - val_loss: 145.0807\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6377 - val_loss: 154.1356\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.8201 - val_loss: 144.6487\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2490 - val_loss: 142.5743\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1036 - val_loss: 133.1812\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 156.6967 - val_loss: 139.7057\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 161.4058 - val_loss: 240.0415\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 144.5679 - val_loss: 154.0703\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.0756 - val_loss: 146.5761\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4044 - val_loss: 129.8307\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.1065 - val_loss: 145.1908\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9371 - val_loss: 169.0130\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.6831 - val_loss: 228.4115\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9115 - val_loss: 157.0509\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6047 - val_loss: 136.0905\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7920 - val_loss: 185.6031\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8549 - val_loss: 170.4324\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4396 - val_loss: 234.4828\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0938 - val_loss: 156.8225\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.3438 - val_loss: 163.3152\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6996 - val_loss: 185.7136\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0413 - val_loss: 172.7508\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6055 - val_loss: 136.7789\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9650 - val_loss: 135.0761\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8608 - val_loss: 144.9215\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8846 - val_loss: 129.7396\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1910 - val_loss: 136.6105\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1207 - val_loss: 135.0775\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0748 - val_loss: 133.2048\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6113 - val_loss: 129.0405\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9859 - val_loss: 133.4079\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.4408 - val_loss: 184.8130\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.6496 - val_loss: 137.5982\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5068 - val_loss: 149.9831\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.8247 - val_loss: 140.2737\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1988 - val_loss: 148.2896\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0816 - val_loss: 138.7683\n",
      "Epoch 2362/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0745 - val_loss: 136.4667\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1513 - val_loss: 150.9288\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4878 - val_loss: 146.8307\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2305 - val_loss: 148.4086\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7628 - val_loss: 177.2760\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8000 - val_loss: 153.1488\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5105 - val_loss: 140.6536\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5920 - val_loss: 134.6638\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1307 - val_loss: 156.8950\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7502 - val_loss: 141.5051\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8379 - val_loss: 149.4260\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6092 - val_loss: 141.5458\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3450 - val_loss: 149.5652\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7528 - val_loss: 129.6055\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0739 - val_loss: 131.5520\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4181 - val_loss: 152.3133\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9560 - val_loss: 152.8014\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6357 - val_loss: 145.7124\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9863 - val_loss: 175.0267\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1866 - val_loss: 136.3829\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9421 - val_loss: 156.7196\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5947 - val_loss: 149.4245\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5182 - val_loss: 141.9235\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.4267 - val_loss: 152.9101\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0503 - val_loss: 144.1895\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2020 - val_loss: 150.3442\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5499 - val_loss: 170.3602\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.0311 - val_loss: 163.9611\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.0479 - val_loss: 344.1422\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7611 - val_loss: 144.1268\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5345 - val_loss: 193.1747\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5265 - val_loss: 166.3664\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4714 - val_loss: 169.5318\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2180 - val_loss: 249.4395\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9959 - val_loss: 132.7903\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2874 - val_loss: 135.2102\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5731 - val_loss: 129.8067\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1887 - val_loss: 133.8539\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9789 - val_loss: 141.9051\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.6559 - val_loss: 203.8180\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 262.1304 - val_loss: 141.7077\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 149.4803 - val_loss: 150.3600\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.0198 - val_loss: 171.6871\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.8327 - val_loss: 239.1888\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.1537 - val_loss: 142.7013\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.9754 - val_loss: 139.0313\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.9923 - val_loss: 132.9263\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.3030 - val_loss: 167.3634\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.5945 - val_loss: 137.5955\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8223 - val_loss: 249.6028\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3025 - val_loss: 137.0794\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0959 - val_loss: 168.9791\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2946 - val_loss: 181.1970\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.5382 - val_loss: 134.4581\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.8882 - val_loss: 265.7434\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.6579 - val_loss: 153.2109\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8202 - val_loss: 155.7324\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2054 - val_loss: 151.2804\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5075 - val_loss: 174.8122\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4318 - val_loss: 134.6497\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1058 - val_loss: 141.1882\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1594 - val_loss: 135.1507\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6157 - val_loss: 139.4910\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7518 - val_loss: 181.0744\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.7365 - val_loss: 142.2196\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0652 - val_loss: 135.6831\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9824 - val_loss: 138.4735\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8199 - val_loss: 152.8537\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9887 - val_loss: 149.2903\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.7799 - val_loss: 141.2840\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5949 - val_loss: 164.6325\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4120 - val_loss: 170.9896\n",
      "Epoch 2434/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 176.5914 - val_loss: 131.9393\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.1108 - val_loss: 137.9958\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.2192 - val_loss: 171.7713\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2078 - val_loss: 158.9276\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6550 - val_loss: 134.2672\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1391 - val_loss: 135.7716\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6583 - val_loss: 129.9914\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7096 - val_loss: 174.4664\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.2739 - val_loss: 155.8907\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2264 - val_loss: 152.3797\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.2658 - val_loss: 131.6899\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.4381 - val_loss: 155.3745\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5909 - val_loss: 139.1212\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1079 - val_loss: 161.0981\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7653 - val_loss: 139.2596\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.4565 - val_loss: 159.7393\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.4696 - val_loss: 261.8857\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.7457 - val_loss: 145.1055\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3161 - val_loss: 130.5793\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5531 - val_loss: 171.7342\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.0523 - val_loss: 132.3525\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 135.406 - 0s 57us/step - loss: 136.2600 - val_loss: 142.1871\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 377.8919 - val_loss: 539.2069\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 372.6208 - val_loss: 277.8364\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 260.9758 - val_loss: 176.1221\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.7076 - val_loss: 177.1263\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.4220 - val_loss: 189.6633\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.7540 - val_loss: 148.8540\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 193.6332 - val_loss: 163.4318\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 173.7871 - val_loss: 159.7404\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2766 - val_loss: 156.6175\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.0462 - val_loss: 157.8699\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3210 - val_loss: 155.8710\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.0641 - val_loss: 148.6349\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 274.7278 - val_loss: 181.3026\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0516 - val_loss: 212.2421\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9678 - val_loss: 151.8015\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5741 - val_loss: 157.0023\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 154.2882 - val_loss: 149.7616\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.2781 - val_loss: 159.1499\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8949 - val_loss: 160.0757\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.3665 - val_loss: 165.1650\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7373 - val_loss: 147.0413\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6605 - val_loss: 148.7340\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1434 - val_loss: 159.2583\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.2961 - val_loss: 209.3615\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.8814 - val_loss: 197.3873\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2826 - val_loss: 166.8495\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.2965 - val_loss: 227.1759\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6002 - val_loss: 140.4076\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 150.0190 - val_loss: 153.8878\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 156.6251 - val_loss: 159.3674\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 214.3234 - val_loss: 262.0841\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.6822 - val_loss: 162.5782\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6980 - val_loss: 186.2037\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.1349 - val_loss: 160.5877\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3497 - val_loss: 216.4826\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4933 - val_loss: 186.8245\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6962 - val_loss: 138.6075\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.2134 - val_loss: 152.9237\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5932 - val_loss: 187.9063\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4600 - val_loss: 196.7038\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2383 - val_loss: 152.4310\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6704 - val_loss: 172.0425\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.2059 - val_loss: 159.1521\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.4183 - val_loss: 159.1667\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5635 - val_loss: 143.9013\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1962 - val_loss: 137.4036\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.1121 - val_loss: 165.6676\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1256 - val_loss: 182.2278\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2674 - val_loss: 190.6039\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3264 - val_loss: 154.3562\n",
      "Epoch 2506/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8734 - val_loss: 147.0451\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4167 - val_loss: 138.0934\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1159 - val_loss: 139.8930\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0920 - val_loss: 174.0984\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 199.1699 - val_loss: 195.4969\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0642 - val_loss: 149.1313\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0545 - val_loss: 141.9236\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9850 - val_loss: 147.7491\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7182 - val_loss: 144.5083\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7174 - val_loss: 160.1880\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6684 - val_loss: 207.8260\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9495 - val_loss: 146.2999\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6619 - val_loss: 145.6443\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7593 - val_loss: 148.9552\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.8659 - val_loss: 139.5840\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7619 - val_loss: 139.5410\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.1332 - val_loss: 182.2034\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7750 - val_loss: 158.7330\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1705 - val_loss: 144.1809\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2979 - val_loss: 141.6671\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.9104 - val_loss: 145.1642\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8091 - val_loss: 141.6625\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8406 - val_loss: 135.5680\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4334 - val_loss: 192.7433\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5036 - val_loss: 149.2303\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0249 - val_loss: 154.8238\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2627 - val_loss: 137.7417\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8074 - val_loss: 138.6762\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5059 - val_loss: 187.1730\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3404 - val_loss: 149.6409\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3312 - val_loss: 183.9589\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8562 - val_loss: 137.4509\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.2671 - val_loss: 171.5756\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0675 - val_loss: 143.1450\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7419 - val_loss: 149.1797\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0708 - val_loss: 152.1605\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3125 - val_loss: 177.4341\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.0939 - val_loss: 171.3087\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0349 - val_loss: 159.0512\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.7541 - val_loss: 159.0462\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 139.1907 - val_loss: 151.5449\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.0023 - val_loss: 137.2016\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 139.1751 - val_loss: 155.7746\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.2817 - val_loss: 142.3760\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.2692 - val_loss: 154.4897\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.4080 - val_loss: 141.2456\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.0774 - val_loss: 138.7030\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4073 - val_loss: 133.6915\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4726 - val_loss: 149.2998\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5204 - val_loss: 136.4958\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5699 - val_loss: 144.4754\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8530 - val_loss: 141.1714\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6533 - val_loss: 141.7342\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5320 - val_loss: 138.5995\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7464 - val_loss: 138.3027\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6170 - val_loss: 141.4415\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.9964 - val_loss: 163.0572\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3464 - val_loss: 136.1944\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9210 - val_loss: 139.2587\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3504 - val_loss: 135.9496\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3368 - val_loss: 151.1058\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5060 - val_loss: 220.2720\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0631 - val_loss: 137.2195\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.5230 - val_loss: 206.6069\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.5355 - val_loss: 203.0995\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6999 - val_loss: 144.3511\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1218 - val_loss: 139.8540\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9823 - val_loss: 160.3367\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.8725 - val_loss: 150.5578\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.7662 - val_loss: 158.9442\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2537 - val_loss: 143.8346\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.1582 - val_loss: 141.6469\n",
      "Epoch 2578/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9510 - val_loss: 145.1379\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1195 - val_loss: 245.4639\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.0374 - val_loss: 151.4424\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7866 - val_loss: 140.2760\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8615 - val_loss: 138.5944\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3652 - val_loss: 189.0914\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2527 - val_loss: 174.2577\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1885 - val_loss: 158.4813\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3694 - val_loss: 199.3174\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.3714 - val_loss: 149.8919\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.7887 - val_loss: 168.6961\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.4189 - val_loss: 137.3642\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9421 - val_loss: 149.8306\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9919 - val_loss: 132.9516\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0602 - val_loss: 175.5707\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3965 - val_loss: 152.9375\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5187 - val_loss: 158.1658\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7462 - val_loss: 149.4843\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8234 - val_loss: 146.0052\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4169 - val_loss: 143.0289\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4489 - val_loss: 139.6292\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9337 - val_loss: 146.5755\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2445 - val_loss: 147.9891\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3657 - val_loss: 150.7659\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9380 - val_loss: 145.2186\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0039 - val_loss: 142.6093\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3069 - val_loss: 183.3168\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7611 - val_loss: 142.6148\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7838 - val_loss: 141.8630\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1460 - val_loss: 180.4023\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1985 - val_loss: 151.7952\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8496 - val_loss: 133.7892\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0837 - val_loss: 138.8830\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.8319 - val_loss: 197.7962\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2767 - val_loss: 144.9903\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6148 - val_loss: 138.9543\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7068 - val_loss: 141.0661\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2863 - val_loss: 135.1595\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 159.6022 - val_loss: 138.3642\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.2044 - val_loss: 133.8019\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 142.6970 - val_loss: 168.0045\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.0147 - val_loss: 193.2160\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3312 - val_loss: 169.9874\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.1753 - val_loss: 161.8666\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3796 - val_loss: 135.9517\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.1248 - val_loss: 150.8324\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1139 - val_loss: 154.2579\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2092 - val_loss: 141.2739\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3741 - val_loss: 160.4472\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8399 - val_loss: 151.5383\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1742 - val_loss: 140.7724\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6000 - val_loss: 138.7824\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1803 - val_loss: 146.3083\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2385 - val_loss: 134.2886\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4926 - val_loss: 142.7564\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2086 - val_loss: 147.7814\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8446 - val_loss: 136.5873\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4236 - val_loss: 184.5333\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4232 - val_loss: 153.2484\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5028 - val_loss: 165.6546\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0973 - val_loss: 140.7482\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0438 - val_loss: 133.5288\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6282 - val_loss: 149.0713\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9840 - val_loss: 156.7359\n",
      "Epoch 02641: early stopping\n",
      "Fold score (RMSE): 12.279497146606445\n",
      "Fold #4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 17127.5549 - val_loss: 5693.4343\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 4894.9240 - val_loss: 4682.6927\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 4534.9216 - val_loss: 4501.9412\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4385.0718 - val_loss: 4386.9429\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4248.5315 - val_loss: 4229.0845\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4094.7252 - val_loss: 4059.9529\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4087.7922 - val_loss: 4176.2802\n",
      "Epoch 8/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 4060.1986 - val_loss: 4813.2532\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3900.0092 - val_loss: 4116.4685\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3832.4749 - val_loss: 3816.2852\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3568.6036 - val_loss: 3434.4972\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 3349.0484 - val_loss: 3151.4169\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 3141.2965 - val_loss: 2778.8106\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 2916.8626 - val_loss: 2720.7732\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2696.3525 - val_loss: 2819.7413\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 2201.0521 - val_loss: 3382.6985\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2166.8287 - val_loss: 1640.1828\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1476.9905 - val_loss: 946.3351\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 1647.1201 - val_loss: 1537.7055\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1225.2010 - val_loss: 1188.6859\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1099.5132 - val_loss: 600.0380\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 888.6877 - val_loss: 563.7411\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 880.0359 - val_loss: 714.9294\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 875.8069 - val_loss: 496.2615\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 815.8387 - val_loss: 473.4907\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 737.3248 - val_loss: 1054.2527\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 634.2913 - val_loss: 421.6445\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 712.6815 - val_loss: 458.7688\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 630.3794 - val_loss: 416.7307\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 590.7137 - val_loss: 710.2881\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 683.0176 - val_loss: 452.2808\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 514.8792 - val_loss: 403.1531\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 543.8649 - val_loss: 953.3232\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 585.6413 - val_loss: 393.0067\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 464.2890 - val_loss: 294.4068\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 473.1430 - val_loss: 828.3412\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 495.5747 - val_loss: 273.3839\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 531.6578 - val_loss: 396.9993\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 590.7852 - val_loss: 491.8242\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 472.6808 - val_loss: 466.3504\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 485.1546 - val_loss: 651.6457\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 516.5926 - val_loss: 457.5830\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 574.6461 - val_loss: 324.1472\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 492.1733 - val_loss: 941.6794\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 449.1833 - val_loss: 277.8397\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 501.7615 - val_loss: 526.3689\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 492.2703 - val_loss: 466.9739\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 498.9275 - val_loss: 338.8785\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 451.3328 - val_loss: 456.5681\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 441.2783 - val_loss: 420.8270\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 399.6743 - val_loss: 239.6774\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 413.9526 - val_loss: 446.7027\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 469.5615 - val_loss: 903.9537\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 489.6750 - val_loss: 287.3411\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 486.5433 - val_loss: 376.8904\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 428.0874 - val_loss: 224.5426\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 371.2984 - val_loss: 260.1753\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 410.7884 - val_loss: 383.3278\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 383.9362 - val_loss: 342.3643\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 396.2443 - val_loss: 227.9418\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 476.5413 - val_loss: 252.0681\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 419.5780 - val_loss: 301.2832\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 412.2329 - val_loss: 444.9334\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 410.7822 - val_loss: 268.7977\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 403.6969 - val_loss: 404.8638\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 377.0070 - val_loss: 483.9934\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 389.8533 - val_loss: 233.4244\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 384.8353 - val_loss: 350.8090\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 388.6816 - val_loss: 399.1907\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 350.4534 - val_loss: 216.3530\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 397.8530 - val_loss: 201.7643\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 320.0995 - val_loss: 195.5956\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 448.5403 - val_loss: 223.8629\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 474.2578 - val_loss: 314.8595\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 432.7439 - val_loss: 474.8689\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 408.1593 - val_loss: 218.7301\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 342.6417 - val_loss: 228.3179\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 326.6908 - val_loss: 251.7044\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 340.9407 - val_loss: 207.2602\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 320.4079 - val_loss: 337.9277\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 378.1609 - val_loss: 254.8691\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 389.1282 - val_loss: 202.7025\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 378.1356 - val_loss: 1407.7459\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 351.0917 - val_loss: 208.5324\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 295.2546 - val_loss: 377.7688\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 335.5526 - val_loss: 334.9762\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 322.1175 - val_loss: 329.0680\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 352.2299 - val_loss: 234.0797\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 326.4554 - val_loss: 271.0246\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 329.6692 - val_loss: 242.8969\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 401.8776 - val_loss: 364.2908\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 396.1303 - val_loss: 274.6218\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 358.6201 - val_loss: 216.9418\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 412.9121 - val_loss: 210.2453\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 311.9703 - val_loss: 231.9174\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 315.2585 - val_loss: 207.6260\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 349.0758 - val_loss: 226.4799\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 281.6966 - val_loss: 321.5899\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 323.9392 - val_loss: 287.8492\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 371.0445 - val_loss: 239.3574\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 309.5689 - val_loss: 663.6637\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 319.5293 - val_loss: 375.3834\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 292.0962 - val_loss: 210.1964\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 318.3446 - val_loss: 197.3026\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 407.7111 - val_loss: 295.3406\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 309.7050 - val_loss: 177.6662\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 280.6644 - val_loss: 191.5797\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 329.8883 - val_loss: 195.8830\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 272.8426 - val_loss: 254.5726\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 312.9153 - val_loss: 237.9076\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 511.7510 - val_loss: 242.8152\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 290.0697 - val_loss: 269.9450\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 267.4400 - val_loss: 187.6537\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 266.9607 - val_loss: 277.9078\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 326.2240 - val_loss: 266.9698\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 346.6119 - val_loss: 570.9883\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 352.2225 - val_loss: 366.0160\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 281.3110 - val_loss: 240.4579\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 279.6558 - val_loss: 431.6990\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 348.8152 - val_loss: 202.7107\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 507.4015 - val_loss: 259.4976\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 321.8597 - val_loss: 283.6307\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 294.1670 - val_loss: 207.4604\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 272.6452 - val_loss: 191.1582\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 277.0976 - val_loss: 193.3446\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 270.7323 - val_loss: 212.3687\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 266.2678 - val_loss: 228.2391\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 270.4964 - val_loss: 338.8599\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 346.9482 - val_loss: 204.6353\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 309.0109 - val_loss: 178.1369\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 295.8337 - val_loss: 189.2780\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 291.5445 - val_loss: 214.0087\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 303.2476 - val_loss: 231.6751\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 251.5252 - val_loss: 163.9999\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.9851 - val_loss: 301.3572\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 347.7050 - val_loss: 168.7335\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 405.9554 - val_loss: 197.2676\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 255.6765 - val_loss: 171.5466\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.0917 - val_loss: 161.7604\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 254.7434 - val_loss: 416.0926\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 270.5508 - val_loss: 414.4581\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 330.4633 - val_loss: 224.6861\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.5154 - val_loss: 182.3488\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 281.8365 - val_loss: 209.8040\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 262.1712 - val_loss: 169.3179\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 256.6642 - val_loss: 157.0174\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.2276 - val_loss: 198.8616\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 316.8770 - val_loss: 206.5964\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 243.0459 - val_loss: 320.4710\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 274.3260 - val_loss: 193.7435\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 262.4922 - val_loss: 287.6700\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 303.8392 - val_loss: 211.2969\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 289.3871 - val_loss: 270.3698\n",
      "Epoch 154/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 328.1492 - val_loss: 175.3113\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.6160 - val_loss: 195.7093\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.0213 - val_loss: 185.4004\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 275.5884 - val_loss: 193.7710\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 427.8016 - val_loss: 221.8697\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 322.3496 - val_loss: 251.7937\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 313.4455 - val_loss: 178.1480\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 445.1328 - val_loss: 203.0334\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 240.7352 - val_loss: 221.2354\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 300.5577 - val_loss: 201.1102\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 259.7806 - val_loss: 161.3601\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 256.2775 - val_loss: 356.5445\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 363.0722 - val_loss: 230.1104\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 308.2648 - val_loss: 286.0455\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 262.8415 - val_loss: 422.6492\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 272.9845 - val_loss: 207.8056\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 241.4707 - val_loss: 156.1721\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 259.9916 - val_loss: 409.8451\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.8869 - val_loss: 160.7303\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 270.6907 - val_loss: 152.6692\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 226.5989 - val_loss: 190.7564\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 243.3005 - val_loss: 161.5107\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 341.9190 - val_loss: 385.8927\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 242.0486 - val_loss: 515.2458\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 316.1998 - val_loss: 211.1055\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 286.4098 - val_loss: 295.5706\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 733.3582 - val_loss: 1446.0353\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 528.9338 - val_loss: 211.7721\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 287.4915 - val_loss: 291.6284\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 353.1544 - val_loss: 391.3780\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 313.3778 - val_loss: 241.1101\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 277.4964 - val_loss: 207.2965\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 314.5053 - val_loss: 234.1024\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 262.5931 - val_loss: 178.0163\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 310.6608 - val_loss: 262.6377\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 293.2444 - val_loss: 195.5376\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.4937 - val_loss: 199.6279\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 259.3646 - val_loss: 168.8328\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 240.8260 - val_loss: 162.6771\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 322.3266 - val_loss: 221.4393\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 273.4418 - val_loss: 189.4908\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 252.6896 - val_loss: 212.5990\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 274.4553 - val_loss: 220.4417\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 263.0001 - val_loss: 565.4537\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 270.3527 - val_loss: 302.2395\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 269.0731 - val_loss: 301.1918\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 253.5304 - val_loss: 175.7731\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 263.9300 - val_loss: 187.0326\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 284.7830 - val_loss: 177.5499\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 225.3567 - val_loss: 324.4291\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 252.7325 - val_loss: 186.4941\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 250.3549 - val_loss: 148.7892\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 273.1450 - val_loss: 190.7788\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 290.3306 - val_loss: 292.1595\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 320.0586 - val_loss: 624.8738\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 262.8200 - val_loss: 162.1054\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 260.3008 - val_loss: 264.5986\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 266.7259 - val_loss: 213.4088\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 223.1445 - val_loss: 157.2797\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 273.3824 - val_loss: 187.8537\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 225.1884 - val_loss: 216.9675\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 236.8529 - val_loss: 168.0938\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 299.1800 - val_loss: 158.3565\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 242.2693 - val_loss: 212.9284\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.0658 - val_loss: 153.6540\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 298.8010 - val_loss: 392.5198\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.0567 - val_loss: 150.1804\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 236.9016 - val_loss: 150.5664\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 329.3143 - val_loss: 188.1438\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.3674 - val_loss: 259.9820\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 290.4392 - val_loss: 168.7088\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 277.0152 - val_loss: 158.4825\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.5514 - val_loss: 247.0605\n",
      "Epoch 227/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 262.5067 - val_loss: 484.9168\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 252.6553 - val_loss: 170.3532\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.7811 - val_loss: 168.6974\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 255.2963 - val_loss: 269.9637\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.6105 - val_loss: 164.6297\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 280.3019 - val_loss: 178.2027\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 250.1216 - val_loss: 231.6331\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 263.7517 - val_loss: 264.9209\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.1335 - val_loss: 240.6988\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.6688 - val_loss: 224.1258\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.0974 - val_loss: 156.2039\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.7937 - val_loss: 141.2187\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 225.2440 - val_loss: 142.1072\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.0389 - val_loss: 149.8355\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.5677 - val_loss: 168.3748\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.2344 - val_loss: 189.4404\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 293.4604 - val_loss: 261.1496\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 287.8047 - val_loss: 306.8267\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 286.0008 - val_loss: 156.2552\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 265.5444 - val_loss: 435.4220\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 284.0082 - val_loss: 149.1922\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.9876 - val_loss: 227.6423\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 258.9469 - val_loss: 226.0558\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 272.2416 - val_loss: 191.8974\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 217.4015 - val_loss: 140.0946\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 210.3813 - val_loss: 178.7075\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 240.7221 - val_loss: 203.0876\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 256.9141 - val_loss: 146.6351\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.8797 - val_loss: 288.4061\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 334.0125 - val_loss: 166.2107\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 234.1889 - val_loss: 169.3573\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.2058 - val_loss: 215.0332\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 223.4441 - val_loss: 179.9760\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 219.4367 - val_loss: 151.6398\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 296.7025 - val_loss: 153.7764\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.1477 - val_loss: 188.3459\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.5257 - val_loss: 149.1554\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 282.4769 - val_loss: 2943.6127\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 265.7486 - val_loss: 159.1335\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.3215 - val_loss: 306.6006\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.9803 - val_loss: 160.8358\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.9326 - val_loss: 197.3898\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.1175 - val_loss: 150.2429\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.2772 - val_loss: 143.3473\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.1634 - val_loss: 132.9229\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.2060 - val_loss: 135.7434\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 267.6689 - val_loss: 253.5700\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 265.4922 - val_loss: 172.0794\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.1863 - val_loss: 165.6584\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.3402 - val_loss: 186.2274\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 227.5023 - val_loss: 155.1677\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.6773 - val_loss: 171.6476\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 221.1242 - val_loss: 170.8350\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 231.3285 - val_loss: 165.6801\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.7546 - val_loss: 265.1245\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.7630 - val_loss: 143.7909\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.4215 - val_loss: 144.4152\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.5176 - val_loss: 161.1906\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.2349 - val_loss: 196.3219\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 377.5930 - val_loss: 206.7090\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.2261 - val_loss: 206.4539\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.7253 - val_loss: 242.2229\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.3440 - val_loss: 157.8115\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.6383 - val_loss: 164.4956\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 257.2922 - val_loss: 176.4491\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.6224 - val_loss: 132.5983\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 201.9442 - val_loss: 134.7212\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 328.8467 - val_loss: 141.3966\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.6147 - val_loss: 185.8404\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.3569 - val_loss: 236.8898\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.8837 - val_loss: 175.1538\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 243.5749 - val_loss: 163.8269\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 264.8741 - val_loss: 169.9394\n",
      "Epoch 300/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.9059 - val_loss: 148.1063\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.0692 - val_loss: 191.9468\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 286.8396 - val_loss: 170.3806\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 307.2292 - val_loss: 632.3568\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 309.6659 - val_loss: 237.7865\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.2767 - val_loss: 228.4808\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 198.5925 - val_loss: 155.6765\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 209.2381 - val_loss: 137.1229\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 245.3710 - val_loss: 163.5987\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 204.2336 - val_loss: 132.6597\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.8787 - val_loss: 143.8611\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4289 - val_loss: 156.0862\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.1368 - val_loss: 164.0351\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.7152 - val_loss: 201.4164\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.7960 - val_loss: 228.0448\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.5492 - val_loss: 168.4687\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.0229 - val_loss: 143.0052\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 277.6121 - val_loss: 220.7311\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.0187 - val_loss: 144.2579\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.2878 - val_loss: 466.3946\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 217.8961 - val_loss: 142.4206\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 236.0791 - val_loss: 273.1413\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 213.5464 - val_loss: 150.6945\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 206.1086 - val_loss: 161.4447\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 512.2077 - val_loss: 252.2235\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 249.4192 - val_loss: 161.9922\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 431.4600 - val_loss: 197.4769\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.0325 - val_loss: 135.5242\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.9971 - val_loss: 138.9480\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.9363 - val_loss: 129.2125\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.3982 - val_loss: 178.4349\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.0477 - val_loss: 173.0525\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.7033 - val_loss: 242.0943\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 364.6991 - val_loss: 157.5447\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.6939 - val_loss: 211.3462\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.6342 - val_loss: 128.4583\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.3790 - val_loss: 135.0806\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.8965 - val_loss: 150.9516\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.2684 - val_loss: 157.1440\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.9043 - val_loss: 151.0354\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.3250 - val_loss: 138.8997\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.5604 - val_loss: 258.8684\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 355.2434 - val_loss: 154.8521\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.9856 - val_loss: 130.3748\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.1370 - val_loss: 146.5166\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.1809 - val_loss: 164.1439\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 199.0407 - val_loss: 133.9133\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 595.4741 - val_loss: 272.0836\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.6280 - val_loss: 192.1732\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 187.1493 - val_loss: 137.9799\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.3131 - val_loss: 146.0869\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.5031 - val_loss: 150.7205\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.7079 - val_loss: 161.4878\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 184.2387 - val_loss: 140.3918\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 192.2205 - val_loss: 140.6279\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 289.5133 - val_loss: 160.5285\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 211.7180 - val_loss: 356.3531\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 337.7168 - val_loss: 163.6592\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.2601 - val_loss: 183.3560\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.9724 - val_loss: 267.2725\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.0698 - val_loss: 134.7151\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.3734 - val_loss: 140.6117\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 228.8636 - val_loss: 148.3895\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.4902 - val_loss: 150.7305\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 324.5102 - val_loss: 287.5523\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.6714 - val_loss: 142.6616\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.5442 - val_loss: 205.5290\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.6163 - val_loss: 140.1005\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.7743 - val_loss: 135.9119\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 198.9566 - val_loss: 189.7705\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.0915 - val_loss: 140.6850\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 603.0768 - val_loss: 486.8967\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 274.7355 - val_loss: 189.1846\n",
      "Epoch 373/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.9210 - val_loss: 208.0573\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 232.8273 - val_loss: 209.7566\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.5470 - val_loss: 143.6630\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.6978 - val_loss: 130.6854\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.4948 - val_loss: 135.1798\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 295.4481 - val_loss: 205.5388\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.8156 - val_loss: 139.6686\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.5421 - val_loss: 146.4088\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 385.9387 - val_loss: 186.8325\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 228.9891 - val_loss: 213.8694\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 482.4431 - val_loss: 248.8541\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.4191 - val_loss: 137.7661\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.6995 - val_loss: 146.2833\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.3127 - val_loss: 129.2617\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.0511 - val_loss: 126.8822\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.4370 - val_loss: 202.4268\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 364.9328 - val_loss: 177.1387\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 320.3168 - val_loss: 225.6877\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 187.3270 - val_loss: 142.5187\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 191.8048 - val_loss: 142.7595\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 176.7964 - val_loss: 134.5931\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 190.4920 - val_loss: 130.6267\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 199.7755 - val_loss: 164.3160\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.2106 - val_loss: 148.8971\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.9456 - val_loss: 131.9918\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.5545 - val_loss: 293.5965\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.6659 - val_loss: 192.9378\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 205.1154 - val_loss: 244.6008\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.1900 - val_loss: 143.9719\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.8548 - val_loss: 133.8137\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.5496 - val_loss: 174.1156\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.1586 - val_loss: 141.3282\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.8679 - val_loss: 143.5094\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 300.5653 - val_loss: 345.1862\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.3965 - val_loss: 163.5800\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.9850 - val_loss: 147.0636\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.0213 - val_loss: 151.3278\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 175.8492 - val_loss: 122.5346\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 187.2573 - val_loss: 187.6621\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 199.7283 - val_loss: 135.3138\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.4489 - val_loss: 135.1377\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.5280 - val_loss: 237.3280\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 283.0157 - val_loss: 150.1424\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 220.4170 - val_loss: 197.7683\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.5977 - val_loss: 140.2885\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.4275 - val_loss: 244.1522\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.9073 - val_loss: 615.2273\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.6005 - val_loss: 133.0763\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.1717 - val_loss: 132.1737\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.0190 - val_loss: 138.5022\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.4166 - val_loss: 162.5488\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 240.7128 - val_loss: 177.0985\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.9663 - val_loss: 156.2895\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 288.8605 - val_loss: 161.5769\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.9555 - val_loss: 127.9628\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.1061 - val_loss: 129.7831\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.5077 - val_loss: 138.2017\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 216.3431 - val_loss: 364.6159\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.3257 - val_loss: 128.7121\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.9737 - val_loss: 129.6064\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 241.7870 - val_loss: 528.4672\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.5354 - val_loss: 639.2762\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.8778 - val_loss: 128.7280\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.5568 - val_loss: 124.9238\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.4618 - val_loss: 138.0260\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.0158 - val_loss: 127.5770\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.8074 - val_loss: 200.2788\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.1481 - val_loss: 201.2944\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.4054 - val_loss: 126.1483\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.7372 - val_loss: 196.8807\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 180.2463 - val_loss: 181.8063\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.5043 - val_loss: 128.7675\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.4074 - val_loss: 124.5359\n",
      "Epoch 446/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.5364 - val_loss: 320.8211\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 285.5534 - val_loss: 381.3063\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 191.6256 - val_loss: 249.2794\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 210.2146 - val_loss: 166.8448\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 234.4359 - val_loss: 208.7511\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.5133 - val_loss: 147.2657\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.0033 - val_loss: 292.1109\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 271.1853 - val_loss: 198.3349\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.7946 - val_loss: 161.8978\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 277.9216 - val_loss: 842.7547\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 206.3455 - val_loss: 127.9777\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.2570 - val_loss: 126.4597\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.7261 - val_loss: 142.2576\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.5395 - val_loss: 133.3785\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 188.9045 - val_loss: 140.2741\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 185.3329 - val_loss: 131.9198\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 178.1788 - val_loss: 168.7153\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 217.1874 - val_loss: 141.2732\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 398.5675 - val_loss: 191.8354\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.4986 - val_loss: 131.2039\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.5977 - val_loss: 135.1584\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.8759 - val_loss: 129.6758\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.6203 - val_loss: 180.9422\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.4489 - val_loss: 127.2349\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.9334 - val_loss: 572.4838\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.9411 - val_loss: 134.8985\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.2920 - val_loss: 203.9494\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.6131 - val_loss: 131.8167\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.4125 - val_loss: 151.2886\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.3552 - val_loss: 128.2300\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.7758 - val_loss: 226.9373\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.7480 - val_loss: 156.3660\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.7935 - val_loss: 308.2425\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.7467 - val_loss: 193.1390\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.3988 - val_loss: 497.2392\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 263.1860 - val_loss: 149.8251\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 234.3369 - val_loss: 179.2366\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.9985 - val_loss: 138.0504\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.3747 - val_loss: 252.3364\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.4323 - val_loss: 131.5534\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.3560 - val_loss: 174.5711\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.5800 - val_loss: 126.4464\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 180.1368 - val_loss: 130.7271\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.2286 - val_loss: 124.7046\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.9127 - val_loss: 293.5110\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.8785 - val_loss: 169.6875\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.4630 - val_loss: 222.9716\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.3680 - val_loss: 292.1653\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 213.5068 - val_loss: 129.4724\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 191.6645 - val_loss: 123.3602\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.9060 - val_loss: 136.3838\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 392.3046 - val_loss: 134.6532\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.1554 - val_loss: 147.0572\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 174.0994 - val_loss: 139.4169\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.8314 - val_loss: 176.2550\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 217.3156 - val_loss: 141.6320\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.1264 - val_loss: 133.0611\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.8109 - val_loss: 166.9948\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.2481 - val_loss: 167.8841\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 526.1617 - val_loss: 190.5300\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.1587 - val_loss: 245.7399\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.0263 - val_loss: 174.2118\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 172.7517 - val_loss: 129.2732\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.9268 - val_loss: 147.5821\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9054 - val_loss: 217.5559\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 217.6232 - val_loss: 213.2694\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 282.7748 - val_loss: 223.4620\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 234.0285 - val_loss: 184.9962\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 208.8542 - val_loss: 142.2147\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 210.3829 - val_loss: 156.1053\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 187.4862 - val_loss: 123.4425\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.8321 - val_loss: 253.8893\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.8845 - val_loss: 226.1540\n",
      "Epoch 519/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.0340 - val_loss: 137.9862\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.2352 - val_loss: 130.7638\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 186.1291 - val_loss: 219.9556\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.6059 - val_loss: 228.6786\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 214.7841 - val_loss: 133.5649\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 265.6752 - val_loss: 519.1158\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 263.3320 - val_loss: 131.9595\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.2575 - val_loss: 147.9293\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.1340 - val_loss: 224.9844\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.4264 - val_loss: 386.5330\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 349.7909 - val_loss: 129.7271\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 183.4097 - val_loss: 126.5559\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 165.2733 - val_loss: 122.5145\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.5401 - val_loss: 174.1780\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 172.4428 - val_loss: 122.5013\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 208.6458 - val_loss: 317.0221\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 214.5861 - val_loss: 155.7150\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.3146 - val_loss: 320.0444\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 234.8670 - val_loss: 149.5306\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 199.5168 - val_loss: 189.9225\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 207.7971 - val_loss: 174.7967\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 229.6022 - val_loss: 247.2477\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 344.3779 - val_loss: 122.8501\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 164.2570 - val_loss: 130.2178\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.4743 - val_loss: 179.7523\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.3358 - val_loss: 144.0535\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 169.1202 - val_loss: 123.3118\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 231.1086 - val_loss: 265.9246\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 201.6009 - val_loss: 214.4286\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 172.7792 - val_loss: 119.5842\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 165.6879 - val_loss: 135.2358\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.5616 - val_loss: 120.8048\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 333.5277 - val_loss: 120.5455\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 210.0413 - val_loss: 143.5373\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 159.8017 - val_loss: 118.3434\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 170.1768 - val_loss: 122.4049\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 178.0618 - val_loss: 138.7763\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 166.6161 - val_loss: 119.0256\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.1625 - val_loss: 136.3581\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.4813 - val_loss: 169.6564\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.9634 - val_loss: 136.8010\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 508.7051 - val_loss: 163.9563\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.8523 - val_loss: 132.7806\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.5329 - val_loss: 130.7248\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.1136 - val_loss: 123.4060\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.8916 - val_loss: 123.2976\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.5366 - val_loss: 142.3822\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.7696 - val_loss: 180.6135\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.9647 - val_loss: 153.3046\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 376.5422 - val_loss: 136.9229\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.0266 - val_loss: 146.6880\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 267.9968 - val_loss: 136.7145\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.7622 - val_loss: 144.2832\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.5642 - val_loss: 133.9623\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.2972 - val_loss: 198.3419\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.3211 - val_loss: 137.6773\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.5753 - val_loss: 125.3263\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 200.1516 - val_loss: 135.5621\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.0748 - val_loss: 311.5078\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.8473 - val_loss: 128.5870\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 210.2189 - val_loss: 129.1281\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 179.7696 - val_loss: 162.6398\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 379.5982 - val_loss: 166.2892\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.9011 - val_loss: 216.3624\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 213.6757 - val_loss: 145.7852\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 169.0155 - val_loss: 165.2265\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.5641 - val_loss: 128.9139\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.3830 - val_loss: 212.2207\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.8359 - val_loss: 208.3260\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 271.1538 - val_loss: 243.7484\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 249.8572 - val_loss: 125.8579\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6340 - val_loss: 133.8937\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.4588 - val_loss: 138.2336\n",
      "Epoch 592/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 252.5725 - val_loss: 131.3892\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.8763 - val_loss: 144.9197\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.4475 - val_loss: 140.8469\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 220.6121 - val_loss: 162.9537\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.5105 - val_loss: 122.3730\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 182.9848 - val_loss: 283.7127\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 555.5127 - val_loss: 202.0653\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 231.2796 - val_loss: 163.7792\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 164.0851 - val_loss: 134.0475\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.3613 - val_loss: 137.8179\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.5772 - val_loss: 170.8716\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.2292 - val_loss: 128.1206\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.8334 - val_loss: 148.0748\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.7982 - val_loss: 165.6891\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.4459 - val_loss: 126.6490\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.1797 - val_loss: 132.1838\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.0564 - val_loss: 166.7787\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.4219 - val_loss: 132.4601\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.1202 - val_loss: 128.1614\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.0324 - val_loss: 134.2113\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.4602 - val_loss: 134.3997\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.1187 - val_loss: 137.9255\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.0399 - val_loss: 337.2301\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 442.2692 - val_loss: 191.3410\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.6713 - val_loss: 126.0261\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.5308 - val_loss: 188.0017\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 185.4214 - val_loss: 129.4675\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6789 - val_loss: 233.2863\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.0988 - val_loss: 127.5230\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 278.1390 - val_loss: 449.3033\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.4013 - val_loss: 130.6085\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.6102 - val_loss: 150.3144\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.3966 - val_loss: 135.0992\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.7367 - val_loss: 137.5793\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.0373 - val_loss: 871.0054\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.0552 - val_loss: 156.0690\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.4909 - val_loss: 149.2514\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.5696 - val_loss: 279.5383\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.6158 - val_loss: 227.5021\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.9935 - val_loss: 140.8395\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.5185 - val_loss: 184.6903\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 270.0847 - val_loss: 141.2897\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.4376 - val_loss: 137.9471\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.4027 - val_loss: 134.4818\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.1872 - val_loss: 123.0865\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.8551 - val_loss: 235.7738\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 273.1124 - val_loss: 126.4663\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.3230 - val_loss: 160.1057\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.7745 - val_loss: 121.1599\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.9916 - val_loss: 122.0939\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 324.0692 - val_loss: 138.4529\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.4777 - val_loss: 161.3338\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.7160 - val_loss: 168.0576\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.6824 - val_loss: 123.6836\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8054 - val_loss: 172.0950\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.2125 - val_loss: 139.0552\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 289.6415 - val_loss: 161.6242\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.6134 - val_loss: 127.5942\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.7558 - val_loss: 135.4792\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 239.7223 - val_loss: 125.2371\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 211.7757 - val_loss: 325.4349\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.7503 - val_loss: 125.1307\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.4732 - val_loss: 130.9699\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.2533 - val_loss: 158.0584\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.9349 - val_loss: 131.2321\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6231 - val_loss: 170.3410\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.6526 - val_loss: 246.1127\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 340.8795 - val_loss: 170.7955\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.0000 - val_loss: 155.9251\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 162.5629 - val_loss: 137.6415\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.0498 - val_loss: 203.5676\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 180.5814 - val_loss: 217.6948\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1880 - val_loss: 122.6755\n",
      "Epoch 665/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 162.1967 - val_loss: 118.2775\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 167.2212 - val_loss: 369.2979\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 163.0948 - val_loss: 124.8654\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 194.2315 - val_loss: 156.6032\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 182.4841 - val_loss: 141.3878\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 410.1742 - val_loss: 154.4571\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 217.3322 - val_loss: 136.1131\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.7363 - val_loss: 146.3817\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.0021 - val_loss: 130.5032\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.2635 - val_loss: 233.9594\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.1543 - val_loss: 126.8719\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.9599 - val_loss: 186.7186\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.2782 - val_loss: 152.4351\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.7537 - val_loss: 547.1281\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 211.1312 - val_loss: 122.2905\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 183.4001 - val_loss: 158.6028\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 180.3470 - val_loss: 126.2843\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.5352 - val_loss: 120.3652\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.7153 - val_loss: 150.0456\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.8073 - val_loss: 128.1941\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8945 - val_loss: 129.3397\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.8071 - val_loss: 125.7634\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.3111 - val_loss: 130.0426\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.8368 - val_loss: 229.7457\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8526 - val_loss: 131.2769\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.4930 - val_loss: 129.2033\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.8104 - val_loss: 128.6980\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.2752 - val_loss: 125.5326\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9243 - val_loss: 136.4962\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.9575 - val_loss: 215.4824\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.6482 - val_loss: 133.2250\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.6893 - val_loss: 156.8182\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.3891 - val_loss: 167.7498\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.3547 - val_loss: 215.0187\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.1782 - val_loss: 135.3741\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.4251 - val_loss: 130.4013\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.0631 - val_loss: 155.6784\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.9075 - val_loss: 143.7602\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.5580 - val_loss: 458.4509\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.9215 - val_loss: 125.3686\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.9060 - val_loss: 131.6964\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.6806 - val_loss: 163.4658\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1872 - val_loss: 143.4847\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.5597 - val_loss: 193.3484\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.3325 - val_loss: 133.2715\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 200.5319 - val_loss: 131.1109\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.7421 - val_loss: 120.1276\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.0429 - val_loss: 131.7457\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.6189 - val_loss: 136.9989\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.5487 - val_loss: 131.2581\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.5391 - val_loss: 145.6641\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3539 - val_loss: 124.1294\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.3385 - val_loss: 206.2917\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.7981 - val_loss: 234.8484\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 299.5811 - val_loss: 143.1408\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.0308 - val_loss: 125.1992\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.4819 - val_loss: 116.5383\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.0849 - val_loss: 177.2338\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.4369 - val_loss: 120.0769\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.3062 - val_loss: 236.0559\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.1464 - val_loss: 129.7401\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.4418 - val_loss: 117.2870\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 259.0235 - val_loss: 445.2052\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.0037 - val_loss: 163.4951\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.7576 - val_loss: 121.5494\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.2353 - val_loss: 219.0102\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3216 - val_loss: 169.5535\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3583 - val_loss: 123.7869\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.3629 - val_loss: 122.1209\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.8561 - val_loss: 178.4505\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.5907 - val_loss: 126.8796\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.9103 - val_loss: 126.7538\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 157.0502 - val_loss: 151.3873\n",
      "Epoch 738/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 66us/step - loss: 167.4286 - val_loss: 186.9778\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 169.9338 - val_loss: 134.0924\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8446 - val_loss: 137.4549\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.8589 - val_loss: 133.6355\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.5799 - val_loss: 156.3858\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.2596 - val_loss: 125.6007\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.8023 - val_loss: 208.9332\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.8697 - val_loss: 119.3265\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.3237 - val_loss: 125.4273\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2120 - val_loss: 148.6716\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.8876 - val_loss: 118.9930\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.2333 - val_loss: 157.2790\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.9785 - val_loss: 159.3753\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.1427 - val_loss: 142.0202\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.9632 - val_loss: 131.7729\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.5867 - val_loss: 242.2680\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.2922 - val_loss: 146.4321\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.3678 - val_loss: 157.4516\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.6626 - val_loss: 147.4689\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.9439 - val_loss: 121.4917\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.3801 - val_loss: 117.5677\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2356 - val_loss: 126.5267\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.8604 - val_loss: 211.2457\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7804 - val_loss: 118.7488\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.4349 - val_loss: 499.5507\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.5362 - val_loss: 135.8463\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2747 - val_loss: 163.5220\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.2295 - val_loss: 149.8054\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0682 - val_loss: 133.3149\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1322 - val_loss: 167.0105\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.5927 - val_loss: 143.1839\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.6310 - val_loss: 143.0022\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.8381 - val_loss: 229.3808\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.4313 - val_loss: 127.4243\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.5013 - val_loss: 140.9861\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.1102 - val_loss: 120.4778\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 233.1913 - val_loss: 179.8765\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 156.8925 - val_loss: 165.0804\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 224.9201 - val_loss: 305.4019\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.7683 - val_loss: 123.4501\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.3644 - val_loss: 186.7968\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.1370 - val_loss: 175.7331\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3585 - val_loss: 152.2094\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.3643 - val_loss: 250.2913\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 305.0170 - val_loss: 159.3161\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.5105 - val_loss: 123.4954\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.9426 - val_loss: 123.4034\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2824 - val_loss: 133.0821\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.8007 - val_loss: 142.5804\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6171 - val_loss: 120.3811\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.5667 - val_loss: 142.9862\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 200.1426 - val_loss: 145.3053\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2757 - val_loss: 164.7946\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.5074 - val_loss: 125.3755\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.9983 - val_loss: 158.2490\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.4203 - val_loss: 129.6306\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 263.9177 - val_loss: 372.1624\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.7041 - val_loss: 153.9117\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.0261 - val_loss: 126.4241\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 268.7136 - val_loss: 131.9250\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.2868 - val_loss: 162.0278\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.6744 - val_loss: 148.3331\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5293 - val_loss: 123.3063\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0629 - val_loss: 131.4788\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.8868 - val_loss: 188.8633\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1564 - val_loss: 148.7852\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0288 - val_loss: 170.4712\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.8445 - val_loss: 184.8421\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.5196 - val_loss: 141.3784\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 197.8508 - val_loss: 126.9290\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 166.8106 - val_loss: 140.3417\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 334.3659 - val_loss: 146.7349\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.0613 - val_loss: 168.2395\n",
      "Epoch 811/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.0443 - val_loss: 124.6865\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.8251 - val_loss: 158.9345\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.4426 - val_loss: 212.0905\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.4579 - val_loss: 127.8199\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.6945 - val_loss: 675.7751\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.8006 - val_loss: 132.6185\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.4254 - val_loss: 130.7310\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.9838 - val_loss: 125.5245\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.5823 - val_loss: 146.8914\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2161 - val_loss: 177.8195\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.4702 - val_loss: 132.5905\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 148.3770 - val_loss: 116.2453\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8672 - val_loss: 118.9301\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8430 - val_loss: 116.7973\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.2286 - val_loss: 141.7067\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 185.8516 - val_loss: 364.1869\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 781.6771 - val_loss: 222.9422\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 276.3108 - val_loss: 178.8989\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 236.1139 - val_loss: 187.8530\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.3813 - val_loss: 499.0804\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.1579 - val_loss: 150.6745\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.8070 - val_loss: 149.3587\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 220.7960 - val_loss: 270.5811\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.6127 - val_loss: 159.7924\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 202.1395 - val_loss: 214.2614\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.0344 - val_loss: 186.5044\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.1526 - val_loss: 173.7584\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 234.0719 - val_loss: 212.1959\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.4475 - val_loss: 164.0769\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.0409 - val_loss: 151.3732\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.3526 - val_loss: 141.5152\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.4427 - val_loss: 138.4017\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 204.9897 - val_loss: 139.1615\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.1034 - val_loss: 184.1972\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.2730 - val_loss: 222.4066\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.0339 - val_loss: 143.6382\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.8922 - val_loss: 190.2242\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.8902 - val_loss: 134.9005\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.4684 - val_loss: 123.8648\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.4601 - val_loss: 224.6681\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.6015 - val_loss: 169.7809\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.6469 - val_loss: 139.8597\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.0988 - val_loss: 158.2925\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.2672 - val_loss: 243.9493\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2823 - val_loss: 144.6437\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.8372 - val_loss: 150.6524\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.2678 - val_loss: 168.5952\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.8500 - val_loss: 141.1957\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 180.4394 - val_loss: 173.6667\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.5185 - val_loss: 136.8273\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.8577 - val_loss: 123.5464\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.8758 - val_loss: 150.5526\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.6376 - val_loss: 141.3549\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.4208 - val_loss: 125.7915\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.5772 - val_loss: 121.7538\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2219 - val_loss: 165.5754\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.1084 - val_loss: 125.3220\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.0961 - val_loss: 144.0950\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 179.4594 - val_loss: 250.5472\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.1059 - val_loss: 137.1354\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.5977 - val_loss: 149.5381\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.9107 - val_loss: 119.9725\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.0874 - val_loss: 131.8258\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.5337 - val_loss: 168.2054\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.6000 - val_loss: 116.6520\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4333 - val_loss: 197.7326\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 181.8479 - val_loss: 154.1653\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 180.7271 - val_loss: 131.5405\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 174.6054 - val_loss: 140.6017\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.4890 - val_loss: 165.8037\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.3174 - val_loss: 124.4118\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.8383 - val_loss: 136.8987\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.1911 - val_loss: 155.2622\n",
      "Epoch 884/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.5371 - val_loss: 126.4058\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.4092 - val_loss: 158.5613\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.4379 - val_loss: 196.7340\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.4903 - val_loss: 220.8414\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.9589 - val_loss: 125.3534\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.3010 - val_loss: 150.7808\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.3207 - val_loss: 130.8360\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.6559 - val_loss: 148.3460\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.5469 - val_loss: 156.2598\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.5100 - val_loss: 139.8421\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.2244 - val_loss: 134.0834\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.2389 - val_loss: 178.8890\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 305.7312 - val_loss: 165.2079\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.7133 - val_loss: 185.0320\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.2229 - val_loss: 146.8316\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.6144 - val_loss: 146.1331\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.1556 - val_loss: 147.9378\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.2473 - val_loss: 133.8858\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.4148 - val_loss: 142.6137\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.6034 - val_loss: 123.6190\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.3168 - val_loss: 126.9245\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 188.1757 - val_loss: 137.4390\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.1700 - val_loss: 132.1892\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.8440 - val_loss: 138.8075\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.6847 - val_loss: 156.7076\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.5883 - val_loss: 128.3927\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.3402 - val_loss: 135.5498\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.5304 - val_loss: 121.8415\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.3997 - val_loss: 134.3326\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.1901 - val_loss: 126.4599\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 181.8900 - val_loss: 129.2378\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.6733 - val_loss: 166.7075\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 226.9320 - val_loss: 131.2653\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.4253 - val_loss: 125.5646\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 282.7004 - val_loss: 125.3059\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.8280 - val_loss: 136.0776\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.5464 - val_loss: 129.6018\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.3245 - val_loss: 130.7223\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8375 - val_loss: 128.1867\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.1687 - val_loss: 155.7993\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.5609 - val_loss: 138.1016\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.8100 - val_loss: 131.1876\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.6501 - val_loss: 123.7658\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.3782 - val_loss: 150.2205\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.0106 - val_loss: 175.0153\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.0645 - val_loss: 144.2369\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.8415 - val_loss: 234.4376\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.0479 - val_loss: 121.4532\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.2909 - val_loss: 279.9396\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.5316 - val_loss: 131.5437\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.1528 - val_loss: 132.1810\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 166.8788 - val_loss: 122.3780\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.1428 - val_loss: 141.1812\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.3494 - val_loss: 130.5539\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.7660 - val_loss: 256.4836\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 228.6634 - val_loss: 137.6474\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 205.8141 - val_loss: 125.0294\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.5529 - val_loss: 139.6041\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 161.5374 - val_loss: 172.1584\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.7949 - val_loss: 167.2140\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9469 - val_loss: 124.9091\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.8160 - val_loss: 135.7941\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.6991 - val_loss: 122.8119\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 188.4346 - val_loss: 133.0622\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.4118 - val_loss: 208.9245\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 165.1678 - val_loss: 117.1220\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.3298 - val_loss: 133.9125\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.9673 - val_loss: 403.2557\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.8404 - val_loss: 149.4516\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.1717 - val_loss: 146.8146\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.5661 - val_loss: 145.7888\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.0904 - val_loss: 131.4046\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.9088 - val_loss: 123.2366\n",
      "Epoch 957/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.5807 - val_loss: 129.2850\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.3946 - val_loss: 131.4290\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6934 - val_loss: 133.7167\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.8449 - val_loss: 121.1683\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.4190 - val_loss: 118.3414\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7053 - val_loss: 187.4006\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.6397 - val_loss: 125.2599\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 164.3490 - val_loss: 159.7301\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 174.6779 - val_loss: 125.8229\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.1538 - val_loss: 117.7843\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3316 - val_loss: 145.5069\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.8378 - val_loss: 300.7345\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.7916 - val_loss: 123.9380\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.1170 - val_loss: 122.1035\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.0223 - val_loss: 158.1249\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.8594 - val_loss: 273.6029\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.5150 - val_loss: 127.0233\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.3297 - val_loss: 132.6471\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 219.0851 - val_loss: 134.1597\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.8846 - val_loss: 121.7137\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.6943 - val_loss: 136.9035\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.7067 - val_loss: 121.2392\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2495 - val_loss: 121.3865\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.9019 - val_loss: 201.8755\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 149.5352 - val_loss: 122.5806\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.5100 - val_loss: 192.7018\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.2957 - val_loss: 125.0666\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.0760 - val_loss: 252.9631\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.5167 - val_loss: 211.1110\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.8957 - val_loss: 119.5855\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.6446 - val_loss: 171.3758\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.0798 - val_loss: 139.1992\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6626 - val_loss: 130.3264\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.1057 - val_loss: 119.1628\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8399 - val_loss: 117.4920\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.8628 - val_loss: 156.7810\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.8368 - val_loss: 133.4557\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1131 - val_loss: 142.4426\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.8000 - val_loss: 121.4662\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.2021 - val_loss: 157.7621\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 163.3446 - val_loss: 136.3462\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.4884 - val_loss: 133.1042\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2117 - val_loss: 123.8500\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.4266 - val_loss: 193.9100\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 314.1931 - val_loss: 122.5181\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.4074 - val_loss: 272.5206\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.4606 - val_loss: 177.7570\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.5112 - val_loss: 126.4812\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 158.6062 - val_loss: 127.6437\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 154.8385 - val_loss: 129.1245\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.7000 - val_loss: 142.0209\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.9709 - val_loss: 136.8056\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.7101 - val_loss: 205.2224\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.9489 - val_loss: 135.6233\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.0892 - val_loss: 167.5636\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.8560 - val_loss: 126.4772\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.9339 - val_loss: 126.7629\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.0345 - val_loss: 114.6020\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4050 - val_loss: 206.9693\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.6673 - val_loss: 133.3252\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 156.8750 - val_loss: 118.9575\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 164.8177 - val_loss: 117.3222\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 175.7705 - val_loss: 140.9580\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.6709 - val_loss: 129.1569\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 162.4681 - val_loss: 158.6014\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3645 - val_loss: 124.8643\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3593 - val_loss: 119.0354\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9852 - val_loss: 116.1162\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.7919 - val_loss: 309.1425\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.8079 - val_loss: 201.3429\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.6078 - val_loss: 139.2638\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.9062 - val_loss: 134.5983\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.8553 - val_loss: 139.0373\n",
      "Epoch 1030/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.8784 - val_loss: 194.3400\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.7640 - val_loss: 144.8856\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.0888 - val_loss: 129.9161\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.3395 - val_loss: 136.6157\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.2013 - val_loss: 359.6938\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 171.1440 - val_loss: 119.2723\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4087 - val_loss: 175.3820\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6145 - val_loss: 118.2817\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.9687 - val_loss: 128.6502\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.3313 - val_loss: 151.7221\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.3501 - val_loss: 147.2699\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.7913 - val_loss: 160.5164\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.6310 - val_loss: 188.6851\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.0276 - val_loss: 119.1185\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.7637 - val_loss: 168.4007\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.4596 - val_loss: 124.1127\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 154.2193 - val_loss: 127.3694\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.1325 - val_loss: 115.1070\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.5665 - val_loss: 127.9280\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.7923 - val_loss: 121.4546\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.7096 - val_loss: 115.3007\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.1299 - val_loss: 119.0571\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.4166 - val_loss: 174.2639\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.2751 - val_loss: 132.1787\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.5354 - val_loss: 146.5124\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.9434 - val_loss: 272.9650\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.0521 - val_loss: 118.5974\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6925 - val_loss: 173.5569\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1901 - val_loss: 124.1244\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.4579 - val_loss: 174.9131\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.7766 - val_loss: 149.5158\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.4340 - val_loss: 118.1099\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4738 - val_loss: 128.6193\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.9362 - val_loss: 206.6359\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.9075 - val_loss: 615.0624\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 278.8778 - val_loss: 333.1401\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.3030 - val_loss: 124.4059\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2030 - val_loss: 224.7696\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.0816 - val_loss: 115.1060\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.0299 - val_loss: 127.8832\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.8162 - val_loss: 121.1855\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1102 - val_loss: 139.1202\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.0892 - val_loss: 212.8855\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6053 - val_loss: 157.6035\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.8887 - val_loss: 123.2767\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 168.2403 - val_loss: 120.5636\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 160.9721 - val_loss: 237.7574\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.1029 - val_loss: 138.8343\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.2869 - val_loss: 154.5568\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.6846 - val_loss: 165.7170\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.8683 - val_loss: 148.2027\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.9091 - val_loss: 124.5096\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.8889 - val_loss: 122.2642\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8554 - val_loss: 228.3606\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.1774 - val_loss: 189.5140\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.7282 - val_loss: 404.5131\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 166.2492 - val_loss: 115.1114\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 172.4294 - val_loss: 123.6605\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 149.2388 - val_loss: 142.7769\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.6922 - val_loss: 122.6373\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.0721 - val_loss: 130.8469\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.9458 - val_loss: 131.7031\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.6359 - val_loss: 235.7934\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0075 - val_loss: 189.2060\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6054 - val_loss: 117.4112\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9076 - val_loss: 139.8124\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.2645 - val_loss: 234.8954\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.1207 - val_loss: 124.8373\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.4654 - val_loss: 122.3523\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.6235 - val_loss: 131.0649\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.2624 - val_loss: 162.2622\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.3564 - val_loss: 133.5575\n",
      "Epoch 1102/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 170.3358 - val_loss: 114.1008\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1732 - val_loss: 125.2133\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.5754 - val_loss: 216.6546\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.1922 - val_loss: 122.2434\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.8184 - val_loss: 134.3858\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6865 - val_loss: 153.3998\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.6365 - val_loss: 126.9509\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7057 - val_loss: 119.9583\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8433 - val_loss: 125.2124\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1643 - val_loss: 144.6115\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 146.9158 - val_loss: 121.6969\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 166.2831 - val_loss: 114.0874\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 161.9729 - val_loss: 127.2150\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 158.3967 - val_loss: 124.8408\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2473 - val_loss: 145.9651\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 220.5505 - val_loss: 119.4341\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.4400 - val_loss: 115.9874\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5016 - val_loss: 120.6936\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.4454 - val_loss: 130.3084\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.3287 - val_loss: 115.3036\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.3658 - val_loss: 120.7789\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.6280 - val_loss: 139.1157\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.1380 - val_loss: 222.4728\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9790 - val_loss: 164.2816\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.2653 - val_loss: 123.9376\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.9948 - val_loss: 120.9214\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.0694 - val_loss: 128.6436\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2199 - val_loss: 158.9987\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8113 - val_loss: 119.7460\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.3306 - val_loss: 119.3711\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.7535 - val_loss: 149.7102\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.5779 - val_loss: 134.4832\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.7283 - val_loss: 715.0586\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 391.3509 - val_loss: 140.2487\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.9202 - val_loss: 125.6369\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4360 - val_loss: 116.6105\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4123 - val_loss: 151.8154\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.4000 - val_loss: 141.1705\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.7442 - val_loss: 138.0923\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.4642 - val_loss: 118.1751\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8589 - val_loss: 118.9338\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.3013 - val_loss: 117.0611\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6646 - val_loss: 132.4446\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.8599 - val_loss: 117.1503\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.1064 - val_loss: 112.2725\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.7135 - val_loss: 140.1630\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.3984 - val_loss: 221.7124\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.4683 - val_loss: 117.0157\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 299.9119 - val_loss: 135.7052\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8242 - val_loss: 152.8350\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 200.7836 - val_loss: 119.5422\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.2079 - val_loss: 123.3455\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.1924 - val_loss: 133.1565\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 153.1578 - val_loss: 118.9769\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 145.8944 - val_loss: 139.8650\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 142.3790 - val_loss: 156.4649\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 263.1424 - val_loss: 120.2303\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.0501 - val_loss: 127.5141\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.1168 - val_loss: 116.1380\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7751 - val_loss: 122.3263\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.2743 - val_loss: 133.5486\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.2309 - val_loss: 111.9998\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.6817 - val_loss: 161.8369\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.8315 - val_loss: 168.4508\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7056 - val_loss: 122.0624\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.0963 - val_loss: 126.8380\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0718 - val_loss: 122.7932\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.1356 - val_loss: 116.1050\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5579 - val_loss: 190.6874\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.2367 - val_loss: 127.7891\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9200 - val_loss: 132.2792\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.1904 - val_loss: 136.2035\n",
      "Epoch 1174/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3047 - val_loss: 119.7079\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.0138 - val_loss: 127.9178\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.0073 - val_loss: 213.1877\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.7817 - val_loss: 142.8122\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.0572 - val_loss: 120.4091\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7102 - val_loss: 131.0320\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.9663 - val_loss: 249.8122\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.7800 - val_loss: 125.8416\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.4378 - val_loss: 131.1970\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0210 - val_loss: 135.0305\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 162.5580 - val_loss: 183.1585\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.0290 - val_loss: 118.9489\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.4564 - val_loss: 187.7827\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.2999 - val_loss: 117.2221\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.4220 - val_loss: 166.3737\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1742 - val_loss: 129.6920\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2697 - val_loss: 123.6435\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5946 - val_loss: 175.3479\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.2321 - val_loss: 116.9959\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.9680 - val_loss: 136.2668\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.5811 - val_loss: 224.5314\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 348.8247 - val_loss: 163.1642\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.6686 - val_loss: 128.5223\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.8629 - val_loss: 118.1986\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7288 - val_loss: 126.0116\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.7852 - val_loss: 150.0366\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.0355 - val_loss: 118.2915\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.4161 - val_loss: 117.0639\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.9506 - val_loss: 123.1217\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5011 - val_loss: 149.2387\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.6143 - val_loss: 133.7302\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9403 - val_loss: 130.9981\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.4000 - val_loss: 183.5086\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.5132 - val_loss: 115.2566\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1807 - val_loss: 124.8629\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.9485 - val_loss: 212.4118\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.6217 - val_loss: 142.9260\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.3148 - val_loss: 122.9158\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.7351 - val_loss: 118.5261\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.9030 - val_loss: 179.1793\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 160.8124 - val_loss: 141.7683\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.0331 - val_loss: 126.3792\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7455 - val_loss: 116.7874\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 150.7310 - val_loss: 153.5088\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.8526 - val_loss: 153.7406\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 175.9788 - val_loss: 145.6631\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1642 - val_loss: 114.6111\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 192.5802 - val_loss: 120.7983\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.2951 - val_loss: 198.2402\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3322 - val_loss: 122.3455\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.3478 - val_loss: 135.5214\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.6887 - val_loss: 227.8657\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.2553 - val_loss: 181.7060\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 232.9286 - val_loss: 187.3809\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 165.4976 - val_loss: 133.9727\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.6987 - val_loss: 127.5984\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.1861 - val_loss: 118.5950\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.6682 - val_loss: 138.8248\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.2272 - val_loss: 121.9449\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.1239 - val_loss: 137.1415\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 170.7825 - val_loss: 129.9983\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 159.5541 - val_loss: 119.7489\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 160.2312 - val_loss: 141.9960\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 153.6300 - val_loss: 120.1822\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.8040 - val_loss: 137.8018\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8412 - val_loss: 113.5549\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5148 - val_loss: 114.5304\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.5464 - val_loss: 113.8392\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8004 - val_loss: 123.5880\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 246.7688 - val_loss: 139.0744\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7191 - val_loss: 118.7181\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8901 - val_loss: 123.7123\n",
      "Epoch 1246/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1823 - val_loss: 121.4226\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1836 - val_loss: 114.9472\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.3752 - val_loss: 149.3840\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1110 - val_loss: 138.2003\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3557 - val_loss: 118.0236\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0591 - val_loss: 132.4691\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 254.0856 - val_loss: 1125.6518\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 275.3572 - val_loss: 132.3182\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1519 - val_loss: 135.0922\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0330 - val_loss: 122.1701\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1429 - val_loss: 160.1635\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.5864 - val_loss: 115.9392\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1046 - val_loss: 148.9872\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3311 - val_loss: 117.9456\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2565 - val_loss: 120.1061\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.6870 - val_loss: 139.5041\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2278 - val_loss: 141.0608\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 186.2871 - val_loss: 158.9437\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.6121 - val_loss: 199.2880\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2582 - val_loss: 118.7205\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.8031 - val_loss: 137.2979\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1196 - val_loss: 124.7176\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8627 - val_loss: 113.8675\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.9396 - val_loss: 118.3974\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8109 - val_loss: 119.7471\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 328.8876 - val_loss: 172.3528\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.1347 - val_loss: 151.9520\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2478 - val_loss: 138.9998\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.3220 - val_loss: 134.7910\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.2120 - val_loss: 137.1786\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.0606 - val_loss: 122.1593\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.1557 - val_loss: 169.7300\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 156.5920 - val_loss: 144.0357\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.1417 - val_loss: 148.1471\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.6331 - val_loss: 159.9485\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4340 - val_loss: 116.5756\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.0387 - val_loss: 134.8107\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9315 - val_loss: 119.8710\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.0348 - val_loss: 135.2408\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.9407 - val_loss: 120.6465\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8417 - val_loss: 139.5490\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8483 - val_loss: 140.8603\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1848 - val_loss: 115.0736\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.8332 - val_loss: 131.3636\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.3939 - val_loss: 117.1969\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.6277 - val_loss: 114.4725\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.9111 - val_loss: 134.7405\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8551 - val_loss: 145.2997\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 418.4821 - val_loss: 167.8313\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 153.4780 - val_loss: 148.5352\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 242.7041 - val_loss: 131.6284\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 176.6841 - val_loss: 142.0806\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2271 - val_loss: 114.7476\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 144.3461 - val_loss: 115.9495\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 165.7818 - val_loss: 247.5139\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 242.8698 - val_loss: 119.8992\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.3452 - val_loss: 132.2524\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0069 - val_loss: 123.2262\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4297 - val_loss: 121.3965\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 198.4747 - val_loss: 140.2380\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1235 - val_loss: 118.7869\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.5917 - val_loss: 121.6069\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5615 - val_loss: 147.0158\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6886 - val_loss: 130.8351\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.3703 - val_loss: 131.3159\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.8359 - val_loss: 153.1789\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.9743 - val_loss: 119.3845\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.7145 - val_loss: 121.3134\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.8632 - val_loss: 125.8607\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.3426 - val_loss: 138.9003\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 416.0798 - val_loss: 193.1479\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.3041 - val_loss: 114.0213\n",
      "Epoch 1318/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7904 - val_loss: 155.6348\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6487 - val_loss: 131.2515\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6817 - val_loss: 129.7993\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5531 - val_loss: 124.3966\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1707 - val_loss: 123.3243\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.7063 - val_loss: 144.1614\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3060 - val_loss: 124.4939\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7209 - val_loss: 146.0651\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3360 - val_loss: 130.9540\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.5100 - val_loss: 134.1263\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.0400 - val_loss: 132.6283\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.4220 - val_loss: 125.9288\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.5575 - val_loss: 137.2334\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5450 - val_loss: 139.8862\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.9142 - val_loss: 131.1978\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0834 - val_loss: 181.4418\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.9143 - val_loss: 126.7339\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.8284 - val_loss: 122.3808\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.4565 - val_loss: 161.1054\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.3490 - val_loss: 134.4863\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3773 - val_loss: 131.5889\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.6553 - val_loss: 118.3062\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1028 - val_loss: 119.2690\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4418 - val_loss: 132.3244\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6047 - val_loss: 117.9037\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6425 - val_loss: 158.4859\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.0249 - val_loss: 116.8644\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1026 - val_loss: 160.1770\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.1956 - val_loss: 136.1881\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.2338 - val_loss: 130.4221\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.1323 - val_loss: 123.7522\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9182 - val_loss: 131.1623\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.3319 - val_loss: 121.1697\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8452 - val_loss: 122.4627\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9763 - val_loss: 120.1668\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 182.2263 - val_loss: 122.0580\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6373 - val_loss: 128.2950\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7472 - val_loss: 295.7748\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.3743 - val_loss: 137.1637\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6454 - val_loss: 117.5677\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.4922 - val_loss: 117.7610\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.1545 - val_loss: 152.6959\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7889 - val_loss: 116.6828\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.6611 - val_loss: 145.0814\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8965 - val_loss: 120.9010\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.0746 - val_loss: 118.6649\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.3661 - val_loss: 210.4550\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 162.4440 - val_loss: 130.0461\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 162.4794 - val_loss: 113.9410\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 144.4922 - val_loss: 113.6760\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 139.0701 - val_loss: 127.9029\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.6193 - val_loss: 170.5771\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.1096 - val_loss: 116.2382\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5487 - val_loss: 128.7224\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6645 - val_loss: 114.9896\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6813 - val_loss: 137.7580\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9879 - val_loss: 141.1733\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3168 - val_loss: 160.6935\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.7833 - val_loss: 117.3462\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.9465 - val_loss: 116.6488\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7786 - val_loss: 126.3552\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.1502 - val_loss: 123.2915\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.6976 - val_loss: 131.3192\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 259.5990 - val_loss: 130.8724\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.5793 - val_loss: 132.9317\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.9088 - val_loss: 112.9891\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.7319 - val_loss: 128.8584\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.9978 - val_loss: 129.7527\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.8243 - val_loss: 135.5525\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.1512 - val_loss: 121.3739\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5341 - val_loss: 115.1585\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1488 - val_loss: 118.2962\n",
      "Epoch 1390/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4611 - val_loss: 165.4280\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 151.2977 - val_loss: 111.1148\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2684 - val_loss: 121.7596\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 141.7000 - val_loss: 174.5418\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.7823 - val_loss: 168.4310\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.8163 - val_loss: 124.1198\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.3646 - val_loss: 127.4481\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.9329 - val_loss: 124.6745\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0134 - val_loss: 116.1375\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1293 - val_loss: 130.3842\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.2311 - val_loss: 146.2698\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6453 - val_loss: 127.0823\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.2992 - val_loss: 118.5397\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1615 - val_loss: 139.6653\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3226 - val_loss: 120.2561\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9244 - val_loss: 122.7614\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6755 - val_loss: 126.2070\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.9790 - val_loss: 115.4907\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.8694 - val_loss: 162.6599\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4910 - val_loss: 136.1236\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.2051 - val_loss: 148.1425\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1343 - val_loss: 124.0867\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7034 - val_loss: 132.7828\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.4828 - val_loss: 119.0632\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2388 - val_loss: 189.1196\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0309 - val_loss: 148.3700\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2242 - val_loss: 140.2775\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.1039 - val_loss: 118.7091\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.7988 - val_loss: 266.0789\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.9230 - val_loss: 113.4337\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.4570 - val_loss: 134.0695\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 247.2205 - val_loss: 165.3755\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.5094 - val_loss: 114.0789\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.7584 - val_loss: 186.2389\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5459 - val_loss: 113.4116\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9641 - val_loss: 120.9765\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6901 - val_loss: 194.8534\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1335 - val_loss: 128.9026\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0466 - val_loss: 136.2062\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6339 - val_loss: 138.2468\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.7382 - val_loss: 159.8938\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 243.7133 - val_loss: 131.2052\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.9437 - val_loss: 125.3410\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.0339 - val_loss: 115.0884\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9139 - val_loss: 205.0668\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 160.2403 - val_loss: 129.2717\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 142.2434 - val_loss: 128.0467\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 159.2074 - val_loss: 117.1398\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.8617 - val_loss: 117.8324\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.5692 - val_loss: 146.7023\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.3806 - val_loss: 206.0695\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.6980 - val_loss: 160.6526\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.9165 - val_loss: 111.7493\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.8851 - val_loss: 124.4977\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5233 - val_loss: 128.4449\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6550 - val_loss: 135.6634\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9153 - val_loss: 112.5785\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8351 - val_loss: 114.9826\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.6427 - val_loss: 228.1610\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.5458 - val_loss: 207.2121\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 282.6245 - val_loss: 228.4290\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0977 - val_loss: 135.7583\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0384 - val_loss: 113.2271\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.9098 - val_loss: 141.6476\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4210 - val_loss: 155.8856\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1905 - val_loss: 116.5195\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7229 - val_loss: 157.9087\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8853 - val_loss: 120.0398\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.8273 - val_loss: 129.5101\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.4019 - val_loss: 112.4467\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7668 - val_loss: 113.8038\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.7057 - val_loss: 193.6770\n",
      "Epoch 1462/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1765 - val_loss: 122.3373\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.5138 - val_loss: 155.0140\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0595 - val_loss: 135.7279\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1780 - val_loss: 169.8293\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 222.2413 - val_loss: 144.2173\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.0297 - val_loss: 117.2837\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7608 - val_loss: 114.4779\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.3696 - val_loss: 120.6306\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.7560 - val_loss: 181.5722\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5146 - val_loss: 134.4996\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.7859 - val_loss: 429.0844\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.1621 - val_loss: 135.5017\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1422 - val_loss: 198.7167\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.7922 - val_loss: 119.0900\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 265.1178 - val_loss: 128.8285\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.6572 - val_loss: 140.1996\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.9568 - val_loss: 124.3862\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9543 - val_loss: 117.2731\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9944 - val_loss: 192.3392\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.8821 - val_loss: 136.3977\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.9940 - val_loss: 128.8975\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6751 - val_loss: 119.7080\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.0387 - val_loss: 124.2942\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.2659 - val_loss: 136.6567\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.8946 - val_loss: 122.7451\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.6451 - val_loss: 210.2184\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.0753 - val_loss: 149.3967\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.6088 - val_loss: 141.0555\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.1641 - val_loss: 149.5286\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.5082 - val_loss: 123.3627\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 189.1128 - val_loss: 120.0953\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 146.5508 - val_loss: 121.1201\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 229.7232 - val_loss: 133.9855\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 208.9686 - val_loss: 119.5061\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1477 - val_loss: 121.6015\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0605 - val_loss: 112.9008\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1502 - val_loss: 114.0131\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.4519 - val_loss: 224.5312\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9610 - val_loss: 131.9012\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.9044 - val_loss: 114.1775\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.8794 - val_loss: 173.1563\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.2012 - val_loss: 120.0259\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 241.4256 - val_loss: 137.3803\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 170.9484 - val_loss: 123.3901\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 141.7667 - val_loss: 126.2365\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.5029 - val_loss: 134.9920\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 176.6671 - val_loss: 132.4879\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.0336 - val_loss: 118.9675\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.9825 - val_loss: 142.9867\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.8425 - val_loss: 125.6675\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0067 - val_loss: 112.9705\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2446 - val_loss: 116.0352\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.3607 - val_loss: 115.9275\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5404 - val_loss: 127.5780\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0644 - val_loss: 162.2922\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.1665 - val_loss: 123.1509\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.9032 - val_loss: 112.7596\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.6418 - val_loss: 131.0639\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9062 - val_loss: 132.7007\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0773 - val_loss: 118.9411\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.8929 - val_loss: 154.7086\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0965 - val_loss: 144.3241\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5081 - val_loss: 164.4441\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.4057 - val_loss: 218.6887\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 213.9334 - val_loss: 114.8909\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0183 - val_loss: 194.4932\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3108 - val_loss: 125.0855\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4569 - val_loss: 151.5865\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.5484 - val_loss: 133.0102\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0986 - val_loss: 114.6470\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5795 - val_loss: 125.7106\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.9556 - val_loss: 111.6405\n",
      "Epoch 1534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4653 - val_loss: 123.8056\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.3250 - val_loss: 151.2468\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9790 - val_loss: 125.7641\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3515 - val_loss: 120.0343\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3057 - val_loss: 196.1629\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6465 - val_loss: 126.1826\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.5788 - val_loss: 120.4979\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2974 - val_loss: 134.9516\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7710 - val_loss: 131.8424\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.4044 - val_loss: 132.6460\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.7499 - val_loss: 130.6412\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 274.5663 - val_loss: 117.2946\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0536 - val_loss: 117.9656\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1859 - val_loss: 158.6456\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2478 - val_loss: 215.5906\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5665 - val_loss: 118.1025\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2977 - val_loss: 144.0099\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7922 - val_loss: 114.6207\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9406 - val_loss: 115.4084\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2487 - val_loss: 141.0792\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3779 - val_loss: 119.8095\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2426 - val_loss: 144.9415\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6290 - val_loss: 1160.9654\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.6287 - val_loss: 121.1278\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.4247 - val_loss: 119.8755\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.3982 - val_loss: 148.9183\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.1642 - val_loss: 118.3219\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.9311 - val_loss: 163.6512\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.4181 - val_loss: 160.2199\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.6186 - val_loss: 140.9858\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.0347 - val_loss: 117.1791\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.6529 - val_loss: 116.4190\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3535 - val_loss: 116.6461\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.5270 - val_loss: 115.0680\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3462 - val_loss: 118.0283\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4965 - val_loss: 120.3513\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7592 - val_loss: 134.5404\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9280 - val_loss: 131.8575\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.4228 - val_loss: 135.1871\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 292.8884 - val_loss: 410.5710\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.1673 - val_loss: 138.0353\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 154.2431 - val_loss: 139.5761\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 155.7510 - val_loss: 137.8606\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 196.5600 - val_loss: 157.2631\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 157.1085 - val_loss: 143.4740\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2950 - val_loss: 127.1911\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.2158 - val_loss: 138.7641\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.1881 - val_loss: 117.9158\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.9904 - val_loss: 115.2608\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3613 - val_loss: 131.6551\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4812 - val_loss: 135.9156\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 445.9178 - val_loss: 124.8137\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5398 - val_loss: 123.4381\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9870 - val_loss: 118.3492\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2728 - val_loss: 145.2609\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2129 - val_loss: 121.0850\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.6967 - val_loss: 122.3070\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 169.9396 - val_loss: 141.9914\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.3146 - val_loss: 159.8790\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7065 - val_loss: 177.0270\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.4392 - val_loss: 234.2038\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 355.4755 - val_loss: 126.6115\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1755 - val_loss: 122.8098\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.4059 - val_loss: 156.8134\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3383 - val_loss: 128.7699\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2756 - val_loss: 127.7238\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0743 - val_loss: 126.7883\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3822 - val_loss: 118.2662\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.7598 - val_loss: 130.6367\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.9091 - val_loss: 123.8683\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.9635 - val_loss: 117.6415\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1991 - val_loss: 124.6138\n",
      "Epoch 1606/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1748 - val_loss: 172.5766\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.5196 - val_loss: 170.1205\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9230 - val_loss: 123.4966\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.8353 - val_loss: 132.9714\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.3956 - val_loss: 126.2624\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4836 - val_loss: 116.7290\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1104 - val_loss: 116.1339\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4388 - val_loss: 147.7832\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.4829 - val_loss: 134.3832\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7734 - val_loss: 139.6347\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6756 - val_loss: 133.3463\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4946 - val_loss: 119.8519\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1664 - val_loss: 158.5613\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.5167 - val_loss: 141.3310\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3751 - val_loss: 136.3400\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.3886 - val_loss: 149.3401\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.7394 - val_loss: 138.6541\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.2253 - val_loss: 116.9991\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.2376 - val_loss: 127.7166\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3591 - val_loss: 125.8500\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.3687 - val_loss: 157.4986\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 154.1601 - val_loss: 147.0144\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6507 - val_loss: 138.5333\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.1801 - val_loss: 146.0792\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1684 - val_loss: 134.3768\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0884 - val_loss: 113.6307\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.3339 - val_loss: 116.1821\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.4162 - val_loss: 142.9812\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.2408 - val_loss: 153.0636\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4136 - val_loss: 400.4780\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 622.5246 - val_loss: 229.4863\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 255.3579 - val_loss: 392.1501\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 273.3245 - val_loss: 157.2381\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 284.5333 - val_loss: 190.6588\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 231.3645 - val_loss: 230.0631\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.5165 - val_loss: 147.1355\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.8246 - val_loss: 150.8947\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.1425 - val_loss: 148.6234\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 229.3971 - val_loss: 147.7700\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 205.5045 - val_loss: 227.3488\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 201.5003 - val_loss: 154.5837\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 215.5913 - val_loss: 149.1701\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 231.8596 - val_loss: 172.8380\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.4797 - val_loss: 158.4658\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.2146 - val_loss: 144.6060\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.4942 - val_loss: 152.0090\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.1711 - val_loss: 143.2361\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.6783 - val_loss: 133.5310\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.1195 - val_loss: 135.4669\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.1964 - val_loss: 181.2533\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.4126 - val_loss: 138.6950\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.0277 - val_loss: 145.9801\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.4712 - val_loss: 143.5236\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.7982 - val_loss: 138.8177\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.1101 - val_loss: 168.7660\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.0171 - val_loss: 271.8884\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.1616 - val_loss: 140.3959\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.7941 - val_loss: 136.8467\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.3315 - val_loss: 131.6881\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.6611 - val_loss: 167.7528\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.9137 - val_loss: 123.5767\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.2597 - val_loss: 310.6958\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.1220 - val_loss: 123.3473\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.4309 - val_loss: 130.0692\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 177.4799 - val_loss: 142.9052\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.6061 - val_loss: 171.7539\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 181.6836 - val_loss: 141.0479\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.2329 - val_loss: 129.4522\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.1390 - val_loss: 140.8549\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.6147 - val_loss: 127.6327\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.4451 - val_loss: 139.1488\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.0742 - val_loss: 135.7479\n",
      "Epoch 1678/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.7550 - val_loss: 152.6252\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 172.0928 - val_loss: 119.1843\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.2765 - val_loss: 130.9015\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.1991 - val_loss: 166.6170\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.5054 - val_loss: 124.3911\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.1938 - val_loss: 133.7547\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 241.2216 - val_loss: 123.7357\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 157.8334 - val_loss: 140.0890\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 166.5443 - val_loss: 119.4644\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.4915 - val_loss: 167.7110\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5002 - val_loss: 138.1009\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.1360 - val_loss: 138.7287\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6372 - val_loss: 188.9725\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.1884 - val_loss: 152.8616\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.3159 - val_loss: 125.8989\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.8881 - val_loss: 164.2767\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.5454 - val_loss: 142.9255\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.5959 - val_loss: 117.2005\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.6231 - val_loss: 118.7088\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.5232 - val_loss: 137.2861\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.9909 - val_loss: 160.1565\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.3520 - val_loss: 169.7426\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.2154 - val_loss: 120.1403\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.6955 - val_loss: 147.7445\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 170.1441 - val_loss: 121.8309\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.9569 - val_loss: 157.8381\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.9699 - val_loss: 159.7377\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.8323 - val_loss: 136.1260\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0020 - val_loss: 180.2674\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.6620 - val_loss: 115.1950\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.7266 - val_loss: 124.1433\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7328 - val_loss: 179.3759\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.5012 - val_loss: 134.4160\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.8808 - val_loss: 135.4638\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.3085 - val_loss: 181.6279\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1676 - val_loss: 182.9023\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.3446 - val_loss: 136.1867\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 166.5531 - val_loss: 126.4416\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 156.4871 - val_loss: 115.5800\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 172.5310 - val_loss: 118.6846\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 162.5934 - val_loss: 133.1218\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.8779 - val_loss: 130.8142\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.1915 - val_loss: 217.8071\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.6061 - val_loss: 208.3009\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.8400 - val_loss: 132.3113\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.5688 - val_loss: 150.4859\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.8737 - val_loss: 123.3456\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3860 - val_loss: 119.8112\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.3369 - val_loss: 132.2241\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2906 - val_loss: 119.7906\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.7573 - val_loss: 165.1032\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5420 - val_loss: 135.3379\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3430 - val_loss: 144.0118\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 166.0914 - val_loss: 124.7775\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.0278 - val_loss: 143.6765\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.9890 - val_loss: 131.8393\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7397 - val_loss: 131.2144\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6429 - val_loss: 119.7262\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.4180 - val_loss: 155.3288\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7128 - val_loss: 117.1540\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5719 - val_loss: 114.7602\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.9451 - val_loss: 134.1411\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.4203 - val_loss: 126.3008\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.6020 - val_loss: 129.5524\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.8032 - val_loss: 114.8096\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.9113 - val_loss: 192.2809\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.4667 - val_loss: 123.4579\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.8020 - val_loss: 128.1412\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4830 - val_loss: 150.4326\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.1763 - val_loss: 129.0720\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.8964 - val_loss: 118.3489\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.6464 - val_loss: 163.4076\n",
      "Epoch 1750/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.4757 - val_loss: 134.1227\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.4609 - val_loss: 134.5591\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4222 - val_loss: 121.4001\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.5016 - val_loss: 229.4198\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.4447 - val_loss: 126.5258\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6389 - val_loss: 116.7396\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1534 - val_loss: 118.7995\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.6197 - val_loss: 136.5985\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6082 - val_loss: 136.6630\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.1611 - val_loss: 146.1846\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.4985 - val_loss: 114.7896\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.8911 - val_loss: 205.5963\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3842 - val_loss: 219.5280\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.3192 - val_loss: 117.4995\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.6346 - val_loss: 119.0049\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6974 - val_loss: 216.4222\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.8845 - val_loss: 125.8899\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 155.4160 - val_loss: 180.8417\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.3641 - val_loss: 138.3408\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.3164 - val_loss: 135.3560\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.1537 - val_loss: 118.3528\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.1086 - val_loss: 133.3192\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.8832 - val_loss: 120.4824\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3193 - val_loss: 145.8117\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5596 - val_loss: 134.9965\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.3591 - val_loss: 130.8804\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9571 - val_loss: 155.8280\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.6197 - val_loss: 133.7489\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1589 - val_loss: 194.1170\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 153.7203 - val_loss: 133.6797\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 152.1690 - val_loss: 116.5736\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.7361 - val_loss: 214.5428\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3506 - val_loss: 170.4938\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2773 - val_loss: 145.5726\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 218.8946 - val_loss: 122.2025\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 149.5166 - val_loss: 123.1942\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.8617 - val_loss: 123.6496\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 149.8171 - val_loss: 115.6316\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.1166 - val_loss: 132.5958\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.1367 - val_loss: 128.1009\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.5492 - val_loss: 164.8898\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0673 - val_loss: 138.4609\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7287 - val_loss: 114.8177\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.1970 - val_loss: 118.3428\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3706 - val_loss: 117.3275\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5677 - val_loss: 124.4418\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3785 - val_loss: 125.5708\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9560 - val_loss: 123.4870\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.2038 - val_loss: 151.2765\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.4964 - val_loss: 128.9583\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.4372 - val_loss: 112.9041\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 153.6322 - val_loss: 134.6722\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.8932 - val_loss: 133.1573\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0453 - val_loss: 122.5298\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.0701 - val_loss: 119.2967\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0099 - val_loss: 116.5317\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.7884 - val_loss: 120.6860\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9539 - val_loss: 119.0258\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.0165 - val_loss: 170.4310\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7227 - val_loss: 144.5557\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.3947 - val_loss: 113.5748\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.9124 - val_loss: 125.5768\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2957 - val_loss: 125.8382\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.7862 - val_loss: 117.3099\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2153 - val_loss: 200.5310\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3272 - val_loss: 120.5826\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.8513 - val_loss: 159.9886\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.8517 - val_loss: 124.2617\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.1344 - val_loss: 176.9586\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.8296 - val_loss: 125.4038\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6192 - val_loss: 118.1447\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9539 - val_loss: 113.3810\n",
      "Epoch 1822/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7781 - val_loss: 119.7225\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7533 - val_loss: 134.9066\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7430 - val_loss: 124.5084\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.6375 - val_loss: 239.6921\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.9639 - val_loss: 119.4829\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.8545 - val_loss: 133.2205\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0680 - val_loss: 121.5887\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.8034 - val_loss: 121.4556\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5789 - val_loss: 118.2838\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2080 - val_loss: 124.7399\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.9189 - val_loss: 115.6238\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.9093 - val_loss: 199.0946\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2709 - val_loss: 117.2401\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9892 - val_loss: 117.0408\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 154.3539 - val_loss: 147.1330\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.7728 - val_loss: 137.9312\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.4277 - val_loss: 117.1514\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1934 - val_loss: 142.5355\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5043 - val_loss: 113.8540\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.2830 - val_loss: 157.3217\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0982 - val_loss: 117.1341\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.2753 - val_loss: 130.4210\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7332 - val_loss: 128.4315\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.4804 - val_loss: 120.1753\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.6251 - val_loss: 129.2962\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.3269 - val_loss: 124.9824\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1966 - val_loss: 117.2087\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1760 - val_loss: 144.9172\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.4320 - val_loss: 112.3530\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9284 - val_loss: 117.5723\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1260 - val_loss: 123.8945\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.4876 - val_loss: 122.9189\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.4716 - val_loss: 122.4810\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 155.9605 - val_loss: 148.6295\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 146.1479 - val_loss: 124.1644\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 168.9142 - val_loss: 128.5027\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 153.9340 - val_loss: 207.9463\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 170.5234 - val_loss: 148.2577\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.0275 - val_loss: 114.4477\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.3656 - val_loss: 116.3551\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.0165 - val_loss: 158.7221\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 150.8262 - val_loss: 110.9120\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9475 - val_loss: 116.6502\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4880 - val_loss: 295.7455\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.6335 - val_loss: 146.4539\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.8418 - val_loss: 112.8032\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.3843 - val_loss: 118.7621\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.1627 - val_loss: 118.5523\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.4643 - val_loss: 133.1752\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.8182 - val_loss: 127.4378\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.3419 - val_loss: 125.2430\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.1592 - val_loss: 156.2975\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8398 - val_loss: 129.3188\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7086 - val_loss: 113.4989\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5495 - val_loss: 147.6223\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.7475 - val_loss: 128.4228\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.9230 - val_loss: 118.2483\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0075 - val_loss: 130.9646\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.6127 - val_loss: 113.7253\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.9420 - val_loss: 118.1040\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4613 - val_loss: 138.2877\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.3762 - val_loss: 113.3075\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2502 - val_loss: 125.9170\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.2031 - val_loss: 234.1394\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.0583 - val_loss: 115.0301\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.4273 - val_loss: 148.2108\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.8406 - val_loss: 126.4043\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4102 - val_loss: 119.5773\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.2074 - val_loss: 113.9292\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3866 - val_loss: 115.1304\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.6013 - val_loss: 135.9159\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1197 - val_loss: 116.4934\n",
      "Epoch 1894/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.3104 - val_loss: 123.2850\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0640 - val_loss: 118.8139\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.4910 - val_loss: 116.0403\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4491 - val_loss: 136.6577\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.0992 - val_loss: 123.7908\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1210 - val_loss: 154.0391\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1138 - val_loss: 111.1616\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3737 - val_loss: 130.0256\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4815 - val_loss: 138.1930\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7051 - val_loss: 168.5255\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.9134 - val_loss: 145.7229\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.7801 - val_loss: 195.6988\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.5971 - val_loss: 125.4429\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.3771 - val_loss: 114.2016\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7571 - val_loss: 115.6225\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.7925 - val_loss: 112.8290\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3117 - val_loss: 118.3330\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5946 - val_loss: 125.0345\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.6416 - val_loss: 122.3797\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3828 - val_loss: 129.8404\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.9098 - val_loss: 130.9254\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8754 - val_loss: 118.7086\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.6419 - val_loss: 160.3771\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0623 - val_loss: 150.5180\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4209 - val_loss: 131.4326\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.5156 - val_loss: 131.6996\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.8302 - val_loss: 110.5028\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1143 - val_loss: 126.4764\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.4559 - val_loss: 125.4744\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.2326 - val_loss: 120.4387\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 165.8888 - val_loss: 118.1373\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0365 - val_loss: 267.1897\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6815 - val_loss: 113.5548\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.2481 - val_loss: 113.8293\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.6901 - val_loss: 142.7273\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3717 - val_loss: 116.8859\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.0620 - val_loss: 135.6636\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8014 - val_loss: 132.4956\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9297 - val_loss: 116.5326\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9627 - val_loss: 200.2186\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 158.3586 - val_loss: 135.3005\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.9772 - val_loss: 122.4723\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 144.7963 - val_loss: 268.2169\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 145.0540 - val_loss: 146.7451\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.7423 - val_loss: 109.9381\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.6735 - val_loss: 117.4302\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0098 - val_loss: 198.1578\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.8528 - val_loss: 110.9753\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6237 - val_loss: 139.5649\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 155.3831 - val_loss: 117.6593\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.6022 - val_loss: 141.5591\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4452 - val_loss: 126.7029\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5528 - val_loss: 141.7440\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2503 - val_loss: 155.0277\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6665 - val_loss: 119.7732\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1142 - val_loss: 137.8315\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.2812 - val_loss: 131.2555\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.2897 - val_loss: 111.6328\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.6848 - val_loss: 129.2034\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.7183 - val_loss: 214.1800\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1239 - val_loss: 114.7389\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1857 - val_loss: 115.6382\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.9973 - val_loss: 151.3193\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.8987 - val_loss: 140.8123\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8398 - val_loss: 165.9874\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.2965 - val_loss: 127.7544\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.6627 - val_loss: 114.4286\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.5159 - val_loss: 154.4243\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.0296 - val_loss: 191.2812\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.2969 - val_loss: 112.0416\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.7107 - val_loss: 117.3651\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.9815 - val_loss: 127.7630\n",
      "Epoch 1966/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.2755 - val_loss: 127.8803\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.6554 - val_loss: 196.4428\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.5310 - val_loss: 129.3001\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0269 - val_loss: 152.6777\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.4642 - val_loss: 115.2715\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0115 - val_loss: 117.7399\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.6496 - val_loss: 143.8357\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.4757 - val_loss: 148.6001\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.7368 - val_loss: 130.8504\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.8660 - val_loss: 119.5318\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 145.9614 - val_loss: 168.2724\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.3661 - val_loss: 116.0231\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7862 - val_loss: 122.8810\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 194.9602 - val_loss: 144.9739\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.1807 - val_loss: 166.0515\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.9151 - val_loss: 112.4933\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.5406 - val_loss: 151.7096\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.7703 - val_loss: 118.7418\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.0685 - val_loss: 112.9246\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.4822 - val_loss: 169.1882\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.4049 - val_loss: 138.7911\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.6815 - val_loss: 119.3502\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7959 - val_loss: 123.7657\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.6677 - val_loss: 119.0311\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6780 - val_loss: 180.1706\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.2231 - val_loss: 116.9008\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.6588 - val_loss: 178.9373\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.9848 - val_loss: 112.5321\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 149.9995 - val_loss: 113.9524\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 153.8897 - val_loss: 109.0135\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 150.5551 - val_loss: 116.0521\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 150.1604 - val_loss: 112.0783\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.7824 - val_loss: 125.2201\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.6667 - val_loss: 139.3881\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.2285 - val_loss: 112.2082\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.5130 - val_loss: 122.6665\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.2805 - val_loss: 122.7764\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.5799 - val_loss: 154.1918\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.3873 - val_loss: 128.2852\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.0288 - val_loss: 124.4721\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.1320 - val_loss: 127.3563\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 161.9180 - val_loss: 158.0443\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.7135 - val_loss: 112.8330\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.1211 - val_loss: 126.2542\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.5876 - val_loss: 109.4393\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.4013 - val_loss: 120.1357\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.0875 - val_loss: 110.5598\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.9070 - val_loss: 127.4992\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.7054 - val_loss: 129.3422\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.6731 - val_loss: 108.1388\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1765 - val_loss: 132.8313\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.3640 - val_loss: 117.5890\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.4226 - val_loss: 127.7178\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3686 - val_loss: 155.7724\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.5958 - val_loss: 118.0879\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9286 - val_loss: 115.7976\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.1872 - val_loss: 119.2179\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8499 - val_loss: 125.7240\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 171.3268 - val_loss: 198.4929\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.9908 - val_loss: 149.7963\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.5999 - val_loss: 130.9348\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7187 - val_loss: 140.4302\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.6679 - val_loss: 118.7790\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0203 - val_loss: 120.8050\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3376 - val_loss: 118.3573\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4472 - val_loss: 112.6864\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8894 - val_loss: 117.9428\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 140.5364 - val_loss: 123.3163\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6161 - val_loss: 127.1440\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.0939 - val_loss: 117.8360\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0148 - val_loss: 132.0574\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8101 - val_loss: 119.4996\n",
      "Epoch 2038/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.0460 - val_loss: 163.1974\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.6883 - val_loss: 111.4699\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.5502 - val_loss: 159.9822\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.6711 - val_loss: 114.8617\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 186.0141 - val_loss: 129.0910\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8611 - val_loss: 124.5365\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.7926 - val_loss: 124.7015\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.5397 - val_loss: 128.5617\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3764 - val_loss: 151.1548\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.4669 - val_loss: 113.7169\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.9344 - val_loss: 229.2614\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.3596 - val_loss: 116.2638\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.2249 - val_loss: 119.4909\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.9387 - val_loss: 161.4219\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6144 - val_loss: 118.4472\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.2172 - val_loss: 118.0124\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 144.1648 - val_loss: 114.8407\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.1788 - val_loss: 214.3547\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1446 - val_loss: 149.9875\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.3718 - val_loss: 111.1044\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.1352 - val_loss: 119.3842\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 152.0735 - val_loss: 135.0270\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.6750 - val_loss: 119.3133\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 141.7018 - val_loss: 115.3052\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 144.4523 - val_loss: 118.4114\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 151.9462 - val_loss: 176.3949\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 154.8296 - val_loss: 117.7706\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.6237 - val_loss: 115.7000\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 153.1342 - val_loss: 247.8618\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.9956 - val_loss: 148.8755\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5614 - val_loss: 132.4144\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4519 - val_loss: 114.0703\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9191 - val_loss: 118.5186\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.1262 - val_loss: 143.7541\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.8847 - val_loss: 118.8782\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8125 - val_loss: 123.0671\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9577 - val_loss: 132.6902\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.5785 - val_loss: 112.9905\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.7372 - val_loss: 122.2938\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.6211 - val_loss: 130.1892\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.2788 - val_loss: 112.1804\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7345 - val_loss: 151.1904\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4929 - val_loss: 125.4262\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.4835 - val_loss: 132.7506\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9536 - val_loss: 126.7809\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.3644 - val_loss: 164.7237\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.8815 - val_loss: 115.9845\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2861 - val_loss: 168.3028\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5883 - val_loss: 114.7217\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0664 - val_loss: 161.0913\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0957 - val_loss: 111.4139\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 153.1482 - val_loss: 119.2967\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.2151 - val_loss: 116.7531\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3399 - val_loss: 119.1955\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8993 - val_loss: 117.8298\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.2028 - val_loss: 130.4948\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5260 - val_loss: 108.7522\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.4994 - val_loss: 125.0833\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3325 - val_loss: 143.1170\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4262 - val_loss: 123.2784\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9524 - val_loss: 144.9685\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6298 - val_loss: 143.7652\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.0519 - val_loss: 117.9736\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7334 - val_loss: 115.1057\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7610 - val_loss: 113.0691\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9208 - val_loss: 173.4185\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.9026 - val_loss: 133.1151\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.5820 - val_loss: 126.4914\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3395 - val_loss: 124.8952\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8546 - val_loss: 165.9718\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9219 - val_loss: 166.1182\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.9848 - val_loss: 114.8027\n",
      "Epoch 2110/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 57us/step - loss: 140.5194 - val_loss: 130.3594\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.0031 - val_loss: 112.9360\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.2836 - val_loss: 123.4247\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0185 - val_loss: 156.1440\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8709 - val_loss: 134.0942\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9991 - val_loss: 117.9690\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6019 - val_loss: 128.4114\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8740 - val_loss: 142.1935\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3217 - val_loss: 114.5870\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.0352 - val_loss: 129.1624\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6529 - val_loss: 119.2120\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9695 - val_loss: 130.2111\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2062 - val_loss: 148.4423\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4014 - val_loss: 152.8781\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6818 - val_loss: 159.0521\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.9429 - val_loss: 117.6489\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2019 - val_loss: 123.8230\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4562 - val_loss: 226.6219\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.6650 - val_loss: 115.2387\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.1896 - val_loss: 217.5399\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 146.2953 - val_loss: 131.5266\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 144.9933 - val_loss: 116.2731\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 150.7935 - val_loss: 116.0359\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.6211 - val_loss: 118.4260\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3233 - val_loss: 146.9187\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.1843 - val_loss: 130.1442\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.7140 - val_loss: 150.7442\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2122 - val_loss: 116.1893\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.1437 - val_loss: 126.7551\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.9656 - val_loss: 128.2797\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8509 - val_loss: 140.5176\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3656 - val_loss: 111.5340\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8309 - val_loss: 126.9403\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.5475 - val_loss: 133.9985\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.1615 - val_loss: 313.5839\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 145.6737 - val_loss: 136.4860\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9154 - val_loss: 118.3826\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.9722 - val_loss: 117.5983\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6434 - val_loss: 146.6260\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.6367 - val_loss: 188.2323\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.4822 - val_loss: 119.3785\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7717 - val_loss: 112.1677\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9615 - val_loss: 121.5812\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 139.4146 - val_loss: 109.0863\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3090 - val_loss: 127.8702\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8012 - val_loss: 116.1286\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7802 - val_loss: 116.1838\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4343 - val_loss: 118.8868\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9768 - val_loss: 175.1502\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.8296 - val_loss: 139.1310\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9983 - val_loss: 115.4508\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7816 - val_loss: 125.2144\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.6653 - val_loss: 161.6289\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1205 - val_loss: 117.3538\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.3292 - val_loss: 136.8407\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7831 - val_loss: 141.3571\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1013 - val_loss: 135.8735\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3766 - val_loss: 113.4364\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.9049 - val_loss: 140.1671\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6535 - val_loss: 176.1642\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1728 - val_loss: 110.2837\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.6655 - val_loss: 120.1735\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7227 - val_loss: 131.5615\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9271 - val_loss: 151.7042\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8706 - val_loss: 117.0254\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5696 - val_loss: 142.2193\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6569 - val_loss: 152.7052\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2332 - val_loss: 122.7250\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1160 - val_loss: 116.6158\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.0897 - val_loss: 114.0294\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.8917 - val_loss: 110.8277\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.5212 - val_loss: 117.8446\n",
      "Epoch 2182/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.4992 - val_loss: 114.8493\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.6237 - val_loss: 167.2500\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1475 - val_loss: 122.2968\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.9523 - val_loss: 158.2808\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9834 - val_loss: 122.9811\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.1921 - val_loss: 118.0686\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.2494 - val_loss: 123.7483\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6236 - val_loss: 113.1213\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0491 - val_loss: 136.9085\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3682 - val_loss: 123.1742\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0477 - val_loss: 126.4066\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6387 - val_loss: 186.0087\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.9296 - val_loss: 158.0942\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.1068 - val_loss: 131.8404\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7734 - val_loss: 206.9198\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.9141 - val_loss: 113.3896\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.3521 - val_loss: 118.7663\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.9373 - val_loss: 116.5584\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7342 - val_loss: 130.2417\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.4730 - val_loss: 155.2561\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 149.6107 - val_loss: 132.8240\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 140.9252 - val_loss: 147.1356\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8123 - val_loss: 137.7967\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.1839 - val_loss: 121.9344\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3106 - val_loss: 112.7457\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.8299 - val_loss: 116.4662\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7770 - val_loss: 136.7578\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9538 - val_loss: 189.0573\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.7771 - val_loss: 118.4249\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2428 - val_loss: 114.3991\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6836 - val_loss: 114.9668\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.2500 - val_loss: 166.7541\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.6873 - val_loss: 149.0418\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1527 - val_loss: 148.8787\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.7768 - val_loss: 109.4917\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9386 - val_loss: 177.5760\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6391 - val_loss: 114.0788\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.3423 - val_loss: 126.9088\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1688 - val_loss: 121.1062\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4540 - val_loss: 168.7790\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4525 - val_loss: 143.2337\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6687 - val_loss: 135.6806\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6391 - val_loss: 109.3121\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7185 - val_loss: 121.1354\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.2000 - val_loss: 122.3187\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 157.0584 - val_loss: 113.4362\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9642 - val_loss: 126.5563\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.8733 - val_loss: 113.9590\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6632 - val_loss: 124.8164\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.9516 - val_loss: 151.6645\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.0081 - val_loss: 113.0777\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7543 - val_loss: 177.0920\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.3474 - val_loss: 119.6195\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1254 - val_loss: 114.9738\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8472 - val_loss: 137.0657\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4140 - val_loss: 223.4025\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.2340 - val_loss: 125.7670\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.5534 - val_loss: 118.1961\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2687 - val_loss: 134.0855\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2214 - val_loss: 112.5742\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2678 - val_loss: 126.8740\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1617 - val_loss: 120.4129\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7860 - val_loss: 111.0512\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0961 - val_loss: 144.7383\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.9906 - val_loss: 111.3942\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.7401 - val_loss: 141.2115\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4942 - val_loss: 122.1488\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9784 - val_loss: 111.2759\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.0842 - val_loss: 111.6496\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1323 - val_loss: 119.4367\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.5222 - val_loss: 206.8703\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.7158 - val_loss: 124.8409\n",
      "Epoch 2254/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9127 - val_loss: 110.8070\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7237 - val_loss: 121.1460\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.1734 - val_loss: 123.6217\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8816 - val_loss: 127.0959\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3702 - val_loss: 114.1759\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6895 - val_loss: 169.8527\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3000 - val_loss: 154.1035\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0209 - val_loss: 118.3738\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1492 - val_loss: 120.3482\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4202 - val_loss: 139.8592\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.0125 - val_loss: 320.2208\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.5434 - val_loss: 115.3360\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6073 - val_loss: 116.9548\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.3021 - val_loss: 117.7002\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6444 - val_loss: 125.4525\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.2124 - val_loss: 137.6752\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1654 - val_loss: 116.4239\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 156.7625 - val_loss: 123.2908\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.2575 - val_loss: 149.3119\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.5629 - val_loss: 128.1845\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3803 - val_loss: 270.8557\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4441 - val_loss: 111.0160\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1858 - val_loss: 118.1723\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5619 - val_loss: 132.2572\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9512 - val_loss: 218.6306\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2314 - val_loss: 116.0709\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0056 - val_loss: 115.4122\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5551 - val_loss: 134.1503\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.9264 - val_loss: 114.2516\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6979 - val_loss: 130.1270\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.0628 - val_loss: 122.1442\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0260 - val_loss: 113.3398\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.4013 - val_loss: 127.8390\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.9989 - val_loss: 139.6165\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7699 - val_loss: 153.6062\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7954 - val_loss: 117.3827\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.2967 - val_loss: 112.9296\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1299 - val_loss: 113.1994\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8641 - val_loss: 121.0146\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.8660 - val_loss: 111.2525\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.4381 - val_loss: 132.7481\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3198 - val_loss: 119.7842\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.2519 - val_loss: 139.8695\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2499 - val_loss: 115.4414\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.9454 - val_loss: 135.2979\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.9405 - val_loss: 111.7150\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.2332 - val_loss: 145.4886\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.1800 - val_loss: 121.9898\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.6508 - val_loss: 116.3492\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0457 - val_loss: 174.6766\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5886 - val_loss: 127.1226\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.5843 - val_loss: 112.2222\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0256 - val_loss: 128.1485\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2341 - val_loss: 117.8112\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.9859 - val_loss: 170.9611\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3242 - val_loss: 124.3384\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1793 - val_loss: 118.8105\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7801 - val_loss: 119.8655\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7469 - val_loss: 144.4663\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.9833 - val_loss: 125.0355\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.1386 - val_loss: 123.5470\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.3085 - val_loss: 134.8042\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2470 - val_loss: 122.1658\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.4911 - val_loss: 142.4890\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3857 - val_loss: 118.6783\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2939 - val_loss: 121.2570\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6436 - val_loss: 116.2879\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.0354 - val_loss: 118.7258\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1313 - val_loss: 168.7598\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.3838 - val_loss: 129.9857\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4315 - val_loss: 134.4701\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.9784 - val_loss: 129.4411\n",
      "Epoch 2326/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3631 - val_loss: 118.1240\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4488 - val_loss: 119.2513\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.4071 - val_loss: 145.7226\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.0862 - val_loss: 112.9438\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5113 - val_loss: 156.2394\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4534 - val_loss: 162.5297\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7029 - val_loss: 126.4030\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.2649 - val_loss: 118.3777\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6268 - val_loss: 213.0842\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7820 - val_loss: 118.9874\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7532 - val_loss: 129.7312\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.9609 - val_loss: 125.4152\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0248 - val_loss: 133.6804\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.3004 - val_loss: 119.8293\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.1207 - val_loss: 122.6138\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.6172 - val_loss: 120.2759\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 136.3066 - val_loss: 136.0645\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 144.9437 - val_loss: 123.7134\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.0271 - val_loss: 116.0575\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 162.3050 - val_loss: 143.8493\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.7158 - val_loss: 116.3430\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.7773 - val_loss: 113.6324\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2748 - val_loss: 113.9057\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.4080 - val_loss: 128.6719\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5369 - val_loss: 119.6618\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2371 - val_loss: 114.7320\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9600 - val_loss: 118.8798\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5749 - val_loss: 112.5565\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.8112 - val_loss: 136.6005\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8512 - val_loss: 121.3397\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8150 - val_loss: 130.2859\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.4938 - val_loss: 121.6595\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.8097 - val_loss: 188.3138\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.1632 - val_loss: 108.5608\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4885 - val_loss: 121.5634\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8215 - val_loss: 181.8106\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5403 - val_loss: 145.2706\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8049 - val_loss: 113.2592\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2702 - val_loss: 123.7423\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.6179 - val_loss: 113.0101\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4668 - val_loss: 165.1440\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.7812 - val_loss: 152.3358\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.7520 - val_loss: 118.6323\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.5257 - val_loss: 118.9510\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.4744 - val_loss: 159.5342\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.0728 - val_loss: 131.4728\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0917 - val_loss: 118.5448\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.3766 - val_loss: 119.9142\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.7168 - val_loss: 115.9820\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 147.3836 - val_loss: 163.2402\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.4063 - val_loss: 123.7795\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4106 - val_loss: 110.6127\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7571 - val_loss: 118.5549\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.3209 - val_loss: 112.6821\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.3198 - val_loss: 114.4711\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7514 - val_loss: 149.9030\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6110 - val_loss: 214.6122\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2608 - val_loss: 122.0820\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1407 - val_loss: 129.3516\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.3798 - val_loss: 125.9227\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9056 - val_loss: 115.0354\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.9029 - val_loss: 157.7163\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.1541 - val_loss: 173.1687\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.6180 - val_loss: 121.4063\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2718 - val_loss: 134.3040\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.0725 - val_loss: 138.8017\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.7852 - val_loss: 116.2216\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 136.8962 - val_loss: 118.2211\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.0577 - val_loss: 123.5798\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.1829 - val_loss: 125.2396\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4936 - val_loss: 119.3502\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5816 - val_loss: 128.4003\n",
      "Epoch 2398/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2346 - val_loss: 114.2391\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1527 - val_loss: 127.6198\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6144 - val_loss: 151.0795\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7121 - val_loss: 134.9048\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 325.7014 - val_loss: 183.8367\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.5323 - val_loss: 152.9480\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.8704 - val_loss: 119.5691\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7492 - val_loss: 114.8052\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.6283 - val_loss: 131.0592\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9092 - val_loss: 131.7001\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.3526 - val_loss: 135.6322\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.3136 - val_loss: 115.0348\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 134.9741 - val_loss: 124.4006\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 145.5304 - val_loss: 149.0112\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 166.2101 - val_loss: 289.9779\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.6112 - val_loss: 112.5565\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.3887 - val_loss: 115.5336\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7597 - val_loss: 112.3127\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7906 - val_loss: 123.9808\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9086 - val_loss: 120.7521\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9624 - val_loss: 147.8409\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7926 - val_loss: 143.4863\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.1276 - val_loss: 114.7172\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4526 - val_loss: 123.1400\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.2027 - val_loss: 124.8819\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.6398 - val_loss: 110.3869\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6413 - val_loss: 158.2108\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.0006 - val_loss: 137.4952\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3286 - val_loss: 116.9462\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2218 - val_loss: 116.0255\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2626 - val_loss: 135.8527\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9274 - val_loss: 115.1681\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9766 - val_loss: 126.5554\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8380 - val_loss: 120.3261\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.5729 - val_loss: 121.6446\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1805 - val_loss: 123.4611\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6688 - val_loss: 145.8032\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.7445 - val_loss: 114.0894\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4988 - val_loss: 165.8134\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9501 - val_loss: 147.4039\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.8844 - val_loss: 115.2032\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 147.4397 - val_loss: 117.6625\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.9259 - val_loss: 111.8301\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5515 - val_loss: 165.1462\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 188.0504 - val_loss: 117.7204\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.6138 - val_loss: 214.8072\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1479 - val_loss: 114.4296\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9161 - val_loss: 111.8459\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4306 - val_loss: 127.5084\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3365 - val_loss: 172.5171\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6321 - val_loss: 119.7302\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8733 - val_loss: 121.7460\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5967 - val_loss: 125.1009\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.8613 - val_loss: 113.8971\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0201 - val_loss: 171.3363\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.4931 - val_loss: 148.6781\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6872 - val_loss: 134.7584\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3878 - val_loss: 141.7873\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5452 - val_loss: 113.9934\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.4816 - val_loss: 130.0810\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9732 - val_loss: 112.6024\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.0158 - val_loss: 126.9933\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9986 - val_loss: 116.8150\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3169 - val_loss: 114.4663\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0811 - val_loss: 132.6026\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7611 - val_loss: 116.4299\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.9544 - val_loss: 117.0135\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9616 - val_loss: 123.1766\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0864 - val_loss: 111.9856\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3035 - val_loss: 139.9403\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.6234 - val_loss: 120.5730\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3704 - val_loss: 158.0860\n",
      "Epoch 2470/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5780 - val_loss: 121.4628\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3013 - val_loss: 123.9362\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3049 - val_loss: 115.3851\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0364 - val_loss: 115.4615\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3822 - val_loss: 125.3084\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.9921 - val_loss: 120.9125\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4974 - val_loss: 135.3255\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.7223 - val_loss: 118.9913\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9787 - val_loss: 212.7455\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.2057 - val_loss: 140.2118\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 143.0236 - val_loss: 131.8974\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.4354 - val_loss: 315.2070\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 151.2887 - val_loss: 119.5222\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3178 - val_loss: 124.3421\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7729 - val_loss: 116.7225\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9122 - val_loss: 151.9646\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.8280 - val_loss: 111.6646\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5189 - val_loss: 134.8633\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.4030 - val_loss: 216.9726\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 162.4428 - val_loss: 118.4426\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.3583 - val_loss: 179.9940\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.4782 - val_loss: 117.6391\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.7429 - val_loss: 115.0868\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6368 - val_loss: 121.9960\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5630 - val_loss: 119.1744\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0975 - val_loss: 197.6519\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8761 - val_loss: 116.1033\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9018 - val_loss: 153.7696\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3474 - val_loss: 115.6260\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7337 - val_loss: 117.0127\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0794 - val_loss: 207.4768\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8193 - val_loss: 111.1141\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8847 - val_loss: 119.4387\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8745 - val_loss: 111.1345\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.6886 - val_loss: 110.3997\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.0669 - val_loss: 127.7128\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.5192 - val_loss: 216.8663\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.6115 - val_loss: 133.0878\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.1110 - val_loss: 116.0606\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.0388 - val_loss: 146.5243\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5005 - val_loss: 160.5799\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8876 - val_loss: 112.1161\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7262 - val_loss: 156.3060\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.6493 - val_loss: 126.3181\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7050 - val_loss: 113.8823\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6473 - val_loss: 134.0980\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2351 - val_loss: 113.6047\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4599 - val_loss: 148.6547\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.5322 - val_loss: 113.3127\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5254 - val_loss: 115.8939\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.7276 - val_loss: 125.8833\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.0235 - val_loss: 111.0135\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3875 - val_loss: 120.4959\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0460 - val_loss: 129.3612\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1194 - val_loss: 164.9580\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.6310 - val_loss: 124.4291\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.0010 - val_loss: 111.5664\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.2486 - val_loss: 150.6740\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4632 - val_loss: 118.3264\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1565 - val_loss: 223.2676\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9099 - val_loss: 119.4006\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.7611 - val_loss: 127.0154\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.3887 - val_loss: 119.6811\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6745 - val_loss: 131.6470\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.0501 - val_loss: 186.7147\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9215 - val_loss: 115.6426\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8909 - val_loss: 139.9151\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.2143 - val_loss: 144.4730\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.6620 - val_loss: 120.8124\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0143 - val_loss: 145.8915\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1872 - val_loss: 128.9230\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5736 - val_loss: 115.1634\n",
      "Epoch 2542/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.2344 - val_loss: 114.5803\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 141.5794 - val_loss: 125.6752\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.8131 - val_loss: 126.4903\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.8726 - val_loss: 116.2926\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7607 - val_loss: 119.7461\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1398 - val_loss: 119.9429\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1871 - val_loss: 164.6374\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.1477 - val_loss: 119.4062\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.5745 - val_loss: 130.2858\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 153.9806 - val_loss: 132.4734\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 142.8969 - val_loss: 113.1569\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3109 - val_loss: 122.6690\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.2483 - val_loss: 128.2409\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6234 - val_loss: 115.5205\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7287 - val_loss: 113.5639\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.4507 - val_loss: 121.1122\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4545 - val_loss: 117.7651\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2097 - val_loss: 202.1048\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5416 - val_loss: 114.6600\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.3664 - val_loss: 119.1052\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9637 - val_loss: 141.9020\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.5333 - val_loss: 117.8392\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3025 - val_loss: 139.0129\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4937 - val_loss: 148.0002\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9298 - val_loss: 130.5732\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.0729 - val_loss: 132.7810\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.8308 - val_loss: 144.8677\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4725 - val_loss: 130.0277\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3594 - val_loss: 119.5343\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9787 - val_loss: 111.7587\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7289 - val_loss: 221.0619\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 153.7717 - val_loss: 137.3382\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.6775 - val_loss: 135.2923\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8680 - val_loss: 138.5542\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8568 - val_loss: 127.6765\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8843 - val_loss: 150.5930\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 142.1545 - val_loss: 138.8292\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.8733 - val_loss: 161.4289\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.1055 - val_loss: 178.4717\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0198 - val_loss: 116.0840\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 161.8441 - val_loss: 116.6207\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.8351 - val_loss: 119.5687\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.1214 - val_loss: 132.6590\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8276 - val_loss: 129.6405\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.3737 - val_loss: 109.9074\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 141.3920 - val_loss: 117.1631\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.7826 - val_loss: 191.7876\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9735 - val_loss: 114.9014\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4931 - val_loss: 143.7586\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6134 - val_loss: 115.4905\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0748 - val_loss: 111.4550\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9043 - val_loss: 121.1332\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.8017 - val_loss: 150.9589\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2497 - val_loss: 138.8678\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.4767 - val_loss: 112.8858\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.1054 - val_loss: 110.9267\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.9368 - val_loss: 116.3582\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4909 - val_loss: 110.8512\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1934 - val_loss: 117.3105\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.7653 - val_loss: 125.1348\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8683 - val_loss: 113.9048\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.7292 - val_loss: 129.4252\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 151.0581 - val_loss: 111.2081\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.8609 - val_loss: 158.1027\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.5562 - val_loss: 126.8700\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.4433 - val_loss: 109.6055\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.4734 - val_loss: 120.6248\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4799 - val_loss: 130.6177\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9849 - val_loss: 116.8540\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.4426 - val_loss: 131.6941\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9878 - val_loss: 129.2086\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.8630 - val_loss: 121.8074\n",
      "Epoch 2614/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9223 - val_loss: 140.8203\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.9028 - val_loss: 134.9428\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4735 - val_loss: 187.4326\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8779 - val_loss: 162.3320\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2319 - val_loss: 119.3945\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.1467 - val_loss: 160.4692\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.1260 - val_loss: 124.3682\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6816 - val_loss: 122.1935\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7551 - val_loss: 141.6644\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.3362 - val_loss: 111.6247\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.5899 - val_loss: 130.4634\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.6991 - val_loss: 121.5194\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5164 - val_loss: 144.5691\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.8910 - val_loss: 135.5864\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.8543 - val_loss: 140.8525\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 135.7778 - val_loss: 142.2852\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 134.1077 - val_loss: 137.1597\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 142.0695 - val_loss: 115.1407\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.2048 - val_loss: 190.2279\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 145.3853 - val_loss: 120.0779\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 141.8309 - val_loss: 120.4633\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 183.9578 - val_loss: 133.0358\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 141.3867 - val_loss: 173.1791\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.0025 - val_loss: 132.8781\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.2187 - val_loss: 127.3426\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 158.7495 - val_loss: 134.5892\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.1301 - val_loss: 120.3898\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8046 - val_loss: 158.0377\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.3789 - val_loss: 122.6132\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7409 - val_loss: 122.4477\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.4846 - val_loss: 117.2497\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 134.6916 - val_loss: 165.9831\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 156.7002 - val_loss: 148.4645\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 147.2404 - val_loss: 116.5264\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 143.2514 - val_loss: 120.6526\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 161.9538 - val_loss: 184.6745\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 137.1576 - val_loss: 115.2673\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 135.1066 - val_loss: 116.1858\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 134.8183 - val_loss: 127.1060\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 134.7596 - val_loss: 204.7589\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 1s 177us/step - loss: 150.9999 - val_loss: 142.1154\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 147.8736 - val_loss: 110.8768\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 132.1620 - val_loss: 165.7755\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 141.9434 - val_loss: 114.5938\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 144.9686 - val_loss: 117.7028\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 148.2204 - val_loss: 140.0050\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 141.5196 - val_loss: 119.6291\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 157.7158 - val_loss: 132.8740\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 219.6850 - val_loss: 115.2083\n",
      "Epoch 2663/10000\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 137.1919 - val_loss: 118.5627\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 137.0220 - val_loss: 117.5583\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.9448 - val_loss: 122.1362\n",
      "Epoch 2666/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 135.0863 - val_loss: 151.4854\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 135.4049 - val_loss: 118.7974\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 140.6895 - val_loss: 139.6923\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 141.1046 - val_loss: 123.6376\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 140.4556 - val_loss: 348.6442\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 146.7408 - val_loss: 132.7626\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 150.3678 - val_loss: 129.4908\n",
      "Epoch 2673/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 144.3014 - val_loss: 122.2942\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 144.0626 - val_loss: 133.1671\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 135.7107 - val_loss: 112.7118\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 139.5794 - val_loss: 137.9711\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 142.8198 - val_loss: 121.2201\n",
      "Epoch 2678/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 130.5274 - val_loss: 148.7195\n",
      "Epoch 2679/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 142.5706 - val_loss: 128.6052\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 134.9225 - val_loss: 120.1079\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 148.4557 - val_loss: 163.9785\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 142.7080 - val_loss: 126.2035\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 130.603 - 1s 63us/step - loss: 134.7700 - val_loss: 118.5560\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 141.5630 - val_loss: 119.1988\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 140.2505 - val_loss: 117.7798\n",
      "Epoch 2686/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 80us/step - loss: 144.0380 - val_loss: 114.4208\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 141.6782 - val_loss: 113.2993\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 135.5648 - val_loss: 118.3405\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 143.5517 - val_loss: 112.1101\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.5598 - val_loss: 122.6512\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.6439 - val_loss: 120.3459\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.0357 - val_loss: 127.0427\n",
      "Epoch 2693/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 136.1351 - val_loss: 125.3249\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 141.4741 - val_loss: 119.0245\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 135.9659 - val_loss: 129.6782\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 218.4016 - val_loss: 183.5006\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 134.0483 - val_loss: 146.4047\n",
      "Epoch 2698/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 133.4544 - val_loss: 118.5175\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.6738 - val_loss: 118.7972\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 133.1526 - val_loss: 123.7129\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.1153 - val_loss: 125.7347\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 138.1964 - val_loss: 162.9605\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 138.3334 - val_loss: 132.5859\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 139.2617 - val_loss: 195.4559\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 143.1615 - val_loss: 128.7842\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 138.7557 - val_loss: 119.8228\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 134.8311 - val_loss: 148.3374\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 139.4763 - val_loss: 162.4891\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 139.2210 - val_loss: 139.4393\n",
      "Epoch 2710/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 156.1794 - val_loss: 125.4432\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 172.6796 - val_loss: 122.1549\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 153.4345 - val_loss: 114.3448\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 133.0699 - val_loss: 108.8223\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.7545 - val_loss: 122.1575\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 154.8598 - val_loss: 255.1460\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 135.2469 - val_loss: 128.4260\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 145.0174 - val_loss: 165.5228\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.8001 - val_loss: 160.3573\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 130.9848 - val_loss: 118.6405\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 144.5393 - val_loss: 149.7799\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 136.9477 - val_loss: 117.0057\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 140.7997 - val_loss: 132.6970\n",
      "Epoch 2723/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 144.0085 - val_loss: 123.2999\n",
      "Epoch 2724/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 129.9391 - val_loss: 165.2301\n",
      "Epoch 2725/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 135.2742 - val_loss: 111.7403\n",
      "Epoch 2726/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 139.3919 - val_loss: 123.0416\n",
      "Epoch 2727/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 148.2559 - val_loss: 114.1389\n",
      "Epoch 2728/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.1864 - val_loss: 111.8867\n",
      "Epoch 2729/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.9037 - val_loss: 130.1408\n",
      "Epoch 2730/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.7132 - val_loss: 118.8738\n",
      "Epoch 2731/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.6559 - val_loss: 124.3220\n",
      "Epoch 2732/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 159.3792 - val_loss: 153.9717\n",
      "Epoch 2733/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 137.8686 - val_loss: 118.0864\n",
      "Epoch 2734/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 148.1800 - val_loss: 140.1645\n",
      "Epoch 2735/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 138.8565 - val_loss: 110.2983\n",
      "Epoch 2736/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 152.3658 - val_loss: 128.7934\n",
      "Epoch 2737/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.7421 - val_loss: 123.6762\n",
      "Epoch 2738/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 145.8177 - val_loss: 113.2164\n",
      "Epoch 2739/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 133.9182 - val_loss: 119.5061\n",
      "Epoch 2740/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 148.6522 - val_loss: 137.8002\n",
      "Epoch 2741/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 140.7238 - val_loss: 121.0702\n",
      "Epoch 2742/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 134.6423 - val_loss: 148.4711\n",
      "Epoch 2743/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.6274 - val_loss: 116.8299\n",
      "Epoch 2744/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 150.0048 - val_loss: 114.4949\n",
      "Epoch 2745/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 138.6465 - val_loss: 184.8920\n",
      "Epoch 2746/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 144.6857 - val_loss: 112.4104\n",
      "Epoch 2747/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 148.6717 - val_loss: 128.4442\n",
      "Epoch 2748/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 136.0307 - val_loss: 154.1011\n",
      "Epoch 2749/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 141.5322 - val_loss: 114.6381\n",
      "Epoch 2750/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 134.1654 - val_loss: 113.5354\n",
      "Epoch 2751/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 160.3415 - val_loss: 133.0835\n",
      "Epoch 2752/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 134.3592 - val_loss: 115.9328\n",
      "Epoch 2753/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 162.7148 - val_loss: 146.8211\n",
      "Epoch 2754/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 141.5495 - val_loss: 114.0327\n",
      "Epoch 2755/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 155.9279 - val_loss: 139.4089\n",
      "Epoch 2756/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 138.2447 - val_loss: 144.6201\n",
      "Epoch 2757/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 138.7358 - val_loss: 146.7578\n",
      "Epoch 2758/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 79us/step - loss: 137.6766 - val_loss: 129.2077\n",
      "Epoch 2759/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 138.8216 - val_loss: 118.5484\n",
      "Epoch 2760/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 153.2112 - val_loss: 116.4448\n",
      "Epoch 2761/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 148.2227 - val_loss: 114.7519\n",
      "Epoch 2762/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 131.9601 - val_loss: 125.8418\n",
      "Epoch 2763/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.5958 - val_loss: 119.1725\n",
      "Epoch 2764/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 149.8660 - val_loss: 120.7304\n",
      "Epoch 2765/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 154.0431 - val_loss: 126.6136\n",
      "Epoch 2766/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.8087 - val_loss: 143.3810\n",
      "Epoch 2767/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 149.2534 - val_loss: 134.6100\n",
      "Epoch 2768/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 134.8512 - val_loss: 146.6341\n",
      "Epoch 2769/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 136.2621 - val_loss: 120.2734\n",
      "Epoch 2770/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 145.1570 - val_loss: 124.6407\n",
      "Epoch 2771/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 162.5827 - val_loss: 119.5447\n",
      "Epoch 2772/10000\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 134.3096 - val_loss: 135.5354\n",
      "Epoch 2773/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 136.1690 - val_loss: 124.4959\n",
      "Epoch 2774/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 158.0874 - val_loss: 225.5456\n",
      "Epoch 2775/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 152.4302 - val_loss: 114.6857\n",
      "Epoch 2776/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 142.4771 - val_loss: 153.6921\n",
      "Epoch 2777/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 134.1103 - val_loss: 135.6619\n",
      "Epoch 2778/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 141.3359 - val_loss: 147.2510\n",
      "Epoch 2779/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 148.0158 - val_loss: 114.3896\n",
      "Epoch 2780/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 138.4659 - val_loss: 119.0988\n",
      "Epoch 2781/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 141.6162 - val_loss: 149.0362\n",
      "Epoch 2782/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 132.7205 - val_loss: 145.6863\n",
      "Epoch 2783/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 143.6239 - val_loss: 120.0259\n",
      "Epoch 2784/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 133.5218 - val_loss: 113.9437\n",
      "Epoch 2785/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 139.1315 - val_loss: 123.9291\n",
      "Epoch 2786/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 136.9060 - val_loss: 124.3052\n",
      "Epoch 2787/10000\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 137.5942 - val_loss: 124.9323\n",
      "Epoch 2788/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 158.0005 - val_loss: 128.6677\n",
      "Epoch 2789/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 136.8845 - val_loss: 116.6189\n",
      "Epoch 2790/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 194.1511 - val_loss: 120.0210\n",
      "Epoch 2791/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 176.2187 - val_loss: 116.6674\n",
      "Epoch 2792/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 134.2151 - val_loss: 163.9542\n",
      "Epoch 2793/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 139.0609 - val_loss: 120.5468\n",
      "Epoch 2794/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.4568 - val_loss: 241.3195\n",
      "Epoch 2795/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 177.9781 - val_loss: 127.0893\n",
      "Epoch 2796/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 152.4459 - val_loss: 120.6250\n",
      "Epoch 2797/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 155.5276 - val_loss: 116.8192\n",
      "Epoch 2798/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 142.4938 - val_loss: 120.5986\n",
      "Epoch 2799/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 135.6723 - val_loss: 140.5446\n",
      "Epoch 2800/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 140.5110 - val_loss: 118.7952\n",
      "Epoch 2801/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 141.4836 - val_loss: 155.0235\n",
      "Epoch 2802/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 155.0332 - val_loss: 121.0715\n",
      "Epoch 2803/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 131.4867 - val_loss: 126.7123\n",
      "Epoch 2804/10000\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 142.8650 - val_loss: 115.1970\n",
      "Epoch 2805/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 136.3980 - val_loss: 129.3302\n",
      "Epoch 2806/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 132.9806 - val_loss: 111.1865\n",
      "Epoch 2807/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 157.6204 - val_loss: 143.3409\n",
      "Epoch 2808/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 146.5463 - val_loss: 125.6872\n",
      "Epoch 2809/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.3968 - val_loss: 112.0886\n",
      "Epoch 2810/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 133.1574 - val_loss: 116.2481\n",
      "Epoch 2811/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 136.3783 - val_loss: 122.7363\n",
      "Epoch 2812/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 157.5980 - val_loss: 135.0014\n",
      "Epoch 2813/10000\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 139.4745 - val_loss: 127.9752\n",
      "Epoch 2814/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 142.0979 - val_loss: 115.6333\n",
      "Epoch 2815/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 155.8888 - val_loss: 150.9755\n",
      "Epoch 2816/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 149.4253 - val_loss: 121.6430\n",
      "Epoch 2817/10000\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 133.7839 - val_loss: 136.0233\n",
      "Epoch 2818/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 195.0248 - val_loss: 229.5219\n",
      "Epoch 2819/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 171.7647 - val_loss: 117.4979\n",
      "Epoch 2820/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 189.5213 - val_loss: 114.3207\n",
      "Epoch 2821/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 142.0544 - val_loss: 113.7468\n",
      "Epoch 2822/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 150.2314 - val_loss: 115.7918\n",
      "Epoch 2823/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 131.8302 - val_loss: 111.9386\n",
      "Epoch 2824/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 130.9873 - val_loss: 114.8774\n",
      "Epoch 2825/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 134.0911 - val_loss: 126.9027\n",
      "Epoch 2826/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.5467 - val_loss: 120.1211\n",
      "Epoch 2827/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 137.4870 - val_loss: 120.5074\n",
      "Epoch 2828/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 137.6064 - val_loss: 123.7048\n",
      "Epoch 2829/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 131.9654 - val_loss: 113.4747\n",
      "Epoch 2830/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 71us/step - loss: 180.9288 - val_loss: 131.6598\n",
      "Epoch 2831/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 165.3742 - val_loss: 121.6268\n",
      "Epoch 2832/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 130.6458 - val_loss: 112.7116\n",
      "Epoch 2833/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 142.9504 - val_loss: 219.2765\n",
      "Epoch 2834/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.1361 - val_loss: 114.3488\n",
      "Epoch 2835/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 139.0266 - val_loss: 110.7986\n",
      "Epoch 2836/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 145.0391 - val_loss: 130.9532\n",
      "Epoch 2837/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.6635 - val_loss: 119.2722\n",
      "Epoch 2838/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 138.0800 - val_loss: 151.3319\n",
      "Epoch 2839/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 164.0372 - val_loss: 155.2754\n",
      "Epoch 2840/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 144.7700 - val_loss: 134.8058\n",
      "Epoch 2841/10000\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 138.5397 - val_loss: 113.5970\n",
      "Epoch 2842/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 143.1242 - val_loss: 113.4038\n",
      "Epoch 2843/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 137.5343 - val_loss: 136.1176\n",
      "Epoch 2844/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.8360 - val_loss: 117.8909\n",
      "Epoch 2845/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.3639 - val_loss: 196.2770\n",
      "Epoch 2846/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 156.9390 - val_loss: 164.9532\n",
      "Epoch 2847/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.2821 - val_loss: 117.6155\n",
      "Epoch 2848/10000\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 132.7697 - val_loss: 146.7606\n",
      "Epoch 2849/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 132.3201 - val_loss: 122.0261\n",
      "Epoch 2850/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.9437 - val_loss: 116.4328\n",
      "Epoch 2851/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.3262 - val_loss: 156.1049\n",
      "Epoch 2852/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1271 - val_loss: 180.8585\n",
      "Epoch 2853/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.0983 - val_loss: 119.6265\n",
      "Epoch 2854/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6038 - val_loss: 130.3588\n",
      "Epoch 2855/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7851 - val_loss: 127.4023\n",
      "Epoch 2856/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2225 - val_loss: 127.5961\n",
      "Epoch 2857/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.7029 - val_loss: 124.2504\n",
      "Epoch 2858/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7350 - val_loss: 121.8560\n",
      "Epoch 2859/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.6968 - val_loss: 122.5799\n",
      "Epoch 2860/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8342 - val_loss: 117.0691\n",
      "Epoch 2861/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.7570 - val_loss: 114.8895\n",
      "Epoch 2862/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6402 - val_loss: 124.1808\n",
      "Epoch 2863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9628 - val_loss: 124.3233\n",
      "Epoch 2864/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.1101 - val_loss: 122.4856\n",
      "Epoch 2865/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3179 - val_loss: 120.4600\n",
      "Epoch 2866/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.2788 - val_loss: 114.3522\n",
      "Epoch 2867/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.7640 - val_loss: 145.8690\n",
      "Epoch 2868/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.3153 - val_loss: 115.0229\n",
      "Epoch 2869/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.1851 - val_loss: 113.4410\n",
      "Epoch 2870/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.4592 - val_loss: 152.2707\n",
      "Epoch 2871/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.9204 - val_loss: 118.6047\n",
      "Epoch 2872/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.2563 - val_loss: 165.4165\n",
      "Epoch 2873/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.8287 - val_loss: 115.6660\n",
      "Epoch 2874/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 137.4781 - val_loss: 129.5274\n",
      "Epoch 2875/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7152 - val_loss: 119.4554\n",
      "Epoch 2876/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9715 - val_loss: 129.1799\n",
      "Epoch 2877/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4496 - val_loss: 116.7034\n",
      "Epoch 2878/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7184 - val_loss: 115.9550\n",
      "Epoch 2879/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6837 - val_loss: 181.1288\n",
      "Epoch 2880/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.1356 - val_loss: 186.1252\n",
      "Epoch 2881/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3860 - val_loss: 112.5966\n",
      "Epoch 2882/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5780 - val_loss: 118.1316\n",
      "Epoch 2883/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.4298 - val_loss: 158.8060\n",
      "Epoch 2884/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.0663 - val_loss: 127.9140\n",
      "Epoch 2885/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5123 - val_loss: 129.8496\n",
      "Epoch 2886/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.4683 - val_loss: 142.6876\n",
      "Epoch 2887/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.9734 - val_loss: 151.0926\n",
      "Epoch 2888/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.2325 - val_loss: 115.0597\n",
      "Epoch 2889/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.0172 - val_loss: 131.2346\n",
      "Epoch 2890/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 128.5860 - val_loss: 117.7191\n",
      "Epoch 2891/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.6355 - val_loss: 131.2733\n",
      "Epoch 2892/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1821 - val_loss: 121.1071\n",
      "Epoch 2893/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.0826 - val_loss: 156.7371\n",
      "Epoch 2894/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.7480 - val_loss: 155.5200\n",
      "Epoch 2895/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.1732 - val_loss: 216.6097\n",
      "Epoch 2896/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.3974 - val_loss: 116.6887\n",
      "Epoch 2897/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.3824 - val_loss: 131.8025\n",
      "Epoch 2898/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.2739 - val_loss: 113.6798\n",
      "Epoch 2899/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.2574 - val_loss: 135.1950\n",
      "Epoch 2900/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1992 - val_loss: 118.5143\n",
      "Epoch 2901/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9166 - val_loss: 110.3432\n",
      "Epoch 2902/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.9233 - val_loss: 142.1616\n",
      "Epoch 2903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9988 - val_loss: 113.7236\n",
      "Epoch 2904/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.3892 - val_loss: 133.6176\n",
      "Epoch 2905/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.9227 - val_loss: 120.4703\n",
      "Epoch 2906/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.9568 - val_loss: 119.0436\n",
      "Epoch 2907/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7683 - val_loss: 116.0039\n",
      "Epoch 2908/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6648 - val_loss: 115.1443\n",
      "Epoch 2909/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.7607 - val_loss: 128.6224\n",
      "Epoch 2910/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.9978 - val_loss: 118.4140\n",
      "Epoch 2911/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3960 - val_loss: 115.9500\n",
      "Epoch 2912/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1983 - val_loss: 151.3418\n",
      "Epoch 2913/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.5006 - val_loss: 112.9214\n",
      "Epoch 2914/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.8857 - val_loss: 127.5530\n",
      "Epoch 2915/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.8594 - val_loss: 117.5198\n",
      "Epoch 2916/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0677 - val_loss: 124.3252\n",
      "Epoch 2917/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.1369 - val_loss: 119.6092\n",
      "Epoch 2918/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.0707 - val_loss: 150.2251\n",
      "Epoch 2919/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0620 - val_loss: 135.3328\n",
      "Epoch 2920/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.3519 - val_loss: 154.8262\n",
      "Epoch 2921/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.9237 - val_loss: 121.2232\n",
      "Epoch 2922/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9583 - val_loss: 130.6692\n",
      "Epoch 2923/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2140 - val_loss: 121.5385\n",
      "Epoch 2924/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4495 - val_loss: 133.3908\n",
      "Epoch 2925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2471 - val_loss: 117.9932\n",
      "Epoch 2926/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.4393 - val_loss: 114.9904\n",
      "Epoch 2927/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.0557 - val_loss: 144.1131\n",
      "Epoch 2928/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7081 - val_loss: 131.0008\n",
      "Epoch 2929/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.3803 - val_loss: 129.5535\n",
      "Epoch 2930/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.5780 - val_loss: 120.7883\n",
      "Epoch 2931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6744 - val_loss: 373.1863\n",
      "Epoch 2932/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1263 - val_loss: 130.0987\n",
      "Epoch 2933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7427 - val_loss: 136.8307\n",
      "Epoch 2934/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7490 - val_loss: 163.1600\n",
      "Epoch 2935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0077 - val_loss: 119.6738\n",
      "Epoch 2936/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7864 - val_loss: 121.0461\n",
      "Epoch 2937/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.9524 - val_loss: 133.5846\n",
      "Epoch 2938/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3719 - val_loss: 140.4985\n",
      "Epoch 2939/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6197 - val_loss: 137.0887\n",
      "Epoch 2940/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.5091 - val_loss: 118.5642\n",
      "Epoch 2941/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 141.5318 - val_loss: 123.7674\n",
      "Epoch 2942/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 141.1407 - val_loss: 111.1907\n",
      "Epoch 2943/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.2218 - val_loss: 112.3761\n",
      "Epoch 2944/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 131.1670 - val_loss: 121.5178\n",
      "Epoch 2945/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.2046 - val_loss: 114.6880\n",
      "Epoch 2946/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3979 - val_loss: 124.8734\n",
      "Epoch 2947/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.5655 - val_loss: 139.4187\n",
      "Epoch 2948/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6616 - val_loss: 132.3918\n",
      "Epoch 2949/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0341 - val_loss: 123.9765\n",
      "Epoch 2950/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1910 - val_loss: 114.7229\n",
      "Epoch 2951/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3995 - val_loss: 139.9533\n",
      "Epoch 2952/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.4008 - val_loss: 121.2187\n",
      "Epoch 2953/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4462 - val_loss: 128.5117\n",
      "Epoch 2954/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.8178 - val_loss: 179.5953\n",
      "Epoch 2955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0661 - val_loss: 128.4064\n",
      "Epoch 2956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4678 - val_loss: 118.8764\n",
      "Epoch 2957/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5104 - val_loss: 142.8555\n",
      "Epoch 2958/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.8823 - val_loss: 123.9670\n",
      "Epoch 2959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8615 - val_loss: 145.1382\n",
      "Epoch 2960/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.1875 - val_loss: 116.8759\n",
      "Epoch 2961/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9345 - val_loss: 140.0031\n",
      "Epoch 2962/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9107 - val_loss: 122.2608\n",
      "Epoch 2963/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.5610 - val_loss: 150.3370\n",
      "Epoch 2964/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7823 - val_loss: 121.7104\n",
      "Epoch 2965/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.5427 - val_loss: 127.4663\n",
      "Epoch 2966/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9349 - val_loss: 121.5384\n",
      "Epoch 2967/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.0599 - val_loss: 120.3540\n",
      "Epoch 2968/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.2146 - val_loss: 127.8372\n",
      "Epoch 2969/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.2776 - val_loss: 117.1505\n",
      "Epoch 2970/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5601 - val_loss: 126.5219\n",
      "Epoch 2971/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.0826 - val_loss: 178.4130\n",
      "Epoch 2972/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7940 - val_loss: 142.1662\n",
      "Epoch 2973/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7909 - val_loss: 115.6470\n",
      "Epoch 2974/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9482 - val_loss: 123.5314\n",
      "Epoch 2975/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 161.8825 - val_loss: 164.4286\n",
      "Epoch 2976/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3022 - val_loss: 115.8498\n",
      "Epoch 2977/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.0527 - val_loss: 113.3484\n",
      "Epoch 2978/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.9681 - val_loss: 130.9163\n",
      "Epoch 2979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.2101 - val_loss: 114.9305\n",
      "Epoch 2980/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8494 - val_loss: 130.3593\n",
      "Epoch 2981/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.6599 - val_loss: 116.9924\n",
      "Epoch 2982/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2085 - val_loss: 116.9378\n",
      "Epoch 2983/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.3397 - val_loss: 113.4959\n",
      "Epoch 2984/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3884 - val_loss: 117.8936\n",
      "Epoch 2985/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.9226 - val_loss: 110.8053\n",
      "Epoch 2986/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5868 - val_loss: 130.0355\n",
      "Epoch 2987/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2967 - val_loss: 111.6670\n",
      "Epoch 2988/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5182 - val_loss: 114.7750\n",
      "Epoch 2989/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8618 - val_loss: 130.8587\n",
      "Epoch 2990/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.9145 - val_loss: 115.9649\n",
      "Epoch 2991/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.7037 - val_loss: 122.9734\n",
      "Epoch 2992/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.4061 - val_loss: 113.6739\n",
      "Epoch 2993/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5999 - val_loss: 111.1111\n",
      "Epoch 2994/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3399 - val_loss: 155.1424\n",
      "Epoch 2995/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9320 - val_loss: 120.4547\n",
      "Epoch 2996/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4977 - val_loss: 118.7532\n",
      "Epoch 2997/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7165 - val_loss: 112.7128\n",
      "Epoch 2998/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.5807 - val_loss: 157.4424\n",
      "Epoch 2999/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.3830 - val_loss: 109.6127\n",
      "Epoch 3000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6667 - val_loss: 234.0499\n",
      "Epoch 3001/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3990 - val_loss: 117.3263\n",
      "Epoch 3002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5869 - val_loss: 144.6471\n",
      "Epoch 3003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.7776 - val_loss: 140.5286\n",
      "Epoch 3004/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.3838 - val_loss: 121.6687\n",
      "Epoch 3005/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.1496 - val_loss: 116.9929\n",
      "Epoch 3006/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1967 - val_loss: 120.6875\n",
      "Epoch 3007/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.9573 - val_loss: 113.6798\n",
      "Epoch 3008/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6302 - val_loss: 118.1490\n",
      "Epoch 3009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7390 - val_loss: 118.6768\n",
      "Epoch 3010/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.3761 - val_loss: 123.6085\n",
      "Epoch 3011/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 189.2436 - val_loss: 146.9602\n",
      "Epoch 3012/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 162.8272 - val_loss: 132.5740\n",
      "Epoch 3013/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 153.7924 - val_loss: 153.0264\n",
      "Epoch 3014/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.9086 - val_loss: 136.2819\n",
      "Epoch 3015/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.5473 - val_loss: 129.7367\n",
      "Epoch 03015: early stopping\n",
      "Fold score (RMSE): 11.118331909179688\n",
      "Fold #5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 7024.3445 - val_loss: 4378.6987\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 5002.6836 - val_loss: 3888.2885\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4621.7113 - val_loss: 3843.3858\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4362.9720 - val_loss: 3978.6155\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4473.8240 - val_loss: 3640.3877\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 4259.3501 - val_loss: 3966.2711\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4255.3317 - val_loss: 3462.7733\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4026.5538 - val_loss: 3736.0153\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 4119.3750 - val_loss: 3247.6548\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3995.3071 - val_loss: 3127.3763\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 3822.7621 - val_loss: 3288.4013\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3553.7300 - val_loss: 3754.1579\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 3290.7187 - val_loss: 2379.0965\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 2985.8313 - val_loss: 2120.2255\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 2771.9232 - val_loss: 2200.4340\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 2851.4815 - val_loss: 1614.5892\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 2081.0310 - val_loss: 1294.4981\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1651.0400 - val_loss: 920.4422\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 1325.6035 - val_loss: 2533.7735\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 1403.3060 - val_loss: 795.1674\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 1041.4353 - val_loss: 600.1617\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 932.8943 - val_loss: 488.6006\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 766.5554 - val_loss: 485.3831\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 865.2691 - val_loss: 521.0791\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 696.9379 - val_loss: 464.2483\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 668.1555 - val_loss: 475.1596\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 689.1895 - val_loss: 481.6246\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 668.4092 - val_loss: 518.3517\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 754.6835 - val_loss: 667.8927\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 565.4950 - val_loss: 423.1087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 562.2136 - val_loss: 472.2903\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 593.6484 - val_loss: 357.1786\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 668.7541 - val_loss: 376.4187\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 709.6467 - val_loss: 389.4664\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 550.5907 - val_loss: 589.7098\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 517.9803 - val_loss: 337.9361\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 545.4588 - val_loss: 394.2183\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 577.3888 - val_loss: 388.0958\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 513.8551 - val_loss: 402.1779\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 488.7151 - val_loss: 322.6576\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 496.9018 - val_loss: 414.0735\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 523.9687 - val_loss: 284.6308\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 512.4499 - val_loss: 770.6507\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 455.7005 - val_loss: 276.5815\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 492.3552 - val_loss: 308.5592\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 567.7120 - val_loss: 326.3317\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 450.8634 - val_loss: 416.9894\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 528.8572 - val_loss: 286.5198\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 502.3890 - val_loss: 315.7486\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 438.3722 - val_loss: 261.0219\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 758.4728 - val_loss: 948.1561\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 478.6392 - val_loss: 630.2848\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 502.5429 - val_loss: 358.1380\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 477.1740 - val_loss: 304.3162\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 516.3441 - val_loss: 584.2691\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 413.5281 - val_loss: 612.8702\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 410.3462 - val_loss: 242.7294\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 444.4272 - val_loss: 280.5028\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 417.4288 - val_loss: 244.2437\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 399.2555 - val_loss: 325.9956\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 457.5683 - val_loss: 316.7751\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 374.0557 - val_loss: 247.2646\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 427.3707 - val_loss: 325.3496\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 358.5554 - val_loss: 293.5688\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 371.5938 - val_loss: 234.2666\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 324.8735 - val_loss: 332.0097\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 393.7966 - val_loss: 465.5811\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 400.7880 - val_loss: 244.9251\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 323.4465 - val_loss: 255.5856\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 331.9728 - val_loss: 227.5591\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 360.1920 - val_loss: 287.0202\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 371.0242 - val_loss: 314.7635\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 376.5474 - val_loss: 364.7706\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 466.8291 - val_loss: 291.4953\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 314.5354 - val_loss: 217.8742\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 346.2930 - val_loss: 596.0993\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 367.4372 - val_loss: 329.5534\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 423.8842 - val_loss: 305.1960\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 406.3198 - val_loss: 242.0350\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 310.6889 - val_loss: 239.6611\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 326.4673 - val_loss: 347.2215\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 371.8058 - val_loss: 259.8467\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 350.2697 - val_loss: 655.7615\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 372.0910 - val_loss: 266.8569\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 340.0480 - val_loss: 229.6470\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 332.3104 - val_loss: 253.6471\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 400.8249 - val_loss: 296.3309\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 394.6951 - val_loss: 577.2979\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 395.2822 - val_loss: 198.7993\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 313.3824 - val_loss: 268.7702\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 331.9801 - val_loss: 405.2735\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 346.6343 - val_loss: 231.6501\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 396.2226 - val_loss: 443.3255\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 308.4216 - val_loss: 217.5729\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 299.0803 - val_loss: 216.0872\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 293.7895 - val_loss: 191.3672\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 293.1203 - val_loss: 472.1367\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 438.4025 - val_loss: 361.9326\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 381.9566 - val_loss: 206.1911\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 289.9179 - val_loss: 751.0560\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 331.2256 - val_loss: 230.1204\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 267.0532 - val_loss: 202.5797\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 294.6350 - val_loss: 189.4579\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 422.1446 - val_loss: 230.8449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 428.0420 - val_loss: 332.7440\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 285.2690 - val_loss: 194.0874\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 268.3803 - val_loss: 206.0237\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 292.8284 - val_loss: 184.4547\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 288.8857 - val_loss: 190.7278\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 274.3009 - val_loss: 178.4597\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 292.9621 - val_loss: 179.0411\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 275.8557 - val_loss: 487.1195\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 340.8444 - val_loss: 206.0330\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 295.8616 - val_loss: 195.4825\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 311.1367 - val_loss: 926.2656\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 277.7474 - val_loss: 295.8552\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 278.9055 - val_loss: 183.6227\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 327.6246 - val_loss: 431.7634\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 359.7826 - val_loss: 337.5189\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 310.2025 - val_loss: 167.4703\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 338.1169 - val_loss: 197.1665\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.5115 - val_loss: 273.8788\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 310.4060 - val_loss: 477.3974\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 277.1327 - val_loss: 220.2795\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 275.4920 - val_loss: 196.0743\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 340.3348 - val_loss: 737.5396\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 331.7223 - val_loss: 511.4503\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 333.9484 - val_loss: 198.9755\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 331.6514 - val_loss: 190.2031\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 316.3571 - val_loss: 391.2331\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 310.8687 - val_loss: 208.0964\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 261.4035 - val_loss: 172.7313\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 249.0009 - val_loss: 173.0174\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 297.7343 - val_loss: 227.2265\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 282.2852 - val_loss: 333.9334\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 349.9447 - val_loss: 187.9491\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 282.2836 - val_loss: 178.5507\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 255.6048 - val_loss: 206.0672\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.6863 - val_loss: 167.7953\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 264.7116 - val_loss: 169.7351\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 288.1128 - val_loss: 268.5041\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 324.2745 - val_loss: 165.8321\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 272.0812 - val_loss: 177.3140\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 254.8247 - val_loss: 161.3034\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 296.6074 - val_loss: 675.4934\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 270.1131 - val_loss: 284.7312\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 291.6298 - val_loss: 222.2467\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 287.4304 - val_loss: 172.0432\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 270.6828 - val_loss: 222.2265\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 271.2674 - val_loss: 174.3697\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 264.8548 - val_loss: 187.3036\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 357.7372 - val_loss: 171.3037\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 283.5212 - val_loss: 495.6972\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.7207 - val_loss: 167.7622\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 225.0193 - val_loss: 359.1019\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 320.9908 - val_loss: 175.4036\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 334.5977 - val_loss: 426.4446\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 269.6277 - val_loss: 171.3380\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 302.0525 - val_loss: 185.5556\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 292.1310 - val_loss: 162.8081\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 285.0838 - val_loss: 173.4350\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 281.7171 - val_loss: 211.9841\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.0263 - val_loss: 170.6862\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 251.2510 - val_loss: 253.8166\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.8106 - val_loss: 159.0880\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 234.4443 - val_loss: 180.7549\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.9777 - val_loss: 156.4278\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 261.0343 - val_loss: 187.4943\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 208.7159 - val_loss: 168.6446\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 242.8250 - val_loss: 184.6564\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 303.3641 - val_loss: 181.9450\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 312.2863 - val_loss: 328.6697\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 272.6949 - val_loss: 166.8757\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 275.5763 - val_loss: 151.9473\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 245.6945 - val_loss: 163.7565\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 323.5836 - val_loss: 175.1626\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.6784 - val_loss: 175.3848\n",
      "Epoch 178/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 210.7627 - val_loss: 425.5484\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 326.8274 - val_loss: 173.3547\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.9233 - val_loss: 177.6604\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.2386 - val_loss: 222.6294\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 311.5955 - val_loss: 175.1481\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 277.3542 - val_loss: 203.0622\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 443.2645 - val_loss: 198.0855\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.2870 - val_loss: 187.4906\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 228.2845 - val_loss: 155.8431\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 193.3438 - val_loss: 154.3696\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 230.5849 - val_loss: 220.7951\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.6710 - val_loss: 154.5768\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 316.9962 - val_loss: 174.0529\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 395.0204 - val_loss: 224.6259\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 248.7351 - val_loss: 244.1890\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 333.7723 - val_loss: 376.3243\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 252.3409 - val_loss: 145.2813\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 231.4328 - val_loss: 234.5340\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 246.9355 - val_loss: 213.8694\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 215.9899 - val_loss: 161.6984\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.7394 - val_loss: 144.0865\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 247.9518 - val_loss: 223.6657\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 289.0275 - val_loss: 365.2577\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 324.9186 - val_loss: 149.1005\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.2812 - val_loss: 155.6924\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 225.0757 - val_loss: 254.6712\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 258.4807 - val_loss: 157.4174\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 258.1609 - val_loss: 177.8432\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 262.6866 - val_loss: 784.8741\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 319.1650 - val_loss: 184.2330\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 227.2545 - val_loss: 178.3592\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 201.8530 - val_loss: 152.3104\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 226.7081 - val_loss: 214.5014\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 218.1610 - val_loss: 199.4760\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 213.8359 - val_loss: 254.4950\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 258.6877 - val_loss: 258.2915\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.7559 - val_loss: 195.2613\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 459.9675 - val_loss: 203.2555\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 232.5922 - val_loss: 190.2278\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 229.8405 - val_loss: 276.8984\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 260.0817 - val_loss: 162.9087\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 259.1341 - val_loss: 142.6143\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 292.6094 - val_loss: 413.5633\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 236.6936 - val_loss: 144.1273\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.3762 - val_loss: 312.8068\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.7674 - val_loss: 169.2128\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 242.9697 - val_loss: 168.9289\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 268.4926 - val_loss: 157.1939\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 253.1882 - val_loss: 182.0917\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 253.4358 - val_loss: 204.3555\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 229.2570 - val_loss: 190.8216\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 313.9573 - val_loss: 160.9938\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 209.0281 - val_loss: 156.6755\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 282.3541 - val_loss: 149.9669\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 282.4450 - val_loss: 133.6418\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 217.9498 - val_loss: 215.3785\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 215.0481 - val_loss: 198.9568\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 226.1592 - val_loss: 141.0920\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 383.0836 - val_loss: 168.3234\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 234.2733 - val_loss: 221.7988\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 206.9929 - val_loss: 250.9003\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 290.2098 - val_loss: 144.3741\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 192.6891 - val_loss: 141.0768\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 284.1686 - val_loss: 186.4984\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 188.0932 - val_loss: 132.8795\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 211.5951 - val_loss: 150.3683\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 192.4842 - val_loss: 138.3820\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 231.3549 - val_loss: 929.4742\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 352.8733 - val_loss: 144.3902\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 211.6535 - val_loss: 214.4691\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 258.2415 - val_loss: 163.4776\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 234.3052 - val_loss: 144.4497\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 316.8139 - val_loss: 147.4345\n",
      "Epoch 251/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 59us/step - loss: 248.7457 - val_loss: 157.7096\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 197.0318 - val_loss: 159.0168\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 242.0617 - val_loss: 138.1503\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 202.4442 - val_loss: 146.1798\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 190.6377 - val_loss: 166.9577\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 306.4133 - val_loss: 260.7202\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 243.8653 - val_loss: 142.2220\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 268.3197 - val_loss: 150.4342\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 213.3670 - val_loss: 143.6659\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 216.3847 - val_loss: 325.9328\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 198.0286 - val_loss: 160.4730\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 213.8640 - val_loss: 136.3115\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 399.7835 - val_loss: 169.3307\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 241.6304 - val_loss: 140.4007\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 204.0111 - val_loss: 136.3980\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 217.5214 - val_loss: 437.8957\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 234.8464 - val_loss: 142.9928\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 174.4061 - val_loss: 181.3217\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 209.3528 - val_loss: 167.0219\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 227.3700 - val_loss: 220.7469\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 213.9073 - val_loss: 311.4446\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 287.8523 - val_loss: 260.9682\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 218.3106 - val_loss: 147.1794\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 355.9616 - val_loss: 146.7351\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.4015 - val_loss: 145.7258\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 190.8499 - val_loss: 148.3839\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 260.4118 - val_loss: 143.5832\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.7514 - val_loss: 162.7486\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.1686 - val_loss: 216.6566\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 353.5889 - val_loss: 135.5564\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 369.9470 - val_loss: 195.8718\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.2090 - val_loss: 168.3251\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.4372 - val_loss: 149.7781\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.0322 - val_loss: 152.1990\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.3678 - val_loss: 130.9321\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 273.8374 - val_loss: 137.1575\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 443.9856 - val_loss: 581.6140\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 327.6421 - val_loss: 161.8338\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 240.8088 - val_loss: 160.7897\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 292.6251 - val_loss: 177.5055\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.8595 - val_loss: 170.2366\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 270.1627 - val_loss: 190.2019\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.7460 - val_loss: 143.2157\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.4323 - val_loss: 140.2481\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.2394 - val_loss: 168.5673\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 200.4172 - val_loss: 132.8843\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 218.2344 - val_loss: 383.3154\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 211.3310 - val_loss: 275.2879\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.3388 - val_loss: 134.1960\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 221.9230 - val_loss: 141.5570\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 207.8235 - val_loss: 189.5508\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.5365 - val_loss: 360.5425\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 244.1875 - val_loss: 136.4506\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.7702 - val_loss: 250.3875\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.7725 - val_loss: 143.9628\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.6233 - val_loss: 143.9535\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 276.4722 - val_loss: 1100.7894\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 480.1971 - val_loss: 154.0594\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 256.4908 - val_loss: 138.7767\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.1364 - val_loss: 141.2348\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 231.3781 - val_loss: 153.4097\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.4509 - val_loss: 150.1698\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 227.7314 - val_loss: 211.7388\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.1334 - val_loss: 329.6154\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 252.4591 - val_loss: 181.2628\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 334.0143 - val_loss: 128.4456\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.5879 - val_loss: 241.5931\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 207.1274 - val_loss: 131.6703\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.4886 - val_loss: 381.1733\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 185.4798 - val_loss: 151.8645\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 201.4567 - val_loss: 148.9756\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.4291 - val_loss: 134.1617\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 220.0335 - val_loss: 225.9134\n",
      "Epoch 324/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.9901 - val_loss: 214.7793\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 276.7013 - val_loss: 197.9677\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 207.9856 - val_loss: 177.2776\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 272.1021 - val_loss: 142.9759\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 198.2785 - val_loss: 396.7765\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 198.4162 - val_loss: 148.7771\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 182.5798 - val_loss: 140.6254\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 217.0229 - val_loss: 135.4349\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 218.1545 - val_loss: 130.4151\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.6414 - val_loss: 149.2764\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 192.6382 - val_loss: 190.1240\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 241.5759 - val_loss: 212.8518\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.3056 - val_loss: 137.1253\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 204.2253 - val_loss: 137.4532\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 302.5179 - val_loss: 144.2395\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 200.8493 - val_loss: 210.5439\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 222.3999 - val_loss: 266.6895\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 260.3340 - val_loss: 143.8715\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 180.5685 - val_loss: 132.9063\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.8265 - val_loss: 135.6662\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.9126 - val_loss: 198.1619\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.1140 - val_loss: 128.6090\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 234.1021 - val_loss: 329.5566\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.6700 - val_loss: 241.4355\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 235.3223 - val_loss: 137.1225\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 189.8252 - val_loss: 153.0923\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.9339 - val_loss: 150.3161\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.3009 - val_loss: 126.0821\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.1910 - val_loss: 137.3805\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.0003 - val_loss: 133.7478\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.4264 - val_loss: 167.6225\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.5662 - val_loss: 177.7045\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 194.6610 - val_loss: 166.5861\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 808.4898 - val_loss: 718.7220\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 386.1097 - val_loss: 160.5358\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 309.4428 - val_loss: 142.4974\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.2344 - val_loss: 176.8051\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 243.8630 - val_loss: 168.2407\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.8527 - val_loss: 173.2465\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 359.4615 - val_loss: 196.4156\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.9615 - val_loss: 232.5990\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.5161 - val_loss: 191.9539\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 210.7962 - val_loss: 201.7254\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 224.3875 - val_loss: 145.4468\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 223.6878 - val_loss: 186.8177\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 238.0398 - val_loss: 143.3057\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 226.8266 - val_loss: 135.5549\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 225.3774 - val_loss: 133.0864\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 188.7458 - val_loss: 174.6766\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 241.5589 - val_loss: 219.3033\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 286.0566 - val_loss: 169.0953\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.6103 - val_loss: 181.3839\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 232.6442 - val_loss: 215.5933\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 214.4852 - val_loss: 150.7030\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 208.1707 - val_loss: 136.2890\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.2051 - val_loss: 224.1827\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 211.1880 - val_loss: 142.6081\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 207.0031 - val_loss: 344.1324\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 296.0978 - val_loss: 178.2037\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.8802 - val_loss: 167.7648\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.2685 - val_loss: 142.4603\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 234.4033 - val_loss: 274.2363\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 246.8998 - val_loss: 225.4236\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.8741 - val_loss: 187.2375\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 207.4711 - val_loss: 132.1955\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 189.3724 - val_loss: 192.8695\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 229.2958 - val_loss: 181.1517\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.1108 - val_loss: 182.7620\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 288.1803 - val_loss: 130.9952\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.0215 - val_loss: 137.6997\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.2872 - val_loss: 144.9677\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 474.4734 - val_loss: 238.4783\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 304.6830 - val_loss: 197.7420\n",
      "Epoch 397/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 62us/step - loss: 242.2618 - val_loss: 172.7223\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 291.9760 - val_loss: 296.8226\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 271.9780 - val_loss: 157.7754\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.0228 - val_loss: 319.2480\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 273.8189 - val_loss: 159.1039\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 220.0760 - val_loss: 235.8929\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 273.3027 - val_loss: 175.7370\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 312.2086 - val_loss: 235.5689\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.4920 - val_loss: 254.6475\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.0112 - val_loss: 164.3699\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.3694 - val_loss: 156.8760\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.7366 - val_loss: 143.9725\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.9868 - val_loss: 140.8063\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 241.7710 - val_loss: 366.7736\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.3730 - val_loss: 154.3700\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.0787 - val_loss: 167.0111\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 225.7181 - val_loss: 147.9760\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.8988 - val_loss: 215.1060\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.5702 - val_loss: 250.3176\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 263.1815 - val_loss: 318.3248\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 219.7760 - val_loss: 249.9741\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 213.7156 - val_loss: 247.2541\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 229.9164 - val_loss: 189.7269\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.0688 - val_loss: 154.2864\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.5965 - val_loss: 138.0973\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.2714 - val_loss: 246.5161\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.0867 - val_loss: 160.0097\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 223.5718 - val_loss: 173.8425\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.7363 - val_loss: 252.6713\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 298.3716 - val_loss: 198.4307\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.3013 - val_loss: 140.7771\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.2346 - val_loss: 162.1876\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.8809 - val_loss: 229.6790\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.1451 - val_loss: 149.8498\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.6021 - val_loss: 150.7659\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 244.8470 - val_loss: 241.0206\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.9944 - val_loss: 455.1171\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.2097 - val_loss: 141.1578\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.5224 - val_loss: 279.3421\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 253.1964 - val_loss: 142.6974\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.6054 - val_loss: 234.5070\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.6612 - val_loss: 134.2628\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.7316 - val_loss: 143.8553\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 228.0768 - val_loss: 175.8698\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.9508 - val_loss: 143.7194\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.2222 - val_loss: 234.6139\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.7347 - val_loss: 137.5007\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.3194 - val_loss: 136.5700\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 204.7736 - val_loss: 141.1328\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.0546 - val_loss: 132.1113\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.4257 - val_loss: 342.9173\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.6551 - val_loss: 145.7046\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.8028 - val_loss: 222.6773\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.5705 - val_loss: 130.1394\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.5009 - val_loss: 198.8256\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.8974 - val_loss: 367.2892\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 178.7289 - val_loss: 137.5923\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 225.5063 - val_loss: 159.2329\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 211.4482 - val_loss: 195.8265\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 184.6959 - val_loss: 195.9326\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.4563 - val_loss: 157.0836\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.8408 - val_loss: 149.8337\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.2257 - val_loss: 135.5199\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 293.5511 - val_loss: 247.3712\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.0889 - val_loss: 148.5222\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.5007 - val_loss: 142.5395\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.0447 - val_loss: 208.2245\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 218.4514 - val_loss: 133.0422\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 194.3203 - val_loss: 223.4369\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 195.3360 - val_loss: 149.7244\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 184.5907 - val_loss: 136.6269\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 185.7615 - val_loss: 134.3789\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 192.7053 - val_loss: 144.2205\n",
      "Epoch 470/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.4954 - val_loss: 138.0699\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.8853 - val_loss: 213.1266\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 295.4691 - val_loss: 136.2053\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.8217 - val_loss: 126.9943\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.6188 - val_loss: 127.0865\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9065 - val_loss: 129.6857\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.8812 - val_loss: 192.1069\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.2359 - val_loss: 162.7713\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.0506 - val_loss: 145.1859\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.0935 - val_loss: 145.1453\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 265.1730 - val_loss: 248.0475\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 280.0028 - val_loss: 170.1285\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 321.2657 - val_loss: 357.3277\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 218.0563 - val_loss: 267.3084\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 251.1415 - val_loss: 151.2196\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 189.5721 - val_loss: 153.8522\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 221.7916 - val_loss: 146.3100\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 234.0373 - val_loss: 137.7326\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.6528 - val_loss: 152.9557\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.9278 - val_loss: 149.1802\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.0956 - val_loss: 145.2210\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 220.7835 - val_loss: 146.7008\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.2478 - val_loss: 138.6134\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.8778 - val_loss: 171.2608\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.3602 - val_loss: 176.7281\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.0481 - val_loss: 176.2193\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.6362 - val_loss: 145.5292\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.9583 - val_loss: 134.1307\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.9039 - val_loss: 134.0271\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.9020 - val_loss: 170.8969\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.1215 - val_loss: 194.3073\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.2506 - val_loss: 338.9556\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.6512 - val_loss: 216.3323\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.6521 - val_loss: 141.4711\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 260.1001 - val_loss: 173.6545\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.7263 - val_loss: 207.8662\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 220.0356 - val_loss: 196.0121\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.0164 - val_loss: 152.8428\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.2697 - val_loss: 372.3502\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.9254 - val_loss: 136.0140\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 190.6607 - val_loss: 153.0781\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.1007 - val_loss: 127.7978\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.6736 - val_loss: 161.5899\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.0435 - val_loss: 214.5782\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 239.3533 - val_loss: 178.3076\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.6756 - val_loss: 152.9590\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.9316 - val_loss: 140.2683\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.9952 - val_loss: 147.4838\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1344 - val_loss: 145.2737\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 231.6586 - val_loss: 230.4662\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 282.9879 - val_loss: 136.2734\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.1008 - val_loss: 154.8993\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.7791 - val_loss: 166.5208\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.9753 - val_loss: 192.3018\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.8060 - val_loss: 138.3566\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 197.1534 - val_loss: 173.9628\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 177.3173 - val_loss: 203.4712\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 390.3089 - val_loss: 169.1561\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.4358 - val_loss: 139.9281\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.8682 - val_loss: 192.0588\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 229.3447 - val_loss: 153.2059\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.2726 - val_loss: 140.2816\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.1693 - val_loss: 190.8151\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.7181 - val_loss: 749.8436\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 225.0769 - val_loss: 130.7673\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 185.6896 - val_loss: 168.5392\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 197.0439 - val_loss: 205.2819\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 182.4500 - val_loss: 125.6561\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.3932 - val_loss: 145.3367\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.6405 - val_loss: 177.8713\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.2040 - val_loss: 140.2160\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.8678 - val_loss: 237.2715\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.4868 - val_loss: 123.6156\n",
      "Epoch 543/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.6537 - val_loss: 158.3139\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.5129 - val_loss: 126.3985\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.4032 - val_loss: 136.1861\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.6967 - val_loss: 208.4884\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 303.3870 - val_loss: 155.8851\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.9259 - val_loss: 134.2165\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.4633 - val_loss: 186.3660\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.5394 - val_loss: 133.2375\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.7053 - val_loss: 314.0303\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.7431 - val_loss: 126.7083\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 239.7432 - val_loss: 163.5638\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.7143 - val_loss: 139.3221\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.7076 - val_loss: 224.9718\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.6412 - val_loss: 140.6206\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.3986 - val_loss: 150.3860\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.4057 - val_loss: 128.7482\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.8814 - val_loss: 195.4871\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.0751 - val_loss: 141.6151\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 335.1980 - val_loss: 157.1021\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 203.9733 - val_loss: 126.9970\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 179.6111 - val_loss: 126.1278\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 178.6465 - val_loss: 155.6569\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 186.0282 - val_loss: 151.9875\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.9791 - val_loss: 125.1244\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 194.6936 - val_loss: 131.3682\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.1388 - val_loss: 194.4385\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.2352 - val_loss: 155.6206\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 230.0033 - val_loss: 132.0130\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.5827 - val_loss: 141.1273\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.0649 - val_loss: 135.2150\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.3415 - val_loss: 309.2021\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.7513 - val_loss: 124.2132\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.1596 - val_loss: 133.1254\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 616.6977 - val_loss: 306.9972\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 433.2467 - val_loss: 192.0306\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 358.6116 - val_loss: 205.9062\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 291.1139 - val_loss: 168.0230\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 318.8050 - val_loss: 202.7658\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.5399 - val_loss: 153.6273\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.7311 - val_loss: 168.0554\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.7188 - val_loss: 153.0988\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 290.8294 - val_loss: 148.4068\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.0479 - val_loss: 151.3736\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.6849 - val_loss: 147.8306\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 239.5092 - val_loss: 152.2748\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 217.6909 - val_loss: 193.4468\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.2340 - val_loss: 141.3528\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 244.8657 - val_loss: 139.7473\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.3665 - val_loss: 138.8415\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.0322 - val_loss: 244.1645\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 267.2356 - val_loss: 272.9893\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.4746 - val_loss: 204.9764\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.4387 - val_loss: 139.2840\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 204.0772 - val_loss: 180.0429\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.6914 - val_loss: 172.2648\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.0166 - val_loss: 127.9039\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.3376 - val_loss: 159.3954\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.0349 - val_loss: 144.2789\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.0455 - val_loss: 177.5905\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 222.6016 - val_loss: 159.5264\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 226.3803 - val_loss: 204.5718\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 206.9676 - val_loss: 155.1772\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 210.9524 - val_loss: 126.7630\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 181.7286 - val_loss: 153.8323\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 225.3580 - val_loss: 245.9331\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.0484 - val_loss: 156.9571\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.7170 - val_loss: 189.9646\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 213.9510 - val_loss: 238.2434\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.2158 - val_loss: 166.8461\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.5882 - val_loss: 134.2877\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 199.8070 - val_loss: 147.0922\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 206.6758 - val_loss: 131.7475\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 241.6431 - val_loss: 198.9540\n",
      "Epoch 616/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.6344 - val_loss: 185.1224\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.8174 - val_loss: 445.9965\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 227.6026 - val_loss: 183.0015\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 217.4243 - val_loss: 136.5490\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.9211 - val_loss: 129.7882\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.4545 - val_loss: 140.2539\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.3922 - val_loss: 175.3805\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.0830 - val_loss: 241.9903\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.5474 - val_loss: 158.0954\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.1640 - val_loss: 139.9206\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.7951 - val_loss: 173.1557\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.3749 - val_loss: 136.3354\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.3539 - val_loss: 175.4774\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.9700 - val_loss: 132.8868\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 192.2545 - val_loss: 141.5095\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 187.4547 - val_loss: 159.4953\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 197.1810 - val_loss: 158.9160\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.6127 - val_loss: 174.5148\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.0377 - val_loss: 143.8670\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.7153 - val_loss: 146.8399\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.2761 - val_loss: 130.2958\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.6115 - val_loss: 153.4714\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.9585 - val_loss: 150.4902\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 297.1562 - val_loss: 139.5994\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.5975 - val_loss: 160.8630\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.2786 - val_loss: 181.4581\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.2375 - val_loss: 249.3592\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.9547 - val_loss: 127.1720\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 211.4056 - val_loss: 131.9512\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.8641 - val_loss: 139.2971\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 205.6407 - val_loss: 205.0154\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.5190 - val_loss: 130.2899\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 175.6861 - val_loss: 244.7523\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.2413 - val_loss: 154.4259\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.9321 - val_loss: 231.4985\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.5694 - val_loss: 145.8689\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.4194 - val_loss: 137.9931\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.5875 - val_loss: 143.3051\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.6092 - val_loss: 237.7888\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.6666 - val_loss: 173.3277\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.4363 - val_loss: 130.2286\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 236.7740 - val_loss: 132.4948\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.9572 - val_loss: 181.7228\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.8585 - val_loss: 145.4401\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.6738 - val_loss: 221.1763\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.3119 - val_loss: 129.3459\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.0960 - val_loss: 131.7335\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 234.4837 - val_loss: 213.4045\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 201.9809 - val_loss: 124.6790\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.6444 - val_loss: 145.8893\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.4293 - val_loss: 136.1936\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.5130 - val_loss: 251.2455\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.6496 - val_loss: 172.3768\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.1229 - val_loss: 162.0147\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.6401 - val_loss: 220.7601\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.3336 - val_loss: 122.7380\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 162.6097 - val_loss: 124.0349\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 208.9915 - val_loss: 180.5580\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 200.1461 - val_loss: 139.8514\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 187.4779 - val_loss: 130.7316\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 184.5063 - val_loss: 151.8781\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 211.9357 - val_loss: 190.4627\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.4782 - val_loss: 155.1237\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1738 - val_loss: 144.2070\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.6532 - val_loss: 132.2019\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.1743 - val_loss: 149.1924\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 178.7495 - val_loss: 130.5011\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.6643 - val_loss: 128.4791\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.0662 - val_loss: 295.4576\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.8086 - val_loss: 123.6384\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.6800 - val_loss: 172.1638\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.9199 - val_loss: 192.3113\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.5506 - val_loss: 190.4044\n",
      "Epoch 689/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.6517 - val_loss: 164.8789\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.2527 - val_loss: 205.5023\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.7185 - val_loss: 124.9528\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.7508 - val_loss: 155.2624\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.9098 - val_loss: 312.4005\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 234.7770 - val_loss: 155.8221\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.4804 - val_loss: 137.5154\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.1660 - val_loss: 157.3141\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 309.1354 - val_loss: 148.1610\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.6096 - val_loss: 137.9535\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.6563 - val_loss: 124.8662\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.2022 - val_loss: 144.4141\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.2587 - val_loss: 154.5078\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.8337 - val_loss: 184.5467\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.3481 - val_loss: 122.9648\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.5700 - val_loss: 210.5617\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.5378 - val_loss: 268.1786\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.6247 - val_loss: 154.9820\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.1838 - val_loss: 223.6930\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 240.1682 - val_loss: 183.1596\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.8120 - val_loss: 133.1634\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.6072 - val_loss: 195.0702\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.7667 - val_loss: 138.3480\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.1686 - val_loss: 144.1571\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.2098 - val_loss: 239.7088\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.4208 - val_loss: 194.4226\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 213.8229 - val_loss: 253.0573\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2910 - val_loss: 136.8105\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.9199 - val_loss: 124.6635\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.3194 - val_loss: 136.1969\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 157.4285 - val_loss: 165.2647\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 173.7391 - val_loss: 155.5456\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 171.1048 - val_loss: 200.3472\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.0595 - val_loss: 138.6713\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 398.9531 - val_loss: 193.0019\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.0593 - val_loss: 398.7428\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.5725 - val_loss: 127.1933\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2277 - val_loss: 124.5371\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.5198 - val_loss: 227.3176\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.0522 - val_loss: 142.0650\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.1055 - val_loss: 128.0961\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.3191 - val_loss: 139.8851\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.1597 - val_loss: 345.4737\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 205.7898 - val_loss: 134.7262\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.6292 - val_loss: 136.1165\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.0513 - val_loss: 318.2489\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.0427 - val_loss: 128.4163\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.6065 - val_loss: 124.2700\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 178.1136 - val_loss: 125.8317\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.0828 - val_loss: 206.4385\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.2502 - val_loss: 152.0631\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.4417 - val_loss: 141.6130\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.0853 - val_loss: 161.5030\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 205.4135 - val_loss: 177.5555\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 171.2181 - val_loss: 126.1091\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 164.5496 - val_loss: 177.9912\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 211.4048 - val_loss: 234.2537\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.7929 - val_loss: 117.5495\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.5741 - val_loss: 140.5826\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.6461 - val_loss: 152.0030\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.2571 - val_loss: 150.7583\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.8013 - val_loss: 131.3546\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.4618 - val_loss: 138.5049\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 229.4166 - val_loss: 189.3824\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.1168 - val_loss: 218.6611\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.4885 - val_loss: 133.9682\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.8288 - val_loss: 138.6077\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.9351 - val_loss: 133.2664\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.1242 - val_loss: 139.0685\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.1628 - val_loss: 150.1705\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3833 - val_loss: 122.8225\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.6459 - val_loss: 124.6837\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.4126 - val_loss: 126.9736\n",
      "Epoch 762/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 241.8588 - val_loss: 212.0663\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.5295 - val_loss: 157.2890\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.3488 - val_loss: 118.6823\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.3043 - val_loss: 119.6915\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.7067 - val_loss: 188.1733\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.1002 - val_loss: 210.1741\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.6324 - val_loss: 186.0223\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 192.2778 - val_loss: 157.8310\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.7605 - val_loss: 135.3469\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 175.7954 - val_loss: 135.8993\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.7356 - val_loss: 125.7293\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.0474 - val_loss: 131.5193\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 247.6912 - val_loss: 138.3822\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.8012 - val_loss: 159.1782\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2781 - val_loss: 140.4647\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 268.2260 - val_loss: 675.0146\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 297.7703 - val_loss: 173.7476\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.9560 - val_loss: 123.8715\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1363 - val_loss: 136.0677\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5304 - val_loss: 149.8028\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.1991 - val_loss: 124.3314\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.9239 - val_loss: 132.1530\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3166 - val_loss: 139.1224\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.0855 - val_loss: 126.2220\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.1658 - val_loss: 140.7151\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.2139 - val_loss: 127.7522\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.9859 - val_loss: 183.1361\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6800 - val_loss: 167.0754\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.6132 - val_loss: 155.8034\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7989 - val_loss: 128.3720\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.6630 - val_loss: 229.0392\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3364 - val_loss: 210.6758\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.3324 - val_loss: 137.5708\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.5941 - val_loss: 122.3813\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.6263 - val_loss: 253.6930\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.4409 - val_loss: 135.9436\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.8023 - val_loss: 117.2896\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.1402 - val_loss: 164.5719\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4341 - val_loss: 134.5719\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 260.2322 - val_loss: 135.3874\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 204.4583 - val_loss: 142.8815\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.4535 - val_loss: 138.8689\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.1379 - val_loss: 178.4944\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4589 - val_loss: 131.7163\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.5685 - val_loss: 137.0785\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.7421 - val_loss: 120.1089\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3732 - val_loss: 199.0272\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.7381 - val_loss: 239.3211\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.9860 - val_loss: 160.8407\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.4048 - val_loss: 129.7464\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.5002 - val_loss: 211.8028\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 168.6095 - val_loss: 161.6443\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 219.7200 - val_loss: 133.0509\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 178.9008 - val_loss: 162.0872\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 167.2041 - val_loss: 131.7035\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.7394 - val_loss: 134.2314\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4607 - val_loss: 354.9995\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.3811 - val_loss: 173.4246\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.7387 - val_loss: 121.6280\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.3175 - val_loss: 119.0387\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.7889 - val_loss: 221.8996\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 216.6313 - val_loss: 238.3621\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.7494 - val_loss: 134.1417\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.9858 - val_loss: 139.4515\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.5667 - val_loss: 367.4365\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.4812 - val_loss: 135.9268\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 164.1595 - val_loss: 118.5228\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.0247 - val_loss: 127.2050\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.1410 - val_loss: 174.2206\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.5334 - val_loss: 119.3063\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.1407 - val_loss: 137.9404\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.3354 - val_loss: 194.6662\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.0145 - val_loss: 117.1989\n",
      "Epoch 835/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.0880 - val_loss: 142.5490\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.3656 - val_loss: 124.1634\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.8795 - val_loss: 121.7632\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.8298 - val_loss: 146.3694\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.7255 - val_loss: 124.6934\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.9772 - val_loss: 139.2200\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 157.7637 - val_loss: 115.6881\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.1389 - val_loss: 287.8909\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 261.9437 - val_loss: 122.5897\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.6400 - val_loss: 135.5553\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.6257 - val_loss: 121.1936\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.3590 - val_loss: 125.2924\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.9589 - val_loss: 135.6783\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 195.0557 - val_loss: 921.9711\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 214.4313 - val_loss: 128.8617\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.5897 - val_loss: 122.0683\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.3575 - val_loss: 122.6595\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.3051 - val_loss: 135.7380\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5125 - val_loss: 130.2724\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.0769 - val_loss: 122.7117\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 203.9656 - val_loss: 175.9708\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.0320 - val_loss: 142.8153\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.9904 - val_loss: 165.3867\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.5908 - val_loss: 114.4352\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.9499 - val_loss: 172.5247\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.3413 - val_loss: 148.3322\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.8767 - val_loss: 120.4745\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.3928 - val_loss: 175.0880\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.0359 - val_loss: 150.0965\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7759 - val_loss: 127.7729\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.0889 - val_loss: 120.5662\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.9445 - val_loss: 140.1780\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.8447 - val_loss: 170.3415\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6216 - val_loss: 151.6255\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.5370 - val_loss: 163.8058\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.4997 - val_loss: 138.7240\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 181.1539 - val_loss: 175.6238\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.4390 - val_loss: 128.5969\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4164 - val_loss: 131.3600\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 321.7775 - val_loss: 133.4543\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.7287 - val_loss: 124.0206\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.3736 - val_loss: 121.9870\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.7432 - val_loss: 118.7597\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7160 - val_loss: 113.5447\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.1758 - val_loss: 208.0233\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 343.5166 - val_loss: 133.7350\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 157.8430 - val_loss: 128.1354\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 149.2288 - val_loss: 135.2972\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 158.5130 - val_loss: 122.1825\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 145.3969 - val_loss: 114.4324\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 153.9647 - val_loss: 119.4503\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 202.6515 - val_loss: 127.6057\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 151.5421 - val_loss: 130.2449\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 164.5222 - val_loss: 355.6878\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 148.8816 - val_loss: 119.1077\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 151.5405 - val_loss: 131.4787\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 166.9613 - val_loss: 142.8873\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 224.2255 - val_loss: 136.2672\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 171.0312 - val_loss: 118.9885\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 150.8259 - val_loss: 118.9654\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 176.9886 - val_loss: 127.9205\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 166.8318 - val_loss: 119.2685\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 155.6002 - val_loss: 133.6949\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 225.1373 - val_loss: 213.6866\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 162.7741 - val_loss: 121.0663\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 167.6455 - val_loss: 121.7645\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 152.6547 - val_loss: 118.2670\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 200.9046 - val_loss: 139.1127\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 273.2229 - val_loss: 140.4327\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 180.0257 - val_loss: 124.3353\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 173.0961 - val_loss: 159.9295\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 166.9394 - val_loss: 116.5322\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 162.9078 - val_loss: 129.8209\n",
      "Epoch 908/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 62us/step - loss: 173.7225 - val_loss: 162.2530\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 171.8263 - val_loss: 119.1433\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 166.4722 - val_loss: 133.7169\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.2760 - val_loss: 151.2868\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 184.5457 - val_loss: 177.9231\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 161.0115 - val_loss: 122.4116\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 154.4381 - val_loss: 120.5843\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 171.4812 - val_loss: 115.0956\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 147.6799 - val_loss: 120.3507\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 163.0349 - val_loss: 228.6879\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 170.8664 - val_loss: 127.6601\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 166.8250 - val_loss: 225.6381\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 306.5143 - val_loss: 124.9675\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 153.4357 - val_loss: 116.9630\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.8493 - val_loss: 119.2378\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 148.4122 - val_loss: 124.3630\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 142.0799 - val_loss: 121.8784\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 174.7825 - val_loss: 124.0370\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 169.6236 - val_loss: 116.4753\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.5684 - val_loss: 124.6894\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 155.5656 - val_loss: 126.2351\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.7199 - val_loss: 120.0615\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8192 - val_loss: 127.0165\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 232.2272 - val_loss: 134.6971\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.1241 - val_loss: 115.8316\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 187.3156 - val_loss: 119.4850\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.2150 - val_loss: 140.3453\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7663 - val_loss: 139.2541\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3086 - val_loss: 136.3383\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.7995 - val_loss: 239.8972\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.1856 - val_loss: 162.8797\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.6210 - val_loss: 120.9972\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.4145 - val_loss: 142.7148\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2276 - val_loss: 129.7125\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 169.2664 - val_loss: 142.7812\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 148.8261 - val_loss: 113.3473\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 173.6018 - val_loss: 119.4466\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 174.5762 - val_loss: 115.5908\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4994 - val_loss: 141.7289\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2725 - val_loss: 119.8307\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.8056 - val_loss: 122.3873\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.7632 - val_loss: 153.7957\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 219.6517 - val_loss: 150.0576\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.3104 - val_loss: 141.3479\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 203.1337 - val_loss: 121.2653\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.7924 - val_loss: 140.7894\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.8466 - val_loss: 139.8209\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.9170 - val_loss: 121.5730\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.8927 - val_loss: 154.7611\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 204.2068 - val_loss: 119.6835\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 174.7024 - val_loss: 144.3632\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 250.8380 - val_loss: 122.9170\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.2154 - val_loss: 129.6428\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.3815 - val_loss: 118.6752\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.7564 - val_loss: 122.7843\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.0224 - val_loss: 201.1333\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.3185 - val_loss: 114.1957\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.6837 - val_loss: 122.7773\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8117 - val_loss: 115.7944\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 222.5389 - val_loss: 125.6726\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 153.8933 - val_loss: 153.2258\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3296 - val_loss: 115.4579\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.9118 - val_loss: 137.3871\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.7647 - val_loss: 143.1014\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4901 - val_loss: 137.9597\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.0645 - val_loss: 362.1533\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 276.6960 - val_loss: 129.0338\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2930 - val_loss: 138.6689\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1444 - val_loss: 129.5973\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.6531 - val_loss: 131.0871\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.5207 - val_loss: 327.9412\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 163.1002 - val_loss: 120.9440\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 150.1827 - val_loss: 122.5815\n",
      "Epoch 981/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 156.6275 - val_loss: 292.5024\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 164.1322 - val_loss: 138.2175\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 160.8819 - val_loss: 115.0014\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 187.9053 - val_loss: 135.5902\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.8495 - val_loss: 139.6484\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.5806 - val_loss: 150.7923\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.4245 - val_loss: 150.8426\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.7717 - val_loss: 156.3600\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.1891 - val_loss: 136.5340\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.8436 - val_loss: 136.2597\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5557 - val_loss: 120.5538\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.4072 - val_loss: 123.4830\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.7497 - val_loss: 161.1677\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4390 - val_loss: 160.5831\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8278 - val_loss: 128.6234\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.4696 - val_loss: 117.9994\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.3794 - val_loss: 118.1258\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.9372 - val_loss: 132.8598\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4420 - val_loss: 146.6314\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.0868 - val_loss: 192.6829\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.1292 - val_loss: 257.9280\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 295.7077 - val_loss: 123.0348\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.9124 - val_loss: 171.5706\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.2149 - val_loss: 122.7528\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4316 - val_loss: 117.5039\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1313 - val_loss: 119.1094\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.1133 - val_loss: 137.7043\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 283.5529 - val_loss: 522.5073\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 343.7731 - val_loss: 154.9367\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.6631 - val_loss: 121.9856\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 157.0484 - val_loss: 128.0864\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 150.8806 - val_loss: 124.8487\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.8242 - val_loss: 118.3052\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 208.9410 - val_loss: 127.5434\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 200.5371 - val_loss: 139.8051\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.8379 - val_loss: 120.0243\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7283 - val_loss: 220.7978\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5851 - val_loss: 111.9661\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.1713 - val_loss: 134.2928\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.0073 - val_loss: 140.1533\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 310.3429 - val_loss: 136.6677\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5491 - val_loss: 130.5470\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3127 - val_loss: 128.2613\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.2090 - val_loss: 124.8110\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5487 - val_loss: 114.1224\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.7521 - val_loss: 115.7047\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.2290 - val_loss: 143.3949\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.7859 - val_loss: 122.8447\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.0419 - val_loss: 123.1538\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.8776 - val_loss: 119.5152\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.3544 - val_loss: 139.2948\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9545 - val_loss: 117.8025\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.5214 - val_loss: 147.2087\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.2906 - val_loss: 123.1296\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.1731 - val_loss: 137.2653\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.8937 - val_loss: 145.9756\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 147.2573 - val_loss: 163.8467\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.1347 - val_loss: 129.0983\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7204 - val_loss: 121.5630\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.1998 - val_loss: 121.9137\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.1044 - val_loss: 183.6782\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.2545 - val_loss: 143.0387\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.1041 - val_loss: 119.9663\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2136 - val_loss: 118.0609\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.4004 - val_loss: 116.0277\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7900 - val_loss: 114.2525\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.9812 - val_loss: 130.7611\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5961 - val_loss: 148.3967\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.4234 - val_loss: 126.1408\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9214 - val_loss: 115.3312\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2872 - val_loss: 217.1742\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6160 - val_loss: 117.2100\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3508 - val_loss: 122.5102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 164.2324 - val_loss: 124.6137\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.7458 - val_loss: 179.9532\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4927 - val_loss: 133.1979\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.5226 - val_loss: 114.0889\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 200.9790 - val_loss: 150.8199\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.8024 - val_loss: 147.0427\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.1461 - val_loss: 126.6518\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.5813 - val_loss: 141.5806\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.8457 - val_loss: 241.3910\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.4733 - val_loss: 221.8029\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.3044 - val_loss: 235.6108\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.2177 - val_loss: 135.6147\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7357 - val_loss: 113.8610\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.4811 - val_loss: 135.7086\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.7785 - val_loss: 116.5407\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1716 - val_loss: 130.3126\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.8849 - val_loss: 174.4282\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.9610 - val_loss: 125.9680\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 195.0034 - val_loss: 147.9270\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.1377 - val_loss: 116.2811\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.3220 - val_loss: 127.7412\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4215 - val_loss: 128.7746\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0042 - val_loss: 121.3990\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2379 - val_loss: 123.1568\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3003 - val_loss: 129.0569\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.4420 - val_loss: 134.8553\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.0676 - val_loss: 141.5334\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.2012 - val_loss: 135.1103\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 152.7458 - val_loss: 115.8707\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 175.9386 - val_loss: 344.0305\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 168.3656 - val_loss: 135.3183\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9009 - val_loss: 119.2516\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.2162 - val_loss: 121.0344\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.0542 - val_loss: 117.1849\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.6107 - val_loss: 175.3985\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 203.1225 - val_loss: 141.8592\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.9936 - val_loss: 168.9876\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0261 - val_loss: 181.3173\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.1003 - val_loss: 256.0900\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.6398 - val_loss: 116.7487\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.4004 - val_loss: 125.7542\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7003 - val_loss: 131.6438\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.8827 - val_loss: 164.0088\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.8119 - val_loss: 117.8371\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.7116 - val_loss: 114.3544\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9958 - val_loss: 112.4806\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9531 - val_loss: 115.1720\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.6287 - val_loss: 237.0051\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.0729 - val_loss: 148.7488\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.0412 - val_loss: 142.8170\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.6093 - val_loss: 144.0265\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.4874 - val_loss: 117.1429\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 211.4128 - val_loss: 159.1911\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7335 - val_loss: 118.4245\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.1461 - val_loss: 150.5186\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.9281 - val_loss: 154.0049\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.5066 - val_loss: 138.4043\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.7238 - val_loss: 112.6462\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 356.1374 - val_loss: 145.2234\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 222.9285 - val_loss: 122.2106\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7535 - val_loss: 129.7755\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.5283 - val_loss: 155.6875\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.5114 - val_loss: 118.1047\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7548 - val_loss: 191.5101\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9540 - val_loss: 116.7487\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.5163 - val_loss: 148.6147\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.2334 - val_loss: 127.7413\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.1664 - val_loss: 119.3540\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3939 - val_loss: 128.3951\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 273.5513 - val_loss: 171.7882\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7587 - val_loss: 143.2397\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.4764 - val_loss: 123.8498\n",
      "Epoch 1126/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.3046 - val_loss: 179.7496\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.6713 - val_loss: 132.6957\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3744 - val_loss: 124.2940\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.8974 - val_loss: 183.8012\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.3036 - val_loss: 288.6690\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.9166 - val_loss: 140.4755\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.5801 - val_loss: 126.2552\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4785 - val_loss: 123.8396\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.0601 - val_loss: 179.0428\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9622 - val_loss: 137.2514\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.9174 - val_loss: 192.4324\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.9679 - val_loss: 131.0070\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8161 - val_loss: 127.8959\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.1046 - val_loss: 136.7700\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0028 - val_loss: 117.0030\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 144.5156 - val_loss: 117.2613\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5529 - val_loss: 117.0517\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.5960 - val_loss: 128.2085\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.9407 - val_loss: 188.4403\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.7864 - val_loss: 492.9115\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.4503 - val_loss: 147.8320\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9355 - val_loss: 182.8474\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.0891 - val_loss: 140.4242\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4270 - val_loss: 110.0700\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8332 - val_loss: 126.9096\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.6412 - val_loss: 138.1036\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 183.2142 - val_loss: 117.2628\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 146.1539 - val_loss: 117.1512\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 160.9499 - val_loss: 122.3499\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.0608 - val_loss: 176.5313\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.5738 - val_loss: 162.8863\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.7877 - val_loss: 137.5877\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 263.1354 - val_loss: 121.6045\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6153 - val_loss: 126.3729\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.9257 - val_loss: 118.6959\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.6547 - val_loss: 157.8018\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.6490 - val_loss: 120.2608\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8493 - val_loss: 140.0201\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6989 - val_loss: 164.1225\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.6879 - val_loss: 117.4358\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 172.1292 - val_loss: 174.4983\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.5750 - val_loss: 112.1422\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2478 - val_loss: 119.5774\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.7236 - val_loss: 147.6001\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 175.8007 - val_loss: 125.3685\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1455 - val_loss: 132.9934\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.5228 - val_loss: 117.1904\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.5809 - val_loss: 118.2069\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.9643 - val_loss: 131.1872\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.6982 - val_loss: 116.3630\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 257.3582 - val_loss: 231.7749\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.4601 - val_loss: 116.8165\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9461 - val_loss: 134.7099\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9014 - val_loss: 114.1254\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.6388 - val_loss: 115.3657\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.2140 - val_loss: 146.8840\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0768 - val_loss: 139.5172\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.1636 - val_loss: 161.6953\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5858 - val_loss: 127.1674\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.5210 - val_loss: 131.5384\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.0760 - val_loss: 133.2799\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.2492 - val_loss: 129.3202\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4545 - val_loss: 144.3620\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.2059 - val_loss: 117.1236\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7515 - val_loss: 122.5524\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4162 - val_loss: 174.5591\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4681 - val_loss: 132.7789\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.3043 - val_loss: 121.8065\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.0411 - val_loss: 125.0618\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.4663 - val_loss: 112.3528\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.1612 - val_loss: 199.2378\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.0688 - val_loss: 143.8286\n",
      "Epoch 1198/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.1895 - val_loss: 145.9156\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.9937 - val_loss: 129.5575\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.5299 - val_loss: 121.4293\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9454 - val_loss: 141.2539\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.2585 - val_loss: 741.6467\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 462.5007 - val_loss: 149.1045\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.0738 - val_loss: 161.0491\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.8008 - val_loss: 156.5027\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.9007 - val_loss: 129.0666\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5300 - val_loss: 119.3342\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5582 - val_loss: 132.7306\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.5856 - val_loss: 112.4032\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7215 - val_loss: 136.7799\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.7748 - val_loss: 125.2010\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.0257 - val_loss: 136.5574\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 265.9558 - val_loss: 174.3663\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.3058 - val_loss: 172.1384\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.8575 - val_loss: 148.1431\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.1009 - val_loss: 123.3188\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.3337 - val_loss: 117.7182\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.7049 - val_loss: 120.7646\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9950 - val_loss: 129.9339\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.2688 - val_loss: 136.7893\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6330 - val_loss: 125.1251\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 154.4484 - val_loss: 113.9770\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 154.0891 - val_loss: 116.7841\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 210.9517 - val_loss: 239.3991\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.1462 - val_loss: 130.6460\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6429 - val_loss: 144.0025\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.5784 - val_loss: 127.6436\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.8644 - val_loss: 119.2862\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 230.6745 - val_loss: 130.8137\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.8708 - val_loss: 118.5131\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3151 - val_loss: 204.4475\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.0544 - val_loss: 135.6751\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.9097 - val_loss: 118.7898\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.3639 - val_loss: 121.6239\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4427 - val_loss: 137.6880\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4987 - val_loss: 117.0763\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.0079 - val_loss: 123.4675\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.1779 - val_loss: 121.0910\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6751 - val_loss: 121.0044\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0435 - val_loss: 130.6602\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5059 - val_loss: 123.4159\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.0818 - val_loss: 126.4880\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8262 - val_loss: 112.6329\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 149.8104 - val_loss: 140.5842\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 146.6333 - val_loss: 112.7512\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.8646 - val_loss: 137.5954\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 209.4157 - val_loss: 145.9367\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.1114 - val_loss: 126.5569\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8642 - val_loss: 117.8967\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.3967 - val_loss: 116.9497\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4331 - val_loss: 113.1504\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3302 - val_loss: 116.3729\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1579 - val_loss: 116.3405\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5344 - val_loss: 181.8510\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.2439 - val_loss: 123.3324\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5700 - val_loss: 127.2088\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 164.0859 - val_loss: 126.6805\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9318 - val_loss: 139.8203\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8735 - val_loss: 116.6541\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.5455 - val_loss: 130.6681\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.7504 - val_loss: 121.3540\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 311.8615 - val_loss: 227.9643\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 277.3617 - val_loss: 158.1440\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 234.2315 - val_loss: 142.4552\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.6898 - val_loss: 173.3429\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.5757 - val_loss: 192.4958\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.3892 - val_loss: 143.2281\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.0355 - val_loss: 168.3383\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.1603 - val_loss: 134.1069\n",
      "Epoch 1270/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.2595 - val_loss: 128.2838\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.7931 - val_loss: 128.7678\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.5971 - val_loss: 173.9090\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.8753 - val_loss: 136.8251\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.5419 - val_loss: 124.0171\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1455 - val_loss: 114.3255\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3998 - val_loss: 190.2430\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.3267 - val_loss: 112.7613\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.4653 - val_loss: 156.7223\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.5418 - val_loss: 116.9087\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.0069 - val_loss: 159.4666\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.3917 - val_loss: 129.8681\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.8356 - val_loss: 131.5530\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1635 - val_loss: 134.7523\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.2412 - val_loss: 160.5859\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.5790 - val_loss: 170.4486\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.4107 - val_loss: 116.6098\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.5228 - val_loss: 126.9405\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4626 - val_loss: 128.4913\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.6234 - val_loss: 127.6025\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.2162 - val_loss: 122.2095\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.5377 - val_loss: 148.8692\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 156.3229 - val_loss: 126.6288\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.2771 - val_loss: 160.5926\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 150.0550 - val_loss: 116.2920\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.7443 - val_loss: 125.1822\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.3884 - val_loss: 120.4729\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.5171 - val_loss: 166.4672\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8655 - val_loss: 116.0691\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 220.6334 - val_loss: 144.6824\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.7168 - val_loss: 121.4571\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.1527 - val_loss: 122.7255\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.8006 - val_loss: 120.3366\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3490 - val_loss: 186.1065\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.0676 - val_loss: 124.1456\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5130 - val_loss: 131.0056\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.6815 - val_loss: 118.2116\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4338 - val_loss: 134.8575\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.6552 - val_loss: 189.5144\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.6253 - val_loss: 116.8718\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.4211 - val_loss: 122.9130\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.7097 - val_loss: 112.8204\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3096 - val_loss: 120.3702\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4067 - val_loss: 152.4623\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.6451 - val_loss: 109.5323\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.7206 - val_loss: 114.5566\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.8199 - val_loss: 177.7708\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.0387 - val_loss: 111.2502\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.3686 - val_loss: 128.0346\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.5727 - val_loss: 112.9850\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.4745 - val_loss: 119.8834\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.5246 - val_loss: 110.6908\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.9826 - val_loss: 208.1780\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.1848 - val_loss: 121.9022\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.1099 - val_loss: 124.4644\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0991 - val_loss: 132.6306\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.6915 - val_loss: 114.7951\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.7154 - val_loss: 132.6146\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5169 - val_loss: 122.7277\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.0087 - val_loss: 216.3421\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.2958 - val_loss: 120.7379\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9196 - val_loss: 111.6383\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.1939 - val_loss: 114.3002\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.2957 - val_loss: 156.0762\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4632 - val_loss: 123.5568\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1164 - val_loss: 125.7207\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 205.0225 - val_loss: 182.1671\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9436 - val_loss: 151.2140\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.6876 - val_loss: 115.6548\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.3715 - val_loss: 129.9608\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0644 - val_loss: 132.0812\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.3296 - val_loss: 115.3878\n",
      "Epoch 1342/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6563 - val_loss: 145.9913\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.7473 - val_loss: 184.2338\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.4132 - val_loss: 143.8971\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 213.6767 - val_loss: 145.6509\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5390 - val_loss: 121.0517\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5885 - val_loss: 150.8377\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1346 - val_loss: 115.9331\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.0242 - val_loss: 118.5413\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.2405 - val_loss: 133.9902\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.6053 - val_loss: 116.2956\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6349 - val_loss: 114.4614\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6242 - val_loss: 113.3349\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 252.1324 - val_loss: 119.1838\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.8489 - val_loss: 132.4761\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0412 - val_loss: 125.6136\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.8716 - val_loss: 120.1850\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1915 - val_loss: 118.0720\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.5692 - val_loss: 114.4141\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.0646 - val_loss: 121.9596\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.6785 - val_loss: 135.8049\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 178.3645 - val_loss: 123.8004\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 149.4923 - val_loss: 118.8507\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 144.1321 - val_loss: 145.4621\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 315.3980 - val_loss: 481.2510\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.8954 - val_loss: 135.2010\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 185.0483 - val_loss: 132.0088\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7285 - val_loss: 149.7563\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.2114 - val_loss: 125.0715\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.7994 - val_loss: 115.3497\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4652 - val_loss: 147.5864\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2853 - val_loss: 118.4911\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8370 - val_loss: 153.9124\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.7644 - val_loss: 125.0683\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8161 - val_loss: 114.0800\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0500 - val_loss: 145.1516\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.9903 - val_loss: 119.6179\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6802 - val_loss: 118.4953\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.8927 - val_loss: 127.0136\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7659 - val_loss: 151.6803\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.1359 - val_loss: 130.6789\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 266.7129 - val_loss: 127.0915\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.0910 - val_loss: 159.0406\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.9277 - val_loss: 118.5875\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.9162 - val_loss: 112.8443\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2118 - val_loss: 128.3109\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 214.3112 - val_loss: 155.2308\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.8482 - val_loss: 159.2651\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.9333 - val_loss: 120.2269\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.1980 - val_loss: 125.3101\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.1965 - val_loss: 168.4295\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8259 - val_loss: 111.7275\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.9092 - val_loss: 116.9012\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.5352 - val_loss: 164.5292\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.2136 - val_loss: 116.9739\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.8610 - val_loss: 134.5765\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3421 - val_loss: 121.7644\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.4802 - val_loss: 122.7925\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3875 - val_loss: 127.7901\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.8091 - val_loss: 121.7282\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.4834 - val_loss: 127.1984\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.9431 - val_loss: 124.2640\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1134 - val_loss: 130.7269\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6116 - val_loss: 119.9063\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.6890 - val_loss: 134.3034\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2384 - val_loss: 139.6397\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5195 - val_loss: 144.9229\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.4434 - val_loss: 115.3642\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.1378 - val_loss: 136.1217\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3572 - val_loss: 209.1132\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.3267 - val_loss: 118.8960\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.3374 - val_loss: 122.2434\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7459 - val_loss: 115.1205\n",
      "Epoch 1414/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.5242 - val_loss: 177.8587\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.4854 - val_loss: 117.4537\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.8654 - val_loss: 118.0413\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.2689 - val_loss: 118.7943\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1636 - val_loss: 153.1107\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.5617 - val_loss: 201.4209\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.4299 - val_loss: 120.1182\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.8188 - val_loss: 122.4754\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9437 - val_loss: 116.3577\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0888 - val_loss: 137.7700\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5415 - val_loss: 117.2796\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.8627 - val_loss: 152.9619\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.3966 - val_loss: 118.1323\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.4924 - val_loss: 127.7358\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5703 - val_loss: 122.1306\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5611 - val_loss: 215.7496\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.1036 - val_loss: 117.7888\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.5140 - val_loss: 192.3142\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 169.8074 - val_loss: 112.6098\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 171.4727 - val_loss: 126.6097\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 157.6292 - val_loss: 118.1374\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 146.2376 - val_loss: 125.6238\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 154.2946 - val_loss: 120.0067\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 172.5924 - val_loss: 129.5751\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.9503 - val_loss: 117.6229\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4141 - val_loss: 134.7502\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6480 - val_loss: 301.8565\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.2445 - val_loss: 112.7522\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1421 - val_loss: 134.6763\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6023 - val_loss: 140.7666\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2837 - val_loss: 113.9839\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.4259 - val_loss: 146.3601\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.6801 - val_loss: 170.3377\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 236.2061 - val_loss: 118.0411\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.7310 - val_loss: 124.1740\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8098 - val_loss: 144.1888\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5916 - val_loss: 151.2378\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 168.3820 - val_loss: 159.9915\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.7275 - val_loss: 120.6905\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.5302 - val_loss: 113.6973\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.7898 - val_loss: 112.3975\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8827 - val_loss: 116.3453\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6157 - val_loss: 118.4318\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.3286 - val_loss: 122.9057\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.7894 - val_loss: 137.2442\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.4955 - val_loss: 176.5677\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.6395 - val_loss: 135.8231\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.1583 - val_loss: 128.6961\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2707 - val_loss: 123.8954\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0116 - val_loss: 118.4220\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 234.4190 - val_loss: 168.0570\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.9128 - val_loss: 121.4672\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.2850 - val_loss: 121.7017\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.5496 - val_loss: 120.0889\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.8483 - val_loss: 122.2813\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.7975 - val_loss: 116.3430\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7663 - val_loss: 120.5626\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1512 - val_loss: 113.6762\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.1380 - val_loss: 123.1723\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8467 - val_loss: 127.4822\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6364 - val_loss: 122.4732\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.1716 - val_loss: 113.5872\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4024 - val_loss: 110.7389\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.3285 - val_loss: 124.7964\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.9393 - val_loss: 118.9966\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1935 - val_loss: 115.4613\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.3772 - val_loss: 111.8094\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.8404 - val_loss: 127.9900\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.0326 - val_loss: 143.9080\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.3224 - val_loss: 121.8903\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.0225 - val_loss: 127.0991\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.2504 - val_loss: 152.7693\n",
      "Epoch 1486/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6735 - val_loss: 131.7533\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0520 - val_loss: 122.2157\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5279 - val_loss: 113.8138\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.2866 - val_loss: 142.2491\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8546 - val_loss: 120.3117\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.1271 - val_loss: 148.1543\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.0502 - val_loss: 156.7787\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 280.8880 - val_loss: 139.5274\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3976 - val_loss: 112.1882\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7417 - val_loss: 151.8890\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.7020 - val_loss: 133.2261\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0516 - val_loss: 131.0294\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6124 - val_loss: 127.7754\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.2711 - val_loss: 121.7279\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4776 - val_loss: 122.2099\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.0912 - val_loss: 128.8363\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 174.7139 - val_loss: 117.6124\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.4348 - val_loss: 115.7482\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 148.2272 - val_loss: 144.9745\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.6691 - val_loss: 138.6920\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.5776 - val_loss: 114.9182\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6705 - val_loss: 114.8635\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.7418 - val_loss: 123.5396\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.2195 - val_loss: 132.7497\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.0434 - val_loss: 112.8224\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.4085 - val_loss: 138.1876\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.8972 - val_loss: 140.8050\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7843 - val_loss: 123.1841\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.0668 - val_loss: 127.4004\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1677 - val_loss: 143.4025\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4271 - val_loss: 162.5113\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6255 - val_loss: 145.8516\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2116 - val_loss: 126.1826\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4576 - val_loss: 117.1055\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7380 - val_loss: 151.4439\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.8185 - val_loss: 163.8620\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.6413 - val_loss: 115.2739\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.8620 - val_loss: 115.0318\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 136.8495 - val_loss: 115.8246\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.7402 - val_loss: 218.5891\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2810 - val_loss: 117.2805\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.5602 - val_loss: 119.4301\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 145.4126 - val_loss: 127.6110\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.2819 - val_loss: 113.9248\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 176.9892 - val_loss: 116.5052\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4838 - val_loss: 136.8794\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4512 - val_loss: 140.7428\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7490 - val_loss: 212.7512\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.0273 - val_loss: 127.6468\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 356.9626 - val_loss: 119.3657\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5402 - val_loss: 119.7335\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.3490 - val_loss: 120.0959\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9439 - val_loss: 127.3936\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8752 - val_loss: 118.6038\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.1095 - val_loss: 168.6260\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.3096 - val_loss: 120.0038\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.3609 - val_loss: 123.8763\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.5511 - val_loss: 130.4408\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.8428 - val_loss: 116.8126\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8956 - val_loss: 123.7158\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4949 - val_loss: 127.1934\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8348 - val_loss: 112.6349\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.0155 - val_loss: 120.7136\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6421 - val_loss: 115.1954\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1436 - val_loss: 118.3332\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.2441 - val_loss: 114.9035\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9525 - val_loss: 116.3238\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.9249 - val_loss: 113.1892\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5104 - val_loss: 113.4363\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.6713 - val_loss: 130.6268\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5491 - val_loss: 119.0091\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8708 - val_loss: 165.5560\n",
      "Epoch 1558/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.3506 - val_loss: 122.5852\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.9178 - val_loss: 137.2918\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 374.6572 - val_loss: 171.0531\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.9833 - val_loss: 117.0628\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5941 - val_loss: 114.0902\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.3954 - val_loss: 120.7655\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.3476 - val_loss: 114.1756\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0851 - val_loss: 120.8408\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5634 - val_loss: 118.1708\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8129 - val_loss: 117.0886\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5757 - val_loss: 122.5596\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3821 - val_loss: 136.1910\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9363 - val_loss: 119.0867\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.7718 - val_loss: 141.4220\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.0257 - val_loss: 140.5274\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6717 - val_loss: 138.9300\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.8709 - val_loss: 119.0464\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3592 - val_loss: 127.7040\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.8757 - val_loss: 120.6143\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0154 - val_loss: 149.5920\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6709 - val_loss: 137.3571\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9000 - val_loss: 151.9145\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 237.7258 - val_loss: 131.3162\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9953 - val_loss: 123.7326\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 144.0482 - val_loss: 121.0283\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.5840 - val_loss: 116.3010\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 145.1626 - val_loss: 118.1623\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.2619 - val_loss: 115.3681\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 165.3803 - val_loss: 115.1079\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 168.1006 - val_loss: 163.0429\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.2445 - val_loss: 112.0730\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.8935 - val_loss: 263.2371\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3923 - val_loss: 112.3968\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.0238 - val_loss: 115.1077\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.8640 - val_loss: 183.8518\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.5939 - val_loss: 118.0812\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.7561 - val_loss: 123.7852\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5274 - val_loss: 150.5644\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.9090 - val_loss: 115.5204\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.0994 - val_loss: 127.7010\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.4898 - val_loss: 135.2327\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2723 - val_loss: 114.2489\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.3672 - val_loss: 120.4160\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1517 - val_loss: 119.3085\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.5643 - val_loss: 139.6025\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0048 - val_loss: 146.3322\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1959 - val_loss: 127.5645\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.0173 - val_loss: 115.9688\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6370 - val_loss: 112.2027\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6653 - val_loss: 206.9536\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8211 - val_loss: 144.1754\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.6057 - val_loss: 134.7243\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5049 - val_loss: 118.5449\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.2895 - val_loss: 127.4776\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.3659 - val_loss: 115.7588\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1371 - val_loss: 126.1094\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3703 - val_loss: 119.3424\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7803 - val_loss: 332.7444\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.3228 - val_loss: 155.1791\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6603 - val_loss: 112.1899\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.4425 - val_loss: 121.1551\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5378 - val_loss: 135.9806\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.3318 - val_loss: 115.2084\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.0811 - val_loss: 126.6477\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.7638 - val_loss: 161.0204\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 146.8443 - val_loss: 132.5427\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 148.7465 - val_loss: 137.0541\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.5863 - val_loss: 114.4534\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.8416 - val_loss: 119.0428\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2721 - val_loss: 116.7269\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.5601 - val_loss: 117.1705\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.4911 - val_loss: 120.1691\n",
      "Epoch 1630/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 195.5054 - val_loss: 167.1629\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.3008 - val_loss: 119.9749\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.6961 - val_loss: 123.5937\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.8280 - val_loss: 148.3223\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 157.1678 - val_loss: 124.7580\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.4258 - val_loss: 113.4453\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.6054 - val_loss: 133.5880\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.6591 - val_loss: 168.8196\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 174.2384 - val_loss: 114.1145\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 145.4748 - val_loss: 118.1887\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 146.2269 - val_loss: 120.3048\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 146.3907 - val_loss: 127.0940\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 154.0936 - val_loss: 114.6147\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 146.5698 - val_loss: 200.4065\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 227.4221 - val_loss: 116.1337\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.1313 - val_loss: 119.6792\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.4208 - val_loss: 116.9620\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.9183 - val_loss: 136.9378\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.1171 - val_loss: 110.7069\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.8565 - val_loss: 119.3827\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.6901 - val_loss: 125.7131\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.1554 - val_loss: 127.6611\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.4009 - val_loss: 111.7893\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.8899 - val_loss: 121.6421\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.9457 - val_loss: 132.3724\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 186.0447 - val_loss: 122.0601\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.5487 - val_loss: 110.7435\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.6144 - val_loss: 113.1589\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 187.2148 - val_loss: 139.5536\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 161.8211 - val_loss: 117.7424\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.1779 - val_loss: 111.1517\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 168.0896 - val_loss: 158.2342\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 191.4394 - val_loss: 146.5947\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.4271 - val_loss: 119.7969\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.3728 - val_loss: 122.5578\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.0549 - val_loss: 237.9665\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.1718 - val_loss: 117.0315\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.6268 - val_loss: 115.2802\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 148.1793 - val_loss: 114.0286\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.7851 - val_loss: 135.3279\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3708 - val_loss: 117.5133\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.8165 - val_loss: 117.3577\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.0491 - val_loss: 271.5342\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 187.7255 - val_loss: 124.5412\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.8438 - val_loss: 110.5478\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0358 - val_loss: 127.3782\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1133 - val_loss: 120.9214\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3548 - val_loss: 115.7107\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.4320 - val_loss: 115.6643\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.6723 - val_loss: 133.7985\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.2590 - val_loss: 156.5837\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6397 - val_loss: 151.4574\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.3592 - val_loss: 136.6093\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.3850 - val_loss: 113.5135\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.3370 - val_loss: 113.0500\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.8767 - val_loss: 163.8340\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 286.4138 - val_loss: 128.2418\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7583 - val_loss: 116.9100\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4921 - val_loss: 115.7745\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.2295 - val_loss: 117.7042\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6585 - val_loss: 122.3760\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.8171 - val_loss: 147.8874\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.8805 - val_loss: 141.7931\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.9795 - val_loss: 128.4067\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.4309 - val_loss: 138.9963\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6071 - val_loss: 115.1393\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.2904 - val_loss: 125.8130\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.0077 - val_loss: 226.3717\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.0849 - val_loss: 126.9417\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3821 - val_loss: 118.1425\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.1900 - val_loss: 177.5862\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 258.4707 - val_loss: 142.6866\n",
      "Epoch 1702/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.2951 - val_loss: 131.2984\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.9969 - val_loss: 122.2732\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.7759 - val_loss: 124.2666\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.6434 - val_loss: 152.9886\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.6541 - val_loss: 168.4152\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.7151 - val_loss: 178.8635\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.8497 - val_loss: 134.5772\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 168.5275 - val_loss: 127.4745\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 152.0394 - val_loss: 120.4693\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 141.0724 - val_loss: 135.5144\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 144.7515 - val_loss: 114.5336\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.6822 - val_loss: 111.8367\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.4275 - val_loss: 112.8478\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0134 - val_loss: 112.8219\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.9881 - val_loss: 121.7666\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.1858 - val_loss: 123.2242\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.3131 - val_loss: 143.5819\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.7087 - val_loss: 136.0407\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6147 - val_loss: 114.7826\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.3751 - val_loss: 113.9866\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.9547 - val_loss: 124.4057\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.6203 - val_loss: 115.9130\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.6989 - val_loss: 119.3146\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.7091 - val_loss: 111.1401\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.7284 - val_loss: 117.2976\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5747 - val_loss: 116.9704\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.3326 - val_loss: 132.5224\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.8798 - val_loss: 136.3659\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 140.8270 - val_loss: 119.5845\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.2179 - val_loss: 127.0729\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.7704 - val_loss: 116.2789\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 153.3898 - val_loss: 163.0883\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 263.1941 - val_loss: 130.5140\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.2790 - val_loss: 135.5450\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.0117 - val_loss: 122.7318\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3177 - val_loss: 121.1618\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.6512 - val_loss: 112.2910\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9246 - val_loss: 114.1926\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.8289 - val_loss: 112.7145\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9362 - val_loss: 110.4906\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7238 - val_loss: 119.3210\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5896 - val_loss: 122.0753\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.1129 - val_loss: 118.8851\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8447 - val_loss: 113.2407\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7871 - val_loss: 132.8977\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.6153 - val_loss: 124.1170\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6213 - val_loss: 116.7916\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 154.4346 - val_loss: 126.3462\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.1829 - val_loss: 135.3279\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.3111 - val_loss: 196.2265\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.7716 - val_loss: 113.4309\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8211 - val_loss: 173.1162\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.0231 - val_loss: 112.2730\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9052 - val_loss: 146.0845\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3664 - val_loss: 138.7089\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2852 - val_loss: 114.9920\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1132 - val_loss: 131.2112\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.0035 - val_loss: 111.3244\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.9308 - val_loss: 122.4768\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.3713 - val_loss: 125.2233\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.4046 - val_loss: 118.7828\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6667 - val_loss: 115.9886\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.2649 - val_loss: 135.2847\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.1805 - val_loss: 117.6339\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.0712 - val_loss: 144.9487\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4479 - val_loss: 118.0103\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.0598 - val_loss: 149.1473\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 252.6976 - val_loss: 149.6756\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2566 - val_loss: 121.1297\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.6999 - val_loss: 120.4401\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.0642 - val_loss: 118.7141\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9381 - val_loss: 125.9446\n",
      "Epoch 1774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3703 - val_loss: 113.5084\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5571 - val_loss: 137.2076\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1267 - val_loss: 112.6156\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4852 - val_loss: 160.6553\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.6055 - val_loss: 116.6861\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 154.0430 - val_loss: 174.2606\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 142.7110 - val_loss: 113.5613\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.6945 - val_loss: 127.2331\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.9741 - val_loss: 113.3092\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.7350 - val_loss: 135.0715\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6542 - val_loss: 118.5095\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.6732 - val_loss: 134.0406\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.2626 - val_loss: 122.5483\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9369 - val_loss: 124.9151\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4490 - val_loss: 110.3363\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1621 - val_loss: 199.0170\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5870 - val_loss: 120.3870\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.3893 - val_loss: 124.7024\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2669 - val_loss: 121.9506\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8204 - val_loss: 135.7402\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.1848 - val_loss: 125.1476\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9854 - val_loss: 123.5491\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2762 - val_loss: 123.6865\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.6725 - val_loss: 117.7550\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.7040 - val_loss: 119.2502\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5216 - val_loss: 119.9281\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0583 - val_loss: 112.8161\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.8320 - val_loss: 147.6499\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6968 - val_loss: 333.0925\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.1513 - val_loss: 124.5349\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3919 - val_loss: 139.2728\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.9219 - val_loss: 173.1975\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3681 - val_loss: 119.7654\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 147.6540 - val_loss: 145.2743\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.5571 - val_loss: 125.4132\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.1097 - val_loss: 130.5977\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.2249 - val_loss: 118.5779\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6160 - val_loss: 115.6428\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.3171 - val_loss: 135.0753\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.8490 - val_loss: 142.4014\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6868 - val_loss: 126.7665\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.1668 - val_loss: 117.6128\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.5258 - val_loss: 124.5574\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.0217 - val_loss: 112.9292\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7236 - val_loss: 130.6549\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0805 - val_loss: 112.7880\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6717 - val_loss: 113.1821\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3866 - val_loss: 124.4569\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9267 - val_loss: 112.5728\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.8960 - val_loss: 234.8991\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 267.3995 - val_loss: 119.4196\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8102 - val_loss: 116.1514\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4362 - val_loss: 142.4808\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2167 - val_loss: 113.2798\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0495 - val_loss: 119.4485\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.6077 - val_loss: 272.5402\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2034 - val_loss: 117.6067\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.4408 - val_loss: 111.3743\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.8325 - val_loss: 431.2277\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.8533 - val_loss: 116.4445\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4517 - val_loss: 145.8521\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.6586 - val_loss: 140.3210\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1905 - val_loss: 128.6051\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.3390 - val_loss: 118.1591\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7332 - val_loss: 117.3092\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6906 - val_loss: 118.1211\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6239 - val_loss: 110.7154\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6112 - val_loss: 121.8130\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0002 - val_loss: 112.8399\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.4774 - val_loss: 121.0703\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7526 - val_loss: 116.3366\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8916 - val_loss: 123.6528\n",
      "Epoch 1846/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4507 - val_loss: 114.7798\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.7755 - val_loss: 120.6267\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6258 - val_loss: 113.0909\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 201.9959 - val_loss: 118.3982\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 204.1834 - val_loss: 130.4314\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 160.1461 - val_loss: 138.6727\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 190.4482 - val_loss: 145.8639\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.5984 - val_loss: 116.0581\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.4537 - val_loss: 111.4950\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0480 - val_loss: 116.5026\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.4478 - val_loss: 119.2191\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.4811 - val_loss: 199.9271\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6066 - val_loss: 111.0250\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.8243 - val_loss: 111.1378\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.6441 - val_loss: 150.0574\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7564 - val_loss: 114.1246\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1772 - val_loss: 129.4544\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5850 - val_loss: 121.6220\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9690 - val_loss: 115.0765\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9651 - val_loss: 115.4306\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1372 - val_loss: 125.3996\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7220 - val_loss: 119.5228\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9614 - val_loss: 157.7824\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.9195 - val_loss: 115.6979\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.8310 - val_loss: 142.3597\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4217 - val_loss: 111.0836\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4248 - val_loss: 143.2719\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1546 - val_loss: 113.4208\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4194 - val_loss: 119.0066\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 166.3223 - val_loss: 132.8377\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0346 - val_loss: 131.4561\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.7846 - val_loss: 117.0863\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.8197 - val_loss: 114.5687\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4742 - val_loss: 121.9083\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4741 - val_loss: 187.0207\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0735 - val_loss: 128.6581\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.3809 - val_loss: 165.2480\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.6711 - val_loss: 115.2161\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.1275 - val_loss: 111.8140\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 144.6784 - val_loss: 123.9544\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.0340 - val_loss: 117.9093\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.8969 - val_loss: 120.3762\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2492 - val_loss: 111.9537\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.3178 - val_loss: 127.2343\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9474 - val_loss: 138.1397\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3409 - val_loss: 116.6197\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5481 - val_loss: 113.9487\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6886 - val_loss: 123.6343\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.9311 - val_loss: 112.8350\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8571 - val_loss: 144.4797\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.3050 - val_loss: 124.2405\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5237 - val_loss: 112.5011\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9852 - val_loss: 112.2018\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7833 - val_loss: 154.7294\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.3107 - val_loss: 214.6448\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.1012 - val_loss: 119.2687\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2499 - val_loss: 133.6092\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.8358 - val_loss: 134.4546\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5944 - val_loss: 147.0720\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.8104 - val_loss: 119.7632\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6975 - val_loss: 116.5994\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.8068 - val_loss: 127.2852\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6699 - val_loss: 113.3600\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.9156 - val_loss: 112.1987\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.0575 - val_loss: 114.2910\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3831 - val_loss: 116.2500\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5351 - val_loss: 126.6166\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.3812 - val_loss: 116.2555\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.8345 - val_loss: 121.5152\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.9242 - val_loss: 115.6880\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9868 - val_loss: 149.5670\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5698 - val_loss: 113.5881\n",
      "Epoch 1918/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.9631 - val_loss: 117.5120\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 142.4640 - val_loss: 118.9745\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 151.3932 - val_loss: 264.2228\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 189.8979 - val_loss: 111.3180\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 141.0709 - val_loss: 119.6597\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0508 - val_loss: 124.1202\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6175 - val_loss: 150.9275\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.4319 - val_loss: 114.3114\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.6356 - val_loss: 127.5519\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5693 - val_loss: 111.9160\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5730 - val_loss: 217.6399\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7339 - val_loss: 116.2746\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.2451 - val_loss: 118.5783\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 482.9037 - val_loss: 223.5196\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.1798 - val_loss: 134.1231\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2023 - val_loss: 131.1797\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.3006 - val_loss: 124.9718\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0384 - val_loss: 123.1246\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.1010 - val_loss: 132.3994\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9537 - val_loss: 127.5964\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.8161 - val_loss: 123.5936\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.3438 - val_loss: 131.3616\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.2497 - val_loss: 129.6755\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.0973 - val_loss: 126.4278\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7094 - val_loss: 134.9835\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8971 - val_loss: 116.1652\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.8995 - val_loss: 129.4177\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.2062 - val_loss: 132.7919\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4871 - val_loss: 121.1929\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.8854 - val_loss: 168.1034\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.1258 - val_loss: 164.3362\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.6556 - val_loss: 112.7851\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.3501 - val_loss: 124.9803\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.2293 - val_loss: 129.7991\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.6676 - val_loss: 120.3801\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.5071 - val_loss: 116.9774\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.8656 - val_loss: 114.1946\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8940 - val_loss: 117.3762\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0222 - val_loss: 115.2195\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.8081 - val_loss: 112.3933\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0372 - val_loss: 111.7783\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3408 - val_loss: 134.7118\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.2353 - val_loss: 168.3122\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.1920 - val_loss: 119.5074\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.8812 - val_loss: 116.3352\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5320 - val_loss: 114.0294\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8045 - val_loss: 111.9084\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.8310 - val_loss: 112.1717\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.4044 - val_loss: 122.9129\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.1018 - val_loss: 117.2570\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7395 - val_loss: 125.9920\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.7839 - val_loss: 142.0934\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.9581 - val_loss: 133.9732\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7864 - val_loss: 145.1432\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7887 - val_loss: 120.1745\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.0205 - val_loss: 134.7410\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3096 - val_loss: 123.1942\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.8154 - val_loss: 123.7010\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0181 - val_loss: 122.4114\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.6755 - val_loss: 136.4118\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.1040 - val_loss: 132.2907\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.8430 - val_loss: 126.9130\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9057 - val_loss: 126.6339\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0030 - val_loss: 212.4663\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.1912 - val_loss: 210.2470\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8334 - val_loss: 114.4118\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5584 - val_loss: 130.7882\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2977 - val_loss: 139.6796\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4190 - val_loss: 163.1628\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.1184 - val_loss: 179.0143\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.8900 - val_loss: 125.9441\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 174.6391 - val_loss: 120.1622\n",
      "Epoch 1990/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 65us/step - loss: 137.8505 - val_loss: 118.6379\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 137.5618 - val_loss: 118.8323\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 195.7572 - val_loss: 122.6537\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7644 - val_loss: 118.0208\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.2323 - val_loss: 113.1616\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.5040 - val_loss: 115.2700\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.0709 - val_loss: 113.7061\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3748 - val_loss: 111.9888\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.6519 - val_loss: 131.8143\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.4337 - val_loss: 117.2222\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.2295 - val_loss: 121.1410\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.9049 - val_loss: 302.2454\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.9462 - val_loss: 118.9673\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2491 - val_loss: 117.5703\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4984 - val_loss: 121.8017\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5515 - val_loss: 113.7484\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.3928 - val_loss: 137.0258\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.4802 - val_loss: 112.7445\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4609 - val_loss: 123.6759\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.9362 - val_loss: 120.9988\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.1185 - val_loss: 126.7652\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.2581 - val_loss: 119.1270\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5514 - val_loss: 120.6447\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.6212 - val_loss: 112.9607\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.0973 - val_loss: 140.9878\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.6873 - val_loss: 117.1851\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1900 - val_loss: 124.3816\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2632 - val_loss: 152.7589\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6324 - val_loss: 114.4028\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4528 - val_loss: 123.2753\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8297 - val_loss: 118.5397\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3210 - val_loss: 119.6086\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 266.6132 - val_loss: 122.9286\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.1336 - val_loss: 126.9836\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7360 - val_loss: 125.0260\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.6584 - val_loss: 115.7559\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.5047 - val_loss: 119.1140\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.5134 - val_loss: 125.2864\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.2235 - val_loss: 118.1529\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3860 - val_loss: 130.6773\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.9368 - val_loss: 117.6608\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.8680 - val_loss: 125.1051\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7429 - val_loss: 123.8115\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1064 - val_loss: 138.7992\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.8205 - val_loss: 110.6934\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0811 - val_loss: 117.2004\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.6449 - val_loss: 110.0926\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.4088 - val_loss: 124.7082\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.3466 - val_loss: 199.6080\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 267.6895 - val_loss: 125.0573\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7203 - val_loss: 116.2121\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.8293 - val_loss: 120.9516\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.9321 - val_loss: 117.3949\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5024 - val_loss: 125.0371\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3927 - val_loss: 112.1315\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 225.1618 - val_loss: 148.6484\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6620 - val_loss: 117.1674\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3099 - val_loss: 172.0904\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.2126 - val_loss: 180.5838\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4271 - val_loss: 138.0498\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5163 - val_loss: 122.1050\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6191 - val_loss: 114.8761\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7594 - val_loss: 133.0806\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.5817 - val_loss: 147.4878\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.7438 - val_loss: 115.7607\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0334 - val_loss: 138.3510\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.2710 - val_loss: 116.3982\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.8544 - val_loss: 144.6354\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2133 - val_loss: 134.6121\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 313.0090 - val_loss: 131.5778\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 174.0457 - val_loss: 143.0432\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 149.5014 - val_loss: 114.0854\n",
      "Epoch 2062/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/step - loss: 145.3214 - val_loss: 114.6927\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.6515 - val_loss: 134.0644\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.2290 - val_loss: 115.6660\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5513 - val_loss: 119.4149\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4601 - val_loss: 113.8613\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2223 - val_loss: 132.1201\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2285 - val_loss: 118.5531\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.7250 - val_loss: 125.4247\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6417 - val_loss: 297.2391\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7526 - val_loss: 134.9095\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8105 - val_loss: 123.0149\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3569 - val_loss: 133.8109\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5457 - val_loss: 122.6650\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2215 - val_loss: 139.4538\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.5351 - val_loss: 120.6181\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1687 - val_loss: 121.6778\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6678 - val_loss: 112.9402\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.5391 - val_loss: 113.0668\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.6736 - val_loss: 135.3620\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.6737 - val_loss: 120.3627\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.6934 - val_loss: 123.2365\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3710 - val_loss: 140.0751\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0230 - val_loss: 118.0429\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.4127 - val_loss: 127.1419\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.8012 - val_loss: 139.1377\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.4397 - val_loss: 134.3526\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7730 - val_loss: 129.7948\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.4147 - val_loss: 117.8125\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.7670 - val_loss: 125.8108\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2970 - val_loss: 141.6161\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.1564 - val_loss: 138.6635\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1342 - val_loss: 118.9753\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1125 - val_loss: 114.7143\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.1106 - val_loss: 111.2003\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.7229 - val_loss: 114.4183\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.4053 - val_loss: 110.0954\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3276 - val_loss: 113.9012\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.2193 - val_loss: 110.0954\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8526 - val_loss: 148.7959\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.6453 - val_loss: 168.9182\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 387.5511 - val_loss: 270.2748\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 267.9340 - val_loss: 208.9240\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.7431 - val_loss: 133.7596\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1617 - val_loss: 131.5040\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2606 - val_loss: 115.1651\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1350 - val_loss: 112.8163\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8930 - val_loss: 114.7278\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.0812 - val_loss: 111.2386\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6962 - val_loss: 112.9199\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.2792 - val_loss: 117.5161\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7682 - val_loss: 111.8602\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.6593 - val_loss: 129.8840\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5034 - val_loss: 113.8599\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.4645 - val_loss: 114.8053\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0122 - val_loss: 117.3324\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.8940 - val_loss: 114.7710\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.8861 - val_loss: 167.1249\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.8762 - val_loss: 180.3440\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8625 - val_loss: 149.3966\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0625 - val_loss: 136.5768\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2208 - val_loss: 126.7342\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8304 - val_loss: 123.8921\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3591 - val_loss: 117.7277\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3611 - val_loss: 112.0249\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.4846 - val_loss: 134.1188\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.8776 - val_loss: 130.3585\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.3556 - val_loss: 118.7767\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 152.4008 - val_loss: 113.3946\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 165.3111 - val_loss: 129.5568\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 140.1072 - val_loss: 122.1644\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.5942 - val_loss: 122.4777\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7571 - val_loss: 119.4110\n",
      "Epoch 2134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.9708 - val_loss: 113.1684\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2636 - val_loss: 126.5077\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.7499 - val_loss: 217.6378\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 143.0114 - val_loss: 129.9461\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 155.9928 - val_loss: 133.9854\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5244 - val_loss: 137.4960\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.2680 - val_loss: 138.3657\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6687 - val_loss: 115.1771\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9857 - val_loss: 135.7713\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8212 - val_loss: 108.2917\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8959 - val_loss: 148.5499\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9907 - val_loss: 112.6883\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4015 - val_loss: 118.3479\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0510 - val_loss: 113.1658\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3925 - val_loss: 133.0656\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.4997 - val_loss: 123.6860\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.3912 - val_loss: 156.6595\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.0377 - val_loss: 113.0039\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7048 - val_loss: 115.2035\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.0577 - val_loss: 117.0898\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.5568 - val_loss: 109.9026\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.2368 - val_loss: 112.7717\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.9488 - val_loss: 175.7801\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 256.3294 - val_loss: 144.3340\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4256 - val_loss: 123.0963\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5650 - val_loss: 115.4371\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2634 - val_loss: 190.4648\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.2276 - val_loss: 119.2003\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0628 - val_loss: 122.4795\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.2942 - val_loss: 116.3261\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.2704 - val_loss: 113.7460\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4811 - val_loss: 116.1219\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.0225 - val_loss: 136.8315\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4692 - val_loss: 134.3090\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.0017 - val_loss: 123.5284\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.7719 - val_loss: 128.6729\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.0187 - val_loss: 113.9766\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.3401 - val_loss: 119.0209\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4044 - val_loss: 114.3944\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.2986 - val_loss: 115.3604\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6586 - val_loss: 124.1618\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.9568 - val_loss: 122.5209\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.2454 - val_loss: 116.4856\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9070 - val_loss: 118.7806\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0682 - val_loss: 113.0662\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.4155 - val_loss: 115.9611\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.4662 - val_loss: 119.0832\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8409 - val_loss: 160.4505\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.9090 - val_loss: 123.9105\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8926 - val_loss: 113.3722\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 153.8808 - val_loss: 132.7406\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.0467 - val_loss: 161.1187\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.7400 - val_loss: 121.5100\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.0516 - val_loss: 148.5228\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3575 - val_loss: 115.4503\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9307 - val_loss: 144.2900\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2639 - val_loss: 121.1553\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4165 - val_loss: 124.4150\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8754 - val_loss: 145.2183\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.3233 - val_loss: 193.9653\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.7523 - val_loss: 174.7030\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6731 - val_loss: 115.5614\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0501 - val_loss: 118.7369\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.7520 - val_loss: 144.5755\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 268.6246 - val_loss: 117.2997\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.7704 - val_loss: 116.8011\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 141.4685 - val_loss: 113.3765\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 140.9147 - val_loss: 113.5553\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.2211 - val_loss: 114.7973\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6639 - val_loss: 119.8681\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0600 - val_loss: 119.1409\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4868 - val_loss: 113.9478\n",
      "Epoch 2206/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5507 - val_loss: 108.9616\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6639 - val_loss: 129.1102\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7859 - val_loss: 135.7291\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3339 - val_loss: 116.2883\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.6390 - val_loss: 290.3813\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.0011 - val_loss: 113.2092\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9008 - val_loss: 119.7785\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.5167 - val_loss: 117.4503\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1823 - val_loss: 117.6091\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8500 - val_loss: 111.8296\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0148 - val_loss: 242.6509\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8742 - val_loss: 120.4181\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.3594 - val_loss: 123.5835\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.6900 - val_loss: 117.1569\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.6150 - val_loss: 130.0202\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6823 - val_loss: 157.3818\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.5871 - val_loss: 154.0765\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8418 - val_loss: 118.7870\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1965 - val_loss: 124.4833\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3335 - val_loss: 112.4115\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6135 - val_loss: 114.4322\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.2303 - val_loss: 147.1844\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.4309 - val_loss: 112.6322\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 142.6923 - val_loss: 111.8139\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.1249 - val_loss: 111.2205\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 180.3256 - val_loss: 112.9641\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.7324 - val_loss: 137.0414\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6317 - val_loss: 132.0109\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9175 - val_loss: 119.6918\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6735 - val_loss: 116.6486\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.2056 - val_loss: 204.5583\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3744 - val_loss: 116.8738\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7327 - val_loss: 175.4091\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6720 - val_loss: 112.0545\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9119 - val_loss: 113.7143\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.9888 - val_loss: 117.4179\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.5245 - val_loss: 152.3265\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.4842 - val_loss: 137.1216\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7967 - val_loss: 122.5816\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7517 - val_loss: 155.5571\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.7850 - val_loss: 131.2894\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7351 - val_loss: 117.0715\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8925 - val_loss: 114.7015\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3069 - val_loss: 140.9482\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.6002 - val_loss: 136.8724\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3880 - val_loss: 116.7683\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8309 - val_loss: 121.7454\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6741 - val_loss: 130.0707\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.7087 - val_loss: 120.4016\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0775 - val_loss: 131.7272\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3398 - val_loss: 113.9511\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.4269 - val_loss: 188.2703\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3269 - val_loss: 120.5334\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3946 - val_loss: 120.0096\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.7157 - val_loss: 126.4774\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.5500 - val_loss: 136.5788\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.7280 - val_loss: 119.4940\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3526 - val_loss: 113.4947\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 131.6803 - val_loss: 115.1758\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8021 - val_loss: 114.1646\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1129 - val_loss: 138.4392\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.9291 - val_loss: 149.2258\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.2848 - val_loss: 122.3548\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4342 - val_loss: 207.2444\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.2172 - val_loss: 116.6062\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.5195 - val_loss: 130.3097\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.5043 - val_loss: 122.0547\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6355 - val_loss: 114.8693\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.8595 - val_loss: 115.7062\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6158 - val_loss: 140.3130\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1189 - val_loss: 128.4584\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4082 - val_loss: 125.5436\n",
      "Epoch 2278/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 68us/step - loss: 139.2070 - val_loss: 153.0695\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 140.7102 - val_loss: 114.5515\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 151.8412 - val_loss: 112.8806\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.8049 - val_loss: 125.2287\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7372 - val_loss: 116.0162\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.3012 - val_loss: 135.0738\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.1861 - val_loss: 113.7314\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7522 - val_loss: 112.8434\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.5371 - val_loss: 176.1203\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 169.0462 - val_loss: 179.2471\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 162.7359 - val_loss: 113.8344\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.4520 - val_loss: 161.8022\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6265 - val_loss: 188.7176\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.9457 - val_loss: 118.8104\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.7982 - val_loss: 118.8206\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.1750 - val_loss: 112.2743\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0323 - val_loss: 147.1569\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9447 - val_loss: 117.3298\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 224.0453 - val_loss: 158.1411\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.3611 - val_loss: 131.9702\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1361 - val_loss: 122.9922\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9073 - val_loss: 150.4237\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.7364 - val_loss: 111.6471\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.5469 - val_loss: 111.2724\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.4898 - val_loss: 119.1884\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0908 - val_loss: 112.7069\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8563 - val_loss: 128.7383\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.2329 - val_loss: 114.0400\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3487 - val_loss: 152.6818\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.6327 - val_loss: 155.4028\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.6283 - val_loss: 111.6744\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.1008 - val_loss: 120.8109\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7008 - val_loss: 132.7691\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.1564 - val_loss: 145.1604\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.9617 - val_loss: 111.2183\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.6736 - val_loss: 113.1436\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.0589 - val_loss: 133.1149\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4190 - val_loss: 123.8290\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3562 - val_loss: 114.5750\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.2578 - val_loss: 111.4538\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7277 - val_loss: 125.4332\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1871 - val_loss: 150.9040\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.7347 - val_loss: 187.2005\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.6762 - val_loss: 167.2187\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2690 - val_loss: 148.4583\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.3172 - val_loss: 121.8018\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7846 - val_loss: 112.5500\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.0277 - val_loss: 135.0480\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5321 - val_loss: 110.7959\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7160 - val_loss: 156.4897\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.9909 - val_loss: 114.7704\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4894 - val_loss: 138.8992\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7732 - val_loss: 119.2458\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.0367 - val_loss: 139.9016\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.9272 - val_loss: 124.6466\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.0382 - val_loss: 136.6374\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8938 - val_loss: 117.1046\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2809 - val_loss: 130.7534\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.5171 - val_loss: 113.6239\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.4003 - val_loss: 125.1317\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 138.2207 - val_loss: 117.1615\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 142.2196 - val_loss: 156.3773\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 136.2345 - val_loss: 113.3035\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8274 - val_loss: 120.7814\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9509 - val_loss: 122.6983\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.8937 - val_loss: 160.0454\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.8620 - val_loss: 115.0304\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8647 - val_loss: 131.6518\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7246 - val_loss: 149.3365\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9437 - val_loss: 145.5927\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0131 - val_loss: 120.7109\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 280.9475 - val_loss: 218.7682\n",
      "Epoch 2350/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.0158 - val_loss: 117.1919\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4837 - val_loss: 131.8853\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.0724 - val_loss: 112.1475\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0973 - val_loss: 111.3692\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.0782 - val_loss: 186.1365\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.8495 - val_loss: 115.6472\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.6674 - val_loss: 129.0046\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0524 - val_loss: 108.4322\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7635 - val_loss: 121.9630\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8279 - val_loss: 111.3246\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.0620 - val_loss: 129.5412\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.4691 - val_loss: 141.8339\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.7377 - val_loss: 162.3387\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4483 - val_loss: 115.5108\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6172 - val_loss: 140.6129\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0960 - val_loss: 139.0742\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.1448 - val_loss: 143.6472\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8827 - val_loss: 113.8324\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.4345 - val_loss: 122.8327\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7833 - val_loss: 145.6733\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7418 - val_loss: 112.2824\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.8919 - val_loss: 126.4714\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.0445 - val_loss: 115.6463\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.1487 - val_loss: 114.1395\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9330 - val_loss: 116.3845\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.0308 - val_loss: 131.8798\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8315 - val_loss: 115.5521\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3832 - val_loss: 111.0677\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3995 - val_loss: 110.1270\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7436 - val_loss: 119.4673\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.2193 - val_loss: 112.4271\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4844 - val_loss: 113.1629\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7043 - val_loss: 121.3190\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.7640 - val_loss: 123.4478\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7773 - val_loss: 123.8085\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.3618 - val_loss: 147.2472\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5096 - val_loss: 192.4236\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.5590 - val_loss: 129.5456\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0305 - val_loss: 116.0316\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.2250 - val_loss: 115.3867\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.0804 - val_loss: 120.7865\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.2347 - val_loss: 152.5114\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.8671 - val_loss: 111.1170\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.1321 - val_loss: 114.5512\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.5315 - val_loss: 146.6374\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1214 - val_loss: 112.6507\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.6818 - val_loss: 119.3296\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5217 - val_loss: 123.2034\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.1605 - val_loss: 125.0130\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0577 - val_loss: 117.9863\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3625 - val_loss: 114.7748\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.5214 - val_loss: 114.4984\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.4251 - val_loss: 124.7634\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.2361 - val_loss: 136.8316\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.0674 - val_loss: 129.2545\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7453 - val_loss: 151.3550\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.1165 - val_loss: 119.0397\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.0930 - val_loss: 132.0704\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 142.0340 - val_loss: 121.5308\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 159.2751 - val_loss: 228.9314\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 184.3795 - val_loss: 121.2337\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8822 - val_loss: 113.1314\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2885 - val_loss: 178.8553\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 250.6034 - val_loss: 124.1981\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.1021 - val_loss: 127.6211\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.2914 - val_loss: 114.2007\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2975 - val_loss: 116.3128\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4266 - val_loss: 116.8493\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.8926 - val_loss: 154.2296\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.4664 - val_loss: 114.9336\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.5585 - val_loss: 113.5341\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6245 - val_loss: 112.9903\n",
      "Epoch 2422/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.8722 - val_loss: 123.2842\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9521 - val_loss: 111.5207\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6283 - val_loss: 124.6650\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.8126 - val_loss: 111.5313\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8967 - val_loss: 117.6009\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.0975 - val_loss: 131.2296\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4568 - val_loss: 146.4182\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.2237 - val_loss: 117.2376\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8847 - val_loss: 146.4215\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.4721 - val_loss: 132.3221\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1809 - val_loss: 122.2068\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8363 - val_loss: 123.7890\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.5607 - val_loss: 157.8201\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.5003 - val_loss: 116.8545\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.7709 - val_loss: 112.0731\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0547 - val_loss: 112.4857\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6039 - val_loss: 160.0986\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8319 - val_loss: 143.3959\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8523 - val_loss: 125.5316\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.2425 - val_loss: 116.9013\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5070 - val_loss: 161.2262\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4053 - val_loss: 137.5290\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2006 - val_loss: 113.6593\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.4307 - val_loss: 121.8691\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.7692 - val_loss: 147.3781\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.6005 - val_loss: 135.4303\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.4300 - val_loss: 136.4704\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5287 - val_loss: 115.2078\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.1058 - val_loss: 123.4995\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.0439 - val_loss: 109.9478\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.8030 - val_loss: 157.2322\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.9817 - val_loss: 123.3642\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3448 - val_loss: 110.8129\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.4584 - val_loss: 140.0211\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1585 - val_loss: 141.7362\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.8222 - val_loss: 130.9197\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 204.7131 - val_loss: 119.4243\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6768 - val_loss: 111.7215\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.6120 - val_loss: 114.5624\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4601 - val_loss: 132.3058\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 136.4250 - val_loss: 107.7137\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.1239 - val_loss: 190.5790\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.6319 - val_loss: 122.3618\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.6666 - val_loss: 123.5615\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7744 - val_loss: 140.3141\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3631 - val_loss: 119.2238\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7513 - val_loss: 128.3117\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.2744 - val_loss: 121.1684\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.3631 - val_loss: 168.6887\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.2840 - val_loss: 117.2596\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8237 - val_loss: 128.1020\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.9350 - val_loss: 117.2198\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7844 - val_loss: 110.4231\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8632 - val_loss: 119.8170\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.2407 - val_loss: 133.7671\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 150.6657 - val_loss: 115.7690\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.6052 - val_loss: 114.8717\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 141.2212 - val_loss: 112.6700\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 166.5519 - val_loss: 130.0484\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.1160 - val_loss: 152.3534\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1127 - val_loss: 121.1326\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6876 - val_loss: 138.5506\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 253.1283 - val_loss: 149.2326\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1649 - val_loss: 122.0652\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7400 - val_loss: 127.9452\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6583 - val_loss: 137.2113\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6553 - val_loss: 115.0070\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7254 - val_loss: 140.7226\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9237 - val_loss: 113.9385\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3239 - val_loss: 121.6527\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6138 - val_loss: 110.6113\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.6436 - val_loss: 112.7496\n",
      "Epoch 2494/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.1183 - val_loss: 113.2186\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1759 - val_loss: 113.2308\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.1662 - val_loss: 133.5500\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.8716 - val_loss: 140.6273\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.1477 - val_loss: 113.6923\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2692 - val_loss: 121.0790\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1958 - val_loss: 110.4401\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0756 - val_loss: 116.5778\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2603 - val_loss: 109.3001\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9932 - val_loss: 118.4573\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4465 - val_loss: 129.7596\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.5905 - val_loss: 116.4710\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3821 - val_loss: 119.7275\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4955 - val_loss: 202.3814\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5066 - val_loss: 117.6800\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.3174 - val_loss: 122.7204\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.5283 - val_loss: 224.3376\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5182 - val_loss: 113.5071\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.5383 - val_loss: 110.0154\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.5541 - val_loss: 111.0370\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.2263 - val_loss: 113.5989\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2922 - val_loss: 118.7489\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2521 - val_loss: 119.1095\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.0642 - val_loss: 110.1591\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.8578 - val_loss: 107.5290\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.4450 - val_loss: 127.4630\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2705 - val_loss: 127.3478\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.9654 - val_loss: 368.9496\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.6811 - val_loss: 118.3767\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.2891 - val_loss: 118.8360\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1067 - val_loss: 117.6669\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6684 - val_loss: 125.6768\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7835 - val_loss: 132.8326\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.4075 - val_loss: 137.2718\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.5102 - val_loss: 116.4148\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.0084 - val_loss: 123.1570\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9814 - val_loss: 123.0884\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.1134 - val_loss: 166.2649\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.1515 - val_loss: 113.4944\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8480 - val_loss: 135.5694\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.3862 - val_loss: 164.0471\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.9350 - val_loss: 126.5935\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.6960 - val_loss: 120.7960\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0460 - val_loss: 114.5161\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.2009 - val_loss: 119.6450\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.6392 - val_loss: 117.2290\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.1409 - val_loss: 126.4375\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.0807 - val_loss: 113.9021\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.8365 - val_loss: 117.9213\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.6295 - val_loss: 114.8042\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8913 - val_loss: 112.0098\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4590 - val_loss: 140.9951\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.8225 - val_loss: 201.6510\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 153.5615 - val_loss: 114.0546\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 136.5971 - val_loss: 132.1867\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.9635 - val_loss: 144.2331\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.7548 - val_loss: 135.4863\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9006 - val_loss: 135.8709\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9717 - val_loss: 127.7914\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0912 - val_loss: 127.8120\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0155 - val_loss: 214.5617\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0079 - val_loss: 130.5263\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8024 - val_loss: 140.3125\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.4484 - val_loss: 130.5572\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.4827 - val_loss: 120.2657\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1423 - val_loss: 121.3891\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8972 - val_loss: 136.0994\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5653 - val_loss: 143.3867\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.3744 - val_loss: 132.0997\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.5854 - val_loss: 108.4656\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9491 - val_loss: 163.3178\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9531 - val_loss: 127.2212\n",
      "Epoch 2566/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.1107 - val_loss: 117.7034\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.0248 - val_loss: 145.3789\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.7443 - val_loss: 112.4812\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.7489 - val_loss: 921.0060\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 247.9139 - val_loss: 116.2392\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.5709 - val_loss: 113.7977\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6224 - val_loss: 120.0548\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.8847 - val_loss: 121.6666\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.7732 - val_loss: 113.7248\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.9065 - val_loss: 115.4867\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.8176 - val_loss: 125.7304\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2831 - val_loss: 110.3494\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8802 - val_loss: 187.2801\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6872 - val_loss: 117.9757\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9328 - val_loss: 122.1895\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5640 - val_loss: 116.0828\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6222 - val_loss: 136.3730\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.2095 - val_loss: 115.7576\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3234 - val_loss: 141.1457\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.9816 - val_loss: 120.0072\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8666 - val_loss: 126.5873\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8092 - val_loss: 115.2709\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8503 - val_loss: 1511.5265\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.0070 - val_loss: 131.5341\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.0825 - val_loss: 118.8212\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.1055 - val_loss: 113.8170\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.7366 - val_loss: 119.5746\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.6291 - val_loss: 127.8115\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3476 - val_loss: 122.8644\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4278 - val_loss: 114.7258\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4161 - val_loss: 119.5129\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.4342 - val_loss: 137.0087\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.9407 - val_loss: 116.2163\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7403 - val_loss: 138.7450\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4496 - val_loss: 150.4732\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3046 - val_loss: 119.8583\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.0395 - val_loss: 119.9657\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.3940 - val_loss: 113.6259\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7028 - val_loss: 117.9457\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0626 - val_loss: 122.6715\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.3752 - val_loss: 153.0452\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2668 - val_loss: 113.9666\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9017 - val_loss: 143.7594\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.7591 - val_loss: 117.7308\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1028 - val_loss: 112.3239\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0159 - val_loss: 115.0714\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5218 - val_loss: 185.7972\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.4214 - val_loss: 114.9155\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5972 - val_loss: 114.4650\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.9955 - val_loss: 117.1185\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.7444 - val_loss: 125.2551\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.3924 - val_loss: 110.2413\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 133.6867 - val_loss: 117.0644\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 139.5543 - val_loss: 111.1785\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.3420 - val_loss: 115.2556\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6062 - val_loss: 120.1963\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6808 - val_loss: 125.5725\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.9213 - val_loss: 238.7993\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.7203 - val_loss: 189.3272\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.1183 - val_loss: 127.9286\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0255 - val_loss: 132.2820\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5675 - val_loss: 124.8479\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.2185 - val_loss: 113.2249\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5124 - val_loss: 110.2783\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2734 - val_loss: 116.4950\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1529 - val_loss: 108.6421\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.2526 - val_loss: 178.4326\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8814 - val_loss: 127.3078\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5525 - val_loss: 119.6557\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.2523 - val_loss: 116.2439\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.3640 - val_loss: 117.9572\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.4519 - val_loss: 145.2183\n",
      "Epoch 2638/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4709 - val_loss: 114.5791\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.7344 - val_loss: 114.5722\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4975 - val_loss: 115.6595\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.9612 - val_loss: 114.6073\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9953 - val_loss: 117.0342\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.8902 - val_loss: 121.5191\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5608 - val_loss: 147.6079\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.8517 - val_loss: 151.2098\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 220.4262 - val_loss: 129.7456\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8794 - val_loss: 113.9212\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9128 - val_loss: 117.0156\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4338 - val_loss: 114.6970\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1532 - val_loss: 111.8332\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1250 - val_loss: 114.0330\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7278 - val_loss: 110.7682\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.2126 - val_loss: 138.8020\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 135.2296 - val_loss: 124.2597\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 210.2649 - val_loss: 127.3808\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.2094 - val_loss: 143.9780\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7055 - val_loss: 121.8045\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6776 - val_loss: 117.9908\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4108 - val_loss: 114.1505\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.1260 - val_loss: 127.0272\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1312 - val_loss: 188.5773\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9349 - val_loss: 127.7029\n",
      "Epoch 2663/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.3694 - val_loss: 125.3563\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.3963 - val_loss: 191.5443\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.0077 - val_loss: 159.3350\n",
      "Epoch 2666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2378 - val_loss: 114.4083\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7664 - val_loss: 124.2014\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4439 - val_loss: 134.2121\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.8951 - val_loss: 113.2963\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6659 - val_loss: 117.5419\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.2016 - val_loss: 112.5553\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.6603 - val_loss: 131.4598\n",
      "Epoch 2673/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.0299 - val_loss: 137.5781\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 151.7658 - val_loss: 149.6541\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4986 - val_loss: 127.9422\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.8556 - val_loss: 110.9935\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2020 - val_loss: 119.3785\n",
      "Epoch 2678/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2548 - val_loss: 118.2163\n",
      "Epoch 2679/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4524 - val_loss: 110.5716\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.2758 - val_loss: 163.9273\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9704 - val_loss: 177.7866\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1244 - val_loss: 116.8823\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.1149 - val_loss: 123.3714\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.2893 - val_loss: 180.0506\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 231.3893 - val_loss: 174.2931\n",
      "Epoch 2686/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 193.1869 - val_loss: 113.5638\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.9902 - val_loss: 110.6880\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 139.8055 - val_loss: 116.9229\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.6045 - val_loss: 148.8019\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 142.0257 - val_loss: 134.6004\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6250 - val_loss: 116.8135\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 251.0779 - val_loss: 114.8889\n",
      "Epoch 2693/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6257 - val_loss: 111.9625\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6058 - val_loss: 119.5644\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6050 - val_loss: 111.6273\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.2972 - val_loss: 116.7706\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.7224 - val_loss: 114.8763\n",
      "Epoch 2698/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2778 - val_loss: 124.4273\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.3840 - val_loss: 112.2591\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.8446 - val_loss: 259.1721\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8373 - val_loss: 133.3165\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1644 - val_loss: 116.4019\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2313 - val_loss: 116.6643\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0781 - val_loss: 129.6514\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8525 - val_loss: 152.1438\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.1670 - val_loss: 123.7084\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.1429 - val_loss: 121.1939\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.2349 - val_loss: 126.6614\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 160.0750 - val_loss: 122.8690\n",
      "Epoch 2710/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 204.5832 - val_loss: 120.7488\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.8458 - val_loss: 119.1121\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.9356 - val_loss: 112.2187\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.4666 - val_loss: 112.6317\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.2941 - val_loss: 109.4275\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.7237 - val_loss: 139.2875\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.3408 - val_loss: 122.2996\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 141.7707 - val_loss: 111.9949\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9042 - val_loss: 116.3860\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.9948 - val_loss: 131.2038\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.1282 - val_loss: 159.7327\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5407 - val_loss: 133.1595\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.5141 - val_loss: 159.7915\n",
      "Epoch 2723/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.1277 - val_loss: 132.6593\n",
      "Epoch 2724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1750 - val_loss: 117.1803\n",
      "Epoch 2725/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.9114 - val_loss: 147.9822\n",
      "Epoch 2726/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.9978 - val_loss: 124.9253\n",
      "Epoch 2727/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.1203 - val_loss: 119.7511\n",
      "Epoch 2728/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.5406 - val_loss: 123.9941\n",
      "Epoch 2729/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3559 - val_loss: 113.3663\n",
      "Epoch 2730/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.3127 - val_loss: 133.2113\n",
      "Epoch 2731/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4822 - val_loss: 114.2130\n",
      "Epoch 2732/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 144.7644 - val_loss: 198.2787\n",
      "Epoch 2733/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 226.5909 - val_loss: 115.2064\n",
      "Epoch 2734/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.9576 - val_loss: 133.5292\n",
      "Epoch 2735/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8084 - val_loss: 114.2076\n",
      "Epoch 2736/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4636 - val_loss: 114.0579\n",
      "Epoch 2737/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4963 - val_loss: 113.8828\n",
      "Epoch 2738/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1610 - val_loss: 111.6596\n",
      "Epoch 2739/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5194 - val_loss: 132.4208\n",
      "Epoch 2740/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.5673 - val_loss: 115.0306\n",
      "Epoch 2741/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8882 - val_loss: 110.3929\n",
      "Epoch 2742/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.4711 - val_loss: 192.6473\n",
      "Epoch 2743/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.1626 - val_loss: 244.8036\n",
      "Epoch 2744/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.4671 - val_loss: 121.1841\n",
      "Epoch 2745/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2812 - val_loss: 119.2407\n",
      "Epoch 2746/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4947 - val_loss: 122.4063\n",
      "Epoch 2747/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.2220 - val_loss: 145.4444\n",
      "Epoch 2748/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.5080 - val_loss: 135.6226\n",
      "Epoch 2749/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.7356 - val_loss: 154.7598\n",
      "Epoch 2750/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.6946 - val_loss: 203.3005\n",
      "Epoch 2751/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.7631 - val_loss: 114.7338\n",
      "Epoch 2752/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.4636 - val_loss: 118.0545\n",
      "Epoch 2753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1086 - val_loss: 111.3458\n",
      "Epoch 2754/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.2118 - val_loss: 137.4412\n",
      "Epoch 2755/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.5833 - val_loss: 132.8238\n",
      "Epoch 2756/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.6665 - val_loss: 115.2534\n",
      "Epoch 2757/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 154.8573 - val_loss: 118.1952\n",
      "Epoch 2758/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.9844 - val_loss: 118.9394\n",
      "Epoch 2759/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 139.0028 - val_loss: 116.1038\n",
      "Epoch 2760/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3330 - val_loss: 114.3015\n",
      "Epoch 2761/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.8531 - val_loss: 127.8142\n",
      "Epoch 2762/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6007 - val_loss: 123.1489\n",
      "Epoch 2763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0017 - val_loss: 120.8445\n",
      "Epoch 2764/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.7523 - val_loss: 126.3541\n",
      "Epoch 2765/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.4319 - val_loss: 179.2242\n",
      "Epoch 2766/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.7435 - val_loss: 112.9189\n",
      "Epoch 2767/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.5096 - val_loss: 121.8824\n",
      "Epoch 2768/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0625 - val_loss: 112.1273\n",
      "Epoch 2769/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3992 - val_loss: 163.0950\n",
      "Epoch 2770/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.7539 - val_loss: 125.3288\n",
      "Epoch 2771/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.4364 - val_loss: 113.7408\n",
      "Epoch 2772/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6081 - val_loss: 132.0822\n",
      "Epoch 2773/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.8076 - val_loss: 128.9065\n",
      "Epoch 2774/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.5910 - val_loss: 124.2540\n",
      "Epoch 2775/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9061 - val_loss: 142.6937\n",
      "Epoch 2776/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.8265 - val_loss: 144.9948\n",
      "Epoch 2777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9247 - val_loss: 114.6734\n",
      "Epoch 2778/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.4042 - val_loss: 120.7927\n",
      "Epoch 2779/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.6771 - val_loss: 119.6456\n",
      "Epoch 2780/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6854 - val_loss: 113.2978\n",
      "Epoch 2781/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.9410 - val_loss: 119.8366\n",
      "Epoch 2782/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.5055 - val_loss: 155.5151\n",
      "Epoch 2783/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.0324 - val_loss: 165.4886\n",
      "Epoch 2784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.7213 - val_loss: 124.6462\n",
      "Epoch 2785/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.9505 - val_loss: 119.0926\n",
      "Epoch 2786/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.3965 - val_loss: 142.1964\n",
      "Epoch 2787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.8489 - val_loss: 147.8867\n",
      "Epoch 2788/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.5673 - val_loss: 119.6818\n",
      "Epoch 2789/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.1458 - val_loss: 162.7344\n",
      "Epoch 2790/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5078 - val_loss: 119.2303\n",
      "Epoch 2791/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.9402 - val_loss: 116.4741\n",
      "Epoch 2792/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3939 - val_loss: 132.6324\n",
      "Epoch 2793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9693 - val_loss: 121.4160\n",
      "Epoch 2794/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 169.5094 - val_loss: 187.2641\n",
      "Epoch 2795/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 198.7594 - val_loss: 112.8625\n",
      "Epoch 2796/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.5419 - val_loss: 131.9736\n",
      "Epoch 2797/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8828 - val_loss: 130.5621\n",
      "Epoch 2798/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6277 - val_loss: 120.7761\n",
      "Epoch 2799/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8194 - val_loss: 111.2843\n",
      "Epoch 2800/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.5724 - val_loss: 121.0801\n",
      "Epoch 2801/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6177 - val_loss: 112.7949\n",
      "Epoch 2802/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.6204 - val_loss: 119.2497\n",
      "Epoch 2803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6733 - val_loss: 116.0140\n",
      "Epoch 2804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1972 - val_loss: 134.6504\n",
      "Epoch 2805/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.0520 - val_loss: 169.9061\n",
      "Epoch 2806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.2279 - val_loss: 118.8281\n",
      "Epoch 2807/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0489 - val_loss: 118.6485\n",
      "Epoch 2808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7396 - val_loss: 118.0745\n",
      "Epoch 2809/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.4200 - val_loss: 116.9633\n",
      "Epoch 2810/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2695 - val_loss: 120.7746\n",
      "Epoch 2811/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6882 - val_loss: 125.1696\n",
      "Epoch 2812/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0635 - val_loss: 163.2136\n",
      "Epoch 2813/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.6453 - val_loss: 119.9220\n",
      "Epoch 2814/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9609 - val_loss: 149.6066\n",
      "Epoch 2815/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 152.4587 - val_loss: 119.2655\n",
      "Epoch 2816/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.3737 - val_loss: 127.6820\n",
      "Epoch 2817/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4234 - val_loss: 112.8799\n",
      "Epoch 2818/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9814 - val_loss: 115.6369\n",
      "Epoch 2819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1632 - val_loss: 129.6165\n",
      "Epoch 2820/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5819 - val_loss: 120.2691\n",
      "Epoch 2821/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.6507 - val_loss: 126.0430\n",
      "Epoch 2822/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1176 - val_loss: 116.0210\n",
      "Epoch 2823/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6946 - val_loss: 124.1396\n",
      "Epoch 2824/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5526 - val_loss: 117.8730\n",
      "Epoch 2825/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.0953 - val_loss: 123.5766\n",
      "Epoch 2826/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 135.4376 - val_loss: 116.9860\n",
      "Epoch 2827/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 151.9679 - val_loss: 118.8633\n",
      "Epoch 2828/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 152.8874 - val_loss: 140.8027\n",
      "Epoch 2829/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 221.9547 - val_loss: 140.3069\n",
      "Epoch 2830/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.0014 - val_loss: 120.8964\n",
      "Epoch 2831/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3468 - val_loss: 122.4363\n",
      "Epoch 2832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4944 - val_loss: 118.1537\n",
      "Epoch 2833/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.2949 - val_loss: 131.6094\n",
      "Epoch 2834/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.7736 - val_loss: 124.7382\n",
      "Epoch 2835/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8796 - val_loss: 112.0711\n",
      "Epoch 2836/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5570 - val_loss: 109.9281\n",
      "Epoch 2837/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.1856 - val_loss: 112.7981\n",
      "Epoch 2838/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2579 - val_loss: 121.6027\n",
      "Epoch 2839/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.7685 - val_loss: 112.2776\n",
      "Epoch 2840/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5405 - val_loss: 130.9187\n",
      "Epoch 2841/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 139.9706 - val_loss: 151.4237\n",
      "Epoch 2842/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.7297 - val_loss: 120.3576\n",
      "Epoch 2843/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 136.8269 - val_loss: 113.9164\n",
      "Epoch 2844/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5225 - val_loss: 127.9879\n",
      "Epoch 2845/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.2397 - val_loss: 127.8326\n",
      "Epoch 2846/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0620 - val_loss: 119.6245\n",
      "Epoch 2847/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.1428 - val_loss: 118.6988\n",
      "Epoch 2848/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.3098 - val_loss: 122.0489\n",
      "Epoch 2849/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2451 - val_loss: 110.7659\n",
      "Epoch 2850/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.1251 - val_loss: 110.9872\n",
      "Epoch 2851/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.0285 - val_loss: 118.8743\n",
      "Epoch 2852/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.1618 - val_loss: 117.6246\n",
      "Epoch 2853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3837 - val_loss: 112.9486\n",
      "Epoch 2854/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.8422 - val_loss: 138.2786\n",
      "Epoch 2855/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.6268 - val_loss: 130.2589\n",
      "Epoch 2856/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7942 - val_loss: 110.3259\n",
      "Epoch 2857/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8757 - val_loss: 112.0080\n",
      "Epoch 2858/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 136.7222 - val_loss: 115.6723\n",
      "Epoch 2859/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.5172 - val_loss: 116.3672\n",
      "Epoch 2860/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.0671 - val_loss: 114.6667\n",
      "Epoch 2861/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.2316 - val_loss: 129.5868\n",
      "Epoch 2862/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8885 - val_loss: 134.6317\n",
      "Epoch 2863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2884 - val_loss: 126.3960\n",
      "Epoch 2864/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.4132 - val_loss: 117.2110\n",
      "Epoch 2865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2573 - val_loss: 111.9951\n",
      "Epoch 2866/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.0026 - val_loss: 116.7627\n",
      "Epoch 2867/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2673 - val_loss: 113.4821\n",
      "Epoch 2868/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.2560 - val_loss: 122.6125\n",
      "Epoch 2869/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.5407 - val_loss: 113.8452\n",
      "Epoch 2870/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.0631 - val_loss: 119.1749\n",
      "Epoch 2871/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.1178 - val_loss: 126.6552\n",
      "Epoch 2872/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7636 - val_loss: 112.4659\n",
      "Epoch 2873/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8327 - val_loss: 121.8980\n",
      "Epoch 2874/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.8573 - val_loss: 111.8652\n",
      "Epoch 2875/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0926 - val_loss: 117.1804\n",
      "Epoch 2876/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.3178 - val_loss: 124.2998\n",
      "Epoch 2877/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0191 - val_loss: 112.4662\n",
      "Epoch 2878/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.7450 - val_loss: 142.3346\n",
      "Epoch 2879/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0317 - val_loss: 117.9563\n",
      "Epoch 2880/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.6518 - val_loss: 137.9172\n",
      "Epoch 2881/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.7793 - val_loss: 137.1463\n",
      "Epoch 2882/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5244 - val_loss: 114.0819\n",
      "Epoch 2883/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4065 - val_loss: 120.9382\n",
      "Epoch 2884/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.7136 - val_loss: 112.7872\n",
      "Epoch 2885/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 143.3699 - val_loss: 129.1259\n",
      "Epoch 2886/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.5556 - val_loss: 124.0115\n",
      "Epoch 2887/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 162.0138 - val_loss: 115.8264\n",
      "Epoch 2888/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.5303 - val_loss: 122.0563\n",
      "Epoch 2889/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.3611 - val_loss: 122.3832\n",
      "Epoch 2890/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 203.8281 - val_loss: 140.4289\n",
      "Epoch 2891/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.6847 - val_loss: 120.5368\n",
      "Epoch 2892/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.4056 - val_loss: 120.7025\n",
      "Epoch 2893/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.8171 - val_loss: 127.8329\n",
      "Epoch 2894/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.4500 - val_loss: 116.2475\n",
      "Epoch 2895/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 134.0361 - val_loss: 134.3921\n",
      "Epoch 2896/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 160.0303 - val_loss: 112.9344\n",
      "Epoch 2897/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.7280 - val_loss: 120.8131\n",
      "Epoch 2898/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 147.4285 - val_loss: 134.9284\n",
      "Epoch 2899/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4775 - val_loss: 120.0551\n",
      "Epoch 2900/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6862 - val_loss: 111.0553\n",
      "Epoch 2901/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3869 - val_loss: 169.2850\n",
      "Epoch 2902/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3603 - val_loss: 120.5253\n",
      "Epoch 2903/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7673 - val_loss: 109.8321\n",
      "Epoch 2904/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.6155 - val_loss: 129.7574\n",
      "Epoch 2905/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1920 - val_loss: 119.5024\n",
      "Epoch 2906/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.9133 - val_loss: 146.6810\n",
      "Epoch 2907/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.9889 - val_loss: 119.6543\n",
      "Epoch 2908/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6603 - val_loss: 114.1910\n",
      "Epoch 2909/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.8354 - val_loss: 119.2595\n",
      "Epoch 2910/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.2045 - val_loss: 135.7304\n",
      "Epoch 2911/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.3856 - val_loss: 132.1473\n",
      "Epoch 2912/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 152.7713 - val_loss: 140.1462\n",
      "Epoch 2913/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 222.3304 - val_loss: 370.4815\n",
      "Epoch 2914/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3526 - val_loss: 121.2213\n",
      "Epoch 2915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.8226 - val_loss: 171.8063\n",
      "Epoch 2916/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.5972 - val_loss: 114.7215\n",
      "Epoch 2917/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.7809 - val_loss: 176.4060\n",
      "Epoch 2918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.2836 - val_loss: 119.1776\n",
      "Epoch 2919/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.9456 - val_loss: 113.0017\n",
      "Epoch 2920/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2963 - val_loss: 182.1392\n",
      "Epoch 2921/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9412 - val_loss: 112.2145\n",
      "Epoch 2922/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5572 - val_loss: 190.5493\n",
      "Epoch 2923/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.1376 - val_loss: 118.8500\n",
      "Epoch 2924/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.0984 - val_loss: 113.2742\n",
      "Epoch 2925/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5531 - val_loss: 133.4921\n",
      "Epoch 2926/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.3438 - val_loss: 110.8598\n",
      "Epoch 2927/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5806 - val_loss: 116.8735\n",
      "Epoch 2928/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.9181 - val_loss: 113.3655\n",
      "Epoch 2929/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5458 - val_loss: 115.7301\n",
      "Epoch 2930/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.2439 - val_loss: 115.1027\n",
      "Epoch 2931/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.3183 - val_loss: 144.5038\n",
      "Epoch 2932/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3512 - val_loss: 113.1969\n",
      "Epoch 2933/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.8939 - val_loss: 110.6110\n",
      "Epoch 2934/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.9186 - val_loss: 118.7559\n",
      "Epoch 2935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0426 - val_loss: 110.1357\n",
      "Epoch 2936/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.5265 - val_loss: 129.0419\n",
      "Epoch 2937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.4607 - val_loss: 150.8151\n",
      "Epoch 2938/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.1696 - val_loss: 122.8015\n",
      "Epoch 2939/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.1510 - val_loss: 176.5106\n",
      "Epoch 2940/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.0109 - val_loss: 137.6280\n",
      "Epoch 2941/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4236 - val_loss: 115.5723\n",
      "Epoch 2942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0368 - val_loss: 122.6828\n",
      "Epoch 2943/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.9613 - val_loss: 125.6231\n",
      "Epoch 2944/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.2660 - val_loss: 112.8383\n",
      "Epoch 2945/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2598 - val_loss: 111.8253\n",
      "Epoch 2946/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.6439 - val_loss: 112.9093\n",
      "Epoch 2947/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.6886 - val_loss: 131.7812\n",
      "Epoch 2948/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.2838 - val_loss: 148.7822\n",
      "Epoch 2949/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.2783 - val_loss: 118.9619\n",
      "Epoch 2950/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5255 - val_loss: 123.7908\n",
      "Epoch 2951/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0234 - val_loss: 114.0035\n",
      "Epoch 2952/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5750 - val_loss: 125.0433\n",
      "Epoch 2953/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.8484 - val_loss: 131.0891\n",
      "Epoch 2954/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 225.6398 - val_loss: 187.1408\n",
      "Epoch 2955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.9427 - val_loss: 126.3723\n",
      "Epoch 2956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8235 - val_loss: 123.9202\n",
      "Epoch 2957/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7357 - val_loss: 116.0288\n",
      "Epoch 2958/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4701 - val_loss: 150.5975\n",
      "Epoch 2959/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6159 - val_loss: 123.1159\n",
      "Epoch 2960/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1165 - val_loss: 134.3142\n",
      "Epoch 2961/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3536 - val_loss: 148.3140\n",
      "Epoch 2962/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.6925 - val_loss: 130.8658\n",
      "Epoch 2963/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.6334 - val_loss: 176.2294\n",
      "Epoch 2964/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 180.8716 - val_loss: 119.3898\n",
      "Epoch 2965/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.2936 - val_loss: 122.6720\n",
      "Epoch 2966/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.4966 - val_loss: 111.9032\n",
      "Epoch 2967/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0745 - val_loss: 116.2520\n",
      "Epoch 2968/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.4278 - val_loss: 128.0948\n",
      "Epoch 2969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.2991 - val_loss: 118.5358\n",
      "Epoch 2970/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.1153 - val_loss: 113.4859\n",
      "Epoch 2971/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9720 - val_loss: 110.0361\n",
      "Epoch 2972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8575 - val_loss: 137.7142\n",
      "Epoch 2973/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.8474 - val_loss: 116.2013\n",
      "Epoch 2974/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9245 - val_loss: 141.9806\n",
      "Epoch 2975/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 147.3270 - val_loss: 112.2889\n",
      "Epoch 2976/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.7105 - val_loss: 174.8914\n",
      "Epoch 2977/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.4502 - val_loss: 114.2343\n",
      "Epoch 2978/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.2612 - val_loss: 123.0142\n",
      "Epoch 2979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.5115 - val_loss: 119.1623\n",
      "Epoch 2980/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1770 - val_loss: 116.7530\n",
      "Epoch 2981/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.6091 - val_loss: 153.5022\n",
      "Epoch 2982/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 135.3517 - val_loss: 143.1528\n",
      "Epoch 2983/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.8996 - val_loss: 157.6185\n",
      "Epoch 2984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3527 - val_loss: 122.8516\n",
      "Epoch 2985/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2588 - val_loss: 117.8382\n",
      "Epoch 2986/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6662 - val_loss: 124.0431\n",
      "Epoch 2987/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.7792 - val_loss: 113.1303\n",
      "Epoch 2988/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.8903 - val_loss: 121.4532\n",
      "Epoch 2989/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.8292 - val_loss: 190.8706\n",
      "Epoch 2990/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 212.8751 - val_loss: 118.1324\n",
      "Epoch 2991/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.2724 - val_loss: 109.8913\n",
      "Epoch 2992/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0839 - val_loss: 111.2795\n",
      "Epoch 2993/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.9852 - val_loss: 112.6880\n",
      "Epoch 2994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7919 - val_loss: 113.7168\n",
      "Epoch 2995/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 269.1494 - val_loss: 200.9234\n",
      "Epoch 2996/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.0075 - val_loss: 148.9357\n",
      "Epoch 2997/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6518 - val_loss: 113.7712\n",
      "Epoch 2998/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.4491 - val_loss: 123.2225\n",
      "Epoch 2999/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.2633 - val_loss: 114.1367\n",
      "Epoch 3000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3995 - val_loss: 134.1391\n",
      "Epoch 3001/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4843 - val_loss: 114.0882\n",
      "Epoch 3002/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7422 - val_loss: 123.0070\n",
      "Epoch 3003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8515 - val_loss: 142.7732\n",
      "Epoch 3004/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.3393 - val_loss: 146.0288\n",
      "Epoch 3005/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.1675 - val_loss: 118.7160\n",
      "Epoch 3006/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9774 - val_loss: 136.1407\n",
      "Epoch 3007/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.0227 - val_loss: 116.2831\n",
      "Epoch 3008/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5421 - val_loss: 130.9428\n",
      "Epoch 3009/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.2023 - val_loss: 111.2158\n",
      "Epoch 3010/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.6991 - val_loss: 125.8977\n",
      "Epoch 3011/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.0656 - val_loss: 121.4209\n",
      "Epoch 3012/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0755 - val_loss: 128.2295\n",
      "Epoch 3013/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7352 - val_loss: 127.9809\n",
      "Epoch 3014/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1481 - val_loss: 124.7299\n",
      "Epoch 3015/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2855 - val_loss: 134.9564\n",
      "Epoch 3016/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.6819 - val_loss: 109.4557\n",
      "Epoch 3017/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.7345 - val_loss: 119.3927\n",
      "Epoch 3018/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4828 - val_loss: 122.8855\n",
      "Epoch 3019/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1340 - val_loss: 204.7572\n",
      "Epoch 3020/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5823 - val_loss: 152.7220\n",
      "Epoch 3021/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5714 - val_loss: 126.6970\n",
      "Epoch 3022/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6844 - val_loss: 115.4433\n",
      "Epoch 3023/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.5613 - val_loss: 123.9403\n",
      "Epoch 3024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.0879 - val_loss: 123.0377\n",
      "Epoch 3025/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.2301 - val_loss: 127.0307\n",
      "Epoch 3026/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7156 - val_loss: 121.0403\n",
      "Epoch 3027/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.7840 - val_loss: 142.1649\n",
      "Epoch 3028/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1884 - val_loss: 116.8842\n",
      "Epoch 3029/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2976 - val_loss: 119.2568\n",
      "Epoch 3030/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5784 - val_loss: 135.0579\n",
      "Epoch 3031/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6930 - val_loss: 112.8174\n",
      "Epoch 3032/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.9293 - val_loss: 116.2435\n",
      "Epoch 3033/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.6037 - val_loss: 119.4865\n",
      "Epoch 3034/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.2546 - val_loss: 109.3546\n",
      "Epoch 3035/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.7611 - val_loss: 118.7210\n",
      "Epoch 3036/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.5386 - val_loss: 137.8854\n",
      "Epoch 3037/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 157.1036 - val_loss: 149.3204\n",
      "Epoch 3038/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1395 - val_loss: 121.1808\n",
      "Epoch 3039/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.4587 - val_loss: 111.1514\n",
      "Epoch 3040/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0253 - val_loss: 114.4224\n",
      "Epoch 3041/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0914 - val_loss: 125.3869\n",
      "Epoch 3042/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.6637 - val_loss: 115.5145\n",
      "Epoch 3043/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.2652 - val_loss: 112.5709\n",
      "Epoch 3044/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6917 - val_loss: 115.8140\n",
      "Epoch 3045/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.0128 - val_loss: 136.7476\n",
      "Epoch 3046/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.1849 - val_loss: 116.1849\n",
      "Epoch 3047/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.1357 - val_loss: 147.8007\n",
      "Epoch 3048/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.7220 - val_loss: 116.1562\n",
      "Epoch 3049/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.4485 - val_loss: 114.5997\n",
      "Epoch 3050/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.3728 - val_loss: 117.7193\n",
      "Epoch 3051/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.5784 - val_loss: 119.4064\n",
      "Epoch 3052/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.1856 - val_loss: 122.2396\n",
      "Epoch 3053/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.2236 - val_loss: 149.2563\n",
      "Epoch 3054/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.8876 - val_loss: 135.2752\n",
      "Epoch 3055/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.5987 - val_loss: 126.4159\n",
      "Epoch 3056/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.5422 - val_loss: 109.9159\n",
      "Epoch 3057/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 142.3365 - val_loss: 112.4353\n",
      "Epoch 3058/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8176 - val_loss: 148.6115\n",
      "Epoch 3059/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8221 - val_loss: 119.0902\n",
      "Epoch 3060/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.5451 - val_loss: 114.8845\n",
      "Epoch 3061/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.6660 - val_loss: 125.9188\n",
      "Epoch 3062/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 132.0323 - val_loss: 111.1363\n",
      "Epoch 3063/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.5731 - val_loss: 169.4072\n",
      "Epoch 3064/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2313 - val_loss: 112.9593\n",
      "Epoch 3065/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.5090 - val_loss: 194.7203\n",
      "Epoch 3066/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.1348 - val_loss: 133.5597\n",
      "Epoch 3067/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 176.1634 - val_loss: 135.4777\n",
      "Epoch 3068/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.1217 - val_loss: 111.0226\n",
      "Epoch 3069/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 132.0769 - val_loss: 115.4075\n",
      "Epoch 3070/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.5031 - val_loss: 131.8893\n",
      "Epoch 3071/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.7587 - val_loss: 118.9218\n",
      "Epoch 3072/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.3115 - val_loss: 110.6773\n",
      "Epoch 3073/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.7806 - val_loss: 112.8066\n",
      "Epoch 3074/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.6439 - val_loss: 180.6049\n",
      "Epoch 3075/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2485 - val_loss: 119.9453\n",
      "Epoch 3076/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.5185 - val_loss: 163.9408\n",
      "Epoch 3077/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.1935 - val_loss: 124.4999\n",
      "Epoch 3078/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.8668 - val_loss: 114.7235\n",
      "Epoch 3079/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 135.1953 - val_loss: 147.5351\n",
      "Epoch 3080/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 181.4086 - val_loss: 127.1248\n",
      "Epoch 3081/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.3618 - val_loss: 120.8951\n",
      "Epoch 3082/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.0774 - val_loss: 138.0329\n",
      "Epoch 3083/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8435 - val_loss: 117.2846\n",
      "Epoch 3084/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.0751 - val_loss: 116.8752\n",
      "Epoch 3085/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7980 - val_loss: 124.5283\n",
      "Epoch 3086/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.1729 - val_loss: 123.5454\n",
      "Epoch 3087/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0747 - val_loss: 119.2323\n",
      "Epoch 3088/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.6167 - val_loss: 113.0222\n",
      "Epoch 3089/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0154 - val_loss: 125.0947\n",
      "Epoch 3090/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5292 - val_loss: 168.9559\n",
      "Epoch 3091/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 189.1100 - val_loss: 118.3042\n",
      "Epoch 3092/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.7382 - val_loss: 132.8332\n",
      "Epoch 3093/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8385 - val_loss: 110.5630\n",
      "Epoch 3094/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5275 - val_loss: 110.6033\n",
      "Epoch 3095/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6770 - val_loss: 119.2316\n",
      "Epoch 3096/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1212 - val_loss: 117.8504\n",
      "Epoch 3097/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.4366 - val_loss: 187.2861\n",
      "Epoch 3098/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.8650 - val_loss: 118.6002\n",
      "Epoch 3099/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3450 - val_loss: 164.2984\n",
      "Epoch 3100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.5003 - val_loss: 124.5225\n",
      "Epoch 3101/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.9701 - val_loss: 111.9261\n",
      "Epoch 3102/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.6970 - val_loss: 122.3833\n",
      "Epoch 3103/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.3370 - val_loss: 113.8889\n",
      "Epoch 3104/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.7055 - val_loss: 149.6051\n",
      "Epoch 3105/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.5018 - val_loss: 140.6770\n",
      "Epoch 3106/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.5636 - val_loss: 119.8795\n",
      "Epoch 3107/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5778 - val_loss: 117.5594\n",
      "Epoch 3108/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0848 - val_loss: 119.7176\n",
      "Epoch 3109/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.2916 - val_loss: 118.4733\n",
      "Epoch 3110/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.4304 - val_loss: 140.3480\n",
      "Epoch 3111/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9357 - val_loss: 115.1992\n",
      "Epoch 3112/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.0914 - val_loss: 123.4635\n",
      "Epoch 3113/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.5974 - val_loss: 113.2110\n",
      "Epoch 3114/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.8424 - val_loss: 157.4926\n",
      "Epoch 3115/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5728 - val_loss: 133.8927\n",
      "Epoch 3116/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.1700 - val_loss: 140.0662\n",
      "Epoch 3117/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.8808 - val_loss: 187.2896\n",
      "Epoch 3118/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.4906 - val_loss: 150.5300\n",
      "Epoch 3119/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3900 - val_loss: 119.5181\n",
      "Epoch 3120/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.9159 - val_loss: 115.2353\n",
      "Epoch 3121/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.5192 - val_loss: 116.3686\n",
      "Epoch 3122/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 194.3428 - val_loss: 143.8602\n",
      "Epoch 3123/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.7783 - val_loss: 120.9241\n",
      "Epoch 3124/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.1364 - val_loss: 122.9285\n",
      "Epoch 3125/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5523 - val_loss: 130.0436\n",
      "Epoch 3126/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.9518 - val_loss: 115.6146\n",
      "Epoch 3127/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3389 - val_loss: 126.1156\n",
      "Epoch 3128/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.8286 - val_loss: 159.5685\n",
      "Epoch 3129/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.3943 - val_loss: 113.1431\n",
      "Epoch 3130/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.2741 - val_loss: 135.0314\n",
      "Epoch 3131/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.1203 - val_loss: 128.2607\n",
      "Epoch 3132/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.1321 - val_loss: 159.6269\n",
      "Epoch 3133/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.5849 - val_loss: 133.0707\n",
      "Epoch 3134/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.4346 - val_loss: 132.4762\n",
      "Epoch 3135/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.5528 - val_loss: 125.4318\n",
      "Epoch 3136/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0888 - val_loss: 114.3855\n",
      "Epoch 3137/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1557 - val_loss: 151.7375\n",
      "Epoch 3138/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.0113 - val_loss: 130.0222\n",
      "Epoch 3139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.6138 - val_loss: 119.7117\n",
      "Epoch 3140/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2499 - val_loss: 121.8964\n",
      "Epoch 3141/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0385 - val_loss: 124.5178\n",
      "Epoch 3142/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0724 - val_loss: 111.4714\n",
      "Epoch 3143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7473 - val_loss: 121.7905\n",
      "Epoch 3144/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9662 - val_loss: 119.8369\n",
      "Epoch 3145/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1965 - val_loss: 137.1088\n",
      "Epoch 3146/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5423 - val_loss: 128.9862\n",
      "Epoch 3147/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.9784 - val_loss: 118.3893\n",
      "Epoch 3148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1620 - val_loss: 112.5144\n",
      "Epoch 3149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7247 - val_loss: 125.0676\n",
      "Epoch 3150/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2834 - val_loss: 111.5942\n",
      "Epoch 3151/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6633 - val_loss: 169.9346\n",
      "Epoch 3152/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 211.5800 - val_loss: 162.4288\n",
      "Epoch 3153/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.0585 - val_loss: 118.1266\n",
      "Epoch 3154/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5893 - val_loss: 133.1124\n",
      "Epoch 3155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5485 - val_loss: 119.9088\n",
      "Epoch 3156/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.7357 - val_loss: 115.0466\n",
      "Epoch 3157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0489 - val_loss: 134.4153\n",
      "Epoch 3158/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.9129 - val_loss: 122.2940\n",
      "Epoch 3159/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7367 - val_loss: 236.8281\n",
      "Epoch 3160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.6366 - val_loss: 130.1009\n",
      "Epoch 3161/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3309 - val_loss: 142.3277\n",
      "Epoch 3162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7072 - val_loss: 133.3900\n",
      "Epoch 3163/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.9437 - val_loss: 126.9015\n",
      "Epoch 3164/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4106 - val_loss: 110.2173\n",
      "Epoch 3165/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.2789 - val_loss: 118.6399\n",
      "Epoch 3166/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1446 - val_loss: 116.0815\n",
      "Epoch 3167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5908 - val_loss: 123.5748\n",
      "Epoch 3168/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7184 - val_loss: 114.0965\n",
      "Epoch 3169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1491 - val_loss: 116.0645\n",
      "Epoch 3170/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.3057 - val_loss: 113.0265\n",
      "Epoch 3171/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 205.0403 - val_loss: 119.9353\n",
      "Epoch 3172/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.7064 - val_loss: 113.8403\n",
      "Epoch 3173/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 136.4129 - val_loss: 154.0107\n",
      "Epoch 3174/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 159.5781 - val_loss: 120.5921\n",
      "Epoch 3175/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4305 - val_loss: 133.8878\n",
      "Epoch 3176/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4615 - val_loss: 113.2190\n",
      "Epoch 3177/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.5969 - val_loss: 118.0215\n",
      "Epoch 3178/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2815 - val_loss: 125.1661\n",
      "Epoch 3179/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7270 - val_loss: 131.5813\n",
      "Epoch 3180/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6597 - val_loss: 113.2951\n",
      "Epoch 3181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.4655 - val_loss: 123.9914\n",
      "Epoch 3182/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.0290 - val_loss: 141.6975\n",
      "Epoch 3183/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.9706 - val_loss: 137.3933\n",
      "Epoch 3184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5703 - val_loss: 134.3530\n",
      "Epoch 3185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.3678 - val_loss: 164.0600\n",
      "Epoch 3186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8886 - val_loss: 128.9281\n",
      "Epoch 3187/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.0763 - val_loss: 161.4714\n",
      "Epoch 3188/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.8609 - val_loss: 171.3235\n",
      "Epoch 3189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.5729 - val_loss: 144.3407\n",
      "Epoch 3190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1237 - val_loss: 122.1570\n",
      "Epoch 3191/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.6264 - val_loss: 131.5829\n",
      "Epoch 3192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.0156 - val_loss: 148.2887\n",
      "Epoch 3193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8444 - val_loss: 119.4105\n",
      "Epoch 3194/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.2571 - val_loss: 114.1024\n",
      "Epoch 3195/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6264 - val_loss: 114.7793\n",
      "Epoch 3196/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.0833 - val_loss: 119.1758\n",
      "Epoch 3197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7087 - val_loss: 114.5320\n",
      "Epoch 3198/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.5783 - val_loss: 138.1386\n",
      "Epoch 3199/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8813 - val_loss: 116.1312\n",
      "Epoch 3200/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 213.0976 - val_loss: 155.9912\n",
      "Epoch 3201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9268 - val_loss: 114.3574\n",
      "Epoch 3202/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.1514 - val_loss: 118.2747\n",
      "Epoch 3203/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6181 - val_loss: 117.6535\n",
      "Epoch 3204/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7561 - val_loss: 122.7270\n",
      "Epoch 3205/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.5039 - val_loss: 162.5597\n",
      "Epoch 3206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7693 - val_loss: 125.2313\n",
      "Epoch 3207/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5326 - val_loss: 116.6578\n",
      "Epoch 3208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9098 - val_loss: 114.2170\n",
      "Epoch 3209/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.3623 - val_loss: 153.2508\n",
      "Epoch 3210/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.1266 - val_loss: 122.4668\n",
      "Epoch 3211/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.7307 - val_loss: 121.8732\n",
      "Epoch 3212/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5175 - val_loss: 138.2389\n",
      "Epoch 3213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4282 - val_loss: 114.8307\n",
      "Epoch 3214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1687 - val_loss: 115.0737\n",
      "Epoch 3215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9674 - val_loss: 110.4028\n",
      "Epoch 3216/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.0204 - val_loss: 118.6288\n",
      "Epoch 3217/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8121 - val_loss: 113.1914\n",
      "Epoch 3218/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.0615 - val_loss: 111.6774\n",
      "Epoch 3219/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.1414 - val_loss: 135.4488\n",
      "Epoch 3220/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0557 - val_loss: 131.3713\n",
      "Epoch 3221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7282 - val_loss: 108.4597\n",
      "Epoch 3222/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.9214 - val_loss: 116.9296\n",
      "Epoch 3223/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 213.6776 - val_loss: 131.8927\n",
      "Epoch 3224/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.6984 - val_loss: 140.5426\n",
      "Epoch 3225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7440 - val_loss: 128.6811\n",
      "Epoch 3226/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.2539 - val_loss: 113.5152\n",
      "Epoch 3227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3615 - val_loss: 150.0284\n",
      "Epoch 3228/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0435 - val_loss: 118.6485\n",
      "Epoch 3229/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.8194 - val_loss: 112.8871\n",
      "Epoch 3230/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9158 - val_loss: 111.9388\n",
      "Epoch 3231/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.9491 - val_loss: 127.8005\n",
      "Epoch 3232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.2623 - val_loss: 113.2164\n",
      "Epoch 3233/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.3977 - val_loss: 127.9427\n",
      "Epoch 3234/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.5364 - val_loss: 113.5339\n",
      "Epoch 3235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7269 - val_loss: 121.4533\n",
      "Epoch 3236/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7968 - val_loss: 122.4061\n",
      "Epoch 3237/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.1306 - val_loss: 117.7116\n",
      "Epoch 3238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1160 - val_loss: 122.9303\n",
      "Epoch 3239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1488 - val_loss: 144.7417\n",
      "Epoch 3240/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.1693 - val_loss: 113.8674\n",
      "Epoch 3241/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.4327 - val_loss: 111.0375\n",
      "Epoch 3242/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.2186 - val_loss: 114.6966\n",
      "Epoch 3243/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.0979 - val_loss: 135.3347\n",
      "Epoch 3244/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 143.9091 - val_loss: 131.2363\n",
      "Epoch 3245/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.7904 - val_loss: 125.2941\n",
      "Epoch 3246/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.8442 - val_loss: 112.3755\n",
      "Epoch 3247/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.4048 - val_loss: 113.1243\n",
      "Epoch 3248/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6371 - val_loss: 136.7400\n",
      "Epoch 3249/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5001 - val_loss: 124.0903\n",
      "Epoch 3250/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.4974 - val_loss: 153.3590\n",
      "Epoch 3251/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.9685 - val_loss: 122.2389\n",
      "Epoch 3252/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.7019 - val_loss: 149.4883\n",
      "Epoch 3253/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.3083 - val_loss: 126.2885\n",
      "Epoch 3254/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1154 - val_loss: 147.6952\n",
      "Epoch 3255/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5719 - val_loss: 115.0062\n",
      "Epoch 3256/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.1612 - val_loss: 126.7640\n",
      "Epoch 3257/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.1483 - val_loss: 164.9825\n",
      "Epoch 3258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.2846 - val_loss: 129.9023\n",
      "Epoch 3259/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2870 - val_loss: 145.0190\n",
      "Epoch 3260/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6103 - val_loss: 110.5818\n",
      "Epoch 3261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3271 - val_loss: 112.9671\n",
      "Epoch 3262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1971 - val_loss: 111.6144\n",
      "Epoch 3263/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8905 - val_loss: 113.3578\n",
      "Epoch 3264/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.3175 - val_loss: 115.4166\n",
      "Epoch 3265/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.6672 - val_loss: 123.3802\n",
      "Epoch 3266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.2679 - val_loss: 144.1630\n",
      "Epoch 3267/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.8171 - val_loss: 128.2382\n",
      "Epoch 3268/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 190.0847 - val_loss: 124.0378\n",
      "Epoch 3269/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1238 - val_loss: 126.2608\n",
      "Epoch 3270/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.2488 - val_loss: 140.4799\n",
      "Epoch 3271/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3186 - val_loss: 116.1272\n",
      "Epoch 3272/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2903 - val_loss: 112.1813\n",
      "Epoch 3273/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3693 - val_loss: 137.1120\n",
      "Epoch 3274/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.5421 - val_loss: 114.2559\n",
      "Epoch 3275/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.6978 - val_loss: 110.4460\n",
      "Epoch 3276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1582 - val_loss: 133.3440\n",
      "Epoch 3277/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4053 - val_loss: 138.8984\n",
      "Epoch 3278/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 253.2959 - val_loss: 136.5322\n",
      "Epoch 3279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8065 - val_loss: 110.1823\n",
      "Epoch 3280/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7351 - val_loss: 140.4200\n",
      "Epoch 3281/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.2845 - val_loss: 123.7931\n",
      "Epoch 3282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1295 - val_loss: 152.2874\n",
      "Epoch 3283/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.8145 - val_loss: 120.2705\n",
      "Epoch 3284/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7138 - val_loss: 121.1441\n",
      "Epoch 3285/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.9411 - val_loss: 120.5436\n",
      "Epoch 3286/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.1698 - val_loss: 117.2864\n",
      "Epoch 3287/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.4820 - val_loss: 111.3572\n",
      "Epoch 3288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.6012 - val_loss: 137.7372\n",
      "Epoch 3289/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2888 - val_loss: 119.7367\n",
      "Epoch 3290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.0193 - val_loss: 148.7551\n",
      "Epoch 3291/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.1819 - val_loss: 159.8736\n",
      "Epoch 3292/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.3670 - val_loss: 185.4246\n",
      "Epoch 3293/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7852 - val_loss: 110.9732\n",
      "Epoch 3294/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0927 - val_loss: 126.2050\n",
      "Epoch 3295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7190 - val_loss: 115.4938\n",
      "Epoch 3296/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6851 - val_loss: 113.5899\n",
      "Epoch 3297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.6930 - val_loss: 174.4704\n",
      "Epoch 3298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1342 - val_loss: 121.0927\n",
      "Epoch 3299/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.7943 - val_loss: 119.5120\n",
      "Epoch 3300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3941 - val_loss: 124.6464\n",
      "Epoch 3301/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0766 - val_loss: 108.7890\n",
      "Epoch 3302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3627 - val_loss: 127.0656\n",
      "Epoch 3303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3719 - val_loss: 155.3544\n",
      "Epoch 3304/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.5732 - val_loss: 126.0863\n",
      "Epoch 3305/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5766 - val_loss: 150.6417\n",
      "Epoch 3306/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.3453 - val_loss: 116.7808\n",
      "Epoch 3307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1319 - val_loss: 114.2864\n",
      "Epoch 3308/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.2538 - val_loss: 124.9686\n",
      "Epoch 3309/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0088 - val_loss: 115.6315\n",
      "Epoch 3310/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.6716 - val_loss: 120.6383\n",
      "Epoch 3311/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.4486 - val_loss: 137.9091\n",
      "Epoch 3312/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 166.0729 - val_loss: 115.5680\n",
      "Epoch 3313/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.4008 - val_loss: 115.6733\n",
      "Epoch 3314/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 149.2336 - val_loss: 112.8783\n",
      "Epoch 3315/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 129.1374 - val_loss: 121.1819\n",
      "Epoch 3316/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7276 - val_loss: 163.7331\n",
      "Epoch 3317/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7898 - val_loss: 128.9380\n",
      "Epoch 3318/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4194 - val_loss: 113.7882\n",
      "Epoch 3319/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.8029 - val_loss: 115.2675\n",
      "Epoch 3320/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8360 - val_loss: 146.3605\n",
      "Epoch 3321/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.1013 - val_loss: 121.4691\n",
      "Epoch 3322/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7668 - val_loss: 128.6488\n",
      "Epoch 3323/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.4362 - val_loss: 138.1406\n",
      "Epoch 3324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.5751 - val_loss: 120.5573\n",
      "Epoch 3325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7769 - val_loss: 153.6814\n",
      "Epoch 3326/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.3541 - val_loss: 134.5125\n",
      "Epoch 3327/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.0878 - val_loss: 131.0879\n",
      "Epoch 3328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2611 - val_loss: 119.0702\n",
      "Epoch 3329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5445 - val_loss: 123.8602\n",
      "Epoch 3330/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0758 - val_loss: 162.5447\n",
      "Epoch 3331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.2553 - val_loss: 114.2928\n",
      "Epoch 3332/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0918 - val_loss: 113.7749\n",
      "Epoch 3333/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.7738 - val_loss: 113.3092\n",
      "Epoch 3334/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5757 - val_loss: 124.1843\n",
      "Epoch 3335/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.1512 - val_loss: 137.7425\n",
      "Epoch 3336/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7049 - val_loss: 126.5287\n",
      "Epoch 3337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0966 - val_loss: 136.3234\n",
      "Epoch 3338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4199 - val_loss: 117.2000\n",
      "Epoch 3339/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2317 - val_loss: 123.8081\n",
      "Epoch 3340/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 200.5824 - val_loss: 122.9228\n",
      "Epoch 3341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.1034 - val_loss: 132.4795\n",
      "Epoch 3342/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7704 - val_loss: 176.7718\n",
      "Epoch 3343/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5937 - val_loss: 181.5143\n",
      "Epoch 3344/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.5586 - val_loss: 126.1461\n",
      "Epoch 3345/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5778 - val_loss: 116.8514\n",
      "Epoch 3346/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.5675 - val_loss: 122.8936\n",
      "Epoch 3347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8142 - val_loss: 129.5484\n",
      "Epoch 3348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3015 - val_loss: 117.7451\n",
      "Epoch 3349/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6544 - val_loss: 113.3803\n",
      "Epoch 3350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0539 - val_loss: 182.2807\n",
      "Epoch 3351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9638 - val_loss: 119.1447\n",
      "Epoch 3352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4803 - val_loss: 133.8150\n",
      "Epoch 3353/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4700 - val_loss: 130.3879\n",
      "Epoch 3354/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.9739 - val_loss: 146.2335\n",
      "Epoch 3355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.3782 - val_loss: 181.3744\n",
      "Epoch 3356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.7432 - val_loss: 153.9208\n",
      "Epoch 3357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9344 - val_loss: 116.5639\n",
      "Epoch 3358/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.6761 - val_loss: 141.9734\n",
      "Epoch 3359/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.7063 - val_loss: 118.6841\n",
      "Epoch 3360/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5356 - val_loss: 134.7062\n",
      "Epoch 3361/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.4064 - val_loss: 115.7335\n",
      "Epoch 3362/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6982 - val_loss: 119.8071\n",
      "Epoch 3363/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7442 - val_loss: 144.5881\n",
      "Epoch 3364/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.6905 - val_loss: 155.0883\n",
      "Epoch 3365/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.6952 - val_loss: 144.2976\n",
      "Epoch 3366/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3661 - val_loss: 122.5797\n",
      "Epoch 3367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8104 - val_loss: 126.9883\n",
      "Epoch 3368/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4080 - val_loss: 114.4454\n",
      "Epoch 3369/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.3371 - val_loss: 117.2481\n",
      "Epoch 3370/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.6679 - val_loss: 116.5256\n",
      "Epoch 3371/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.3984 - val_loss: 124.5682\n",
      "Epoch 3372/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0798 - val_loss: 112.9281\n",
      "Epoch 3373/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9458 - val_loss: 114.8630\n",
      "Epoch 3374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0910 - val_loss: 115.2536\n",
      "Epoch 3375/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5216 - val_loss: 111.8099\n",
      "Epoch 3376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0065 - val_loss: 114.6530\n",
      "Epoch 3377/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4439 - val_loss: 129.7432\n",
      "Epoch 3378/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.4875 - val_loss: 113.9142\n",
      "Epoch 3379/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 179.9501 - val_loss: 156.5524\n",
      "Epoch 3380/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.7819 - val_loss: 123.1304\n",
      "Epoch 3381/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 143.5032 - val_loss: 116.5481\n",
      "Epoch 3382/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 134.6939 - val_loss: 114.2003\n",
      "Epoch 3383/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 134.0975 - val_loss: 113.7652\n",
      "Epoch 3384/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.5149 - val_loss: 123.7721\n",
      "Epoch 3385/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.2966 - val_loss: 133.2330\n",
      "Epoch 3386/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.7738 - val_loss: 207.0739\n",
      "Epoch 3387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7004 - val_loss: 160.1139\n",
      "Epoch 3388/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3349 - val_loss: 119.9473\n",
      "Epoch 3389/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.8178 - val_loss: 113.2774\n",
      "Epoch 3390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4810 - val_loss: 118.6800\n",
      "Epoch 3391/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9798 - val_loss: 115.5642\n",
      "Epoch 3392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0536 - val_loss: 119.6205\n",
      "Epoch 3393/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.7988 - val_loss: 113.9561\n",
      "Epoch 3394/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4670 - val_loss: 111.3399\n",
      "Epoch 3395/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2419 - val_loss: 134.9504\n",
      "Epoch 3396/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.6569 - val_loss: 121.5146\n",
      "Epoch 3397/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6667 - val_loss: 129.6433\n",
      "Epoch 3398/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2555 - val_loss: 109.7311\n",
      "Epoch 3399/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5700 - val_loss: 118.2547\n",
      "Epoch 3400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6012 - val_loss: 131.1489\n",
      "Epoch 3401/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6780 - val_loss: 115.2178\n",
      "Epoch 3402/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4341 - val_loss: 119.3702\n",
      "Epoch 3403/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.0549 - val_loss: 126.4120\n",
      "Epoch 3404/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.5757 - val_loss: 114.0214\n",
      "Epoch 3405/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.9787 - val_loss: 222.7580\n",
      "Epoch 3406/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.6918 - val_loss: 126.6517\n",
      "Epoch 3407/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5298 - val_loss: 118.8187\n",
      "Epoch 3408/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 132.5279 - val_loss: 116.9901\n",
      "Epoch 3409/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4851 - val_loss: 113.5893\n",
      "Epoch 3410/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.8519 - val_loss: 126.2649\n",
      "Epoch 3411/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5678 - val_loss: 116.0244\n",
      "Epoch 3412/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.4976 - val_loss: 111.5738\n",
      "Epoch 3413/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.3719 - val_loss: 115.1191\n",
      "Epoch 3414/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7840 - val_loss: 158.4619\n",
      "Epoch 3415/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.1567 - val_loss: 126.6772\n",
      "Epoch 3416/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.2491 - val_loss: 114.0491\n",
      "Epoch 3417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8217 - val_loss: 124.2959\n",
      "Epoch 3418/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6082 - val_loss: 120.9091\n",
      "Epoch 3419/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2819 - val_loss: 123.9762\n",
      "Epoch 3420/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.2202 - val_loss: 115.1836\n",
      "Epoch 3421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.7519 - val_loss: 114.3446\n",
      "Epoch 3422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4765 - val_loss: 111.7673\n",
      "Epoch 3423/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.9334 - val_loss: 144.5592\n",
      "Epoch 3424/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7029 - val_loss: 112.8039\n",
      "Epoch 3425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.2515 - val_loss: 111.6670\n",
      "Epoch 3426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8824 - val_loss: 137.9699\n",
      "Epoch 3427/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.0810 - val_loss: 172.1389\n",
      "Epoch 3428/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7159 - val_loss: 115.7911\n",
      "Epoch 3429/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.3955 - val_loss: 117.8067\n",
      "Epoch 3430/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.3776 - val_loss: 118.4669\n",
      "Epoch 3431/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5200 - val_loss: 134.1427\n",
      "Epoch 3432/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.9595 - val_loss: 228.5290\n",
      "Epoch 3433/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.0740 - val_loss: 150.7590\n",
      "Epoch 3434/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.5205 - val_loss: 121.0717\n",
      "Epoch 3435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0396 - val_loss: 115.7579\n",
      "Epoch 3436/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0005 - val_loss: 120.4322\n",
      "Epoch 3437/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6145 - val_loss: 131.4844\n",
      "Epoch 3438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6442 - val_loss: 124.1266\n",
      "Epoch 3439/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6174 - val_loss: 114.8606\n",
      "Epoch 3440/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.7649 - val_loss: 122.0010\n",
      "Epoch 3441/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5322 - val_loss: 113.6316\n",
      "Epoch 3442/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5801 - val_loss: 112.6300\n",
      "Epoch 3443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5836 - val_loss: 134.9937\n",
      "Epoch 3444/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.5637 - val_loss: 111.2827\n",
      "Epoch 3445/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2668 - val_loss: 164.1696\n",
      "Epoch 3446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6630 - val_loss: 199.3395\n",
      "Epoch 3447/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6614 - val_loss: 114.1523\n",
      "Epoch 3448/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.7549 - val_loss: 114.6295\n",
      "Epoch 3449/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9218 - val_loss: 124.5438\n",
      "Epoch 3450/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.6115 - val_loss: 116.1291\n",
      "Epoch 3451/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.5450 - val_loss: 110.2211\n",
      "Epoch 3452/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 162.2442 - val_loss: 150.4659\n",
      "Epoch 3453/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 162.1902 - val_loss: 136.5896\n",
      "Epoch 3454/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 168.0108 - val_loss: 123.4092\n",
      "Epoch 3455/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5123 - val_loss: 125.7062\n",
      "Epoch 3456/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.0870 - val_loss: 129.3638\n",
      "Epoch 3457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9801 - val_loss: 113.9453\n",
      "Epoch 3458/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1370 - val_loss: 117.1318\n",
      "Epoch 3459/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.5140 - val_loss: 110.7800\n",
      "Epoch 3460/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5666 - val_loss: 123.6684\n",
      "Epoch 3461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.1312 - val_loss: 116.2586\n",
      "Epoch 3462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5777 - val_loss: 117.5593\n",
      "Epoch 3463/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.6702 - val_loss: 118.5411\n",
      "Epoch 3464/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5394 - val_loss: 165.2252\n",
      "Epoch 3465/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.8263 - val_loss: 153.7917\n",
      "Epoch 3466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7878 - val_loss: 126.1893\n",
      "Epoch 3467/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.5657 - val_loss: 129.0231\n",
      "Epoch 3468/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2762 - val_loss: 118.5893\n",
      "Epoch 3469/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8750 - val_loss: 133.1215\n",
      "Epoch 3470/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 222.1387 - val_loss: 136.1782\n",
      "Epoch 3471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.4245 - val_loss: 127.2496\n",
      "Epoch 3472/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.4627 - val_loss: 236.4651\n",
      "Epoch 3473/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.9383 - val_loss: 120.6704\n",
      "Epoch 3474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4337 - val_loss: 139.3802\n",
      "Epoch 3475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5594 - val_loss: 152.5523\n",
      "Epoch 3476/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 165.6900 - val_loss: 129.8415\n",
      "Epoch 3477/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 200.8076 - val_loss: 112.9263\n",
      "Epoch 3478/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.1510 - val_loss: 178.9069\n",
      "Epoch 3479/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.5198 - val_loss: 166.2239\n",
      "Epoch 3480/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.0419 - val_loss: 120.6875\n",
      "Epoch 3481/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2316 - val_loss: 140.8808\n",
      "Epoch 3482/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.3054 - val_loss: 116.7859\n",
      "Epoch 3483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8106 - val_loss: 122.0575\n",
      "Epoch 3484/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.2599 - val_loss: 190.7963\n",
      "Epoch 3485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.6913 - val_loss: 116.4894\n",
      "Epoch 3486/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9312 - val_loss: 114.0630\n",
      "Epoch 3487/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7898 - val_loss: 114.8464\n",
      "Epoch 3488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5111 - val_loss: 109.1825\n",
      "Epoch 3489/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7333 - val_loss: 115.8773\n",
      "Epoch 3490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.2268 - val_loss: 115.5943\n",
      "Epoch 3491/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.4869 - val_loss: 123.5641\n",
      "Epoch 3492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1267 - val_loss: 124.8512\n",
      "Epoch 3493/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.1582 - val_loss: 139.2806\n",
      "Epoch 3494/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.0301 - val_loss: 114.4289\n",
      "Epoch 3495/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7857 - val_loss: 121.2536\n",
      "Epoch 3496/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.7957 - val_loss: 139.1303\n",
      "Epoch 3497/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.6203 - val_loss: 115.5797\n",
      "Epoch 3498/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.3709 - val_loss: 115.5737\n",
      "Epoch 3499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7784 - val_loss: 115.3812\n",
      "Epoch 3500/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.5047 - val_loss: 129.3488\n",
      "Epoch 3501/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2832 - val_loss: 122.4218\n",
      "Epoch 3502/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.2092 - val_loss: 162.3878\n",
      "Epoch 3503/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7274 - val_loss: 123.1343\n",
      "Epoch 3504/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 171.9982 - val_loss: 194.3539\n",
      "Epoch 3505/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4080 - val_loss: 120.4329\n",
      "Epoch 3506/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5915 - val_loss: 118.2858\n",
      "Epoch 3507/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4758 - val_loss: 115.0062\n",
      "Epoch 3508/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.9694 - val_loss: 109.7831\n",
      "Epoch 3509/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 188.8383 - val_loss: 151.6253\n",
      "Epoch 3510/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.3419 - val_loss: 119.0336\n",
      "Epoch 3511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6174 - val_loss: 124.6104\n",
      "Epoch 3512/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1807 - val_loss: 120.0173\n",
      "Epoch 3513/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.0958 - val_loss: 119.5360\n",
      "Epoch 3514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2393 - val_loss: 114.9585\n",
      "Epoch 3515/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.6432 - val_loss: 120.8064\n",
      "Epoch 3516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4565 - val_loss: 119.7743\n",
      "Epoch 3517/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0005 - val_loss: 112.0466\n",
      "Epoch 3518/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.5951 - val_loss: 387.1420\n",
      "Epoch 03518: early stopping\n",
      "Fold score (RMSE): 19.522615432739258\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validate\n",
    "kf = KFold(5)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filename_checkpoint, verbose=0, save_best_only=True)\n",
    "\n",
    "# Turn off KFold\n",
    "#if (0):\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "    \n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dropout(0.01)) # Dropout Layer\n",
    "    model.add(Dense(50, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(25, \n",
    "                    #kernel_regularizer=regularizers.l2(0.01), #L2 regularization\n",
    "                    activity_regularizer=regularizers.l1(0.01), #L1 Lasso regularization\n",
    "                    activation='relu')) # Hidden 3 \n",
    "    model.add(Dense(10, activation='relu')) # Hidden 4\n",
    "    model.add(Dense(1)) # Output\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=1000, verbose=1, mode='auto')\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpoint],verbose=1,epochs=10000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's RMSE\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final, out of sample score (RMSE): 13.814482688903809\n"
     ]
    }
   ],
   "source": [
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#pred = model.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "#score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "#print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "#chart_regression(pred.flatten(),y_test)\n",
    "#chart_regression(pred.flatten(),y_test,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(filename_checkpoint)\n",
    "\n",
    "df_test = pd.read_csv(filename_test,na_values=['NA','?'])\n",
    "\n",
    "extract_and_encode_features(df_test)\n",
    "\n",
    "ids_test = df_test['id']\n",
    "df_test.drop('id',1,inplace=True)\n",
    "\n",
    "names_test = df_test['name']\n",
    "df_test.drop('name',1,inplace=True)\n",
    "\n",
    "x_submit = df_test.as_matrix().astype(np.float32)\n",
    "pred_submit = model.predict(x_submit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = [n if n > 0 else n * -1 for n in pred_submit[:,0]]\n",
    "df_submit = pd.DataFrame({'id': ids_test,'cost': cost})\n",
    "df_submit = df_submit[['id', 'cost']]\n",
    "df_submit.to_csv(filename_submit, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
