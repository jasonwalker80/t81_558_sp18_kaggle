{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Kaggle Assignment: **\n",
    "\n",
    "**Student Name: Jason Walker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Description\n",
    "This is one of the projects from the course T81-855: Applications of Deep Learning at Washington University in St. Louis. All students must create a Kaggle account and submit a solution. Once you have submitted your solution entry log into Blackboard (at WUSTL) and submit a single file telling me your Kaggle name on the leaderboard (you do not need to register to Kaggle with your real name). This competition will be visible to the public, so there may be non-student submissions as well as student.\n",
    "\n",
    "The data set for this competition consists of a number of input columns that should be used to predict a stores sales. This is a regression problem. The inputs are a mixture of discrete and category values. The data set is from a simulation.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The evaluation pages describes how submissions will be scored and how students should format their submissions. The scores are in RMSE.\n",
    "Submission Format\n",
    "\n",
    "For every store in the dataset, submission files should contain a sales volume.\n",
    "\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "```\n",
    "100000,1.23\n",
    "100001,1.123\n",
    "100002,3.332\n",
    "100003,1.53\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Data Description\n",
    "\n",
    "The data contains data and costs for various office supplies. The data came from a simulation and do not directly correspond to any real-world items. See how well you can predict the cost of an item using the provided data. Feature engineering will likely help you. The *name* column may seem useless at first glance; however, it contains information that you can parse to help your predictions.\n",
    "File descriptions\n",
    "```\n",
    "    id - The identifier/primary key.\n",
    "    name - The name of this item.\n",
    "    manufacturer - The manufacturer.\n",
    "    pack - The number of items in this pack.\n",
    "    weight - The weight of a pack of these items.\n",
    "    height - The height of a pack of these items.\n",
    "    width - The width of a pack of these items.\n",
    "    length - The length of a pack of these items.\n",
    "    cost - The cost for this item pack. This is what you are to predict (the target). \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions\n",
    "\n",
    "You will see these at the top of every module and assignment.  These are simply a set of reusable functions that we will make use of.  Each of them will be explained as the semester progresses.  They are explained in greater detail as the course progresses.  Class 4 contains a complete overview of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "        \n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kaggle Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwalker/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "path = './data'\n",
    "\n",
    "filename_test = os.path.join(path,\"test.csv\")\n",
    "filename_train = os.path.join(path,\"train.csv\")\n",
    "filename_sample = os.path.join(path,\"sample.csv\")\n",
    "filename_submit = os.path.join(path,\"submit.csv\")\n",
    "filename_checkpoint = os.path.join(path,\"checkpoint.hdf5\")\n",
    "\n",
    "df_train = pd.read_csv(filename_train,na_values=['NA','?'])\n",
    "\n",
    "np.random.seed(42) # Uncomment this line to get the same shuffle each time\n",
    "df_train = df_train.reindex(np.random.permutation(df_train.index))\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Encode Features\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def extract_and_encode_features(df):\n",
    "    color_regex='(?P<color>red|blue|green|yellow|orange|pink|black|brown|white)'\n",
    "    df['color'] = df.name.str.extract(color_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    quality_regex='(?P<quality>generic|high\\squality)'\n",
    "    df['quality'] = df.name.str.extract(quality_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    size_regex='(?P<size>tiny|small|medium|large)'\n",
    "    df['size'] = df.name.str.extract(size_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    item_regex='(?P<item>paperclips|paperweights|ink\\spens|pencils|stapler|tablets|thumbtacks|post\\sit\\snotes)'\n",
    "    df['item'] = df.name.str.extract(item_regex, flags=re.IGNORECASE, expand=False)\n",
    "    \n",
    "    for column in ['pack','weight','height','width','length']:\n",
    "        missing_median(df,column)\n",
    "    \n",
    "    #df.insert(1,'surface_area',(df['height']*df['width']*df['length']).astype(int))\n",
    "    \n",
    "    ## encode numeric features\n",
    "    #for column in ['pack','weight','height','width','length','surface_area']:\n",
    "    #    encode_numeric_zscore(df,column)\n",
    "\n",
    "    # encode text/categorical features\n",
    "    for column in ['manufacturer','color','quality','size','item']:\n",
    "        encode_text_dummy(df,column)\n",
    "  \n",
    "extract_and_encode_features(df_train)\n",
    "\n",
    "ids_train = df_train['id']\n",
    "df_train.drop('id',1,inplace=True)\n",
    "\n",
    "names_train = df_train['name']\n",
    "df_train.drop('name',1,inplace=True)\n",
    "\n",
    "x,y = to_xy(df_train,'cost')\n",
    "\n",
    "# Used before KFold\n",
    "#x_train, x_test, y_train, y_test = train_test_split(    \n",
    "#    x, y, test_size=0.25, random_state=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to evaluate the coefficients of a regression\n",
    "%matplotlib inline    \n",
    "from IPython.display import display, HTML    \n",
    "\n",
    "def report_coef(names,coef,intercept):\n",
    "    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n",
    "    r = r.sort_values(by=['coef'])\n",
    "    display(r)\n",
    "    print(\"Intercept: {}\".format(intercept))\n",
    "    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))\n",
    "    \n",
    "# Create linear regression\n",
    "regressor = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# Fit/train linear regression\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "print(names)\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_[0,:],\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Lasso(random_state=0,alpha=0.01)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lasso = Lasso(random_state=42)\n",
    "alphas = np.logspace(-8, 8, 10)\n",
    "\n",
    "scores = list()\n",
    "scores_std = list()\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.alpha = alpha\n",
    "    this_scores = cross_val_score(lasso, x, y, cv=n_folds, n_jobs=1)\n",
    "    scores.append(np.mean(this_scores))\n",
    "    scores_std.append(np.std(this_scores))\n",
    "\n",
    "scores, scores_std = np.array(scores), np.array(scores_std)\n",
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Ridge(alpha=1)\n",
    "\n",
    "# Fit/train Ridge\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_[0,:],\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create linear regression\n",
    "regressor = ElasticNet(alpha=0.01, l1_ratio=0.1)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 5175.7872 - val_loss: 4352.9070\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 4924.2017 - val_loss: 3923.2911\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 4585.4411 - val_loss: 3667.3977\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 4383.6586 - val_loss: 3661.4572\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 4246.3518 - val_loss: 3544.9565\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 4228.7725 - val_loss: 3523.5790\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 4188.1532 - val_loss: 3410.1037\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 4034.2734 - val_loss: 3329.7115\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 4097.0783 - val_loss: 3331.7805\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 3839.0922 - val_loss: 3105.3177\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 3828.4099 - val_loss: 4078.4081\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 3633.7292 - val_loss: 2903.8561\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 3417.1659 - val_loss: 2529.9933\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 2936.9049 - val_loss: 2748.8244\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 2503.8781 - val_loss: 1569.0055\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 2057.5719 - val_loss: 1491.6344\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 1756.2315 - val_loss: 1214.9595\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 1381.5369 - val_loss: 1264.6959\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 1273.7766 - val_loss: 680.7429\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 1057.9105 - val_loss: 770.6148\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 984.6723 - val_loss: 468.5222\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 1063.0834 - val_loss: 469.8588\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 860.5728 - val_loss: 550.3226\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 648.1352 - val_loss: 541.5619\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 708.9415 - val_loss: 409.1788\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 734.2203 - val_loss: 578.5605\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 567.2436 - val_loss: 399.8992\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 562.5067 - val_loss: 345.3622\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 572.8948 - val_loss: 447.6977\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 608.8922 - val_loss: 509.4390\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 559.0894 - val_loss: 402.6004\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 580.3340 - val_loss: 327.6925\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 476.0313 - val_loss: 368.0231\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 527.0125 - val_loss: 396.6154\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 521.9858 - val_loss: 300.9868\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 473.2383 - val_loss: 655.6047\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 538.1493 - val_loss: 333.1844\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 555.8319 - val_loss: 299.7412\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 481.9437 - val_loss: 532.9409\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 484.9916 - val_loss: 392.4730\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 553.1848 - val_loss: 307.3755\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 423.9217 - val_loss: 308.7291\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 448.4369 - val_loss: 334.3954\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 554.6379 - val_loss: 1428.5518\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 582.9228 - val_loss: 305.5457\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 439.5954 - val_loss: 672.1966\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 389.6181 - val_loss: 312.9308\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 408.5883 - val_loss: 365.1283\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 562.8489 - val_loss: 376.8280\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 378.7972 - val_loss: 258.5121\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 515.3780 - val_loss: 273.4516\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 364.1160 - val_loss: 400.7692\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 480.4577 - val_loss: 284.6008\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 350.5986 - val_loss: 317.4685\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 405.6691 - val_loss: 257.9248\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 459.2386 - val_loss: 247.7244\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 362.4266 - val_loss: 353.9567\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 459.6153 - val_loss: 611.3595\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 376.5270 - val_loss: 257.8296\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 354.0984 - val_loss: 1055.0217\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 489.6694 - val_loss: 301.2788\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 371.2754 - val_loss: 283.4869\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 329.2751 - val_loss: 296.2399\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 383.1336 - val_loss: 305.6477\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 357.2508 - val_loss: 281.4988\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 391.9221 - val_loss: 211.8782\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 347.0984 - val_loss: 344.7923\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 324.2079 - val_loss: 259.9287\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 283.1323 - val_loss: 264.0994\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 484.6585 - val_loss: 276.5792\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 298.6982 - val_loss: 308.3608\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 332.0179 - val_loss: 241.4565\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 333.0790 - val_loss: 363.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 342.9299 - val_loss: 684.2596\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 435.3010 - val_loss: 328.3805\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 325.4734 - val_loss: 235.2390\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 318.8906 - val_loss: 241.4618\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 281.5494 - val_loss: 475.8683\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 296.4854 - val_loss: 264.4123\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 321.0278 - val_loss: 483.0289\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 295.6610 - val_loss: 219.0106\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 328.5895 - val_loss: 330.7988\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 260.3263 - val_loss: 228.4617\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 280.0237 - val_loss: 250.2862\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 275.7780 - val_loss: 219.1652\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 322.8300 - val_loss: 242.8745\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 285.2375 - val_loss: 309.0423\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 273.9654 - val_loss: 187.1230\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 393.9415 - val_loss: 2000.1863\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 301.1071 - val_loss: 209.2622\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 315.8519 - val_loss: 330.3930\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 426.5653 - val_loss: 300.0483\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 245.7939 - val_loss: 279.2237\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 314.8788 - val_loss: 373.1449\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 301.9059 - val_loss: 252.6333\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 255.3686 - val_loss: 203.4190\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 261.0002 - val_loss: 210.1167\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 414.8390 - val_loss: 295.8145\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 235.8207 - val_loss: 211.2365\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 446.4671 - val_loss: 568.4622\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 399.3193 - val_loss: 560.6352\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 271.1368 - val_loss: 246.4824\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 250.5958 - val_loss: 240.7411\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 320.6410 - val_loss: 586.6137\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 267.6320 - val_loss: 231.2161\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 484.3420 - val_loss: 408.3894\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 253.3248 - val_loss: 214.6676\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 264.4191 - val_loss: 195.2087\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 258.5544 - val_loss: 174.9273\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 273.6572 - val_loss: 323.5575\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 229.7400 - val_loss: 238.7626\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 254.3144 - val_loss: 269.9044\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 488.9062 - val_loss: 224.7717\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 240.3633 - val_loss: 229.8371\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 220.4674 - val_loss: 201.4508\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 271.6109 - val_loss: 255.2801\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 262.3517 - val_loss: 196.8987\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 298.8132 - val_loss: 197.8010\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 267.9713 - val_loss: 166.7351\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 321.7524 - val_loss: 194.3377\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 265.5557 - val_loss: 677.1019\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 275.7995 - val_loss: 222.5490\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 235.1217 - val_loss: 213.9191\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 228.9293 - val_loss: 164.6633\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 380.9102 - val_loss: 221.3667\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 302.3035 - val_loss: 274.1772\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 257.8636 - val_loss: 166.6447\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 204.3024 - val_loss: 232.4259\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 244.6356 - val_loss: 539.6943\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 240.9724 - val_loss: 230.8630\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 256.8156 - val_loss: 197.5359\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 368.4221 - val_loss: 217.3630\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 248.1958 - val_loss: 482.7964\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 240.8612 - val_loss: 167.1533\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 235.1090 - val_loss: 202.1818\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 224.5082 - val_loss: 444.9981\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 259.3260 - val_loss: 257.6734\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 293.8885 - val_loss: 159.9184\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 219.3864 - val_loss: 190.1525\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 274.1476 - val_loss: 181.9958\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 286.3440 - val_loss: 210.5070\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 226.5549 - val_loss: 949.9631\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 255.1118 - val_loss: 172.2428\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 219.6003 - val_loss: 177.5129\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 290.9154 - val_loss: 199.3744\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 242.1789 - val_loss: 334.8166\n",
      "Epoch 147/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/step - loss: 224.4417 - val_loss: 236.6342\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 300.8182 - val_loss: 173.7771\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 249.8253 - val_loss: 214.7953\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 342.2343 - val_loss: 274.1790\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 261.9254 - val_loss: 186.9095\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 241.4432 - val_loss: 821.7349\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 296.7644 - val_loss: 1077.1799\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 298.9697 - val_loss: 167.2944\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 254.5368 - val_loss: 200.8235\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 198.7998 - val_loss: 183.8271\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 224.1119 - val_loss: 259.3219\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 182.5239 - val_loss: 164.2013\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 374.3016 - val_loss: 415.7118\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 259.6976 - val_loss: 404.3276\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.0570 - val_loss: 183.0403\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 354.0041 - val_loss: 200.8529\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 238.4155 - val_loss: 521.5641\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 267.4905 - val_loss: 247.3560\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 243.3112 - val_loss: 163.9418\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 197.7877 - val_loss: 317.7387\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 223.3423 - val_loss: 181.2569\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 214.0299 - val_loss: 385.3112\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 248.5848 - val_loss: 165.2541\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 237.9890 - val_loss: 298.4463\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 480.9404 - val_loss: 359.6240\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 297.6812 - val_loss: 214.2757\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 246.2831 - val_loss: 168.5589\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 212.3048 - val_loss: 193.4663\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 225.9953 - val_loss: 162.3177\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 239.5020 - val_loss: 169.5149\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 203.7602 - val_loss: 194.8766\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 287.6508 - val_loss: 283.2985\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 208.7360 - val_loss: 217.9365\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 229.7840 - val_loss: 368.1716\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 233.2778 - val_loss: 166.6573\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 257.0594 - val_loss: 215.6824\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 253.5857 - val_loss: 200.0526\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 192.2644 - val_loss: 160.3804\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 276.0153 - val_loss: 216.3710\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 222.5949 - val_loss: 189.9754\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 195.8945 - val_loss: 180.7548\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 192.8188 - val_loss: 173.4272\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 234.5601 - val_loss: 240.1057\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 209.5541 - val_loss: 199.9360\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 220.3240 - val_loss: 163.4100\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 364.0093 - val_loss: 173.6363\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 214.6378 - val_loss: 166.4536\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 339.0516 - val_loss: 218.8158\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 274.1080 - val_loss: 159.0874\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 406.4025 - val_loss: 193.8977\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.8871 - val_loss: 216.5097\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 199.6653 - val_loss: 188.3908\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.3266 - val_loss: 241.2435\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 321.3971 - val_loss: 243.2618\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 242.4159 - val_loss: 314.5388\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 200.1783 - val_loss: 291.5020\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 258.5060 - val_loss: 190.5624\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 210.8373 - val_loss: 536.8727\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 340.9790 - val_loss: 214.8138\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 204.5084 - val_loss: 236.3177\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 261.6845 - val_loss: 274.8068\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.1971 - val_loss: 363.6929\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 266.2366 - val_loss: 177.3371\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.2692 - val_loss: 199.5700\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.5045 - val_loss: 184.0396\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 176.0525 - val_loss: 156.0500\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.4222 - val_loss: 200.5541\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.8551 - val_loss: 651.6204\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 423.4592 - val_loss: 164.4804\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.7645 - val_loss: 193.8476\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 219.3684 - val_loss: 185.4647\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 444.1017 - val_loss: 246.9042\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 270.3945 - val_loss: 190.6220\n",
      "Epoch 220/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.7236 - val_loss: 327.7357\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.7098 - val_loss: 278.3927\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 189.2912 - val_loss: 171.6242\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 225.7318 - val_loss: 171.4298\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.6790 - val_loss: 188.8038\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 207.1400 - val_loss: 192.2145\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.5697 - val_loss: 252.3629\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 255.8568 - val_loss: 169.4357\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 228.6719 - val_loss: 189.7494\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 189.3240 - val_loss: 171.3220\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 245.6205 - val_loss: 330.5662\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 221.8349 - val_loss: 161.3592\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.7416 - val_loss: 151.8009\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.3571 - val_loss: 216.5794\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.8625 - val_loss: 160.3049\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.2727 - val_loss: 169.8705\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.4927 - val_loss: 166.1838\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 195.8225 - val_loss: 157.4241\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 256.0696 - val_loss: 181.2472\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 347.4596 - val_loss: 194.4304\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.9965 - val_loss: 200.4901\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.1250 - val_loss: 274.2157\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.1100 - val_loss: 163.9741\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.6780 - val_loss: 159.5355\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.6515 - val_loss: 198.4945\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.9273 - val_loss: 163.8244\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 247.9706 - val_loss: 276.4730\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.0925 - val_loss: 165.0040\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 174.0615 - val_loss: 152.5958\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 194.3455 - val_loss: 205.4338\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 194.2008 - val_loss: 213.9287\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 174.2104 - val_loss: 154.0176\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 291.7647 - val_loss: 165.8667\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 169.7726 - val_loss: 192.5627\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.6936 - val_loss: 338.5090\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 249.7432 - val_loss: 158.3374\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.2402 - val_loss: 307.3874\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.4870 - val_loss: 167.0565\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 312.7715 - val_loss: 237.9654\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 198.8917 - val_loss: 151.7057\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.5520 - val_loss: 268.1695\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.0688 - val_loss: 169.6630\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.1788 - val_loss: 226.2310\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.8326 - val_loss: 186.4068\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.4081 - val_loss: 239.9189\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 188.0666 - val_loss: 158.0136\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 266.2821 - val_loss: 151.2081\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.2432 - val_loss: 196.9222\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.5064 - val_loss: 178.1713\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.0903 - val_loss: 156.9465\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.5452 - val_loss: 159.8906\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 269.7268 - val_loss: 171.0253\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.4344 - val_loss: 152.4802\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.1634 - val_loss: 400.0718\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.5700 - val_loss: 150.0112\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.3434 - val_loss: 472.6281\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.1994 - val_loss: 205.4748\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 291.6561 - val_loss: 158.4493\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 196.9342 - val_loss: 159.7876\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 225.2590 - val_loss: 382.0895\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 198.4712 - val_loss: 145.8162\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.4969 - val_loss: 172.8294\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 232.0685 - val_loss: 173.9050\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 324.4445 - val_loss: 178.7946\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.6107 - val_loss: 158.2647\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 262.4333 - val_loss: 172.3551\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.1110 - val_loss: 154.9390\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.0770 - val_loss: 606.1081\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.3196 - val_loss: 152.5470\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.8733 - val_loss: 225.3179\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.4897 - val_loss: 651.2650\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.3198 - val_loss: 361.6240\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5464 - val_loss: 155.1159\n",
      "Epoch 293/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 177.8844 - val_loss: 382.3879\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 271.3147 - val_loss: 172.3780\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 261.9071 - val_loss: 271.1394\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.5575 - val_loss: 256.0332\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.0370 - val_loss: 190.3013\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.1190 - val_loss: 276.1852\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 407.3614 - val_loss: 165.5791\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 173.6492 - val_loss: 152.2976\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.3076 - val_loss: 200.9187\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.6986 - val_loss: 234.9135\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.5249 - val_loss: 163.9647\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6171 - val_loss: 166.3212\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.0256 - val_loss: 147.3832\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.1599 - val_loss: 155.6629\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4877 - val_loss: 154.9059\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 269.0313 - val_loss: 157.6438\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.2045 - val_loss: 249.5172\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.6994 - val_loss: 163.6470\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 490.3209 - val_loss: 319.8206\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.0859 - val_loss: 151.7658\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 252.7500 - val_loss: 301.2315\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 280.8197 - val_loss: 192.5183\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 277.9636 - val_loss: 155.1102\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.9696 - val_loss: 148.7821\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.8109 - val_loss: 151.1904\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.7024 - val_loss: 354.3206\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.7418 - val_loss: 178.3951\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 216.3482 - val_loss: 180.0403\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 265.0626 - val_loss: 153.7847\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 191.8199 - val_loss: 248.1937\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 228.2825 - val_loss: 267.0964\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.2207 - val_loss: 364.8609\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 186.9219 - val_loss: 306.6339\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.9169 - val_loss: 158.5277\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.5179 - val_loss: 148.7301\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 285.0005 - val_loss: 152.9285\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.5591 - val_loss: 150.8875\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 281.9115 - val_loss: 180.3830\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 354.6629 - val_loss: 388.1607\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.4195 - val_loss: 265.0583\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2522 - val_loss: 162.8017\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.8383 - val_loss: 142.4271\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.5739 - val_loss: 150.1951\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.9145 - val_loss: 146.4441\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 306.5894 - val_loss: 293.3652\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 199.8141 - val_loss: 151.6849\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.7548 - val_loss: 156.1538\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.2941 - val_loss: 161.8448\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 169.1689 - val_loss: 281.1561\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 231.6307 - val_loss: 178.2801\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9705 - val_loss: 149.6597\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 189.7742 - val_loss: 208.8288\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 173.2298 - val_loss: 185.1028\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.9074 - val_loss: 144.1754\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.9379 - val_loss: 169.9714\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 252.9320 - val_loss: 781.8415\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 331.9955 - val_loss: 179.8892\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.9101 - val_loss: 159.1855\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.7191 - val_loss: 202.7031\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.5450 - val_loss: 168.7029\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.8265 - val_loss: 147.0583\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4872 - val_loss: 262.6154\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.6744 - val_loss: 190.9345\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 289.8180 - val_loss: 161.2912\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.3404 - val_loss: 166.6257\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5767 - val_loss: 321.5918\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.9611 - val_loss: 301.5900\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 313.5095 - val_loss: 173.4214\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1160 - val_loss: 170.1399\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.6251 - val_loss: 165.1261\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 473.1478 - val_loss: 217.0941\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 232.8731 - val_loss: 154.4967\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.1179 - val_loss: 152.6661\n",
      "Epoch 366/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.4233 - val_loss: 151.4018\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 208.7199 - val_loss: 192.9489\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.2355 - val_loss: 224.3616\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 226.0062 - val_loss: 175.2016\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.5455 - val_loss: 178.0174\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1439 - val_loss: 231.4948\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.0968 - val_loss: 198.1409\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.3274 - val_loss: 154.1909\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.4909 - val_loss: 153.0542\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 293.4059 - val_loss: 929.9590\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 301.3873 - val_loss: 148.2119\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.9450 - val_loss: 160.6644\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 173.1927 - val_loss: 150.1271\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.9387 - val_loss: 225.9584\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.1640 - val_loss: 168.4349\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.8199 - val_loss: 152.0747\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.4870 - val_loss: 176.5315\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 290.9506 - val_loss: 202.2996\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.1958 - val_loss: 280.3035\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.9622 - val_loss: 219.7960\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.7226 - val_loss: 208.2410\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.7691 - val_loss: 153.0684\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 276.8316 - val_loss: 171.8957\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.0728 - val_loss: 147.3930\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.3775 - val_loss: 151.0980\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.2829 - val_loss: 165.5642\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.1953 - val_loss: 226.3421\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 307.3634 - val_loss: 152.3870\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6499 - val_loss: 149.0034\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.6814 - val_loss: 144.8261\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.7565 - val_loss: 140.7797\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 189.3507 - val_loss: 158.1638\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 581.0446 - val_loss: 355.1107\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.2719 - val_loss: 214.2245\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.2898 - val_loss: 170.9390\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.3371 - val_loss: 223.4720\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 219.9195 - val_loss: 161.8712\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 182.5882 - val_loss: 162.1138\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 238.6486 - val_loss: 176.5902\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 195.6198 - val_loss: 230.6369\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 250.7915 - val_loss: 173.0549\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.5242 - val_loss: 183.3423\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.2828 - val_loss: 159.0933\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.1873 - val_loss: 153.0002\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 323.0058 - val_loss: 148.5649\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.0597 - val_loss: 153.1640\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.6790 - val_loss: 150.9453\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.4480 - val_loss: 172.5634\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.3169 - val_loss: 162.4668\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 343.3433 - val_loss: 172.2955\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.8486 - val_loss: 156.0953\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.2274 - val_loss: 186.2297\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 191.9765 - val_loss: 437.9978\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.2538 - val_loss: 255.5960\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 247.1605 - val_loss: 145.8051\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 194.1294 - val_loss: 209.1685\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.8413 - val_loss: 195.7900\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.3428 - val_loss: 159.7681\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.6963 - val_loss: 279.8060\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.3366 - val_loss: 176.5713\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.0234 - val_loss: 174.6321\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 390.0220 - val_loss: 207.7549\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.5137 - val_loss: 170.9058\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.8317 - val_loss: 165.6336\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.2192 - val_loss: 281.3080\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.4389 - val_loss: 161.5010\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.1442 - val_loss: 176.1969\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.6160 - val_loss: 152.7934\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.4093 - val_loss: 147.2817\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.7916 - val_loss: 305.1363\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.7754 - val_loss: 203.3953\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.9079 - val_loss: 148.7009\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.2351 - val_loss: 145.8918\n",
      "Epoch 439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.7580 - val_loss: 193.4009\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.3686 - val_loss: 146.8992\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.0402 - val_loss: 155.4712\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.6794 - val_loss: 224.5507\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.3542 - val_loss: 240.1690\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.3446 - val_loss: 139.0631\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.6027 - val_loss: 175.6086\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 333.4995 - val_loss: 243.6724\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.3704 - val_loss: 171.6513\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.2902 - val_loss: 156.5173\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.9288 - val_loss: 155.2527\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6587 - val_loss: 170.2448\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.2183 - val_loss: 147.3202\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1395 - val_loss: 140.4403\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.9997 - val_loss: 139.6244\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 252.0940 - val_loss: 150.0809\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.0011 - val_loss: 174.4507\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.5605 - val_loss: 283.3838\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.7769 - val_loss: 141.7600\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.8750 - val_loss: 199.2413\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.4907 - val_loss: 173.0830\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.6911 - val_loss: 149.8869\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 192.8778 - val_loss: 165.2051\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.2177 - val_loss: 342.7988\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.5122 - val_loss: 179.1219\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 188.1693 - val_loss: 139.4626\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 189.0639 - val_loss: 192.7262\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 335.1797 - val_loss: 155.4565\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 189.7687 - val_loss: 162.5782\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 189.1086 - val_loss: 181.2047\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 183.5366 - val_loss: 147.2461\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 208.2625 - val_loss: 182.0269\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.7161 - val_loss: 257.7430\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.5264 - val_loss: 255.9716\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1161 - val_loss: 158.5284\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.4311 - val_loss: 384.7738\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.1320 - val_loss: 176.3013\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.5394 - val_loss: 155.2211\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.2852 - val_loss: 193.9580\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.7506 - val_loss: 149.2743\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 547.0159 - val_loss: 143.9870\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 178.3800 - val_loss: 159.4784\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.9487 - val_loss: 244.4394\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8446 - val_loss: 1456.3431\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 1014.0476 - val_loss: 757.8228\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 402.9982 - val_loss: 153.9099\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9050 - val_loss: 167.4257\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.2177 - val_loss: 140.6097\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.9083 - val_loss: 191.8120\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8034 - val_loss: 193.0168\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.4616 - val_loss: 144.0929\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.6020 - val_loss: 153.6923\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.1195 - val_loss: 148.1501\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 198.8047 - val_loss: 158.8033\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.7955 - val_loss: 185.4239\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.8694 - val_loss: 153.1871\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.2965 - val_loss: 151.3369\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.0916 - val_loss: 137.7234\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.3861 - val_loss: 147.9820\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6285 - val_loss: 142.5205\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.9830 - val_loss: 152.1647\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.8459 - val_loss: 140.2231\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.6910 - val_loss: 160.3910\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.1271 - val_loss: 150.6044\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.0571 - val_loss: 155.4892\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.7991 - val_loss: 198.4873\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.4623 - val_loss: 236.6004\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 282.0711 - val_loss: 143.9712\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8625 - val_loss: 239.3297\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 265.9221 - val_loss: 215.5865\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 181.3980 - val_loss: 168.4190\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.4452 - val_loss: 169.7401\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.7428 - val_loss: 186.8781\n",
      "Epoch 512/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.0043 - val_loss: 141.2112\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.0630 - val_loss: 151.7942\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0282 - val_loss: 147.1481\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3450 - val_loss: 268.8712\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 317.2898 - val_loss: 143.3216\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.9239 - val_loss: 141.3764\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.0668 - val_loss: 142.4282\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.1979 - val_loss: 162.5580\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 173.4634 - val_loss: 143.5263\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 179.1454 - val_loss: 305.3376\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 674.2008 - val_loss: 330.3420\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 480.1921 - val_loss: 381.8570\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 306.4552 - val_loss: 195.4655\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 407.8093 - val_loss: 188.9355\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.5642 - val_loss: 240.8715\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 515.1768 - val_loss: 882.4831\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 279.4896 - val_loss: 174.3323\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.4250 - val_loss: 187.9172\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 208.5404 - val_loss: 282.2144\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 201.5686 - val_loss: 199.9150\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 251.9506 - val_loss: 155.4021\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 253.5218 - val_loss: 155.2060\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.0563 - val_loss: 283.6934\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 349.1175 - val_loss: 390.2932\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 228.7807 - val_loss: 150.7589\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 191.8042 - val_loss: 168.0094\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 174.2142 - val_loss: 149.1493\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.8990 - val_loss: 167.2310\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.6830 - val_loss: 147.6669\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.9229 - val_loss: 162.2937\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.5217 - val_loss: 167.7461\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 202.685 - 0s 51us/step - loss: 205.0042 - val_loss: 154.8916\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.2495 - val_loss: 224.9040\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.9422 - val_loss: 171.3861\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 380.2587 - val_loss: 244.2761\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.7655 - val_loss: 143.8715\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.4415 - val_loss: 155.3513\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.7303 - val_loss: 239.6303\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.9757 - val_loss: 172.9731\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.9931 - val_loss: 198.4351\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.6124 - val_loss: 145.5708\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.0687 - val_loss: 198.1647\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.3922 - val_loss: 172.6907\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5869 - val_loss: 144.0669\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.2134 - val_loss: 199.6140\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.2833 - val_loss: 154.5232\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 267.8823 - val_loss: 146.8811\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.2621 - val_loss: 194.9081\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.8215 - val_loss: 166.8419\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.0409 - val_loss: 324.5053\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.0776 - val_loss: 176.0572\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7901 - val_loss: 148.5409\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 211.218 - 0s 51us/step - loss: 211.0382 - val_loss: 150.2754\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.1477 - val_loss: 198.0055\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.3418 - val_loss: 143.7520\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.9246 - val_loss: 202.6538\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.8311 - val_loss: 157.0203\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.6815 - val_loss: 210.8277\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.4388 - val_loss: 199.5574\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7365 - val_loss: 170.0594\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.0555 - val_loss: 138.3564\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.6609 - val_loss: 144.6696\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.9574 - val_loss: 148.3812\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.3440 - val_loss: 149.6343\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.1929 - val_loss: 214.1490\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3456 - val_loss: 139.0907\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 212.2020 - val_loss: 246.5433\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 530.2641 - val_loss: 182.5870\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.7271 - val_loss: 204.0413\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.3537 - val_loss: 166.4575\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.8234 - val_loss: 215.4222\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.7066 - val_loss: 169.5239\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.7626 - val_loss: 158.3977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.0519 - val_loss: 151.7487\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.5673 - val_loss: 197.5767\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.4345 - val_loss: 216.7885\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.7146 - val_loss: 148.8964\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 173.0683ETA: 0s - loss: 1 - 0s 51us/step - loss: 172.4912 - val_loss: 166.0985\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 269.7508 - val_loss: 482.5823\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.4234 - val_loss: 145.5474\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.6682 - val_loss: 145.3431\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.5239 - val_loss: 161.1257\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0334 - val_loss: 218.8800\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.3592 - val_loss: 146.0703\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.1568 - val_loss: 191.5100\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 352.378 - 0s 50us/step - loss: 346.7187 - val_loss: 186.5672\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 177.0966 - val_loss: 149.0100\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.5758 - val_loss: 140.3165\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.6141 - val_loss: 207.3017\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2335 - val_loss: 152.8754\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.9827 - val_loss: 158.4144\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 199.2968 - val_loss: 147.7034\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.8523 - val_loss: 150.0478\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 232.0979 - val_loss: 159.1291\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.9463 - val_loss: 151.3901\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5347 - val_loss: 146.6128\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.5052 - val_loss: 197.6158\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 157.4616 - val_loss: 146.4052\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 161.0779 - val_loss: 171.3859\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 158.5762 - val_loss: 184.8454\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.4078 - val_loss: 171.2221\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.2187 - val_loss: 210.6112\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 256.3922 - val_loss: 180.4430\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.6200 - val_loss: 206.1798\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.2747 - val_loss: 147.0859\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0413 - val_loss: 139.8958\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.2444 - val_loss: 169.5364\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.9658 - val_loss: 147.1255\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.2869 - val_loss: 230.9910\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.4298 - val_loss: 194.1258\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.4704 - val_loss: 152.1165\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.1215 - val_loss: 161.7717\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.5924 - val_loss: 147.5489\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8854 - val_loss: 213.9303\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.5765 - val_loss: 148.5030\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 411.0698 - val_loss: 628.6845\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 412.3893 - val_loss: 481.2043\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.1631 - val_loss: 155.4263\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5392 - val_loss: 177.7490\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.9573 - val_loss: 161.5770\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.5952 - val_loss: 192.8514\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.5020 - val_loss: 153.5675\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.3807 - val_loss: 140.1563\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8503 - val_loss: 138.3707\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.4373 - val_loss: 150.1097\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4207 - val_loss: 139.8342\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.0945 - val_loss: 146.3148\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.2770 - val_loss: 149.9756\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 267.1941 - val_loss: 146.1513\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2355 - val_loss: 196.5305\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.8959 - val_loss: 152.0105\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.1760 - val_loss: 161.6879\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5626 - val_loss: 204.6407\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.3365 - val_loss: 147.7710\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.9926 - val_loss: 367.9689\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.7713 - val_loss: 212.7214\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.6236 - val_loss: 153.7012\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.4444 - val_loss: 153.4211\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.1019 - val_loss: 149.2098\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.2093 - val_loss: 445.0048\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.2926 - val_loss: 153.1257\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3547 - val_loss: 143.9782\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5911 - val_loss: 164.3702\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6521 - val_loss: 146.3981\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.5199 - val_loss: 153.7765\n",
      "Epoch 657/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.8522 - val_loss: 180.3534\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.0978 - val_loss: 155.2412\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7287 - val_loss: 198.2069\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.8675 - val_loss: 158.1320\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.1320 - val_loss: 168.6414\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1441 - val_loss: 154.3646\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7369 - val_loss: 206.2785\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4489 - val_loss: 170.1533\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.9491 - val_loss: 244.1331\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.0889 - val_loss: 149.9678\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.2807 - val_loss: 189.8519\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.9176 - val_loss: 185.6695\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 155.6294 - val_loss: 154.6090\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.0882 - val_loss: 167.4908\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.8445 - val_loss: 172.2924\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.5697 - val_loss: 176.4483\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.6334 - val_loss: 148.1146\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.4930 - val_loss: 139.1929\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.4329 - val_loss: 145.6427\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.3406 - val_loss: 154.0186\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 297.5175 - val_loss: 187.0752\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.5465 - val_loss: 272.5971\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.8598 - val_loss: 151.0609\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.4763 - val_loss: 167.3886\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 164.8568 - val_loss: 153.7122\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 155.8521 - val_loss: 155.1029\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 196.9351 - val_loss: 178.7046\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.3405 - val_loss: 167.8337\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.8767 - val_loss: 212.6351\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1754 - val_loss: 150.1067\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.5195 - val_loss: 153.3558\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.2994 - val_loss: 190.9276\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.3582 - val_loss: 147.2512\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2308 - val_loss: 252.0528\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.4735 - val_loss: 157.3649\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2842 - val_loss: 154.1921\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 157.5791 - val_loss: 242.6100\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 187.4586 - val_loss: 170.1798\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.2406 - val_loss: 202.6079\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.8959 - val_loss: 149.4074\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.3736 - val_loss: 154.1174\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3150 - val_loss: 191.0513\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3079 - val_loss: 159.3851\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.0827 - val_loss: 333.9242\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9598 - val_loss: 200.8134\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5651 - val_loss: 159.2059\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.3274 - val_loss: 233.9406\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.4867 - val_loss: 150.8537\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.2081 - val_loss: 173.3689\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.3224 - val_loss: 164.8498\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.7510 - val_loss: 145.0423\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6540 - val_loss: 157.7904\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5928 - val_loss: 151.1530\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.7941 - val_loss: 138.8981\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 210.5083 - val_loss: 147.6295\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7262 - val_loss: 163.2651\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.4826 - val_loss: 221.2652\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.6300 - val_loss: 139.8549\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.3902 - val_loss: 277.8672\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 170.1225 - val_loss: 199.1175\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.9549 - val_loss: 168.4763\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2082 - val_loss: 150.0467\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.5819 - val_loss: 239.4966\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1191 - val_loss: 166.4054\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.8526 - val_loss: 143.8213\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5622 - val_loss: 146.4997\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.3394 - val_loss: 161.0396\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0186 - val_loss: 152.3564\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6364 - val_loss: 144.5520\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.4969 - val_loss: 155.5676\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 178.7609 - val_loss: 163.7311\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3296 - val_loss: 150.5013\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3473 - val_loss: 291.1053\n",
      "Epoch 730/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.8384 - val_loss: 160.6248\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5407 - val_loss: 222.8816\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4411 - val_loss: 241.6583\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.9324 - val_loss: 268.0091\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.1743 - val_loss: 157.7507\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3589 - val_loss: 147.5660\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.6917 - val_loss: 185.7907\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8241 - val_loss: 201.0157\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5683 - val_loss: 174.3600\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.9272 - val_loss: 316.0537\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.6114 - val_loss: 139.5176\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.6194 - val_loss: 162.6418\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.6317 - val_loss: 175.2459\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.2207 - val_loss: 169.0897\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4534 - val_loss: 142.2750\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.9957 - val_loss: 141.2824\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.3721 - val_loss: 142.5395\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7576 - val_loss: 174.6849\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.6705 - val_loss: 145.0393\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.0383 - val_loss: 291.5946\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0101 - val_loss: 142.3277\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2716 - val_loss: 146.8495\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1121 - val_loss: 161.2245\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 162.5563 - val_loss: 211.1083\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 164.6933 - val_loss: 166.6811\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 162.4988 - val_loss: 210.0571\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0717 - val_loss: 143.9700\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1936 - val_loss: 139.8072\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.5901 - val_loss: 160.8772\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.7518 - val_loss: 152.5139\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8847 - val_loss: 145.0118\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3473 - val_loss: 139.3716\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.0509 - val_loss: 191.4018\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2323 - val_loss: 176.6634\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0967 - val_loss: 141.5229\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3010 - val_loss: 164.1284\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.9139 - val_loss: 142.4036\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 204.580 - 0s 51us/step - loss: 203.0172 - val_loss: 150.8477\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6653 - val_loss: 185.8104\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.3043 - val_loss: 145.9091\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.9587 - val_loss: 253.9742\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.3156 - val_loss: 506.4464\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9223 - val_loss: 212.7731\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0597 - val_loss: 165.5952\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.7434 - val_loss: 145.2375\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0355 - val_loss: 153.7106\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3331 - val_loss: 179.2791\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.7703 - val_loss: 142.4010\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.9217 - val_loss: 175.9350\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1890 - val_loss: 141.2330\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0049 - val_loss: 178.3914\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.7144 - val_loss: 147.5329\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.3219 - val_loss: 177.4739\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3954 - val_loss: 164.5655\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.9493 - val_loss: 145.4212\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2877 - val_loss: 178.1813\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.7688 - val_loss: 143.7479\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5636 - val_loss: 163.1838\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6127 - val_loss: 176.5497\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.3760 - val_loss: 168.7143\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.5856 - val_loss: 179.4457\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 225.2093 - val_loss: 168.8755\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.6523 - val_loss: 171.6023\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.0519 - val_loss: 172.9614\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.3791 - val_loss: 153.5942\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2660 - val_loss: 150.2405\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.2784 - val_loss: 478.1872\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.9251 - val_loss: 158.2180\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8881 - val_loss: 149.9435\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8583 - val_loss: 143.2841\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 298.7941 - val_loss: 255.2987\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.4831 - val_loss: 140.3922\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1502 - val_loss: 141.1206\n",
      "Epoch 803/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2378 - val_loss: 166.3704\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 177.2812 - val_loss: 160.8849\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 261.7002 - val_loss: 176.8001\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8921 - val_loss: 183.8558\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6507 - val_loss: 197.1262\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.7600 - val_loss: 136.4071\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.7746 - val_loss: 140.8621\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.3448 - val_loss: 190.6106\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9626 - val_loss: 193.8035\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4241 - val_loss: 137.4911\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7065 - val_loss: 163.6223\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.9792 - val_loss: 149.7370\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2247 - val_loss: 147.9010\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3985 - val_loss: 148.4870\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.5104 - val_loss: 273.0416\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4320 - val_loss: 142.6097\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3098 - val_loss: 153.5954\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.2027 - val_loss: 139.6202\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4091 - val_loss: 283.4804\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6547 - val_loss: 152.4332\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4771 - val_loss: 137.6854\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 701.9854 - val_loss: 315.2005\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 287.3756 - val_loss: 245.3505\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 239.7057 - val_loss: 194.1606\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 188.4675 - val_loss: 169.3685\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 201.3249 - val_loss: 162.4736\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.1969 - val_loss: 164.4947\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.5115 - val_loss: 224.5034\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5907 - val_loss: 211.7588\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.5895 - val_loss: 150.2846\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.5440 - val_loss: 156.7681\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1443 - val_loss: 160.3004\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.8954 - val_loss: 186.9747\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7486 - val_loss: 153.3578\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.6996 - val_loss: 144.3854\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6254 - val_loss: 147.2505\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.6306 - val_loss: 154.5209\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.3578 - val_loss: 201.3125\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.8853 - val_loss: 148.5552\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.6025 - val_loss: 156.2971\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.1029 - val_loss: 181.7034\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3217 - val_loss: 185.6898\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.9162 - val_loss: 450.6376\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.0913 - val_loss: 193.7421\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0545 - val_loss: 147.0303\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.6461 - val_loss: 188.3679\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 158.2263 - val_loss: 155.8354\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.4315 - val_loss: 144.2121\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.2566 - val_loss: 186.3853\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.3930 - val_loss: 283.7286\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.3205 - val_loss: 142.9249\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.0302 - val_loss: 304.3642\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.9274 - val_loss: 214.2961\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.6053 - val_loss: 387.3897\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 217.8310 - val_loss: 175.9015\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.1364 - val_loss: 264.0163\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.7024 - val_loss: 171.0434\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.6494 - val_loss: 226.1341\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.7090 - val_loss: 176.0954\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.7555 - val_loss: 141.2526\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.9228 - val_loss: 148.3149\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7020 - val_loss: 207.7797\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1028 - val_loss: 137.7387\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.9980 - val_loss: 148.5699\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3775 - val_loss: 141.9563\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6942 - val_loss: 173.0047\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8817 - val_loss: 154.7921\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7481 - val_loss: 141.1111\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4091 - val_loss: 161.9844\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.9765 - val_loss: 143.3200\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2702 - val_loss: 141.3808\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2148 - val_loss: 144.2402\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3837 - val_loss: 137.7006\n",
      "Epoch 876/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8292 - val_loss: 164.1205\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.3767 - val_loss: 136.8475\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0369 - val_loss: 147.8146\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.5105 - val_loss: 162.5583\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 184.1066 - val_loss: 136.2934\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6109 - val_loss: 141.1841\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1573 - val_loss: 156.7035\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9327 - val_loss: 157.2627\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3092 - val_loss: 158.1626\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6991 - val_loss: 141.5195\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.2613 - val_loss: 157.1377\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4770 - val_loss: 147.7604\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0436 - val_loss: 141.8554\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.0023 - val_loss: 141.7710\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.1444 - val_loss: 153.5008\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5315 - val_loss: 169.0464\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9758 - val_loss: 172.7528\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5731 - val_loss: 137.3861\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 437.2072 - val_loss: 227.0532\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.7012 - val_loss: 261.9589\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 172.1111 - val_loss: 148.5066\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 156.5573 - val_loss: 167.1886\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 156.8073 - val_loss: 174.9174\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 175.0995 - val_loss: 182.8715\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.8846 - val_loss: 159.2291\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5462 - val_loss: 150.8063\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9494 - val_loss: 173.0877\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.8423 - val_loss: 167.3123\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.9156 - val_loss: 148.9654\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7635 - val_loss: 170.0664\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.5774 - val_loss: 176.3682\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.7874 - val_loss: 153.3774\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.6474 - val_loss: 161.8006\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.4001 - val_loss: 159.6596\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.0460 - val_loss: 239.9160\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 228.1514 - val_loss: 145.0898\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.8150 - val_loss: 302.3866\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.6219 - val_loss: 153.5569\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.1572 - val_loss: 141.1734\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.3331 - val_loss: 145.6536\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.3491 - val_loss: 143.9408\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4565 - val_loss: 144.6485\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6169 - val_loss: 159.0867\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7638 - val_loss: 141.0997\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 171.8782 - val_loss: 164.3703\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 229.8987 - val_loss: 195.8839\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6431 - val_loss: 141.7736\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.6267 - val_loss: 259.6131\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.6269 - val_loss: 168.6312\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3176 - val_loss: 278.4747\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.2070 - val_loss: 207.3546\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6139 - val_loss: 146.5974\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1849 - val_loss: 167.7775\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9978 - val_loss: 140.1141\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.0657 - val_loss: 148.7437\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 149.9792 - val_loss: 140.1333\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 162.0412 - val_loss: 163.3385\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4324 - val_loss: 139.9377\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.3336 - val_loss: 247.0115\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 186.1683 - val_loss: 140.0749\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3409 - val_loss: 143.8989\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.3693 - val_loss: 160.1150\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 147.6428 - val_loss: 147.4376\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 178.3794 - val_loss: 276.5614\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.1996 - val_loss: 164.8343\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0240 - val_loss: 156.7798\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 148.1190 - val_loss: 146.2902\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 259.2581 - val_loss: 151.3474\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6942 - val_loss: 137.3087\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1013 - val_loss: 168.7153\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.5760 - val_loss: 136.3446\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.0899 - val_loss: 137.4684\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5389 - val_loss: 150.6811\n",
      "Epoch 949/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 241.0140 - val_loss: 141.1748\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.2719 - val_loss: 222.4703\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8602 - val_loss: 160.0305\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4564 - val_loss: 152.4809\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8467 - val_loss: 144.1878\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1693 - val_loss: 137.0482\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.5826 - val_loss: 179.4734\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8478 - val_loss: 151.8743\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2407 - val_loss: 299.2208\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 347.6986 - val_loss: 190.2604\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0985 - val_loss: 157.0978\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5432 - val_loss: 144.5927\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2450 - val_loss: 139.9753\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6329 - val_loss: 168.7703\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5317 - val_loss: 188.1866\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.4021 - val_loss: 140.4767\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.7137 - val_loss: 158.7048\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 149.1860 - val_loss: 174.2585\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.8897 - val_loss: 149.7578\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 161.1095 - val_loss: 182.1419\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 138.7083 - val_loss: 146.8374\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6541 - val_loss: 142.9006\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7168 - val_loss: 160.3886\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.7096 - val_loss: 204.2794\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 284.5361 - val_loss: 169.4373\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.4036 - val_loss: 201.8480\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5083 - val_loss: 150.3623\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.9141 - val_loss: 161.1275\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9511 - val_loss: 162.4585\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4141 - val_loss: 156.5743\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8878 - val_loss: 159.0575\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.4823 - val_loss: 146.8126\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.6293 - val_loss: 178.6107\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7160 - val_loss: 176.7610\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 190.5649 - val_loss: 145.1010\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.4161 - val_loss: 140.3677\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5930 - val_loss: 177.0711\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6374 - val_loss: 189.8392\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2968 - val_loss: 146.0275\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.2552 - val_loss: 136.0138\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.5085 - val_loss: 135.7209\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8946 - val_loss: 156.1819\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 172.6801 - val_loss: 135.4739\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 262.7435 - val_loss: 145.3132\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.9479 - val_loss: 214.2139\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8715 - val_loss: 204.0453\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1045 - val_loss: 136.7604\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.2202 - val_loss: 145.6621\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4024 - val_loss: 134.0833\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9474 - val_loss: 137.3094\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.2881 - val_loss: 146.9610\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.2571 - val_loss: 157.1005\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.3459 - val_loss: 153.7530\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.5408 - val_loss: 283.2734\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6388 - val_loss: 140.0539\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.1949 - val_loss: 135.8666\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0038 - val_loss: 141.8152\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.1239 - val_loss: 148.9349\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2919 - val_loss: 177.1605\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0829 - val_loss: 136.0127\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.0788 - val_loss: 179.7883\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.9859 - val_loss: 151.4197\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2610 - val_loss: 191.5498\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.4672 - val_loss: 146.3335\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2596 - val_loss: 190.5691\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0634 - val_loss: 153.9092\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.5187 - val_loss: 148.2680\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7565 - val_loss: 134.6720\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9260 - val_loss: 145.3854\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2545 - val_loss: 136.8870\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8703 - val_loss: 134.3941\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7381 - val_loss: 172.0807\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 243.7451 - val_loss: 169.6851\n",
      "Epoch 1022/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 252.7921 - val_loss: 247.2174\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 167.5361 - val_loss: 220.4397\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8732 - val_loss: 137.5265\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.7854 - val_loss: 161.9756\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 382.3434 - val_loss: 306.8545\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 292.9231 - val_loss: 207.8330\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 208.9074 - val_loss: 153.0900\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2154 - val_loss: 162.3465\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.1349 - val_loss: 155.9673\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2137 - val_loss: 146.0903\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.0660 - val_loss: 159.9292\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0734 - val_loss: 138.6751\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9677 - val_loss: 155.8396\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4696 - val_loss: 141.4664\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.6478 - val_loss: 155.7678\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6145 - val_loss: 152.9294\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.9759 - val_loss: 163.7855\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 151.6465 - val_loss: 141.1004\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.0787 - val_loss: 143.2276\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.9726 - val_loss: 150.0031\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.0433 - val_loss: 201.6836\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8766 - val_loss: 134.9414\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8730 - val_loss: 229.7335\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.3642 - val_loss: 151.4688\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7059 - val_loss: 173.4196\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 332.0434 - val_loss: 185.2817\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.3094 - val_loss: 147.3039\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2056 - val_loss: 170.5690\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2272 - val_loss: 144.9717\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7740 - val_loss: 255.3970\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 141.508 - 0s 50us/step - loss: 142.2906 - val_loss: 226.6634\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0785 - val_loss: 143.0037\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.2818 - val_loss: 356.7543\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.3066 - val_loss: 181.6204\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8951 - val_loss: 175.3559\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6858 - val_loss: 136.5853\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3370 - val_loss: 236.7357\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0874 - val_loss: 145.9431\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.1198 - val_loss: 180.5025\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5923 - val_loss: 165.3377\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1121 - val_loss: 227.9260\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7062 - val_loss: 154.6410\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7846 - val_loss: 169.4318\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7927 - val_loss: 145.6082\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.1146 - val_loss: 154.8788\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1944 - val_loss: 169.2308\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.9555 - val_loss: 186.9950\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.7348 - val_loss: 139.2448\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.7523 - val_loss: 167.4979\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0659 - val_loss: 137.1159\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.4419 - val_loss: 180.3752\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5418 - val_loss: 136.4104\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.9189 - val_loss: 172.3329\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7412 - val_loss: 139.6912\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 280.3639 - val_loss: 153.5249\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 137.7180 - val_loss: 151.0275\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.2969 - val_loss: 282.3671\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1843 - val_loss: 191.2376\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.8772 - val_loss: 272.9165\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2282 - val_loss: 231.4341\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.7892 - val_loss: 141.5442\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3437 - val_loss: 242.1925\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6923 - val_loss: 195.3677\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.9632 - val_loss: 136.5214\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.5682 - val_loss: 134.9440\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6200 - val_loss: 148.9577\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.5957 - val_loss: 149.8234\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8533 - val_loss: 192.8236\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.4915 - val_loss: 156.7041\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.5144 - val_loss: 143.0671\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.9261 - val_loss: 137.9675\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6254 - val_loss: 148.0769\n",
      "Epoch 1094/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6193 - val_loss: 136.5412\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6601 - val_loss: 149.0491\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1570 - val_loss: 135.7545\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.0378 - val_loss: 756.8801\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.6935 - val_loss: 133.9839\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 134.4571 - val_loss: 144.9722\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9167 - val_loss: 237.8013\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5705 - val_loss: 161.4763\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8601 - val_loss: 136.4902\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4052 - val_loss: 139.8148\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4564 - val_loss: 144.3098\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9881 - val_loss: 141.8965\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.7712 - val_loss: 153.6005\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2363 - val_loss: 133.6993\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4268 - val_loss: 189.0859\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3501 - val_loss: 136.5991\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3557 - val_loss: 157.3998\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.4411 - val_loss: 139.1173\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2328 - val_loss: 138.1615\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.4324 - val_loss: 170.0678\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8960 - val_loss: 218.1336\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.5835 - val_loss: 165.4227\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4798 - val_loss: 155.3067\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.7082 - val_loss: 177.9802\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.2960 - val_loss: 256.6019\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.1895 - val_loss: 142.9307\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1188 - val_loss: 280.9747\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 147.4687 - val_loss: 164.6984\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 160.1143 - val_loss: 168.3492\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.2988 - val_loss: 164.0878\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 344.6711 - val_loss: 157.9540\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1471 - val_loss: 167.4832\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.7778 - val_loss: 137.9061\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3787 - val_loss: 157.2190\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3687 - val_loss: 199.5222\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5218 - val_loss: 148.4676\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1507 - val_loss: 134.7049\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7392 - val_loss: 199.1045\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.3761 - val_loss: 190.4176\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6696 - val_loss: 140.0667\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8029 - val_loss: 145.0584\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1747 - val_loss: 152.3178\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 129.7110 - val_loss: 188.8034\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 264.6052 - val_loss: 163.9318\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2070 - val_loss: 148.0888\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2229 - val_loss: 142.3221\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8357 - val_loss: 147.3153\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.1076 - val_loss: 158.4393\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9984 - val_loss: 147.5065\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4391 - val_loss: 142.2651\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.0458 - val_loss: 171.8833\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.7358 - val_loss: 153.2527\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.3537 - val_loss: 137.7596\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5947 - val_loss: 138.7632\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2367 - val_loss: 142.1898\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6879 - val_loss: 141.9398\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3069 - val_loss: 144.8411\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.6691 - val_loss: 150.6806\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3454 - val_loss: 140.6153\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.0096 - val_loss: 145.7264\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.8342 - val_loss: 165.0842\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7897 - val_loss: 142.1416\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.8826 - val_loss: 181.1677\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2954 - val_loss: 150.0629\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 212.1200 - val_loss: 247.7135\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.9310 - val_loss: 151.0815\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4908 - val_loss: 142.5161\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.8641 - val_loss: 197.4774\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.3257 - val_loss: 171.6763\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.2257 - val_loss: 144.4948\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8699 - val_loss: 142.9437\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.0576 - val_loss: 164.4908\n",
      "Epoch 1166/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0207 - val_loss: 148.5518\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3195 - val_loss: 145.7646\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7514 - val_loss: 145.0893\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2355 - val_loss: 185.5487\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9731 - val_loss: 201.5022\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8217 - val_loss: 135.7726\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.1555 - val_loss: 138.6214\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0511 - val_loss: 141.2951\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7470 - val_loss: 133.6816\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8287 - val_loss: 163.4481\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 266.6441 - val_loss: 151.4393\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4144 - val_loss: 168.9023\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0287 - val_loss: 149.0141\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9333 - val_loss: 160.9060\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7126 - val_loss: 159.9761\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4683 - val_loss: 137.3832\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.0777 - val_loss: 152.1255\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.0847 - val_loss: 138.4912\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.2653 - val_loss: 171.0651\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 292.5341 - val_loss: 146.4422\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 136.3932 - val_loss: 153.2619\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.0436 - val_loss: 181.6652\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7613 - val_loss: 171.8250\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1764 - val_loss: 158.4525\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.5490 - val_loss: 137.8709\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7077 - val_loss: 142.6530\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.2134 - val_loss: 172.3612\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7825 - val_loss: 146.1789\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9506 - val_loss: 182.8323\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.4112 - val_loss: 144.4193\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4094 - val_loss: 146.0889\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.2022 - val_loss: 137.9398\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.9103 - val_loss: 169.2352\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 165.5695 - val_loss: 231.6642\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.3670 - val_loss: 137.7558\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0568 - val_loss: 137.6537\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.0751 - val_loss: 136.8446\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.2090 - val_loss: 203.8151\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.7999 - val_loss: 132.6098\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4236 - val_loss: 222.5097\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.8264 - val_loss: 185.0301\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6542 - val_loss: 166.1259\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4819 - val_loss: 135.5695\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8638 - val_loss: 135.1835\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.0920 - val_loss: 399.6774\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8375 - val_loss: 218.5133\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.3162 - val_loss: 134.7134\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.3510 - val_loss: 773.6773\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 354.2184 - val_loss: 179.4805\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.2536 - val_loss: 229.2163\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3334 - val_loss: 150.3546\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0771 - val_loss: 170.5522\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0885 - val_loss: 186.7050\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1543 - val_loss: 159.8313\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1962 - val_loss: 141.4350\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0725 - val_loss: 139.9900\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.5536 - val_loss: 457.4424\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.2172 - val_loss: 147.9412\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1634 - val_loss: 134.2366\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.9339 - val_loss: 133.2658\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 189.5780 - val_loss: 256.4441\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.5807 - val_loss: 161.2417\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.3480 - val_loss: 139.1249\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9366 - val_loss: 143.8195\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7909 - val_loss: 171.8769\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1977 - val_loss: 444.0559\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.1625 - val_loss: 188.5177\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0179 - val_loss: 163.0448\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 129.708 - 0s 51us/step - loss: 129.1574 - val_loss: 141.8129\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8855 - val_loss: 139.7058\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 136.520 - 0s 51us/step - loss: 136.8096 - val_loss: 204.2759\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6368 - val_loss: 141.9857\n",
      "Epoch 1238/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.0159 - val_loss: 145.7609\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.6099 - val_loss: 137.1400\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4595 - val_loss: 179.2360\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0146 - val_loss: 138.9832\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2380 - val_loss: 136.7809\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.0844 - val_loss: 136.4457\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.4363 - val_loss: 147.3200\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.8802 - val_loss: 172.6489\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8682 - val_loss: 148.6615\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8008 - val_loss: 154.3091\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7348 - val_loss: 168.0154\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8397 - val_loss: 153.2486\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3105 - val_loss: 140.5103\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1169 - val_loss: 137.2758\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5543 - val_loss: 132.4333\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0710 - val_loss: 142.7834\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8613 - val_loss: 140.4512\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3921 - val_loss: 144.5037\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.1086 - val_loss: 173.9449\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 231.4213 - val_loss: 156.7867\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 150.7818 - val_loss: 198.0932\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 167.6977 - val_loss: 166.6317\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.1459 - val_loss: 134.2355\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.8988 - val_loss: 131.2840\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2560 - val_loss: 141.7972\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0784 - val_loss: 151.9205\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.3005 - val_loss: 152.1995\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7433 - val_loss: 149.7975\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1864 - val_loss: 133.8516\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.3811 - val_loss: 135.0225\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.1931 - val_loss: 168.2705\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0970 - val_loss: 146.5618\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2644 - val_loss: 141.0064\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7152 - val_loss: 135.0329\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0994 - val_loss: 143.1008\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.8288 - val_loss: 144.0434\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.1120 - val_loss: 138.5699\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4398 - val_loss: 152.3940\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2459 - val_loss: 137.9416\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2803 - val_loss: 139.0009\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0931 - val_loss: 136.0521\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1496 - val_loss: 197.8048\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6043 - val_loss: 146.4096\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9928 - val_loss: 140.1047\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9561 - val_loss: 137.7251\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.9592 - val_loss: 157.8586\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9328 - val_loss: 160.7477\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6942 - val_loss: 143.0110\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.6209 - val_loss: 131.2631\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6865 - val_loss: 135.4511\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9059 - val_loss: 167.9757\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0980 - val_loss: 139.0864\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.2804 - val_loss: 134.7454\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1963 - val_loss: 147.2599\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5879 - val_loss: 133.5251\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8482 - val_loss: 157.1893\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3171 - val_loss: 200.8869\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0227 - val_loss: 195.2379\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8474 - val_loss: 176.8985\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 232.7406 - val_loss: 137.5777\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8125 - val_loss: 197.8424\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.8200 - val_loss: 146.6076\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9490 - val_loss: 141.2552\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7048 - val_loss: 188.7462\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.5412 - val_loss: 137.2201\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8802 - val_loss: 146.1724\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.6891 - val_loss: 136.0298\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0676 - val_loss: 134.1633\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3912 - val_loss: 163.9870\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.7942 - val_loss: 160.1254\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3802 - val_loss: 138.7108\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3096 - val_loss: 161.6105\n",
      "Epoch 1310/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8729 - val_loss: 151.9858\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.6180 - val_loss: 144.4427\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5265 - val_loss: 196.0155\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 401.6135 - val_loss: 468.5942\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 364.6603 - val_loss: 308.2167\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 325.4714 - val_loss: 240.1356\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 226.6965 - val_loss: 198.6005\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.1919 - val_loss: 200.7885\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.1364 - val_loss: 265.8572\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.3738 - val_loss: 253.1870\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.4240 - val_loss: 184.9759\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.0632 - val_loss: 176.8009\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.7888 - val_loss: 339.2031\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.1639 - val_loss: 249.1773\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.5269 - val_loss: 238.2868\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.5710 - val_loss: 172.4520\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2922 - val_loss: 280.3260\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.4823 - val_loss: 159.0460\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.8582 - val_loss: 172.1498\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 174.6379 - val_loss: 181.0145\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 181.1687 - val_loss: 168.1553\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 176.6271 - val_loss: 157.8088\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.1671 - val_loss: 174.9906\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6077 - val_loss: 161.6469\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.2884 - val_loss: 151.3263\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1854 - val_loss: 157.5785\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.5228 - val_loss: 161.7251\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6791 - val_loss: 149.8154\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.6308 - val_loss: 201.0537\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.0908 - val_loss: 242.8361\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.3094 - val_loss: 172.1823\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7058 - val_loss: 153.4592\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6940 - val_loss: 166.4298\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1680 - val_loss: 153.4375\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8337 - val_loss: 143.9426\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.3610 - val_loss: 163.6752\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.5563 - val_loss: 218.6473\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.4415 - val_loss: 175.6890\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.3451 - val_loss: 158.0142\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6380 - val_loss: 192.6607\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.8055 - val_loss: 192.7262\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.8589 - val_loss: 153.7288\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.4238 - val_loss: 201.3183\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.0699 - val_loss: 186.0260\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7478 - val_loss: 214.5110\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6176 - val_loss: 157.0374\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4416 - val_loss: 143.6442\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6673 - val_loss: 145.6361\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8627 - val_loss: 387.1363\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7298 - val_loss: 174.0031\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.5000 - val_loss: 152.1050\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7282 - val_loss: 142.9726\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.2329 - val_loss: 163.4671\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0417 - val_loss: 155.9841\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1937 - val_loss: 165.0016\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.6448 - val_loss: 174.3467\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.7115 - val_loss: 160.9882\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.9081 - val_loss: 180.1104\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7892 - val_loss: 139.0846\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.9156 - val_loss: 179.9926\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.8749 - val_loss: 142.2528\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 239.1104 - val_loss: 155.8596\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.2923 - val_loss: 183.5187\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.7299 - val_loss: 155.3996\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 177.5372 - val_loss: 202.7672\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7619 - val_loss: 145.8731\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.5108 - val_loss: 154.1368\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2404 - val_loss: 141.2251\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.4503 - val_loss: 174.2707\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.9245 - val_loss: 170.1689\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1022 - val_loss: 143.7944\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6277 - val_loss: 158.6812\n",
      "Epoch 1382/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4326 - val_loss: 165.6033\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3618 - val_loss: 159.1961\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7669 - val_loss: 145.3027\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.4549 - val_loss: 145.8697\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8844 - val_loss: 148.4195\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6306 - val_loss: 148.9895\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.8768 - val_loss: 150.7017\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.0358 - val_loss: 157.5117\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2078 - val_loss: 143.2633\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.1741 - val_loss: 165.4460\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9833 - val_loss: 142.2619\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2359 - val_loss: 158.5347\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5878 - val_loss: 149.3071\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1250 - val_loss: 163.2619\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 177.8179 - val_loss: 193.2509\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1738 - val_loss: 150.3706\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6169 - val_loss: 233.5559\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2583 - val_loss: 257.4190\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7609 - val_loss: 199.2765\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 155.9510 - val_loss: 180.1419\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 143.3334 - val_loss: 209.8706\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 160.6852 - val_loss: 143.1707\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.2281 - val_loss: 156.6163\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1005 - val_loss: 139.7899\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9714 - val_loss: 162.8586\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.7470 - val_loss: 140.7396\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6827 - val_loss: 177.1828\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9781 - val_loss: 138.8108\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.0645 - val_loss: 143.8358\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4856 - val_loss: 148.3531\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7717 - val_loss: 142.4390\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6553 - val_loss: 153.1529\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 155.7444 - val_loss: 140.8189\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 201.5937 - val_loss: 155.2301\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 153.5924 - val_loss: 162.2970\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.6767 - val_loss: 141.0853\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5154 - val_loss: 143.2573\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 139.998 - 0s 51us/step - loss: 140.5102 - val_loss: 172.3376\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0011 - val_loss: 145.7471\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4939 - val_loss: 137.5610\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.9929 - val_loss: 153.1606\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.0963 - val_loss: 141.5471\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8106 - val_loss: 139.3331\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7520 - val_loss: 141.7187\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2429 - val_loss: 150.4413\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9151 - val_loss: 151.9869\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9219 - val_loss: 154.0288\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.4980 - val_loss: 173.4861\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.8804 - val_loss: 150.2546\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1148 - val_loss: 145.7015\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.9811 - val_loss: 152.6454\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4194 - val_loss: 139.0067\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.1246 - val_loss: 137.9648\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2741 - val_loss: 142.8263\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3497 - val_loss: 242.7607\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2974 - val_loss: 140.1440\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5989 - val_loss: 152.4091\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5205 - val_loss: 149.5956\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5402 - val_loss: 155.7098\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.7262 - val_loss: 164.1011\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0133 - val_loss: 145.5793\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7548 - val_loss: 139.4971\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.7558 - val_loss: 152.1029\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1262 - val_loss: 187.2303\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.0558 - val_loss: 158.6549\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.3979 - val_loss: 271.3035\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.0049 - val_loss: 142.7811\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6149 - val_loss: 147.4080\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6010 - val_loss: 135.9841\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.9405 - val_loss: 157.1912\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2043 - val_loss: 137.4385\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7172 - val_loss: 147.5160\n",
      "Epoch 1454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7569 - val_loss: 136.2261\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5291 - val_loss: 167.0254\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.1005 - val_loss: 154.2315\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.5057 - val_loss: 138.3610\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1761 - val_loss: 202.3697\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9745 - val_loss: 137.7002\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.3650 - val_loss: 161.9580\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5798 - val_loss: 137.6343\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7640 - val_loss: 132.4156\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8864 - val_loss: 203.6675\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.4974 - val_loss: 147.0570\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9303 - val_loss: 142.6812\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3821 - val_loss: 135.0029\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6143 - val_loss: 159.2834\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7949 - val_loss: 175.1392\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0241 - val_loss: 138.8410\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3535 - val_loss: 162.3620\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1268 - val_loss: 176.6856\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4707 - val_loss: 142.5738\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.4450 - val_loss: 148.1653\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 134.0230 - val_loss: 145.6049\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.8384 - val_loss: 176.2661\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 161.4517 - val_loss: 174.5389\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.3315 - val_loss: 143.3111\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0586 - val_loss: 136.3138\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3599 - val_loss: 151.7748\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.7864 - val_loss: 141.6324\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7160 - val_loss: 136.7103\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7622 - val_loss: 175.1424\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.1833 - val_loss: 148.4732\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8421 - val_loss: 148.1372\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9220 - val_loss: 136.7662\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9213 - val_loss: 137.7763\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.8241 - val_loss: 164.9971\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5264 - val_loss: 150.2355\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6330 - val_loss: 136.8238\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2333 - val_loss: 187.8360\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0104 - val_loss: 149.3138\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6699 - val_loss: 136.1681\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.9783 - val_loss: 184.4770\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.8590 - val_loss: 212.2930\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.1998 - val_loss: 135.0959\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7790 - val_loss: 135.4208\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1361 - val_loss: 136.6597\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1163 - val_loss: 140.1892\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2470 - val_loss: 147.3995\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6524 - val_loss: 176.6748\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8408 - val_loss: 146.5141\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.6774 - val_loss: 160.8848\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.1258 - val_loss: 172.5370\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7761 - val_loss: 146.6386\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.1768 - val_loss: 198.1005\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5998 - val_loss: 136.6650\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.7950 - val_loss: 138.4621\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3388 - val_loss: 140.6858\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6725 - val_loss: 149.4496\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.4362 - val_loss: 137.5440\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0527 - val_loss: 137.3786\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7598 - val_loss: 148.2737\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9323 - val_loss: 158.2955\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2463 - val_loss: 133.3278\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.0092 - val_loss: 138.6529\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0963 - val_loss: 156.2820\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0468 - val_loss: 172.2812\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4149 - val_loss: 146.7364\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9682 - val_loss: 139.8113\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9537 - val_loss: 183.8412\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7037 - val_loss: 141.6236\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2708 - val_loss: 150.2226\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.2044 - val_loss: 222.3712\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.0231 - val_loss: 188.0918\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7579 - val_loss: 150.7367\n",
      "Epoch 1526/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7595 - val_loss: 135.1106\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.7080 - val_loss: 131.2532\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.3570 - val_loss: 150.3031\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7572 - val_loss: 139.8471\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4267 - val_loss: 147.2342\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3790 - val_loss: 141.7921\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.8820 - val_loss: 141.4043\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3283 - val_loss: 158.2049\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7204 - val_loss: 156.3307\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1803 - val_loss: 132.9242\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6252 - val_loss: 158.7619\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.1120 - val_loss: 177.5019\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7469 - val_loss: 174.0601\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4499 - val_loss: 132.9943\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1929 - val_loss: 140.3659\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3766 - val_loss: 285.4752\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6268 - val_loss: 161.7429\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8940 - val_loss: 168.0244\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0954 - val_loss: 164.4834\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0760 - val_loss: 152.0452\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 140.0875 - val_loss: 134.4289\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 132.0440 - val_loss: 200.3317\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.1224 - val_loss: 153.1197\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0217 - val_loss: 142.2945\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0297 - val_loss: 152.5332\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.9497 - val_loss: 198.3718\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1957 - val_loss: 222.8707\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.5207 - val_loss: 162.8353\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1827 - val_loss: 133.9657\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4574 - val_loss: 175.6620\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0526 - val_loss: 153.4516\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0363 - val_loss: 202.9724\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0251 - val_loss: 136.5140\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6529 - val_loss: 133.1101\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 237.5272 - val_loss: 152.0558\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.2585 - val_loss: 147.9974\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.9317 - val_loss: 150.0387\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.3482 - val_loss: 177.7034\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.1424 - val_loss: 139.7625\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.221 - 0s 50us/step - loss: 134.3363 - val_loss: 138.1472\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6146 - val_loss: 135.3021\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8048 - val_loss: 147.5799\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.5788 - val_loss: 139.8551\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.6007 - val_loss: 194.2290\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4757 - val_loss: 222.3239\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.9846 - val_loss: 136.6303\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7547 - val_loss: 139.1866\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4820 - val_loss: 135.7533\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2978 - val_loss: 134.4167\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6607 - val_loss: 147.1051\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6410 - val_loss: 140.1641\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.1116 - val_loss: 200.8541\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8677 - val_loss: 144.8941\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4988 - val_loss: 139.6248\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7704 - val_loss: 153.8924\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8547 - val_loss: 181.0170\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0329 - val_loss: 139.9817\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4896 - val_loss: 139.8885\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7804 - val_loss: 156.1601\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0967 - val_loss: 189.0772\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5416 - val_loss: 139.1090\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.9387 - val_loss: 159.7434\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3394 - val_loss: 184.0437\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7140 - val_loss: 131.2351\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3123 - val_loss: 133.9505\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3967 - val_loss: 133.8804\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7033 - val_loss: 177.3192\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.7920 - val_loss: 137.9101\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.4264 - val_loss: 135.5923\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3493 - val_loss: 168.7578\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3702 - val_loss: 159.9336\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0771 - val_loss: 132.2089\n",
      "Epoch 1598/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6389 - val_loss: 684.8028\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2950 - val_loss: 144.8396\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0311 - val_loss: 198.8913\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6340 - val_loss: 168.1822\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.5018 - val_loss: 151.4397\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.3705 - val_loss: 144.1985\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1969 - val_loss: 192.3089\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0431 - val_loss: 135.0756\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.1262 - val_loss: 201.5646\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4621 - val_loss: 134.3764\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0563 - val_loss: 134.6161\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7528 - val_loss: 150.2859\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5790 - val_loss: 182.0611\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3523 - val_loss: 167.5643\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.7433 - val_loss: 166.8145\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8959 - val_loss: 138.3903\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3677 - val_loss: 199.1443\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3841 - val_loss: 139.8976\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.5846 - val_loss: 145.7161\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.9502 - val_loss: 142.2435\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.9881 - val_loss: 157.3942\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 129.7746 - val_loss: 168.4625\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 171.5951 - val_loss: 142.2420\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 137.5866 - val_loss: 144.5511\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1304 - val_loss: 152.2855\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.3401 - val_loss: 144.4183\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8783 - val_loss: 138.7131\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9973 - val_loss: 184.3042\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7949 - val_loss: 142.9414\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.7308 - val_loss: 132.2349\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8077 - val_loss: 179.3884\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2708 - val_loss: 155.4934\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.4279 - val_loss: 153.6410\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0203 - val_loss: 148.1826\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.9043 - val_loss: 194.0305\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1499 - val_loss: 133.4903\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4822 - val_loss: 176.3690\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.9113 - val_loss: 202.6833\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.5129 - val_loss: 146.7894\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7463 - val_loss: 166.7741\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6842 - val_loss: 139.7485\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9279 - val_loss: 134.3878\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3612 - val_loss: 167.5427\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.8041 - val_loss: 152.7618\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5358 - val_loss: 165.8250\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1461 - val_loss: 146.1953\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.5188 - val_loss: 174.6624\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3336 - val_loss: 136.2942\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7519 - val_loss: 169.6880\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 226.7731 - val_loss: 220.6178\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1708 - val_loss: 149.3957\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9895 - val_loss: 143.0700\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8851 - val_loss: 181.4803\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2062 - val_loss: 138.8610\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3659 - val_loss: 167.9474\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5200 - val_loss: 155.5734\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.6836 - val_loss: 142.7442\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6765 - val_loss: 155.2709\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3497 - val_loss: 138.6157\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2000 - val_loss: 137.7909\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5645 - val_loss: 133.3056\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.8736 - val_loss: 162.4892\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9564 - val_loss: 185.2235\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2474 - val_loss: 140.0451\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.1486 - val_loss: 389.9793\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2106 - val_loss: 165.9350\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0841 - val_loss: 173.3145\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3917 - val_loss: 135.8764\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4605 - val_loss: 139.8516\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.7410 - val_loss: 137.0485\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6417 - val_loss: 161.2122\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4628 - val_loss: 144.3698\n",
      "Epoch 1670/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8347 - val_loss: 167.7591\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7614 - val_loss: 151.6161\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4921 - val_loss: 159.5807\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2634 - val_loss: 173.4869\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8628 - val_loss: 147.7052\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5031 - val_loss: 148.0083\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1867 - val_loss: 152.1644\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.1203 - val_loss: 204.9947\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7035 - val_loss: 153.1675\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.8868 - val_loss: 141.0820\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9530 - val_loss: 140.7002\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4900 - val_loss: 144.8125\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9416 - val_loss: 148.7713\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.2815 - val_loss: 137.5841\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3051 - val_loss: 237.0220\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.5638 - val_loss: 154.7253\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9835 - val_loss: 135.8154\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8617 - val_loss: 147.5745\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0062 - val_loss: 137.7978\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.1129 - val_loss: 134.6208\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4909 - val_loss: 172.3981\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 137.9217 - val_loss: 184.0312\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 124.2686 - val_loss: 157.2252\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 126.0757 - val_loss: 131.9244\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 142.4568 - val_loss: 150.8076\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.8256 - val_loss: 191.1695\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.1940 - val_loss: 133.6131\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7191 - val_loss: 150.3715\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9046 - val_loss: 243.4445\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8606 - val_loss: 172.9127\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5187 - val_loss: 148.3550\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7569 - val_loss: 135.3729\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2445 - val_loss: 147.3886\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6202 - val_loss: 155.6283\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5055 - val_loss: 139.4744\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7420 - val_loss: 141.8700\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2216 - val_loss: 204.7057\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0543 - val_loss: 149.1405- ETA: 0s - loss: 14\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.8669 - val_loss: 158.7831\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3463 - val_loss: 135.7336\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0654 - val_loss: 133.7659\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6549 - val_loss: 135.4838\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.1511 - val_loss: 141.8271\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.0134 - val_loss: 143.2789\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5961 - val_loss: 201.4617\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3096 - val_loss: 142.3430\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1081 - val_loss: 138.3268\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3893 - val_loss: 146.0213\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3239 - val_loss: 147.1665\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4493 - val_loss: 134.5261\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9708 - val_loss: 137.5700\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5120 - val_loss: 207.5592\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9772 - val_loss: 139.1790\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2793 - val_loss: 143.8330\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0191 - val_loss: 158.6552\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8715 - val_loss: 143.7559\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1565 - val_loss: 146.1872\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6214 - val_loss: 175.3756\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.4803 - val_loss: 215.2465\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0680 - val_loss: 155.5307\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6490 - val_loss: 141.5549\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.9494 - val_loss: 133.3859\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2450 - val_loss: 170.3324\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.9545 - val_loss: 172.4892\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7405 - val_loss: 144.8106\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.9911 - val_loss: 134.4385\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2765 - val_loss: 136.9558\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2079 - val_loss: 140.9088\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.2928 - val_loss: 237.0331\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9233 - val_loss: 240.7111\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8933 - val_loss: 154.4845\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.7905 - val_loss: 136.6487\n",
      "Epoch 1742/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3057 - val_loss: 161.9245\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5412 - val_loss: 229.1986\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.1185 - val_loss: 136.9736\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9089 - val_loss: 132.7071\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1526 - val_loss: 172.5317\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0238 - val_loss: 292.6629\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9363 - val_loss: 234.0265\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.2775 - val_loss: 157.4979\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9203 - val_loss: 150.2876\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.3559 - val_loss: 150.9088\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9513 - val_loss: 200.8581\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6637 - val_loss: 134.2589\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7967 - val_loss: 139.9502\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4501 - val_loss: 152.7455\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.5891 - val_loss: 173.7303\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0792 - val_loss: 136.0904\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5294 - val_loss: 141.5725\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.9764 - val_loss: 134.3087\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2859 - val_loss: 145.3359\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.7512 - val_loss: 168.0716\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.3525 - val_loss: 168.7411\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3631 - val_loss: 137.4648\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.1105 - val_loss: 223.6393\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 142.9979 - val_loss: 274.0030\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 144.4985 - val_loss: 135.5052\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.8618 - val_loss: 135.3448\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.1752 - val_loss: 142.8423\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8640 - val_loss: 194.9654\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8178 - val_loss: 172.5696\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2177 - val_loss: 190.9372\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9340 - val_loss: 222.8968\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3099 - val_loss: 148.3251\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.6320 - val_loss: 149.0003\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.9627 - val_loss: 168.7856\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2562 - val_loss: 135.0702\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.7732 - val_loss: 175.2638\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0856 - val_loss: 212.7940\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4991 - val_loss: 150.3088\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.9395 - val_loss: 146.9100\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.1115 - val_loss: 226.9723\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1813 - val_loss: 145.1183\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5411 - val_loss: 171.8156\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.5503 - val_loss: 146.6358\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2128 - val_loss: 135.6052\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.6682 - val_loss: 155.8672\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.2318 - val_loss: 152.0020\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4258 - val_loss: 138.3820\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4269 - val_loss: 156.3200\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.0612 - val_loss: 143.7703\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6444 - val_loss: 145.4049\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8970 - val_loss: 168.6951\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3069 - val_loss: 140.8675\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7246 - val_loss: 160.6382\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3758 - val_loss: 136.7213\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.1226 - val_loss: 227.8778\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9607 - val_loss: 175.8115\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4761 - val_loss: 151.4151\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8317 - val_loss: 190.3418\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7238 - val_loss: 189.3572\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9476 - val_loss: 134.9392\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3682 - val_loss: 152.8148\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1221 - val_loss: 135.9020\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 144.0409 - val_loss: 134.8302\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.8034 - val_loss: 191.1184\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.0613 - val_loss: 134.9492\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.8169 - val_loss: 143.2872\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4310 - val_loss: 157.0870\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6344 - val_loss: 137.5442\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8354 - val_loss: 134.1725\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2983 - val_loss: 151.0869\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1616 - val_loss: 132.5979\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.2713 - val_loss: 139.8031\n",
      "Epoch 1814/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 128.0063 - val_loss: 147.7822\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.2330 - val_loss: 137.9734\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.6215 - val_loss: 140.5721\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.9683 - val_loss: 186.4907\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4527 - val_loss: 151.2214\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.3534 - val_loss: 219.9148\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3358 - val_loss: 147.4254\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.1215 - val_loss: 335.8739\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.5308 - val_loss: 212.7685\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.7519 - val_loss: 177.5326\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0093 - val_loss: 131.5347\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5782 - val_loss: 148.3031\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4119 - val_loss: 132.5518\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.8020 - val_loss: 170.7598\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7980 - val_loss: 135.1820\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9240 - val_loss: 146.7471\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 197.8753 - val_loss: 144.2935\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.0867 - val_loss: 144.1421\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6793 - val_loss: 134.9826\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.0373 - val_loss: 146.3852\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.8423 - val_loss: 184.0515\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 133.2811 - val_loss: 161.4863\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 160.3856 - val_loss: 138.2317\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.2169 - val_loss: 138.0974\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5903 - val_loss: 195.7579\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.7516 - val_loss: 274.8566\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.6235 - val_loss: 132.2555\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6376 - val_loss: 151.2416\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9418 - val_loss: 154.7096\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1688 - val_loss: 155.5448\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5836 - val_loss: 144.2300\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3424 - val_loss: 246.4426\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.1417 - val_loss: 145.0505\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.1415 - val_loss: 143.6366\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.6784 - val_loss: 141.3063\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.7105 - val_loss: 132.0002\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.2311 - val_loss: 137.4250\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9407 - val_loss: 133.9720\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4739 - val_loss: 142.4345\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3202 - val_loss: 140.9995\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7020 - val_loss: 162.2242\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.4520 - val_loss: 139.5705\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.4832 - val_loss: 173.4787\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.2920 - val_loss: 213.1948\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3683 - val_loss: 193.7512\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.2883 - val_loss: 208.6712\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4298 - val_loss: 133.5996\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.9861 - val_loss: 134.8615\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4814 - val_loss: 138.6662\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.2492 - val_loss: 143.5613\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 143.7542 - val_loss: 146.4310\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 133.5201 - val_loss: 154.6868\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.3316 - val_loss: 209.1390\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.5591 - val_loss: 137.1751\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.2356 - val_loss: 137.7952\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 132.0008 - val_loss: 142.3860\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.7606 - val_loss: 132.8087\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 125.5310 - val_loss: 135.1598\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 123.4161 - val_loss: 135.8168\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 125.9469 - val_loss: 141.5683\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.0607 - val_loss: 139.7952\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.3319 - val_loss: 148.1534\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.3079 - val_loss: 134.7747\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 131.4420 - val_loss: 142.6370\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 251.0867 - val_loss: 145.9203\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.0064 - val_loss: 132.3271\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.1263 - val_loss: 133.2470\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.8889 - val_loss: 159.6747\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 126.8097 - val_loss: 135.4491\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.2329 - val_loss: 143.7823\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 123.0680 - val_loss: 164.9866\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 129.3520 - val_loss: 148.3151\n",
      "Epoch 1886/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.1328 - val_loss: 138.5183\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 164.3305 - val_loss: 131.0031\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 139.6447 - val_loss: 140.5809\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.7039 - val_loss: 178.4223\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.1210 - val_loss: 160.2439\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.1842 - val_loss: 150.4572\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.7991 - val_loss: 156.8438\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 128.3003 - val_loss: 132.3805\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.1174 - val_loss: 141.6307\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 127.4035 - val_loss: 133.1993\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 126.6778 - val_loss: 234.3229\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.6786 - val_loss: 172.2283\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.3268 - val_loss: 138.0116\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.8784 - val_loss: 167.1186\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.4551 - val_loss: 151.5794\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.6064 - val_loss: 159.1471\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 139.2386 - val_loss: 179.6423\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 132.4646 - val_loss: 136.6093\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 136.7477 - val_loss: 212.8605\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 124.9161 - val_loss: 162.4261\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 138.2876 - val_loss: 169.0647\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 130.5641 - val_loss: 134.4343\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 132.6142 - val_loss: 263.8144\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 141.9421 - val_loss: 132.2711\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 130.2912 - val_loss: 158.7668\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 146.4506 - val_loss: 145.3190\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.9145 - val_loss: 131.3434\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5836 - val_loss: 136.7518\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.9999 - val_loss: 143.3022\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.8225 - val_loss: 159.0347\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3678 - val_loss: 133.8874\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1085 - val_loss: 220.1917\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.3070 - val_loss: 169.5412\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.9568 - val_loss: 155.1716\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4211 - val_loss: 150.9019\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.6302 - val_loss: 134.4030\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.3626 - val_loss: 140.3597\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.7063 - val_loss: 157.1885\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9871 - val_loss: 153.1766\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0520 - val_loss: 135.9500\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6979 - val_loss: 160.9626\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.3458 - val_loss: 135.3571\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6453 - val_loss: 204.2792\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.9110 - val_loss: 141.2121\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2412 - val_loss: 142.6190\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5887 - val_loss: 146.8146\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7089 - val_loss: 132.8967\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0499 - val_loss: 141.3472\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8829 - val_loss: 133.9655\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.1136 - val_loss: 136.0507\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8268 - val_loss: 153.0062\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2829 - val_loss: 163.6061\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.7167 - val_loss: 164.5322\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6674 - val_loss: 154.9024\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4800 - val_loss: 172.3312\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7349 - val_loss: 136.9288\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6280 - val_loss: 137.5617\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 134.863 - 0s 51us/step - loss: 134.3425 - val_loss: 173.7776\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4962 - val_loss: 142.1990\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.4094 - val_loss: 142.7485\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.1079 - val_loss: 159.9081\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4266 - val_loss: 135.6247\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5397 - val_loss: 203.7888\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7679 - val_loss: 137.5171\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8060 - val_loss: 192.4925\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1520 - val_loss: 138.3305\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8763 - val_loss: 148.0008\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.3868 - val_loss: 140.9714\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 129.762 - 0s 51us/step - loss: 128.6441 - val_loss: 149.5421\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0259 - val_loss: 179.3361\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.3695 - val_loss: 177.9076\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5476 - val_loss: 180.5435\n",
      "Epoch 1958/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4886 - val_loss: 153.9956\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.2167 - val_loss: 141.9768\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5171 - val_loss: 135.9310\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.1764 - val_loss: 146.8371\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4296 - val_loss: 141.3163\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4892 - val_loss: 133.1488\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 214.4620 - val_loss: 150.8091\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.0506 - val_loss: 140.6360\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0827 - val_loss: 141.2788\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0236 - val_loss: 137.2468\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5843 - val_loss: 164.0550\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.9834 - val_loss: 154.3741\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7386 - val_loss: 141.1509\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 128.5719 - val_loss: 144.5914\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.2954 - val_loss: 154.2333\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 126.9424 - val_loss: 185.2237\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.7649 - val_loss: 137.9985\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9843 - val_loss: 139.8908\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4586 - val_loss: 241.3728\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8542 - val_loss: 134.9044\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9658 - val_loss: 186.2043\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2759 - val_loss: 412.4377\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.6801 - val_loss: 137.6635\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2668 - val_loss: 216.6689\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8795 - val_loss: 196.0992\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1079 - val_loss: 146.0196\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9327 - val_loss: 205.6362\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1113 - val_loss: 156.9749\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9076 - val_loss: 175.3483\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.4234 - val_loss: 132.2527\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4775 - val_loss: 143.2313\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7774 - val_loss: 184.0789\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1734 - val_loss: 157.2240\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.6548 - val_loss: 133.0349\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.2701 - val_loss: 149.9554\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1001 - val_loss: 150.9675\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6503 - val_loss: 255.9514\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.3956 - val_loss: 149.0604\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8258 - val_loss: 152.8983\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4647 - val_loss: 139.4548\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0234 - val_loss: 133.9909\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.0508 - val_loss: 189.7059\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5097 - val_loss: 195.5269\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3197 - val_loss: 160.5885\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5488 - val_loss: 132.5910\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2795 - val_loss: 136.1056\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8408 - val_loss: 153.3397\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4511 - val_loss: 131.9505\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3068 - val_loss: 176.8052\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4825 - val_loss: 181.1412\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8437 - val_loss: 146.0884\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1106 - val_loss: 158.4010\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4856 - val_loss: 167.4559\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3590 - val_loss: 132.6659\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5430 - val_loss: 150.3208\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4709 - val_loss: 134.4539\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1042 - val_loss: 281.5850\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4839 - val_loss: 144.8149\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4911 - val_loss: 178.8414\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.6150 - val_loss: 139.4798\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.4722 - val_loss: 131.7006\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2014 - val_loss: 166.5887\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0871 - val_loss: 151.6635\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5063 - val_loss: 135.7604\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9184 - val_loss: 146.9308\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6582 - val_loss: 166.9585\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.5180 - val_loss: 137.0971\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.1225 - val_loss: 137.7201\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8613 - val_loss: 142.1381\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8255 - val_loss: 139.9990\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.9035 - val_loss: 229.8910\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.1429 - val_loss: 144.9849\n",
      "Epoch 2030/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.0965 - val_loss: 141.9154\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4676 - val_loss: 140.9745\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2801 - val_loss: 152.2234\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9292 - val_loss: 140.3266\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5001 - val_loss: 160.0137\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9641 - val_loss: 140.9919\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6754 - val_loss: 135.7611\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8005 - val_loss: 178.4419\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6473 - val_loss: 146.9588\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.0308 - val_loss: 168.7792\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9638 - val_loss: 135.4231\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3018 - val_loss: 149.1572\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.7516 - val_loss: 134.4842\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.9814 - val_loss: 148.9043\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.9981 - val_loss: 156.3309\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 125.1848 - val_loss: 143.6217\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 122.4875 - val_loss: 140.6312\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 124.4257 - val_loss: 155.0139\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6669 - val_loss: 158.7952\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.0202 - val_loss: 145.6836\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5517 - val_loss: 143.9229\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1255 - val_loss: 137.4035\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9060 - val_loss: 172.9036\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1144 - val_loss: 159.5310\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.7729 - val_loss: 152.9820\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1702 - val_loss: 210.2098\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6620 - val_loss: 134.6418\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3110 - val_loss: 283.0588\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4607 - val_loss: 139.8664\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9005 - val_loss: 163.0079\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.1320 - val_loss: 132.2898\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8244 - val_loss: 133.8361\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.3215 - val_loss: 138.8661\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7093 - val_loss: 135.8304\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1645 - val_loss: 138.3741\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.6507 - val_loss: 153.6953\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9616 - val_loss: 168.3583\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9365 - val_loss: 156.6779\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4596 - val_loss: 134.5463\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4676 - val_loss: 242.9546\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.0130 - val_loss: 152.0462\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.3964 - val_loss: 152.6933\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7362 - val_loss: 133.7659\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6302 - val_loss: 134.3893\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7088 - val_loss: 188.4444\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.2043 - val_loss: 200.2523\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.6236 - val_loss: 129.6029\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0584 - val_loss: 180.0309\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.0027 - val_loss: 168.7188\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0545 - val_loss: 148.8354\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6518 - val_loss: 135.3789\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5931 - val_loss: 275.0744\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.5532 - val_loss: 302.6984\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8637 - val_loss: 167.2689\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.5395 - val_loss: 137.6680\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0720 - val_loss: 151.8965\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1339 - val_loss: 141.9489\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1930 - val_loss: 134.3993\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5083 - val_loss: 132.3987\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2689 - val_loss: 190.2220\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3043 - val_loss: 158.2245\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5676 - val_loss: 140.2051\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9573 - val_loss: 138.6864\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2769 - val_loss: 139.0569\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2976 - val_loss: 203.0301\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.0088 - val_loss: 136.1265\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8726 - val_loss: 167.7027\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6013 - val_loss: 163.0998\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6291 - val_loss: 142.9738\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8558 - val_loss: 135.9779\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.1161 - val_loss: 150.3203\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2430 - val_loss: 151.8006\n",
      "Epoch 2102/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.9631 - val_loss: 146.6160\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.2348 - val_loss: 144.3567\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 120.0447 - val_loss: 135.1294\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0068 - val_loss: 168.8638\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9707 - val_loss: 140.9279\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3191 - val_loss: 155.8214\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7178 - val_loss: 132.6829\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7517 - val_loss: 136.7734\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.5592 - val_loss: 137.9219\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0873 - val_loss: 164.8824\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5271 - val_loss: 135.7132\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.0936 - val_loss: 145.1133\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5124 - val_loss: 137.5598\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6367 - val_loss: 132.7751\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.2113 - val_loss: 137.8326\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 127.3841 - val_loss: 167.5320\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 127.0204 - val_loss: 131.0199\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.5176 - val_loss: 134.6859\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.6592 - val_loss: 235.2793\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.5000 - val_loss: 142.9527\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9816 - val_loss: 158.8199\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4438 - val_loss: 133.1904\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9688 - val_loss: 166.1678\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9153 - val_loss: 142.9748\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3859 - val_loss: 203.9542\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3811 - val_loss: 146.2617\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.1773 - val_loss: 198.8732\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1627 - val_loss: 136.3491\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5498 - val_loss: 166.4097\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3334 - val_loss: 153.2495\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.9769 - val_loss: 138.0302\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5786 - val_loss: 161.0782\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5978 - val_loss: 136.8231\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4889 - val_loss: 136.6840\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0899 - val_loss: 141.6738\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5605 - val_loss: 168.8631\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.1994 - val_loss: 136.7575\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.5346 - val_loss: 158.1654\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0814 - val_loss: 135.3729\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3951 - val_loss: 137.5259\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7570 - val_loss: 167.3572\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0806 - val_loss: 134.5107\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.4702 - val_loss: 144.4658\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1625 - val_loss: 155.5673\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5595 - val_loss: 132.7456\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 121.7328 - val_loss: 173.0436\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 130.4857 - val_loss: 178.9126\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7383 - val_loss: 133.8960\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6957 - val_loss: 138.3179\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1431 - val_loss: 151.5926\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2915 - val_loss: 177.6751\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8778 - val_loss: 144.7551\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4959 - val_loss: 161.5537\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3814 - val_loss: 195.7031\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5463 - val_loss: 206.4030\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.6855 - val_loss: 159.8219\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5088 - val_loss: 145.1080\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6003 - val_loss: 168.0199\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8834 - val_loss: 153.3246\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2799 - val_loss: 147.6069\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9995 - val_loss: 134.4076\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.9278 - val_loss: 143.6064\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.0394 - val_loss: 148.3043\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 130.9325 - val_loss: 149.6629\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8782 - val_loss: 168.6274\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1343 - val_loss: 158.8902\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.2535 - val_loss: 183.5155\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7076 - val_loss: 154.3777\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0826 - val_loss: 175.6490\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.9850 - val_loss: 143.8351\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6866 - val_loss: 137.1341\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0919 - val_loss: 196.8290\n",
      "Epoch 2174/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.5979 - val_loss: 142.9013\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.8060 - val_loss: 181.7080\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9129 - val_loss: 196.7645\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3226 - val_loss: 178.0025\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8200 - val_loss: 148.2750\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.9753 - val_loss: 131.9973\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7365 - val_loss: 146.6482\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7180 - val_loss: 135.6283\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.6549 - val_loss: 186.2010\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5889 - val_loss: 209.0813\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2431 - val_loss: 134.2807\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2806 - val_loss: 140.9187\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.174 - 0s 51us/step - loss: 126.8896 - val_loss: 141.0070\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4387 - val_loss: 183.1673\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5579 - val_loss: 141.6871\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.7900 - val_loss: 171.3827\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 135.5650 - val_loss: 137.7538\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 122.3528 - val_loss: 136.0186\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 132.0579 - val_loss: 139.8283\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2244 - val_loss: 152.7698\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0314 - val_loss: 146.4219\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.4988 - val_loss: 148.3536\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.9031 - val_loss: 146.4675\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2917 - val_loss: 143.1140\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.9660 - val_loss: 146.4719\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7765 - val_loss: 145.9289\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5606 - val_loss: 135.9100\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9861 - val_loss: 153.8273\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9037 - val_loss: 153.9248\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8439 - val_loss: 157.6614\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5919 - val_loss: 140.2359\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3144 - val_loss: 164.6062\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6875 - val_loss: 146.1445\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.9769 - val_loss: 147.6601\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4152 - val_loss: 138.0591\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.0376 - val_loss: 145.5919\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0839 - val_loss: 154.5468\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.9476 - val_loss: 144.0309\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0013 - val_loss: 144.1661\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1970 - val_loss: 234.2543\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5083 - val_loss: 155.3025\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1150 - val_loss: 171.7527\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4416 - val_loss: 131.8883\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.8408 - val_loss: 132.9173\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4892 - val_loss: 149.7763\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.8943 - val_loss: 297.9171\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4216 - val_loss: 135.6999\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5813 - val_loss: 156.5215\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.7292 - val_loss: 139.0667\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3612 - val_loss: 151.1219\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5464 - val_loss: 145.2091\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1711 - val_loss: 143.5161\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1535 - val_loss: 158.9721\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8693 - val_loss: 155.7389\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0003 - val_loss: 145.9625\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.8614 - val_loss: 150.6420\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.5009 - val_loss: 181.0009\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3751 - val_loss: 139.5801\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.9827 - val_loss: 141.7482\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5271 - val_loss: 138.3201\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7452 - val_loss: 151.2118\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1207 - val_loss: 137.1318\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7874 - val_loss: 142.7967\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0795 - val_loss: 138.4546\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1785 - val_loss: 177.9046\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5329 - val_loss: 165.9050\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8375 - val_loss: 137.9328\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.2299 - val_loss: 140.4747\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3035 - val_loss: 135.2337\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2770 - val_loss: 160.2515\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3205 - val_loss: 148.7287\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.0916 - val_loss: 145.7590\n",
      "Epoch 2246/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.7855 - val_loss: 134.6517\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.9091 - val_loss: 143.3589\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4958 - val_loss: 132.8725\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.6349 - val_loss: 147.9133\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.8315 - val_loss: 149.1487\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8417 - val_loss: 135.0769\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.9165 - val_loss: 186.6106\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8240 - val_loss: 145.0399\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.9631 - val_loss: 149.2784\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4499 - val_loss: 150.7726\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5274 - val_loss: 161.5549\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9075 - val_loss: 133.4196\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.2458 - val_loss: 138.4956\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.7251 - val_loss: 141.1612\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.1367 - val_loss: 153.2813\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4261 - val_loss: 202.1164\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 128.5833 - val_loss: 202.3570\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 160.5997 - val_loss: 131.1149\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.4517 - val_loss: 208.7174\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 123.3968 - val_loss: 138.8630\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.2845 - val_loss: 151.9991\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5142 - val_loss: 322.7483\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8712 - val_loss: 141.7171\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0469 - val_loss: 140.4216\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.1337 - val_loss: 141.7957\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8527 - val_loss: 137.6652\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7784 - val_loss: 168.0152\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.2927 - val_loss: 136.2631\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2858 - val_loss: 167.2792\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6368 - val_loss: 133.9421\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.4009 - val_loss: 193.4833\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.6199 - val_loss: 143.4354\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.4505 - val_loss: 136.3379\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4200 - val_loss: 165.5550\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.6916 - val_loss: 166.2830\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5774 - val_loss: 193.1158\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0470 - val_loss: 178.8324\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.1831 - val_loss: 183.9747\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0972 - val_loss: 153.9789\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8921 - val_loss: 135.6161\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.2036 - val_loss: 199.8790\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5730 - val_loss: 147.8226\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.1771 - val_loss: 169.3344\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.7901 - val_loss: 142.5298\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.0760 - val_loss: 131.6715\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6421 - val_loss: 181.1388\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.8037 - val_loss: 287.0288\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.9132 - val_loss: 166.3511\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0355 - val_loss: 142.1148\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8295 - val_loss: 140.2122\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.0481 - val_loss: 136.4232\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1108 - val_loss: 139.7285\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.1940 - val_loss: 154.8650\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6203 - val_loss: 165.2499\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.1376 - val_loss: 136.9521\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9580 - val_loss: 145.7641\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.8599 - val_loss: 139.0079\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.4137 - val_loss: 129.5824\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.4599 - val_loss: 132.6645\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.1293 - val_loss: 186.4335\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.1845 - val_loss: 169.0059\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.7895 - val_loss: 148.6506\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8977 - val_loss: 149.8903\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.0428 - val_loss: 142.0260\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8263 - val_loss: 131.9379\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5260 - val_loss: 145.3624\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.7230 - val_loss: 159.9510\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.9505 - val_loss: 145.5739\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8544 - val_loss: 142.4948\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1210 - val_loss: 134.6522\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6542 - val_loss: 188.7106\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.3596 - val_loss: 156.3704\n",
      "Epoch 2318/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.7506 - val_loss: 144.9787\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2196 - val_loss: 129.1302\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.5699 - val_loss: 144.0825\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3970 - val_loss: 140.6915\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1159 - val_loss: 136.7961\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5851 - val_loss: 144.1207\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4776 - val_loss: 184.4712\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.7336 - val_loss: 143.7126\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0705 - val_loss: 136.3275\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.5973 - val_loss: 145.6084\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8166 - val_loss: 161.3790\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8562 - val_loss: 137.3823\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3298 - val_loss: 137.9075\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9055 - val_loss: 198.3419\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7532 - val_loss: 165.8821\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 124.4516 - val_loss: 145.1044\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.1153 - val_loss: 137.3617\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.2185 - val_loss: 148.8503\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 125.4877 - val_loss: 171.2624\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3835 - val_loss: 158.4104\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5152 - val_loss: 153.5116\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.1911 - val_loss: 163.6752\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.7464 - val_loss: 134.7487\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.2638 - val_loss: 174.0041\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9502 - val_loss: 145.1396\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0865 - val_loss: 178.2513\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1125 - val_loss: 133.8359\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1480 - val_loss: 132.2915\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.6711 - val_loss: 136.0072\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0301 - val_loss: 134.4861\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.8143 - val_loss: 137.8575\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.7058 - val_loss: 140.8879\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3362 - val_loss: 220.5594\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.4205 - val_loss: 144.3414\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.8207 - val_loss: 177.6303\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.1762 - val_loss: 137.6922\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.4750 - val_loss: 165.3359\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.4994 - val_loss: 156.3794\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0530 - val_loss: 142.0686\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.1312 - val_loss: 139.7763\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.0615 - val_loss: 171.9919\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.4823 - val_loss: 185.7511\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7817 - val_loss: 189.1240\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2161 - val_loss: 148.7147\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.1232 - val_loss: 138.7646\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0504 - val_loss: 134.6307\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9258 - val_loss: 143.4132\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.3541 - val_loss: 167.0481\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9202 - val_loss: 138.0547\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2916 - val_loss: 146.2414\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6562 - val_loss: 150.2630\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5155 - val_loss: 156.2879\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1352 - val_loss: 172.7097\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.5802 - val_loss: 214.1054\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.8538 - val_loss: 136.5294\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6685 - val_loss: 150.0338\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.1427 - val_loss: 139.4636\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3648 - val_loss: 155.8065\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5660 - val_loss: 139.1439\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4898 - val_loss: 137.8898\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9340 - val_loss: 138.3814\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8558 - val_loss: 157.2181\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9540 - val_loss: 220.2276\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0322 - val_loss: 143.4137\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0253 - val_loss: 144.8635\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1590 - val_loss: 170.9186\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9922 - val_loss: 181.6536\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8097 - val_loss: 173.4767\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9615 - val_loss: 134.0615\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9996 - val_loss: 210.8781\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.9236 - val_loss: 222.9542\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9665 - val_loss: 147.6563\n",
      "Epoch 2390/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.9618 - val_loss: 133.5757\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.1497 - val_loss: 158.1021\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7891 - val_loss: 147.2067\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3626 - val_loss: 147.3359\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1232 - val_loss: 139.1365\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8081 - val_loss: 136.4349\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 139.6624 - val_loss: 135.2339\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.8955 - val_loss: 151.2530\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9913 - val_loss: 183.8487\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7448 - val_loss: 156.6093\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6218 - val_loss: 154.9698\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3139 - val_loss: 183.7679\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.5007 - val_loss: 144.7684\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 125.5025 - val_loss: 160.6727\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 125.7083 - val_loss: 138.4182\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.9604 - val_loss: 136.9572\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 132.2139 - val_loss: 139.8811\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 130.8623 - val_loss: 188.7888\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6795 - val_loss: 136.1327\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.3977 - val_loss: 144.3949\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6729 - val_loss: 147.7710\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2658 - val_loss: 135.8955\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0851 - val_loss: 142.4237\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.3082 - val_loss: 142.4255\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0498 - val_loss: 155.2536\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5503 - val_loss: 142.1732\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0886 - val_loss: 220.2703\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.7700 - val_loss: 144.2005\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9732 - val_loss: 142.8571\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8855 - val_loss: 149.2039\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4818 - val_loss: 138.4375\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.6149 - val_loss: 142.1260\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.9436 - val_loss: 145.0719\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3413 - val_loss: 140.3298\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6786 - val_loss: 184.8740\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2454 - val_loss: 143.9743\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4727 - val_loss: 139.8355\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.7692 - val_loss: 202.2783\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8900 - val_loss: 204.2736\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2295 - val_loss: 140.4565\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.9436 - val_loss: 132.3536\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9765 - val_loss: 134.9386\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.5585 - val_loss: 162.3049\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 135.7939 - val_loss: 138.3646\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.9285 - val_loss: 142.0237\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.4621 - val_loss: 144.6537\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5056 - val_loss: 161.8432\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7976 - val_loss: 142.7275\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.2300 - val_loss: 143.2678\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.7202 - val_loss: 137.6325\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4271 - val_loss: 261.7225\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.1055 - val_loss: 165.6472\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6460 - val_loss: 154.5109\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0016 - val_loss: 206.6490\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.8176 - val_loss: 138.2243\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3796 - val_loss: 145.0241\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5867 - val_loss: 273.6347\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9602 - val_loss: 130.0141\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5640 - val_loss: 141.9424\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.9851 - val_loss: 157.1092\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.3759 - val_loss: 146.7162\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 124.7473 - val_loss: 169.1892\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.6172 - val_loss: 160.4336\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.8785 - val_loss: 145.6414\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3442 - val_loss: 131.1224\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3872 - val_loss: 144.7327\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2199 - val_loss: 131.7081\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3304 - val_loss: 129.7221\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2126 - val_loss: 135.4280\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.6657 - val_loss: 146.1939\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0398 - val_loss: 140.6649\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.9361 - val_loss: 197.1221\n",
      "Epoch 2462/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8778 - val_loss: 140.8464\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3623 - val_loss: 182.5733\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7342 - val_loss: 140.8793\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8430 - val_loss: 147.1666\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2718 - val_loss: 167.3978\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.1673 - val_loss: 139.6065\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.4755 - val_loss: 175.1093\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8881 - val_loss: 137.2064\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.2407 - val_loss: 154.5777\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9233 - val_loss: 160.4647\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0529 - val_loss: 190.4240\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.2408 - val_loss: 137.0065\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9611 - val_loss: 195.3442\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.0690 - val_loss: 148.4822\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1046 - val_loss: 142.5698\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.8448 - val_loss: 195.1115\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 127.4138 - val_loss: 133.0775\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.2578 - val_loss: 170.6145\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.1375 - val_loss: 131.7768\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1519 - val_loss: 130.7595\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8429 - val_loss: 138.4702\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.6484 - val_loss: 133.7972\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.6021 - val_loss: 228.7997\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1389 - val_loss: 164.7304\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4991 - val_loss: 135.1339\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7083 - val_loss: 159.6320\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9029 - val_loss: 168.4597\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9566 - val_loss: 190.7856\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9884 - val_loss: 175.4522\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6453 - val_loss: 149.3986\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.8366 - val_loss: 134.5142\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0567 - val_loss: 134.6341\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1581 - val_loss: 207.6086\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7248 - val_loss: 157.9009\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4543 - val_loss: 130.9521\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5855 - val_loss: 134.0096\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8802 - val_loss: 166.9170\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.4466 - val_loss: 144.5147\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.1220 - val_loss: 142.5290\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.3407 - val_loss: 150.7774\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6227 - val_loss: 202.2836\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 234.1768 - val_loss: 136.4496\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6959 - val_loss: 133.3193\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7696 - val_loss: 146.3472\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.2935 - val_loss: 156.5927\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2274 - val_loss: 183.0475\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3676 - val_loss: 135.2177\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.6360 - val_loss: 136.8710\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0358 - val_loss: 143.6215\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.2158 - val_loss: 132.6598\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.6800 - val_loss: 156.7591\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4169 - val_loss: 184.7742\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 130.141 - 0s 51us/step - loss: 128.9436 - val_loss: 142.4591\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.6673 - val_loss: 140.7397\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3224 - val_loss: 159.4367\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8223 - val_loss: 156.5386\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7491 - val_loss: 137.0986\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 118.818 - 0s 51us/step - loss: 120.9788 - val_loss: 188.7286\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3259 - val_loss: 143.9857\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.9479 - val_loss: 132.9401\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.7072 - val_loss: 136.2080\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 121.4730 - val_loss: 137.2226\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3496 - val_loss: 143.1468\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5199 - val_loss: 133.3770\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.4008 - val_loss: 133.8962\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.4641 - val_loss: 159.0959\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.8288 - val_loss: 134.0482\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.5529 - val_loss: 151.6849\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8805 - val_loss: 148.5258\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.6798 - val_loss: 153.7919\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 120.9201 - val_loss: 139.7380\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7876 - val_loss: 215.4899\n",
      "Epoch 2534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.6064 - val_loss: 144.1391\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.2992 - val_loss: 177.9005\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 127.3326 - val_loss: 217.1155\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 151.9596 - val_loss: 137.3795\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.1595 - val_loss: 141.2315\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.9172 - val_loss: 151.8120\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 119.1859 - val_loss: 138.8529\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.9215 - val_loss: 133.0949\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.9727 - val_loss: 153.0962\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.6748 - val_loss: 165.0929\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 125.2795 - val_loss: 142.3784\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 116.3254 - val_loss: 166.2021\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 123.8388 - val_loss: 135.4917\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 124.5971 - val_loss: 133.1321\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 132.9814 - val_loss: 137.4154\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 119.0861 - val_loss: 214.5626\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 192.8704 - val_loss: 145.1033\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 121.1750 - val_loss: 144.0737\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 173.5004 - val_loss: 149.9549\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 125.6905 - val_loss: 133.7712\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 121.6806 - val_loss: 134.9796\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 124.0078 - val_loss: 147.1567\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 123.7141 - val_loss: 157.8554\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 135.6540 - val_loss: 136.7080\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 146.2356 - val_loss: 143.9632\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 123.7571 - val_loss: 161.3038\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 120.8994 - val_loss: 161.3091\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 119.8913 - val_loss: 144.7418\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 122.0486 - val_loss: 174.7813\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 132.4269 - val_loss: 163.9475\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 170.6532 - val_loss: 141.2444\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 117.0675 - val_loss: 142.7368\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 120.2890 - val_loss: 138.5170\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 120.0153 - val_loss: 234.4567\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 119.6006 - val_loss: 167.3839\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 151.9417 - val_loss: 182.4397\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 124.2133 - val_loss: 157.5302\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 130.6430 - val_loss: 147.9704\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 132.1858 - val_loss: 135.4872\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 135.1423 - val_loss: 161.9499\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 122.5429 - val_loss: 168.5813\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 123.2691 - val_loss: 148.3593\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 138.1763 - val_loss: 140.9592\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 127.8616 - val_loss: 158.0772\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 117.8322 - val_loss: 151.6878\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 135.5146 - val_loss: 164.8876\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 120.2834 - val_loss: 136.9372\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 136.5242 - val_loss: 146.7254\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 139.3213 - val_loss: 135.8311\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 151.6773 - val_loss: 190.6752\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 118.0471 - val_loss: 142.2617\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 122.3305 - val_loss: 147.4895\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 140.6856 - val_loss: 197.6920\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 129.7881 - val_loss: 181.9780\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 126.8879 - val_loss: 139.7860\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 118.7783 - val_loss: 292.9832\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 125.5513 - val_loss: 137.5747\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 134.1689 - val_loss: 149.9585\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 119.1829 - val_loss: 156.3244\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 123.6065 - val_loss: 135.4045\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 119.9623 - val_loss: 138.8459\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.2038 - val_loss: 146.8447\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 127.5489 - val_loss: 138.6431\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.5783 - val_loss: 161.2575\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 128.0092 - val_loss: 130.9257\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 127.6326 - val_loss: 147.3106\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.8008 - val_loss: 139.6507\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.2288 - val_loss: 175.3403\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4422 - val_loss: 180.3509\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6938 - val_loss: 133.3707\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.6091 - val_loss: 141.5991\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.2753 - val_loss: 129.6711\n",
      "Epoch 2606/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.8980 - val_loss: 161.8383\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6975 - val_loss: 137.1757\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.5594 - val_loss: 160.0428\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 124.8418 - val_loss: 174.8304\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.2112 - val_loss: 134.0891\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 121.4332 - val_loss: 287.2566\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.5410 - val_loss: 137.9884\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.1369 - val_loss: 137.0385\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.9702 - val_loss: 165.0064\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.2022 - val_loss: 131.0564\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.4483 - val_loss: 143.6840\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 155.5633 - val_loss: 179.4907\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 128.0947 - val_loss: 135.2917\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.6937 - val_loss: 152.5675\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 121.1784 - val_loss: 135.3315\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 125.9170 - val_loss: 130.9769\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 150.1659 - val_loss: 134.5663\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 125.7051 - val_loss: 144.5243\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.9879 - val_loss: 179.2320\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.5124 - val_loss: 154.8153\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 163.5848 - val_loss: 210.9163\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.4856 - val_loss: 232.4530\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 120.5761 - val_loss: 133.9690\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.0056 - val_loss: 159.5226\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 118.9404 - val_loss: 141.4407\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.0351 - val_loss: 134.2793\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 118.9077 - val_loss: 142.2965\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 121.1562 - val_loss: 130.8516\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 127.4956 - val_loss: 131.8821\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.3463 - val_loss: 135.0740\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.9792 - val_loss: 224.0056\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.2262 - val_loss: 142.9553\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 129.5360 - val_loss: 130.7415\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 121.4342 - val_loss: 142.5248\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 125.5513 - val_loss: 143.3886\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 119.8522 - val_loss: 134.7466\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 121.0129 - val_loss: 142.1574\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 129.7801 - val_loss: 131.9479\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.4831 - val_loss: 135.5632\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 117.9802 - val_loss: 132.7742\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 119.3109 - val_loss: 138.9946\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 133.5558 - val_loss: 148.1894\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 130.4905 - val_loss: 164.3836\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 126.7409 - val_loss: 144.2265\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 122.5438 - val_loss: 153.4122\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 135.2820 - val_loss: 144.9271\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 122.1839 - val_loss: 140.2369\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 122.8666 - val_loss: 141.7640\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 141.3806 - val_loss: 132.8024\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 124.0595 - val_loss: 153.5002\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.0242 - val_loss: 139.5349\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 175.9863 - val_loss: 143.7931\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 123.9347 - val_loss: 142.5581\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 121.7098 - val_loss: 143.6387\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 132.5919 - val_loss: 134.4771\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 119.1801 - val_loss: 176.1643\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 119.5125 - val_loss: 199.3361\n",
      "Epoch 2663/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 150.2093 - val_loss: 133.3847\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 120.1651 - val_loss: 134.0635\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 116.1351 - val_loss: 131.5585\n",
      "Epoch 2666/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 129.8027 - val_loss: 130.6062\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 128.3440 - val_loss: 131.1375\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 147.4331 - val_loss: 162.7697\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 155.9851 - val_loss: 132.7369\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 116.4929 - val_loss: 133.1184\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 125.6705 - val_loss: 141.3171\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 114.3536 - val_loss: 154.4403\n",
      "Epoch 2673/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 123.6349 - val_loss: 148.0569\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 123.3608 - val_loss: 132.3596\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 119.5522 - val_loss: 131.9465\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 121.4013 - val_loss: 149.5723\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 144.5422 - val_loss: 151.6333\n",
      "Epoch 2678/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 61us/step - loss: 120.9557 - val_loss: 133.5833\n",
      "Epoch 2679/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.1214 - val_loss: 133.7183\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.3571 - val_loss: 133.7643\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.2409 - val_loss: 154.2564\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 201.8870 - val_loss: 157.0475\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 131.0911 - val_loss: 143.1729\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 129.7996 - val_loss: 136.4252\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.6988 - val_loss: 143.1874\n",
      "Epoch 2686/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 116.4144 - val_loss: 138.6435\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 113.8667 - val_loss: 131.4779\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 174.5983 - val_loss: 191.9996\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.8081 - val_loss: 140.2755\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 122.2042 - val_loss: 142.3152\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 120.3429 - val_loss: 131.7812\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.4717 - val_loss: 164.0078\n",
      "Epoch 2693/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 117.9198 - val_loss: 134.9248\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 120.4445 - val_loss: 148.3420\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 125.4904 - val_loss: 153.9564\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 131.4309 - val_loss: 173.3565\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 123.0173 - val_loss: 142.5960\n",
      "Epoch 2698/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 126.1508 - val_loss: 219.5880\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 117.4907 - val_loss: 180.2981\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 121.7664 - val_loss: 150.6218\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 122.8991 - val_loss: 133.0323\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 118.8968 - val_loss: 135.0116\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 123.2049 - val_loss: 157.7249\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 135.9408 - val_loss: 146.0625\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 137.6433 - val_loss: 150.8357\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 137.4949 - val_loss: 140.3905\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 140.9710 - val_loss: 134.3090\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 121.6111 - val_loss: 136.9010\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 132.5910 - val_loss: 131.7748\n",
      "Epoch 2710/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 116.4212 - val_loss: 137.6903\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 128.6551 - val_loss: 137.6070\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 122.8516 - val_loss: 144.6098\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 125.8251 - val_loss: 147.8253\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 131.1994 - val_loss: 129.0019\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 127.2463 - val_loss: 149.8727\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 124.5030 - val_loss: 143.8033\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 153.6161 - val_loss: 183.1500\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 120.0352 - val_loss: 137.1215\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 116.8055 - val_loss: 157.6802\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4320 - val_loss: 166.7969\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.5491 - val_loss: 143.7192\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.7291 - val_loss: 205.0377\n",
      "Epoch 2723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.6153 - val_loss: 244.6539\n",
      "Epoch 2724/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 174.8229 - val_loss: 139.0741\n",
      "Epoch 2725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.7560 - val_loss: 152.0779\n",
      "Epoch 2726/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.8066 - val_loss: 164.6937\n",
      "Epoch 2727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0580 - val_loss: 179.5678\n",
      "Epoch 2728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1926 - val_loss: 151.9331\n",
      "Epoch 2729/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.1747 - val_loss: 134.1626\n",
      "Epoch 2730/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.2863 - val_loss: 167.3688\n",
      "Epoch 2731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.8987 - val_loss: 154.1048\n",
      "Epoch 2732/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.0562 - val_loss: 137.9471\n",
      "Epoch 2733/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.8449 - val_loss: 155.4221\n",
      "Epoch 2734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6849 - val_loss: 138.7276\n",
      "Epoch 2735/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.1805 - val_loss: 132.7956\n",
      "Epoch 2736/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.9715 - val_loss: 179.8265\n",
      "Epoch 2737/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.9066 - val_loss: 153.6443\n",
      "Epoch 2738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8945 - val_loss: 150.0242\n",
      "Epoch 2739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8059 - val_loss: 138.4667\n",
      "Epoch 2740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7798 - val_loss: 147.5378\n",
      "Epoch 2741/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3778 - val_loss: 133.9119\n",
      "Epoch 2742/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.3622 - val_loss: 167.9905\n",
      "Epoch 2743/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 121.2682 - val_loss: 136.0649\n",
      "Epoch 2744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3495 - val_loss: 169.8881\n",
      "Epoch 2745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7332 - val_loss: 137.3253\n",
      "Epoch 2746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2387 - val_loss: 137.0330\n",
      "Epoch 2747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0863 - val_loss: 137.6481\n",
      "Epoch 2748/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.5407 - val_loss: 144.2222\n",
      "Epoch 2749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4568 - val_loss: 153.3657\n",
      "Epoch 2750/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2614 - val_loss: 134.9355\n",
      "Epoch 2751/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9159 - val_loss: 202.4053\n",
      "Epoch 2752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3210 - val_loss: 189.9327\n",
      "Epoch 2753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.7437 - val_loss: 133.1655\n",
      "Epoch 2754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3849 - val_loss: 181.3796\n",
      "Epoch 2755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8025 - val_loss: 137.0141\n",
      "Epoch 2756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.5294 - val_loss: 164.1568\n",
      "Epoch 2757/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4263 - val_loss: 148.9725\n",
      "Epoch 2758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.7765 - val_loss: 168.0771\n",
      "Epoch 2759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.3420 - val_loss: 168.5448\n",
      "Epoch 2760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6698 - val_loss: 154.1108\n",
      "Epoch 2761/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8611 - val_loss: 132.6588\n",
      "Epoch 2762/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4228 - val_loss: 144.7356\n",
      "Epoch 2763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.1809 - val_loss: 143.9928\n",
      "Epoch 2764/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7479 - val_loss: 129.2369\n",
      "Epoch 2765/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.6943 - val_loss: 141.3086\n",
      "Epoch 2766/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2920 - val_loss: 146.1272\n",
      "Epoch 2767/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 121.2055 - val_loss: 136.8618\n",
      "Epoch 2768/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 124.0974 - val_loss: 167.2847\n",
      "Epoch 2769/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 125.7996 - val_loss: 145.3060\n",
      "Epoch 2770/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 115.3581 - val_loss: 152.7231\n",
      "Epoch 2771/10000\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 131.1668 - val_loss: 139.1300\n",
      "Epoch 2772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1912 - val_loss: 165.7810\n",
      "Epoch 2773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0187 - val_loss: 136.7250\n",
      "Epoch 2774/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9549 - val_loss: 132.4438\n",
      "Epoch 2775/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5637 - val_loss: 179.3459\n",
      "Epoch 2776/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.9862 - val_loss: 146.5870\n",
      "Epoch 2777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0759 - val_loss: 155.7587\n",
      "Epoch 2778/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 126.3143 - val_loss: 146.6259\n",
      "Epoch 2779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8729 - val_loss: 143.2623\n",
      "Epoch 2780/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3909 - val_loss: 140.9181\n",
      "Epoch 2781/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3500 - val_loss: 135.6275\n",
      "Epoch 2782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9915 - val_loss: 149.2009\n",
      "Epoch 2783/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.3523 - val_loss: 148.9844\n",
      "Epoch 2784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4223 - val_loss: 149.8341\n",
      "Epoch 2785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0385 - val_loss: 138.6133\n",
      "Epoch 2786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5106 - val_loss: 135.2229\n",
      "Epoch 2787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1042 - val_loss: 138.0591\n",
      "Epoch 2788/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9013 - val_loss: 146.3056\n",
      "Epoch 2789/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5356 - val_loss: 153.0387\n",
      "Epoch 2790/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4018 - val_loss: 152.0333\n",
      "Epoch 2791/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.2874 - val_loss: 143.9543\n",
      "Epoch 2792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.4384 - val_loss: 146.2280\n",
      "Epoch 2793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.1798 - val_loss: 170.5063\n",
      "Epoch 2794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2489 - val_loss: 144.2391\n",
      "Epoch 2795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.8292 - val_loss: 137.9093\n",
      "Epoch 2796/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.0348 - val_loss: 173.5106\n",
      "Epoch 2797/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 122.2585 - val_loss: 139.8377\n",
      "Epoch 2798/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 130.1163 - val_loss: 153.0331\n",
      "Epoch 2799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5887 - val_loss: 140.2097\n",
      "Epoch 2800/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7723 - val_loss: 142.4898\n",
      "Epoch 2801/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.8632 - val_loss: 296.9970\n",
      "Epoch 2802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3730 - val_loss: 144.1762\n",
      "Epoch 2803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6786 - val_loss: 156.2883\n",
      "Epoch 2804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.4836 - val_loss: 150.5124\n",
      "Epoch 2805/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.1185 - val_loss: 143.5335\n",
      "Epoch 2806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.2348 - val_loss: 148.3809\n",
      "Epoch 2807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1334 - val_loss: 181.6319\n",
      "Epoch 2808/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8789 - val_loss: 129.8476\n",
      "Epoch 2809/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.8204 - val_loss: 147.7199\n",
      "Epoch 2810/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8541 - val_loss: 174.0107\n",
      "Epoch 2811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1958 - val_loss: 179.5488\n",
      "Epoch 2812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0799 - val_loss: 148.8965\n",
      "Epoch 2813/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.9685 - val_loss: 142.9665\n",
      "Epoch 2814/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 119.0940 - val_loss: 129.6301\n",
      "Epoch 2815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7103 - val_loss: 132.9566\n",
      "Epoch 2816/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7771 - val_loss: 178.8365\n",
      "Epoch 2817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8854 - val_loss: 143.8134\n",
      "Epoch 2818/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.6055 - val_loss: 142.1932\n",
      "Epoch 2819/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3096 - val_loss: 143.1701\n",
      "Epoch 2820/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9901 - val_loss: 152.8261\n",
      "Epoch 2821/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8244 - val_loss: 138.3541\n",
      "Epoch 2822/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3651 - val_loss: 137.9452\n",
      "Epoch 2823/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.9345 - val_loss: 132.2914\n",
      "Epoch 2824/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.6136 - val_loss: 166.3932\n",
      "Epoch 2825/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.6100 - val_loss: 135.7228\n",
      "Epoch 2826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2564 - val_loss: 134.2009\n",
      "Epoch 2827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2410 - val_loss: 175.0843\n",
      "Epoch 2828/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2940 - val_loss: 135.9848\n",
      "Epoch 2829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2911 - val_loss: 156.6649\n",
      "Epoch 2830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.7654 - val_loss: 134.1492\n",
      "Epoch 2831/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3373 - val_loss: 257.1036\n",
      "Epoch 2832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7738 - val_loss: 143.4983\n",
      "Epoch 2833/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.6160 - val_loss: 161.0740\n",
      "Epoch 2834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7729 - val_loss: 138.1106\n",
      "Epoch 2835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2944 - val_loss: 147.7562\n",
      "Epoch 2836/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.0264 - val_loss: 135.8010\n",
      "Epoch 2837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1123 - val_loss: 142.8908\n",
      "Epoch 2838/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6631 - val_loss: 139.0825\n",
      "Epoch 2839/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 126.2584 - val_loss: 135.7401\n",
      "Epoch 2840/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 145.3343 - val_loss: 154.0494\n",
      "Epoch 2841/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 120.9122 - val_loss: 137.2701\n",
      "Epoch 2842/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 116.9582 - val_loss: 152.4663\n",
      "Epoch 2843/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.0059 - val_loss: 133.6825\n",
      "Epoch 2844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.4257 - val_loss: 168.7851\n",
      "Epoch 2845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.5178 - val_loss: 132.3022\n",
      "Epoch 2846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.5370 - val_loss: 144.1453\n",
      "Epoch 2847/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1291 - val_loss: 139.1302\n",
      "Epoch 2848/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.1983 - val_loss: 182.6668\n",
      "Epoch 2849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6948 - val_loss: 137.8053\n",
      "Epoch 2850/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.4223 - val_loss: 235.9818\n",
      "Epoch 2851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1575 - val_loss: 136.0106\n",
      "Epoch 2852/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3431 - val_loss: 139.9377\n",
      "Epoch 2853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1132 - val_loss: 160.4491\n",
      "Epoch 2854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4205 - val_loss: 146.0105\n",
      "Epoch 2855/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.6913 - val_loss: 135.9019\n",
      "Epoch 2856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6976 - val_loss: 173.7863\n",
      "Epoch 2857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4921 - val_loss: 152.5536\n",
      "Epoch 2858/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1754 - val_loss: 236.7183\n",
      "Epoch 2859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6565 - val_loss: 140.5928\n",
      "Epoch 2860/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.9287 - val_loss: 151.5643\n",
      "Epoch 2861/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.4805 - val_loss: 151.8975\n",
      "Epoch 2862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0677 - val_loss: 134.2963\n",
      "Epoch 2863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.8626 - val_loss: 135.3587\n",
      "Epoch 2864/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6881 - val_loss: 159.3604\n",
      "Epoch 2865/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.5011 - val_loss: 142.1551\n",
      "Epoch 2866/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.8850 - val_loss: 208.0000\n",
      "Epoch 2867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8887 - val_loss: 133.0026\n",
      "Epoch 2868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.5710 - val_loss: 150.6886\n",
      "Epoch 2869/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.6939 - val_loss: 144.1149\n",
      "Epoch 2870/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9607 - val_loss: 128.7536\n",
      "Epoch 2871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9731 - val_loss: 158.4630\n",
      "Epoch 2872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.7322 - val_loss: 153.3392\n",
      "Epoch 2873/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.1157 - val_loss: 148.1186\n",
      "Epoch 2874/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.7284 - val_loss: 140.0950\n",
      "Epoch 2875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5252 - val_loss: 154.2852\n",
      "Epoch 2876/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5834 - val_loss: 149.4889\n",
      "Epoch 2877/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7079 - val_loss: 153.9155\n",
      "Epoch 2878/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7403 - val_loss: 158.1497\n",
      "Epoch 2879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0243 - val_loss: 163.3204\n",
      "Epoch 2880/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7370 - val_loss: 140.7927\n",
      "Epoch 2881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8100 - val_loss: 137.3520\n",
      "Epoch 2882/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6253 - val_loss: 137.9014\n",
      "Epoch 2883/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3231 - val_loss: 153.4650\n",
      "Epoch 2884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1545 - val_loss: 140.2730\n",
      "Epoch 2885/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.8869 - val_loss: 144.0210\n",
      "Epoch 2886/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 174.368 - 0s 51us/step - loss: 173.9057 - val_loss: 136.1172\n",
      "Epoch 2887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.5653 - val_loss: 144.8966\n",
      "Epoch 2888/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.9022 - val_loss: 179.8628\n",
      "Epoch 2889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3046 - val_loss: 133.8396\n",
      "Epoch 2890/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3433 - val_loss: 140.3384\n",
      "Epoch 2891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2355 - val_loss: 130.8330\n",
      "Epoch 2892/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8141 - val_loss: 161.0871\n",
      "Epoch 2893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6922 - val_loss: 143.7578\n",
      "Epoch 2894/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9818 - val_loss: 134.8765\n",
      "Epoch 2895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1743 - val_loss: 141.6168\n",
      "Epoch 2896/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2069 - val_loss: 226.7794\n",
      "Epoch 2897/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8557 - val_loss: 185.2116\n",
      "Epoch 2898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0217 - val_loss: 138.3802\n",
      "Epoch 2899/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.8109 - val_loss: 145.5559\n",
      "Epoch 2900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6470 - val_loss: 139.7666\n",
      "Epoch 2901/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.8441 - val_loss: 143.2502\n",
      "Epoch 2902/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8256 - val_loss: 184.8085\n",
      "Epoch 2903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1101 - val_loss: 136.7899\n",
      "Epoch 2904/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.2387 - val_loss: 146.0244\n",
      "Epoch 2905/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.004 - 0s 51us/step - loss: 126.0894 - val_loss: 138.6886\n",
      "Epoch 2906/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0876 - val_loss: 147.0649\n",
      "Epoch 2907/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5296 - val_loss: 204.7534\n",
      "Epoch 2908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4231 - val_loss: 139.0905\n",
      "Epoch 2909/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.2445 - val_loss: 156.8645\n",
      "Epoch 2910/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.7097 - val_loss: 163.8487\n",
      "Epoch 2911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3803 - val_loss: 166.1942\n",
      "Epoch 2912/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 130.6307 - val_loss: 188.9718\n",
      "Epoch 2913/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 117.3141 - val_loss: 155.0739\n",
      "Epoch 2914/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 117.3976 - val_loss: 151.0414\n",
      "Epoch 2915/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.1908 - val_loss: 132.1795\n",
      "Epoch 2916/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.8594 - val_loss: 176.7092\n",
      "Epoch 2917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8099 - val_loss: 141.1016\n",
      "Epoch 2918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5072 - val_loss: 157.5791\n",
      "Epoch 2919/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2958 - val_loss: 169.0484\n",
      "Epoch 2920/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1799 - val_loss: 148.3509\n",
      "Epoch 2921/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2192 - val_loss: 141.1990\n",
      "Epoch 2922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2998 - val_loss: 176.0913\n",
      "Epoch 2923/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8631 - val_loss: 135.0601\n",
      "Epoch 2924/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5526 - val_loss: 215.9017\n",
      "Epoch 2925/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.9207 - val_loss: 157.5474\n",
      "Epoch 2926/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.9042 - val_loss: 132.8503\n",
      "Epoch 2927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0138 - val_loss: 192.5268\n",
      "Epoch 2928/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3863 - val_loss: 144.2097\n",
      "Epoch 2929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.7995 - val_loss: 135.7779\n",
      "Epoch 2930/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7324 - val_loss: 237.3383\n",
      "Epoch 2931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8985 - val_loss: 180.1179\n",
      "Epoch 2932/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.6114 - val_loss: 139.4441\n",
      "Epoch 2933/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.3977 - val_loss: 153.6367\n",
      "Epoch 2934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8259 - val_loss: 135.5002\n",
      "Epoch 2935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.9886 - val_loss: 141.1768\n",
      "Epoch 2936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1165 - val_loss: 140.5059\n",
      "Epoch 2937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0830 - val_loss: 187.1733\n",
      "Epoch 2938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2951 - val_loss: 145.1707\n",
      "Epoch 2939/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 117.4581 - val_loss: 151.1835\n",
      "Epoch 2940/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.5010 - val_loss: 137.2271\n",
      "Epoch 2941/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.8227 - val_loss: 182.6214\n",
      "Epoch 2942/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3771 - val_loss: 179.2260\n",
      "Epoch 2943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6592 - val_loss: 155.6078\n",
      "Epoch 2944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3255 - val_loss: 146.4130\n",
      "Epoch 2945/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4956 - val_loss: 135.7696\n",
      "Epoch 2946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.2182 - val_loss: 132.8062\n",
      "Epoch 2947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0343 - val_loss: 145.8219\n",
      "Epoch 2948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9059 - val_loss: 154.8760\n",
      "Epoch 2949/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.5766 - val_loss: 173.1619\n",
      "Epoch 2950/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5379 - val_loss: 167.9238\n",
      "Epoch 2951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6489 - val_loss: 151.4833\n",
      "Epoch 2952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.0826 - val_loss: 154.6656\n",
      "Epoch 2953/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 123.7602 - val_loss: 138.4003\n",
      "Epoch 2954/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2886 - val_loss: 136.4740\n",
      "Epoch 2955/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.4398 - val_loss: 158.2185\n",
      "Epoch 2956/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1601 - val_loss: 160.2530\n",
      "Epoch 2957/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.3178 - val_loss: 157.7501\n",
      "Epoch 2958/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6269 - val_loss: 137.2922\n",
      "Epoch 2959/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.6599 - val_loss: 152.5403\n",
      "Epoch 2960/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7380 - val_loss: 159.0025\n",
      "Epoch 2961/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5813 - val_loss: 152.5552\n",
      "Epoch 2962/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.0197 - val_loss: 201.6726\n",
      "Epoch 2963/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.2133 - val_loss: 170.5941\n",
      "Epoch 2964/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4559 - val_loss: 148.7377\n",
      "Epoch 2965/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.4438 - val_loss: 152.9077\n",
      "Epoch 2966/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.4090 - val_loss: 137.1515\n",
      "Epoch 2967/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.4938 - val_loss: 165.1230\n",
      "Epoch 2968/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1194 - val_loss: 150.2619\n",
      "Epoch 2969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4521 - val_loss: 139.9481\n",
      "Epoch 2970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.6599 - val_loss: 141.0199\n",
      "Epoch 2971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9633 - val_loss: 146.6520\n",
      "Epoch 2972/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8567 - val_loss: 176.0800\n",
      "Epoch 2973/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.0691 - val_loss: 150.0999\n",
      "Epoch 2974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6626 - val_loss: 137.1369\n",
      "Epoch 2975/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.1663 - val_loss: 158.4033\n",
      "Epoch 2976/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0960 - val_loss: 145.2426\n",
      "Epoch 2977/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.7798 - val_loss: 140.2182\n",
      "Epoch 2978/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1693 - val_loss: 147.9747\n",
      "Epoch 2979/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.6325 - val_loss: 154.2577\n",
      "Epoch 2980/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.3367 - val_loss: 134.8404\n",
      "Epoch 2981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0351 - val_loss: 133.6001\n",
      "Epoch 2982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2901 - val_loss: 131.8168\n",
      "Epoch 2983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2402 - val_loss: 130.6206\n",
      "Epoch 2984/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 118.7989 - val_loss: 141.8547\n",
      "Epoch 2985/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 128.2162 - val_loss: 132.0310\n",
      "Epoch 2986/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 116.7109 - val_loss: 139.2363\n",
      "Epoch 2987/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 120.8741 - val_loss: 145.1154\n",
      "Epoch 2988/10000\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 130.4500 - val_loss: 138.0676\n",
      "Epoch 2989/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 285.7337 - val_loss: 160.3280\n",
      "Epoch 2990/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 182.1788 - val_loss: 146.4612\n",
      "Epoch 2991/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7859 - val_loss: 146.1935\n",
      "Epoch 2992/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 160.4679 - val_loss: 183.8019\n",
      "Epoch 2993/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1825 - val_loss: 142.7571\n",
      "Epoch 2994/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2151 - val_loss: 150.4513\n",
      "Epoch 2995/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6113 - val_loss: 137.7633\n",
      "Epoch 2996/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.0844 - val_loss: 139.5886\n",
      "Epoch 2997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6141 - val_loss: 144.9786\n",
      "Epoch 2998/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 138.855 - 0s 50us/step - loss: 139.1897 - val_loss: 149.6473\n",
      "Epoch 2999/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.8344 - val_loss: 143.3450\n",
      "Epoch 3000/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0414 - val_loss: 171.7197\n",
      "Epoch 3001/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.0567 - val_loss: 155.8988\n",
      "Epoch 3002/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2434 - val_loss: 137.4582\n",
      "Epoch 3003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1014 - val_loss: 136.0668\n",
      "Epoch 3004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2612 - val_loss: 138.8811\n",
      "Epoch 3005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6322 - val_loss: 140.3068\n",
      "Epoch 3006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0592 - val_loss: 143.7127\n",
      "Epoch 3007/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.1828 - val_loss: 146.7054\n",
      "Epoch 3008/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4437 - val_loss: 187.0781\n",
      "Epoch 3009/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9090 - val_loss: 135.2438\n",
      "Epoch 3010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5153 - val_loss: 137.0776\n",
      "Epoch 3011/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0627 - val_loss: 144.5241\n",
      "Epoch 3012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6010 - val_loss: 182.0243\n",
      "Epoch 3013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2927 - val_loss: 140.8778\n",
      "Epoch 3014/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.7744 - val_loss: 145.7377\n",
      "Epoch 3015/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1458 - val_loss: 156.1282\n",
      "Epoch 3016/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0535 - val_loss: 146.5177\n",
      "Epoch 3017/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2040 - val_loss: 148.3577\n",
      "Epoch 3018/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7246 - val_loss: 133.0505\n",
      "Epoch 3019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6799 - val_loss: 199.7635\n",
      "Epoch 3020/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.3975 - val_loss: 170.9003\n",
      "Epoch 3021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0726 - val_loss: 152.7775\n",
      "Epoch 3022/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.7075 - val_loss: 137.7786\n",
      "Epoch 3023/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.8361 - val_loss: 149.8509\n",
      "Epoch 3024/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7014 - val_loss: 132.4038\n",
      "Epoch 3025/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0352 - val_loss: 200.4063\n",
      "Epoch 3026/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9595 - val_loss: 217.9002\n",
      "Epoch 3027/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7227 - val_loss: 133.4340\n",
      "Epoch 3028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0796 - val_loss: 132.6612\n",
      "Epoch 3029/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3766 - val_loss: 154.3930\n",
      "Epoch 3030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9997 - val_loss: 149.7334\n",
      "Epoch 3031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3770 - val_loss: 156.9121\n",
      "Epoch 3032/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.1346 - val_loss: 135.9138\n",
      "Epoch 3033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2664 - val_loss: 141.5473\n",
      "Epoch 3034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1719 - val_loss: 130.3991\n",
      "Epoch 3035/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.0871 - val_loss: 134.8131\n",
      "Epoch 3036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5186 - val_loss: 132.4486\n",
      "Epoch 3037/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.0811 - val_loss: 135.2125\n",
      "Epoch 3038/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1263 - val_loss: 133.7309\n",
      "Epoch 3039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5802 - val_loss: 150.1362\n",
      "Epoch 3040/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.8091 - val_loss: 145.4546\n",
      "Epoch 3041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7063 - val_loss: 135.9391\n",
      "Epoch 3042/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1779 - val_loss: 134.8161\n",
      "Epoch 3043/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9579 - val_loss: 131.7902\n",
      "Epoch 3044/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.1732 - val_loss: 141.8759\n",
      "Epoch 3045/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8102 - val_loss: 132.2664\n",
      "Epoch 3046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8663 - val_loss: 199.5102\n",
      "Epoch 3047/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7969 - val_loss: 176.0467\n",
      "Epoch 3048/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.8145 - val_loss: 139.4456\n",
      "Epoch 3049/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4364 - val_loss: 140.5418\n",
      "Epoch 3050/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3384 - val_loss: 187.7862\n",
      "Epoch 3051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0790 - val_loss: 132.7806\n",
      "Epoch 3052/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.0851 - val_loss: 178.4944\n",
      "Epoch 3053/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0999 - val_loss: 135.1555\n",
      "Epoch 3054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9460 - val_loss: 242.5827\n",
      "Epoch 3055/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9403 - val_loss: 164.1800\n",
      "Epoch 3056/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.3755 - val_loss: 131.3875\n",
      "Epoch 3057/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 119.9674 - val_loss: 134.5951\n",
      "Epoch 3058/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 126.4765 - val_loss: 134.0729\n",
      "Epoch 3059/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 134.4732 - val_loss: 193.4769\n",
      "Epoch 3060/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 128.1544 - val_loss: 145.1139\n",
      "Epoch 3061/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.5689 - val_loss: 273.8571\n",
      "Epoch 3062/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.4647 - val_loss: 157.3501\n",
      "Epoch 3063/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.1710 - val_loss: 135.9407\n",
      "Epoch 3064/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.4905 - val_loss: 135.0895\n",
      "Epoch 3065/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.0360 - val_loss: 142.1953\n",
      "Epoch 3066/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.1065 - val_loss: 142.9379\n",
      "Epoch 3067/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9665 - val_loss: 157.2725\n",
      "Epoch 3068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.7505 - val_loss: 156.0682\n",
      "Epoch 3069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.3156 - val_loss: 147.1567\n",
      "Epoch 3070/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7918 - val_loss: 130.4947\n",
      "Epoch 3071/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.2782 - val_loss: 143.8209\n",
      "Epoch 3072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0611 - val_loss: 134.2786\n",
      "Epoch 3073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4837 - val_loss: 152.6105\n",
      "Epoch 3074/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9010 - val_loss: 155.5147\n",
      "Epoch 3075/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1000 - val_loss: 135.6810\n",
      "Epoch 3076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.7708 - val_loss: 191.9202\n",
      "Epoch 3077/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 119.3426 - val_loss: 147.5415\n",
      "Epoch 3078/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 120.408 - 0s 51us/step - loss: 119.6041 - val_loss: 184.7909\n",
      "Epoch 3079/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.6202 - val_loss: 130.0916\n",
      "Epoch 3080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8405 - val_loss: 143.3289\n",
      "Epoch 3081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5734 - val_loss: 170.2331\n",
      "Epoch 3082/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2980 - val_loss: 134.0765\n",
      "Epoch 3083/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5661 - val_loss: 138.1625\n",
      "Epoch 3084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3150 - val_loss: 148.0226\n",
      "Epoch 3085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3040 - val_loss: 140.1224\n",
      "Epoch 3086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7012 - val_loss: 159.8324\n",
      "Epoch 3087/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2636 - val_loss: 146.2577\n",
      "Epoch 3088/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7637 - val_loss: 196.7483\n",
      "Epoch 3089/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.8172 - val_loss: 152.1755\n",
      "Epoch 3090/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.9444 - val_loss: 146.0013\n",
      "Epoch 3091/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7283 - val_loss: 141.6444\n",
      "Epoch 3092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.6670 - val_loss: 160.2928\n",
      "Epoch 3093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.4038 - val_loss: 141.6509\n",
      "Epoch 3094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.6390 - val_loss: 137.3329\n",
      "Epoch 3095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.2018 - val_loss: 169.0320\n",
      "Epoch 3096/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.2960 - val_loss: 139.0996\n",
      "Epoch 3097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1764 - val_loss: 139.7507\n",
      "Epoch 3098/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.2652 - val_loss: 162.9631\n",
      "Epoch 3099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4661 - val_loss: 139.2032\n",
      "Epoch 3100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7507 - val_loss: 165.5354\n",
      "Epoch 3101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6738 - val_loss: 135.9590\n",
      "Epoch 3102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5684 - val_loss: 134.8112\n",
      "Epoch 3103/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.6816 - val_loss: 139.9385\n",
      "Epoch 3104/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.9415 - val_loss: 132.2086\n",
      "Epoch 3105/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.2922 - val_loss: 150.3578\n",
      "Epoch 3106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.4265 - val_loss: 135.5913\n",
      "Epoch 3107/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.6985 - val_loss: 139.6604\n",
      "Epoch 3108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5800 - val_loss: 137.4933\n",
      "Epoch 3109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.1097 - val_loss: 135.0607\n",
      "Epoch 3110/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9580 - val_loss: 130.4329\n",
      "Epoch 3111/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.8961 - val_loss: 142.9282\n",
      "Epoch 3112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6736 - val_loss: 137.0611\n",
      "Epoch 3113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9977 - val_loss: 220.7414\n",
      "Epoch 3114/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.3601 - val_loss: 159.8336\n",
      "Epoch 3115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.5281 - val_loss: 147.5847\n",
      "Epoch 3116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8827 - val_loss: 144.7005\n",
      "Epoch 3117/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.9301 - val_loss: 138.8112\n",
      "Epoch 3118/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6301 - val_loss: 144.5720\n",
      "Epoch 3119/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.6674 - val_loss: 136.8949\n",
      "Epoch 3120/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.3584 - val_loss: 147.7698\n",
      "Epoch 3121/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.9812 - val_loss: 170.8820\n",
      "Epoch 3122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4177 - val_loss: 137.8059\n",
      "Epoch 3123/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1771 - val_loss: 201.6301\n",
      "Epoch 3124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3992 - val_loss: 144.2195\n",
      "Epoch 3125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5629 - val_loss: 159.6619\n",
      "Epoch 3126/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.1194 - val_loss: 144.2318\n",
      "Epoch 3127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8631 - val_loss: 140.7927\n",
      "Epoch 3128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.9318 - val_loss: 144.3979\n",
      "Epoch 3129/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 120.8643 - val_loss: 135.7227\n",
      "Epoch 3130/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 114.3135 - val_loss: 146.1904\n",
      "Epoch 3131/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 117.3201 - val_loss: 138.1387\n",
      "Epoch 3132/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 120.3715 - val_loss: 141.0820\n",
      "Epoch 3133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1156 - val_loss: 154.0914\n",
      "Epoch 3134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8353 - val_loss: 176.6746\n",
      "Epoch 3135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7651 - val_loss: 147.9918\n",
      "Epoch 3136/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.2057 - val_loss: 183.6783\n",
      "Epoch 3137/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4098 - val_loss: 133.7764\n",
      "Epoch 3138/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5248 - val_loss: 132.2087\n",
      "Epoch 3139/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.2926 - val_loss: 140.7942\n",
      "Epoch 3140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.5113 - val_loss: 139.0210\n",
      "Epoch 3141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.1051 - val_loss: 150.2647\n",
      "Epoch 3142/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.2241 - val_loss: 158.1535\n",
      "Epoch 3143/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.1861 - val_loss: 144.0425\n",
      "Epoch 3144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1294 - val_loss: 149.6450\n",
      "Epoch 3145/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.3139 - val_loss: 185.9440\n",
      "Epoch 3146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.1342 - val_loss: 133.1013\n",
      "Epoch 3147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9051 - val_loss: 167.0608\n",
      "Epoch 3148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3683 - val_loss: 138.7312\n",
      "Epoch 3149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.3061 - val_loss: 133.2430\n",
      "Epoch 3150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.5102 - val_loss: 146.5457\n",
      "Epoch 3151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3074 - val_loss: 137.1075\n",
      "Epoch 3152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3301 - val_loss: 167.1454\n",
      "Epoch 3153/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.6265 - val_loss: 166.0104\n",
      "Epoch 3154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6014 - val_loss: 203.5889\n",
      "Epoch 3155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3895 - val_loss: 154.8671\n",
      "Epoch 3156/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3909 - val_loss: 150.9092\n",
      "Epoch 3157/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2486 - val_loss: 147.9464\n",
      "Epoch 3158/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.4809 - val_loss: 138.8581\n",
      "Epoch 3159/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3749 - val_loss: 135.5232\n",
      "Epoch 3160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8152 - val_loss: 134.2560\n",
      "Epoch 3161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.3517 - val_loss: 132.5300\n",
      "Epoch 3162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.2467 - val_loss: 135.3477\n",
      "Epoch 3163/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1768 - val_loss: 145.5556\n",
      "Epoch 3164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.8889 - val_loss: 181.3419\n",
      "Epoch 3165/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.4828 - val_loss: 144.5536\n",
      "Epoch 3166/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.6244 - val_loss: 131.4876\n",
      "Epoch 3167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.0275 - val_loss: 132.9275\n",
      "Epoch 3168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.8625 - val_loss: 160.2787\n",
      "Epoch 3169/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.9601 - val_loss: 159.1822\n",
      "Epoch 3170/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9005 - val_loss: 133.6490\n",
      "Epoch 3171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4696 - val_loss: 170.5062\n",
      "Epoch 3172/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.7856 - val_loss: 154.1181\n",
      "Epoch 3173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.1822 - val_loss: 185.3783\n",
      "Epoch 3174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.2450 - val_loss: 134.5988\n",
      "Epoch 3175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1756 - val_loss: 163.7870\n",
      "Epoch 3176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2869 - val_loss: 176.1852\n",
      "Epoch 3177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.4314 - val_loss: 143.2127\n",
      "Epoch 3178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4549 - val_loss: 132.8591\n",
      "Epoch 3179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1242 - val_loss: 162.6846\n",
      "Epoch 3180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6483 - val_loss: 142.7580\n",
      "Epoch 3181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.2157 - val_loss: 143.8579\n",
      "Epoch 3182/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7720 - val_loss: 148.2861\n",
      "Epoch 3183/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.9387 - val_loss: 142.7506\n",
      "Epoch 3184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.7475 - val_loss: 153.5476\n",
      "Epoch 3185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.0863 - val_loss: 161.3312\n",
      "Epoch 3186/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.6015 - val_loss: 166.6782\n",
      "Epoch 3187/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 129.0969 - val_loss: 152.6907\n",
      "Epoch 3188/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 120.4267 - val_loss: 143.5723\n",
      "Epoch 3189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.6577 - val_loss: 142.0536\n",
      "Epoch 3190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2710 - val_loss: 145.0271\n",
      "Epoch 3191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2272 - val_loss: 142.0817\n",
      "Epoch 3192/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.3798 - val_loss: 136.6619\n",
      "Epoch 3193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7607 - val_loss: 137.5392\n",
      "Epoch 3194/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7340 - val_loss: 155.7129\n",
      "Epoch 3195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.6604 - val_loss: 211.5171\n",
      "Epoch 3196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9492 - val_loss: 139.5042\n",
      "Epoch 3197/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.0008 - val_loss: 196.1284\n",
      "Epoch 3198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5458 - val_loss: 191.2147\n",
      "Epoch 3199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7797 - val_loss: 137.4568\n",
      "Epoch 3200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.6835 - val_loss: 150.1033\n",
      "Epoch 3201/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.0801 - val_loss: 139.3248\n",
      "Epoch 3202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.0120 - val_loss: 175.9604\n",
      "Epoch 3203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5027 - val_loss: 136.8299\n",
      "Epoch 3204/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.5797 - val_loss: 134.9953\n",
      "Epoch 3205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0595 - val_loss: 135.5017\n",
      "Epoch 3206/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.4266 - val_loss: 131.3626\n",
      "Epoch 3207/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.5225 - val_loss: 163.3828\n",
      "Epoch 3208/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9247 - val_loss: 160.3784\n",
      "Epoch 3209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9755 - val_loss: 148.1724\n",
      "Epoch 3210/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.4185 - val_loss: 214.8296\n",
      "Epoch 3211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.5775 - val_loss: 134.4886\n",
      "Epoch 3212/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 115.3751 - val_loss: 144.3666\n",
      "Epoch 3213/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 121.5163 - val_loss: 148.1954\n",
      "Epoch 3214/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 114.5993 - val_loss: 166.7944\n",
      "Epoch 3215/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 111.7238 - val_loss: 164.2841\n",
      "Epoch 3216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.8538 - val_loss: 189.9954\n",
      "Epoch 3217/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.9087 - val_loss: 134.6248\n",
      "Epoch 3218/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 122.3193 - val_loss: 160.4957\n",
      "Epoch 3219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8460 - val_loss: 162.8242\n",
      "Epoch 3220/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1661 - val_loss: 154.0998\n",
      "Epoch 3221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.4692 - val_loss: 135.1596\n",
      "Epoch 3222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.4094 - val_loss: 138.5440\n",
      "Epoch 3223/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.1892 - val_loss: 168.5990\n",
      "Epoch 3224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1148 - val_loss: 163.5723\n",
      "Epoch 3225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.9104 - val_loss: 139.3731\n",
      "Epoch 3226/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8372 - val_loss: 175.0480\n",
      "Epoch 3227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7929 - val_loss: 162.8326\n",
      "Epoch 3228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4845 - val_loss: 150.3624\n",
      "Epoch 3229/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0096 - val_loss: 217.2404\n",
      "Epoch 3230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.9153 - val_loss: 147.5629\n",
      "Epoch 3231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5516 - val_loss: 131.4711\n",
      "Epoch 3232/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.2245 - val_loss: 157.4209\n",
      "Epoch 3233/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.9375 - val_loss: 143.7339\n",
      "Epoch 3234/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5077 - val_loss: 143.1557\n",
      "Epoch 3235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7548 - val_loss: 151.5739\n",
      "Epoch 3236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7286 - val_loss: 139.8581\n",
      "Epoch 3237/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.8820 - val_loss: 181.3628\n",
      "Epoch 3238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8192 - val_loss: 144.9182\n",
      "Epoch 3239/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.6123 - val_loss: 159.8916\n",
      "Epoch 3240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.2741 - val_loss: 160.7889\n",
      "Epoch 3241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.9738 - val_loss: 139.6584\n",
      "Epoch 3242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8994 - val_loss: 134.5994\n",
      "Epoch 3243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.0274 - val_loss: 144.9607\n",
      "Epoch 3244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.4779 - val_loss: 148.1715\n",
      "Epoch 3245/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5621 - val_loss: 137.3593\n",
      "Epoch 3246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4059 - val_loss: 160.3579\n",
      "Epoch 3247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.0279 - val_loss: 200.7449\n",
      "Epoch 3248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7359 - val_loss: 145.5953\n",
      "Epoch 3249/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.1642 - val_loss: 185.1441\n",
      "Epoch 3250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3324 - val_loss: 152.4205\n",
      "Epoch 3251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0385 - val_loss: 207.3015\n",
      "Epoch 3252/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.6345 - val_loss: 134.1091\n",
      "Epoch 3253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0510 - val_loss: 156.2297\n",
      "Epoch 3254/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8123 - val_loss: 193.2449\n",
      "Epoch 3255/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1632 - val_loss: 146.5954\n",
      "Epoch 3256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.2829 - val_loss: 171.1351\n",
      "Epoch 3257/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.2317 - val_loss: 160.7775\n",
      "Epoch 3258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1371 - val_loss: 173.7937\n",
      "Epoch 3259/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9032 - val_loss: 162.1021\n",
      "Epoch 3260/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7041 - val_loss: 222.9617\n",
      "Epoch 3261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.8244 - val_loss: 146.2879\n",
      "Epoch 3262/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.5466 - val_loss: 131.7937\n",
      "Epoch 3263/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2740 - val_loss: 143.0222\n",
      "Epoch 3264/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6327 - val_loss: 139.0026\n",
      "Epoch 3265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3155 - val_loss: 145.4710\n",
      "Epoch 3266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.4558 - val_loss: 137.8059\n",
      "Epoch 3267/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5876 - val_loss: 152.4986\n",
      "Epoch 3268/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.8294 - val_loss: 139.5753\n",
      "Epoch 3269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4494 - val_loss: 158.3566\n",
      "Epoch 3270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4908 - val_loss: 137.0271\n",
      "Epoch 3271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7619 - val_loss: 146.4063\n",
      "Epoch 3272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0080 - val_loss: 132.2805\n",
      "Epoch 3273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3855 - val_loss: 135.1432\n",
      "Epoch 3274/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 122.6662 - val_loss: 141.9629\n",
      "Epoch 3275/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 122.8247 - val_loss: 153.5433\n",
      "Epoch 3276/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.4471 - val_loss: 152.8378\n",
      "Epoch 3277/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 126.3737 - val_loss: 142.5425\n",
      "Epoch 3278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4452 - val_loss: 142.6760\n",
      "Epoch 3279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2106 - val_loss: 141.7176\n",
      "Epoch 3280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2885 - val_loss: 131.9134\n",
      "Epoch 3281/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.9482 - val_loss: 134.5993\n",
      "Epoch 3282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6780 - val_loss: 201.7192\n",
      "Epoch 3283/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5710 - val_loss: 138.1264\n",
      "Epoch 3284/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3932 - val_loss: 137.3199\n",
      "Epoch 3285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1749 - val_loss: 138.3806\n",
      "Epoch 3286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.3472 - val_loss: 134.6539\n",
      "Epoch 3287/10000\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 126.4084 - val_loss: 221.2710\n",
      "Epoch 3288/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5119 - val_loss: 139.6289\n",
      "Epoch 3289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6337 - val_loss: 141.0020\n",
      "Epoch 3290/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3231 - val_loss: 144.3956\n",
      "Epoch 3291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.8193 - val_loss: 189.8278\n",
      "Epoch 3292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9242 - val_loss: 202.9996\n",
      "Epoch 3293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7340 - val_loss: 140.6621\n",
      "Epoch 3294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.9740 - val_loss: 134.9954\n",
      "Epoch 3295/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9872 - val_loss: 181.1904\n",
      "Epoch 3296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2404 - val_loss: 131.1266\n",
      "Epoch 3297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2329 - val_loss: 132.3395\n",
      "Epoch 3298/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.9623 - val_loss: 201.1018\n",
      "Epoch 3299/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.7626 - val_loss: 152.6136\n",
      "Epoch 3300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5942 - val_loss: 133.2583\n",
      "Epoch 3301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5275 - val_loss: 153.1674\n",
      "Epoch 3302/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.1703 - val_loss: 150.7133\n",
      "Epoch 3303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2238 - val_loss: 164.0107\n",
      "Epoch 3304/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.6345 - val_loss: 203.4771\n",
      "Epoch 3305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4684 - val_loss: 142.1689\n",
      "Epoch 3306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9109 - val_loss: 223.2065\n",
      "Epoch 3307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.9095 - val_loss: 138.3998\n",
      "Epoch 3308/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7982 - val_loss: 156.0904\n",
      "Epoch 3309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1426 - val_loss: 145.0848\n",
      "Epoch 3310/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.8715 - val_loss: 147.4751\n",
      "Epoch 3311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7949 - val_loss: 216.1830\n",
      "Epoch 3312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9709 - val_loss: 138.9506\n",
      "Epoch 3313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5389 - val_loss: 133.9256\n",
      "Epoch 3314/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.2849 - val_loss: 143.4221\n",
      "Epoch 3315/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.4036 - val_loss: 140.5356\n",
      "Epoch 3316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4799 - val_loss: 243.9758\n",
      "Epoch 3317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0162 - val_loss: 134.4327\n",
      "Epoch 3318/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.9923 - val_loss: 144.8394\n",
      "Epoch 3319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7758 - val_loss: 154.7104\n",
      "Epoch 3320/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.0089 - val_loss: 131.8596\n",
      "Epoch 3321/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2780 - val_loss: 183.6713\n",
      "Epoch 3322/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.8260 - val_loss: 146.3947\n",
      "Epoch 3323/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.6679 - val_loss: 136.3834\n",
      "Epoch 3324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.1849 - val_loss: 140.5956\n",
      "Epoch 3325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4011 - val_loss: 136.0817\n",
      "Epoch 3326/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.5964 - val_loss: 145.2194\n",
      "Epoch 3327/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.7208 - val_loss: 150.6678\n",
      "Epoch 3328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1738 - val_loss: 157.0643\n",
      "Epoch 3329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1804 - val_loss: 204.6741\n",
      "Epoch 3330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1437 - val_loss: 142.5859\n",
      "Epoch 3331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5996 - val_loss: 158.9832\n",
      "Epoch 3332/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7477 - val_loss: 159.4761\n",
      "Epoch 3333/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 117.2489 - val_loss: 165.9724\n",
      "Epoch 3334/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 121.1187 - val_loss: 140.1416\n",
      "Epoch 3335/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.1545 - val_loss: 132.4760\n",
      "Epoch 3336/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.2786 - val_loss: 143.0374\n",
      "Epoch 3337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3764 - val_loss: 147.9725\n",
      "Epoch 3338/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.2424 - val_loss: 136.2882\n",
      "Epoch 3339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0317 - val_loss: 148.3278\n",
      "Epoch 3340/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3017 - val_loss: 134.6623\n",
      "Epoch 3341/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.7017 - val_loss: 159.8610\n",
      "Epoch 3342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.3205 - val_loss: 140.3963\n",
      "Epoch 3343/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.0560 - val_loss: 151.4104\n",
      "Epoch 3344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6089 - val_loss: 131.2602\n",
      "Epoch 3345/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.0778 - val_loss: 147.0253\n",
      "Epoch 3346/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 123.7084 - val_loss: 152.8928\n",
      "Epoch 3347/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 125.7691 - val_loss: 143.0478\n",
      "Epoch 3348/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 132.8021 - val_loss: 158.6132\n",
      "Epoch 3349/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 121.7850 - val_loss: 330.7785\n",
      "Epoch 3350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5192 - val_loss: 162.6332\n",
      "Epoch 3351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2239 - val_loss: 180.0474\n",
      "Epoch 3352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9537 - val_loss: 172.3836\n",
      "Epoch 3353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9103 - val_loss: 136.3898\n",
      "Epoch 3354/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.9840 - val_loss: 170.7201\n",
      "Epoch 3355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5178 - val_loss: 138.7817\n",
      "Epoch 3356/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0565 - val_loss: 147.3784\n",
      "Epoch 3357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5794 - val_loss: 146.4620\n",
      "Epoch 3358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5527 - val_loss: 141.0734\n",
      "Epoch 3359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.3624 - val_loss: 136.1105\n",
      "Epoch 3360/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.4172 - val_loss: 139.2613\n",
      "Epoch 3361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0252 - val_loss: 175.9183\n",
      "Epoch 3362/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3686 - val_loss: 182.1546\n",
      "Epoch 3363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8237 - val_loss: 146.0855\n",
      "Epoch 3364/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0377 - val_loss: 167.6304\n",
      "Epoch 3365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8943 - val_loss: 145.6764\n",
      "Epoch 3366/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.6218 - val_loss: 142.2718\n",
      "Epoch 3367/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.0466 - val_loss: 159.5276\n",
      "Epoch 3368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5936 - val_loss: 146.0277\n",
      "Epoch 3369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3627 - val_loss: 148.4862\n",
      "Epoch 3370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6930 - val_loss: 137.1614\n",
      "Epoch 3371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.0132 - val_loss: 141.9725\n",
      "Epoch 3372/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.3802 - val_loss: 136.2640\n",
      "Epoch 3373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1195 - val_loss: 138.6086\n",
      "Epoch 3374/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0493 - val_loss: 163.5424\n",
      "Epoch 3375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3199 - val_loss: 135.6061\n",
      "Epoch 3376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4553 - val_loss: 135.9276\n",
      "Epoch 3377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.6115 - val_loss: 135.4307\n",
      "Epoch 3378/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.6730 - val_loss: 165.7782\n",
      "Epoch 3379/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3611 - val_loss: 140.4093\n",
      "Epoch 3380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0117 - val_loss: 142.0495\n",
      "Epoch 3381/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.2085 - val_loss: 136.2614\n",
      "Epoch 3382/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.5442 - val_loss: 134.0300\n",
      "Epoch 3383/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5678 - val_loss: 145.8425\n",
      "Epoch 3384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3488 - val_loss: 144.6920\n",
      "Epoch 3385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7593 - val_loss: 136.8016\n",
      "Epoch 3386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3479 - val_loss: 143.3935\n",
      "Epoch 3387/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.8072 - val_loss: 144.5203\n",
      "Epoch 3388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5157 - val_loss: 151.4574\n",
      "Epoch 3389/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2886 - val_loss: 137.1877\n",
      "Epoch 3390/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.7426 - val_loss: 153.4818\n",
      "Epoch 3391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.7746 - val_loss: 164.1651\n",
      "Epoch 3392/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 120.818 - 0s 51us/step - loss: 121.0399 - val_loss: 142.8114\n",
      "Epoch 3393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6317 - val_loss: 182.2146\n",
      "Epoch 3394/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.2540 - val_loss: 209.8278\n",
      "Epoch 3395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8424 - val_loss: 136.0076\n",
      "Epoch 3396/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.1615 - val_loss: 143.7148\n",
      "Epoch 3397/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5897 - val_loss: 152.6950\n",
      "Epoch 3398/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1414 - val_loss: 136.5020\n",
      "Epoch 3399/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.4477 - val_loss: 181.9982\n",
      "Epoch 3400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7891 - val_loss: 138.9907\n",
      "Epoch 3401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.5351 - val_loss: 135.1740\n",
      "Epoch 3402/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.0864 - val_loss: 152.4005\n",
      "Epoch 3403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4476 - val_loss: 147.4562\n",
      "Epoch 3404/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0081 - val_loss: 146.2660\n",
      "Epoch 3405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4389 - val_loss: 145.6754\n",
      "Epoch 3406/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4247 - val_loss: 616.6400\n",
      "Epoch 3407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2720 - val_loss: 169.6393\n",
      "Epoch 3408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.0599 - val_loss: 181.4215\n",
      "Epoch 3409/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.8964 - val_loss: 203.5649\n",
      "Epoch 3410/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.2398 - val_loss: 142.0120\n",
      "Epoch 3411/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.2864 - val_loss: 138.1126\n",
      "Epoch 3412/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3807 - val_loss: 242.0694\n",
      "Epoch 3413/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9737 - val_loss: 148.9345\n",
      "Epoch 3414/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5792 - val_loss: 131.4463\n",
      "Epoch 3415/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3038 - val_loss: 166.1570\n",
      "Epoch 3416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3303 - val_loss: 132.5972\n",
      "Epoch 3417/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.5014 - val_loss: 137.6219\n",
      "Epoch 3418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5803 - val_loss: 146.1746\n",
      "Epoch 3419/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.1489 - val_loss: 146.6618\n",
      "Epoch 3420/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.9249 - val_loss: 146.7507\n",
      "Epoch 3421/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 122.1266 - val_loss: 147.0064\n",
      "Epoch 3422/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 125.4325 - val_loss: 146.5963\n",
      "Epoch 3423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.1207 - val_loss: 136.3209\n",
      "Epoch 3424/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.6709 - val_loss: 168.3612\n",
      "Epoch 3425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6532 - val_loss: 143.8449\n",
      "Epoch 3426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2302 - val_loss: 131.7493\n",
      "Epoch 3427/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.6320 - val_loss: 156.1196\n",
      "Epoch 3428/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.5175 - val_loss: 136.6380\n",
      "Epoch 3429/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6946 - val_loss: 149.6448\n",
      "Epoch 3430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.4680 - val_loss: 140.9883\n",
      "Epoch 3431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1678 - val_loss: 135.1425\n",
      "Epoch 3432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4186 - val_loss: 143.2404\n",
      "Epoch 3433/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.5448 - val_loss: 166.0004\n",
      "Epoch 3434/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.4470 - val_loss: 140.3292\n",
      "Epoch 3435/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.7797 - val_loss: 151.8829\n",
      "Epoch 3436/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.0918 - val_loss: 176.8341\n",
      "Epoch 3437/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.7146 - val_loss: 141.1946\n",
      "Epoch 3438/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.2176 - val_loss: 169.1252\n",
      "Epoch 3439/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.0085 - val_loss: 153.2838\n",
      "Epoch 3440/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.9616 - val_loss: 205.2332\n",
      "Epoch 3441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.4231 - val_loss: 145.5871\n",
      "Epoch 3442/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.5539 - val_loss: 143.8032\n",
      "Epoch 3443/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 123.600 - 0s 51us/step - loss: 122.5331 - val_loss: 135.8220\n",
      "Epoch 3444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1357 - val_loss: 159.5478\n",
      "Epoch 3445/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5927 - val_loss: 134.2474\n",
      "Epoch 3446/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.0340 - val_loss: 185.2431\n",
      "Epoch 3447/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4832 - val_loss: 152.8294\n",
      "Epoch 3448/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6200 - val_loss: 152.1356\n",
      "Epoch 3449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6352 - val_loss: 148.8059\n",
      "Epoch 3450/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3959 - val_loss: 147.6712\n",
      "Epoch 3451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3581 - val_loss: 262.0519\n",
      "Epoch 3452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.8478 - val_loss: 138.5345\n",
      "Epoch 3453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7455 - val_loss: 133.5766\n",
      "Epoch 3454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.9483 - val_loss: 144.1213\n",
      "Epoch 3455/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.6276 - val_loss: 143.9696\n",
      "Epoch 3456/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.0410 - val_loss: 162.3793\n",
      "Epoch 3457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2396 - val_loss: 149.8436\n",
      "Epoch 3458/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.2884 - val_loss: 136.7977\n",
      "Epoch 3459/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.6811 - val_loss: 152.3270\n",
      "Epoch 3460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9420 - val_loss: 144.1818\n",
      "Epoch 3461/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.1522 - val_loss: 145.1976\n",
      "Epoch 3462/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.4323 - val_loss: 136.8958\n",
      "Epoch 3463/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.7041 - val_loss: 131.7363\n",
      "Epoch 3464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2240 - val_loss: 134.5985\n",
      "Epoch 3465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.6738 - val_loss: 144.5858\n",
      "Epoch 3466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1857 - val_loss: 263.3294\n",
      "Epoch 3467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8925 - val_loss: 150.3031\n",
      "Epoch 3468/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7110 - val_loss: 190.8950\n",
      "Epoch 3469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2263 - val_loss: 168.2564\n",
      "Epoch 3470/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7568 - val_loss: 166.9759\n",
      "Epoch 3471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.2427 - val_loss: 163.6532\n",
      "Epoch 3472/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.7388 - val_loss: 130.2325\n",
      "Epoch 3473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.0212 - val_loss: 131.8066\n",
      "Epoch 3474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3409 - val_loss: 239.8492\n",
      "Epoch 3475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5989 - val_loss: 183.7225\n",
      "Epoch 3476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0700 - val_loss: 138.3940\n",
      "Epoch 3477/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.2970 - val_loss: 181.7540\n",
      "Epoch 3478/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 121.4612 - val_loss: 131.6431\n",
      "Epoch 3479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2762 - val_loss: 154.8001\n",
      "Epoch 3480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.7942 - val_loss: 159.3458\n",
      "Epoch 3481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.9371 - val_loss: 190.3183\n",
      "Epoch 3482/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.1696 - val_loss: 143.4432\n",
      "Epoch 3483/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.6250 - val_loss: 152.2162\n",
      "Epoch 3484/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.2725 - val_loss: 143.0743\n",
      "Epoch 3485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9247 - val_loss: 147.3921\n",
      "Epoch 3486/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1155 - val_loss: 140.3201\n",
      "Epoch 3487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1639 - val_loss: 139.3088\n",
      "Epoch 3488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.2756 - val_loss: 134.0687\n",
      "Epoch 3489/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.7261 - val_loss: 158.1903\n",
      "Epoch 3490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1324 - val_loss: 187.0082\n",
      "Epoch 3491/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.7496 - val_loss: 141.0417\n",
      "Epoch 3492/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 121.4792 - val_loss: 168.9994\n",
      "Epoch 3493/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 167.2179 - val_loss: 159.0828\n",
      "Epoch 3494/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 155.5108 - val_loss: 152.9169\n",
      "Epoch 3495/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9157 - val_loss: 197.5732\n",
      "Epoch 3496/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1379 - val_loss: 145.8604\n",
      "Epoch 3497/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7688 - val_loss: 134.0820\n",
      "Epoch 3498/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3039 - val_loss: 194.8080\n",
      "Epoch 3499/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1944 - val_loss: 173.0326\n",
      "Epoch 3500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.1228 - val_loss: 151.3571\n",
      "Epoch 3501/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8353 - val_loss: 131.6063\n",
      "Epoch 3502/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4364 - val_loss: 143.9797\n",
      "Epoch 3503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2870 - val_loss: 142.8190\n",
      "Epoch 3504/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.5531 - val_loss: 141.0876\n",
      "Epoch 3505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4208 - val_loss: 148.5548\n",
      "Epoch 3506/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.1880 - val_loss: 150.5129\n",
      "Epoch 3507/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.1912 - val_loss: 134.3546\n",
      "Epoch 3508/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.3845 - val_loss: 138.7489\n",
      "Epoch 3509/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.7613 - val_loss: 130.1997\n",
      "Epoch 3510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5485 - val_loss: 152.4042\n",
      "Epoch 3511/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.9405 - val_loss: 143.9308\n",
      "Epoch 3512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.3415 - val_loss: 166.4094\n",
      "Epoch 3513/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0039 - val_loss: 135.0998\n",
      "Epoch 3514/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.9042 - val_loss: 145.5199\n",
      "Epoch 3515/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.5554 - val_loss: 142.6797\n",
      "Epoch 3516/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1088 - val_loss: 155.8701\n",
      "Epoch 3517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.3151 - val_loss: 150.7078\n",
      "Epoch 3518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5039 - val_loss: 155.1197\n",
      "Epoch 3519/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.8114 - val_loss: 141.3038\n",
      "Epoch 3520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.5836 - val_loss: 151.7362\n",
      "Epoch 3521/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.7614 - val_loss: 140.9576\n",
      "Epoch 3522/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9800 - val_loss: 179.0126\n",
      "Epoch 3523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5032 - val_loss: 146.1377\n",
      "Epoch 3524/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8177 - val_loss: 146.0807\n",
      "Epoch 3525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4642 - val_loss: 160.4815\n",
      "Epoch 3526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.0880 - val_loss: 166.9452\n",
      "Epoch 3527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3185 - val_loss: 184.0480\n",
      "Epoch 3528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1685 - val_loss: 135.7518\n",
      "Epoch 3529/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.3746 - val_loss: 161.5978\n",
      "Epoch 3530/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6117 - val_loss: 144.1428\n",
      "Epoch 3531/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.3864 - val_loss: 163.8750\n",
      "Epoch 3532/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.0222 - val_loss: 141.9186\n",
      "Epoch 3533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3942 - val_loss: 161.5363\n",
      "Epoch 3534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4371 - val_loss: 136.4016\n",
      "Epoch 3535/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.3144 - val_loss: 136.5695\n",
      "Epoch 3536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3707 - val_loss: 131.0435\n",
      "Epoch 3537/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.3210 - val_loss: 183.7607\n",
      "Epoch 3538/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4239 - val_loss: 200.6462\n",
      "Epoch 3539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8814 - val_loss: 131.1187\n",
      "Epoch 3540/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.2307 - val_loss: 163.8465\n",
      "Epoch 3541/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7284 - val_loss: 153.2101\n",
      "Epoch 3542/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.8477 - val_loss: 127.9414\n",
      "Epoch 3543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1275 - val_loss: 202.7273\n",
      "Epoch 3544/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0054 - val_loss: 149.0719\n",
      "Epoch 3545/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3081 - val_loss: 135.7487\n",
      "Epoch 3546/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6175 - val_loss: 142.8743\n",
      "Epoch 3547/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5240 - val_loss: 138.6059\n",
      "Epoch 3548/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.9432 - val_loss: 149.8117\n",
      "Epoch 3549/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0106 - val_loss: 178.1954\n",
      "Epoch 3550/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.6434 - val_loss: 135.5677\n",
      "Epoch 3551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.0769 - val_loss: 131.4835\n",
      "Epoch 3552/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7382 - val_loss: 191.1982\n",
      "Epoch 3553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6149 - val_loss: 130.1679\n",
      "Epoch 3554/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.1594 - val_loss: 133.6986\n",
      "Epoch 3555/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.3839 - val_loss: 144.5730\n",
      "Epoch 3556/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.5915 - val_loss: 137.4314\n",
      "Epoch 3557/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.9021 - val_loss: 138.1899\n",
      "Epoch 3558/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 122.7529 - val_loss: 144.1682\n",
      "Epoch 3559/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 126.7834 - val_loss: 151.0112\n",
      "Epoch 3560/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.2820 - val_loss: 132.2214\n",
      "Epoch 3561/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.4326 - val_loss: 141.1639\n",
      "Epoch 3562/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 119.3498 - val_loss: 136.0761\n",
      "Epoch 3563/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 121.8602 - val_loss: 130.9508\n",
      "Epoch 3564/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 117.7977 - val_loss: 250.0407\n",
      "Epoch 3565/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 121.8583 - val_loss: 175.0094\n",
      "Epoch 3566/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2557 - val_loss: 169.7012\n",
      "Epoch 3567/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 116.8380 - val_loss: 134.4797\n",
      "Epoch 3568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.5701 - val_loss: 138.3556\n",
      "Epoch 3569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.7828 - val_loss: 164.6533\n",
      "Epoch 3570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5671 - val_loss: 132.6421\n",
      "Epoch 3571/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2680 - val_loss: 176.2531\n",
      "Epoch 3572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.2520 - val_loss: 180.1698\n",
      "Epoch 3573/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.3792 - val_loss: 141.6639\n",
      "Epoch 3574/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.1811 - val_loss: 146.4260\n",
      "Epoch 3575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0167 - val_loss: 167.8110\n",
      "Epoch 3576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6787 - val_loss: 150.6898\n",
      "Epoch 3577/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.3710 - val_loss: 165.1439\n",
      "Epoch 3578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.7328 - val_loss: 146.2712\n",
      "Epoch 3579/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.6527 - val_loss: 155.9891\n",
      "Epoch 3580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3012 - val_loss: 265.6476\n",
      "Epoch 3581/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3975 - val_loss: 139.1196\n",
      "Epoch 3582/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.4165 - val_loss: 137.0271\n",
      "Epoch 3583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0439 - val_loss: 139.1848\n",
      "Epoch 3584/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0471 - val_loss: 145.5190\n",
      "Epoch 3585/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.8020 - val_loss: 142.6984\n",
      "Epoch 3586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4490 - val_loss: 162.7837\n",
      "Epoch 3587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8150 - val_loss: 145.2475\n",
      "Epoch 3588/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 116.6914 - val_loss: 140.0831\n",
      "Epoch 3589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0684 - val_loss: 153.7029\n",
      "Epoch 3590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8879 - val_loss: 135.3281\n",
      "Epoch 3591/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 124.3506 - val_loss: 175.9147\n",
      "Epoch 3592/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.3332 - val_loss: 184.6535\n",
      "Epoch 3593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.5566 - val_loss: 132.2612\n",
      "Epoch 3594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9712 - val_loss: 145.5493\n",
      "Epoch 3595/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.7569 - val_loss: 137.9785\n",
      "Epoch 3596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9470 - val_loss: 142.4112\n",
      "Epoch 3597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4936 - val_loss: 149.0623\n",
      "Epoch 3598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8698 - val_loss: 134.2949\n",
      "Epoch 3599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9195 - val_loss: 146.1138\n",
      "Epoch 3600/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.4039 - val_loss: 259.3523\n",
      "Epoch 3601/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1042 - val_loss: 139.2046\n",
      "Epoch 3602/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9701 - val_loss: 145.8874\n",
      "Epoch 3603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.5064 - val_loss: 137.0343\n",
      "Epoch 3604/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.0784 - val_loss: 143.4330\n",
      "Epoch 3605/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.9021 - val_loss: 145.8445\n",
      "Epoch 3606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3144 - val_loss: 195.0501\n",
      "Epoch 3607/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.0970 - val_loss: 152.7467\n",
      "Epoch 3608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.6805 - val_loss: 168.0952\n",
      "Epoch 3609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3253 - val_loss: 135.2763\n",
      "Epoch 3610/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.7188 - val_loss: 139.1484\n",
      "Epoch 3611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.5683 - val_loss: 136.6314\n",
      "Epoch 3612/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.1182 - val_loss: 230.8158\n",
      "Epoch 3613/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3187 - val_loss: 141.0613\n",
      "Epoch 3614/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.5307 - val_loss: 155.9623\n",
      "Epoch 3615/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7274 - val_loss: 163.4704\n",
      "Epoch 3616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4792 - val_loss: 153.0961\n",
      "Epoch 3617/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.8027 - val_loss: 130.8925\n",
      "Epoch 3618/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5965 - val_loss: 152.8870\n",
      "Epoch 3619/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8180 - val_loss: 141.8583\n",
      "Epoch 3620/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.5059 - val_loss: 164.4623\n",
      "Epoch 3621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.0861 - val_loss: 153.2075\n",
      "Epoch 3622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.9957 - val_loss: 128.1763\n",
      "Epoch 3623/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.4097 - val_loss: 152.2391\n",
      "Epoch 3624/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.7222 - val_loss: 140.3557\n",
      "Epoch 3625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4657 - val_loss: 144.0375\n",
      "Epoch 3626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.8026 - val_loss: 136.1472\n",
      "Epoch 3627/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.5865 - val_loss: 151.5636\n",
      "Epoch 3628/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 110.5506 - val_loss: 146.8713\n",
      "Epoch 3629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5365 - val_loss: 175.9423\n",
      "Epoch 3630/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.9627 - val_loss: 137.7053\n",
      "Epoch 3631/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.2301 - val_loss: 134.2185\n",
      "Epoch 3632/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.5996 - val_loss: 224.5768\n",
      "Epoch 3633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.9925 - val_loss: 151.4095\n",
      "Epoch 3634/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.4700 - val_loss: 135.1156\n",
      "Epoch 3635/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 132.2216 - val_loss: 136.5607\n",
      "Epoch 3636/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 116.5081 - val_loss: 157.6458\n",
      "Epoch 3637/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 121.7859 - val_loss: 134.9586\n",
      "Epoch 3638/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.6446 - val_loss: 158.7365\n",
      "Epoch 3639/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.8438 - val_loss: 131.0559\n",
      "Epoch 3640/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.6425 - val_loss: 137.0118\n",
      "Epoch 3641/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.8136 - val_loss: 138.4350\n",
      "Epoch 3642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.2967 - val_loss: 162.3593\n",
      "Epoch 3643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3947 - val_loss: 149.1675\n",
      "Epoch 3644/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2136 - val_loss: 138.9048\n",
      "Epoch 3645/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.3031 - val_loss: 150.8136\n",
      "Epoch 3646/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.7312 - val_loss: 135.1199\n",
      "Epoch 3647/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.9360 - val_loss: 146.0064\n",
      "Epoch 3648/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6511 - val_loss: 150.3524\n",
      "Epoch 3649/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.0291 - val_loss: 153.9828\n",
      "Epoch 3650/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.4957 - val_loss: 149.7476\n",
      "Epoch 3651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4184 - val_loss: 160.1774\n",
      "Epoch 3652/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.5278 - val_loss: 183.4891\n",
      "Epoch 3653/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.6669 - val_loss: 134.4383\n",
      "Epoch 3654/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.6210 - val_loss: 139.6820\n",
      "Epoch 3655/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.6013 - val_loss: 142.3816\n",
      "Epoch 3656/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.2212 - val_loss: 139.3800\n",
      "Epoch 3657/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.9873 - val_loss: 234.9876\n",
      "Epoch 3658/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4130 - val_loss: 149.8065\n",
      "Epoch 3659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3977 - val_loss: 135.8999\n",
      "Epoch 3660/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 119.173 - 0s 51us/step - loss: 118.7324 - val_loss: 140.3525\n",
      "Epoch 3661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.2761 - val_loss: 170.2028\n",
      "Epoch 3662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6393 - val_loss: 186.2321\n",
      "Epoch 3663/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.1451 - val_loss: 142.7727\n",
      "Epoch 3664/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4085 - val_loss: 139.2358\n",
      "Epoch 3665/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.1474 - val_loss: 146.0876\n",
      "Epoch 3666/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6012 - val_loss: 145.5142\n",
      "Epoch 3667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8625 - val_loss: 136.1863\n",
      "Epoch 3668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.3555 - val_loss: 170.2285\n",
      "Epoch 3669/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8563 - val_loss: 142.0620\n",
      "Epoch 3670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.0042 - val_loss: 151.6415\n",
      "Epoch 3671/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1621 - val_loss: 166.5326\n",
      "Epoch 3672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.5136 - val_loss: 132.8631\n",
      "Epoch 3673/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2933 - val_loss: 147.3484\n",
      "Epoch 3674/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.2777 - val_loss: 181.9452\n",
      "Epoch 3675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1871 - val_loss: 150.1612\n",
      "Epoch 3676/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.2598 - val_loss: 198.0747\n",
      "Epoch 3677/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.9767 - val_loss: 152.6083\n",
      "Epoch 3678/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.1041 - val_loss: 168.5718- ETA: 0s - loss: 11\n",
      "Epoch 3679/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 132.244 - 0s 50us/step - loss: 135.1541 - val_loss: 235.0742\n",
      "Epoch 3680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9225 - val_loss: 133.0674\n",
      "Epoch 3681/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.8110 - val_loss: 156.8700\n",
      "Epoch 3682/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4258 - val_loss: 131.9794\n",
      "Epoch 3683/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.2652 - val_loss: 137.2786\n",
      "Epoch 3684/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.7778 - val_loss: 136.0736\n",
      "Epoch 3685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8883 - val_loss: 139.9078\n",
      "Epoch 3686/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6662 - val_loss: 133.6359\n",
      "Epoch 3687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.2395 - val_loss: 133.4189\n",
      "Epoch 3688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.7951 - val_loss: 143.5535\n",
      "Epoch 3689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8901 - val_loss: 167.9718\n",
      "Epoch 3690/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7008 - val_loss: 139.0203\n",
      "Epoch 3691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7165 - val_loss: 152.8566\n",
      "Epoch 3692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0041 - val_loss: 137.5543\n",
      "Epoch 3693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2570 - val_loss: 152.3829\n",
      "Epoch 3694/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.8839 - val_loss: 155.8954\n",
      "Epoch 3695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.6392 - val_loss: 206.1888\n",
      "Epoch 3696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4239 - val_loss: 138.7029\n",
      "Epoch 3697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.0538 - val_loss: 142.4364\n",
      "Epoch 3698/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.1195 - val_loss: 175.1664\n",
      "Epoch 3699/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7616 - val_loss: 134.9281\n",
      "Epoch 3700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1404 - val_loss: 163.7014\n",
      "Epoch 3701/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.0760 - val_loss: 154.7646\n",
      "Epoch 3702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9675 - val_loss: 132.5142\n",
      "Epoch 3703/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5546 - val_loss: 143.0010\n",
      "Epoch 3704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.2106 - val_loss: 134.0755\n",
      "Epoch 3705/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.1015 - val_loss: 142.9826\n",
      "Epoch 3706/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 118.4610 - val_loss: 134.4165\n",
      "Epoch 3707/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 116.1738 - val_loss: 135.5401\n",
      "Epoch 3708/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 118.3947 - val_loss: 136.0686\n",
      "Epoch 3709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.4830 - val_loss: 134.0160\n",
      "Epoch 3710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7822 - val_loss: 143.6926\n",
      "Epoch 3711/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 121.9486 - val_loss: 161.7591\n",
      "Epoch 3712/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.0207 - val_loss: 159.1337\n",
      "Epoch 3713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5431 - val_loss: 135.1658\n",
      "Epoch 3714/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.5723 - val_loss: 161.3146\n",
      "Epoch 3715/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1473 - val_loss: 152.7553\n",
      "Epoch 3716/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.2512 - val_loss: 147.1759\n",
      "Epoch 3717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9616 - val_loss: 235.9264\n",
      "Epoch 3718/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.0124 - val_loss: 137.5513\n",
      "Epoch 3719/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.1026 - val_loss: 140.0995\n",
      "Epoch 3720/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9911 - val_loss: 160.0597\n",
      "Epoch 3721/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.2513 - val_loss: 142.0608\n",
      "Epoch 3722/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.7357 - val_loss: 161.8803\n",
      "Epoch 3723/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5238 - val_loss: 130.2781\n",
      "Epoch 3724/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.8966 - val_loss: 133.0273\n",
      "Epoch 3725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0648 - val_loss: 156.7896\n",
      "Epoch 3726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.8273 - val_loss: 151.1123\n",
      "Epoch 3727/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.5184 - val_loss: 130.1501\n",
      "Epoch 3728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.4112 - val_loss: 139.0452\n",
      "Epoch 3729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8995 - val_loss: 144.7083\n",
      "Epoch 3730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.8542 - val_loss: 215.1365\n",
      "Epoch 3731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5069 - val_loss: 176.0951\n",
      "Epoch 3732/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.064 - 0s 51us/step - loss: 126.8336 - val_loss: 137.5286\n",
      "Epoch 3733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9251 - val_loss: 146.2737\n",
      "Epoch 3734/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.0631 - val_loss: 200.8906\n",
      "Epoch 3735/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.8887 - val_loss: 136.5333\n",
      "Epoch 3736/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.8438 - val_loss: 161.3098\n",
      "Epoch 3737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.1657 - val_loss: 133.2754\n",
      "Epoch 3738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.4054 - val_loss: 133.7102\n",
      "Epoch 3739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6068 - val_loss: 152.0691\n",
      "Epoch 3740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.1829 - val_loss: 144.4691\n",
      "Epoch 3741/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7998 - val_loss: 134.0739\n",
      "Epoch 3742/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5207 - val_loss: 171.8446\n",
      "Epoch 3743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6131 - val_loss: 159.8739\n",
      "Epoch 3744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.1404 - val_loss: 143.4400\n",
      "Epoch 3745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0630 - val_loss: 134.0469\n",
      "Epoch 3746/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.0964 - val_loss: 154.8840\n",
      "Epoch 3747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4427 - val_loss: 146.0873\n",
      "Epoch 3748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5800 - val_loss: 150.0983\n",
      "Epoch 3749/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.7684 - val_loss: 152.8768\n",
      "Epoch 3750/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.9617 - val_loss: 186.9769\n",
      "Epoch 3751/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.1112 - val_loss: 147.7761\n",
      "Epoch 3752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5723 - val_loss: 134.9933\n",
      "Epoch 3753/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.9861 - val_loss: 142.6763\n",
      "Epoch 3754/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.2748 - val_loss: 154.9352\n",
      "Epoch 3755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6805 - val_loss: 142.5778\n",
      "Epoch 3756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3916 - val_loss: 129.4333\n",
      "Epoch 3757/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3458 - val_loss: 134.9821\n",
      "Epoch 3758/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 0s - loss: 123.661 - 0s 50us/step - loss: 123.7917 - val_loss: 147.1776\n",
      "Epoch 3759/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6700 - val_loss: 155.4736\n",
      "Epoch 3760/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.0621 - val_loss: 135.0239\n",
      "Epoch 3761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.5116 - val_loss: 144.3727\n",
      "Epoch 3762/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.1309 - val_loss: 133.8535\n",
      "Epoch 3763/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.3145 - val_loss: 142.8662\n",
      "Epoch 3764/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.2413 - val_loss: 160.3746\n",
      "Epoch 3765/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.1796 - val_loss: 160.2526\n",
      "Epoch 3766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5916 - val_loss: 179.7819\n",
      "Epoch 3767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4267 - val_loss: 134.7363\n",
      "Epoch 3768/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2123 - val_loss: 177.7505\n",
      "Epoch 3769/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1298 - val_loss: 139.2282\n",
      "Epoch 3770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.8607 - val_loss: 153.6288\n",
      "Epoch 3771/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7543 - val_loss: 142.7947\n",
      "Epoch 3772/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.5455 - val_loss: 149.5559\n",
      "Epoch 3773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8014 - val_loss: 143.8902\n",
      "Epoch 3774/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0575 - val_loss: 135.4004\n",
      "Epoch 3775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5188 - val_loss: 179.7583\n",
      "Epoch 3776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7134 - val_loss: 155.8721\n",
      "Epoch 3777/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1151 - val_loss: 146.7392\n",
      "Epoch 3778/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 118.8169 - val_loss: 185.3550\n",
      "Epoch 3779/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 122.7689 - val_loss: 143.4297\n",
      "Epoch 3780/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.3858 - val_loss: 138.5995\n",
      "Epoch 3781/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 116.0994 - val_loss: 140.3423\n",
      "Epoch 3782/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.8550 - val_loss: 136.6578\n",
      "Epoch 3783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.5386 - val_loss: 184.4262\n",
      "Epoch 3784/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5467 - val_loss: 146.6594\n",
      "Epoch 3785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.9727 - val_loss: 146.5306\n",
      "Epoch 3786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.5826 - val_loss: 139.8457\n",
      "Epoch 3787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3960 - val_loss: 174.1428\n",
      "Epoch 3788/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.9032 - val_loss: 253.7842\n",
      "Epoch 3789/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0108 - val_loss: 233.5192\n",
      "Epoch 3790/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.3162 - val_loss: 141.3824\n",
      "Epoch 3791/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0285 - val_loss: 135.6211\n",
      "Epoch 3792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0669 - val_loss: 170.1290\n",
      "Epoch 3793/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.0268 - val_loss: 140.5641\n",
      "Epoch 3794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0607 - val_loss: 131.1098\n",
      "Epoch 3795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6569 - val_loss: 135.4716\n",
      "Epoch 3796/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.2237 - val_loss: 141.2716\n",
      "Epoch 3797/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.4429 - val_loss: 158.2620\n",
      "Epoch 3798/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.6008 - val_loss: 158.9253\n",
      "Epoch 3799/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 126.1268 - val_loss: 150.5702\n",
      "Epoch 3800/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 126.3680 - val_loss: 135.5263\n",
      "Epoch 3801/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.3565 - val_loss: 166.2587\n",
      "Epoch 3802/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 111.7208 - val_loss: 140.6049\n",
      "Epoch 3803/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.0562 - val_loss: 140.7930\n",
      "Epoch 3804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.8886 - val_loss: 177.2239\n",
      "Epoch 3805/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.5156 - val_loss: 143.0219\n",
      "Epoch 3806/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7850 - val_loss: 148.7229\n",
      "Epoch 3807/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.7531 - val_loss: 189.4332\n",
      "Epoch 3808/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2704 - val_loss: 144.0566\n",
      "Epoch 3809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4052 - val_loss: 139.1961\n",
      "Epoch 3810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0180 - val_loss: 137.5004\n",
      "Epoch 3811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.9049 - val_loss: 153.6399\n",
      "Epoch 3812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7421 - val_loss: 149.8336\n",
      "Epoch 3813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.2199 - val_loss: 148.2189\n",
      "Epoch 3814/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6577 - val_loss: 160.2535\n",
      "Epoch 3815/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.9893 - val_loss: 132.2777\n",
      "Epoch 3816/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5852 - val_loss: 137.4688\n",
      "Epoch 3817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8178 - val_loss: 150.5333\n",
      "Epoch 3818/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.4173 - val_loss: 156.8513\n",
      "Epoch 3819/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7137 - val_loss: 136.7800\n",
      "Epoch 3820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9194 - val_loss: 204.7015\n",
      "Epoch 3821/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.3745 - val_loss: 144.4828\n",
      "Epoch 3822/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.4519 - val_loss: 136.1768\n",
      "Epoch 3823/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1104 - val_loss: 138.3825\n",
      "Epoch 3824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.8699 - val_loss: 133.3601\n",
      "Epoch 3825/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.4424 - val_loss: 131.9902\n",
      "Epoch 3826/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7805 - val_loss: 140.7360\n",
      "Epoch 3827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5855 - val_loss: 319.9664\n",
      "Epoch 3828/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2087 - val_loss: 174.8597\n",
      "Epoch 3829/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.4458 - val_loss: 146.1502\n",
      "Epoch 3830/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.2777 - val_loss: 192.9743\n",
      "Epoch 3831/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.1728 - val_loss: 132.9913\n",
      "Epoch 3832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4076 - val_loss: 133.0369\n",
      "Epoch 3833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9971 - val_loss: 191.2117\n",
      "Epoch 3834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9269 - val_loss: 134.0298\n",
      "Epoch 3835/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.3432 - val_loss: 151.7690\n",
      "Epoch 3836/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.6221 - val_loss: 174.1762\n",
      "Epoch 3837/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 120.2806 - val_loss: 149.6879\n",
      "Epoch 3838/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2516 - val_loss: 138.9695\n",
      "Epoch 3839/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.9058 - val_loss: 172.6429\n",
      "Epoch 3840/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.8858 - val_loss: 141.6579\n",
      "Epoch 3841/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.4375 - val_loss: 143.1871\n",
      "Epoch 3842/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.9904 - val_loss: 143.3247\n",
      "Epoch 3843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2616 - val_loss: 148.9472\n",
      "Epoch 3844/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.6293 - val_loss: 139.4178\n",
      "Epoch 3845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.2832 - val_loss: 145.2863\n",
      "Epoch 3846/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.5940 - val_loss: 160.7782\n",
      "Epoch 3847/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5600 - val_loss: 173.5105\n",
      "Epoch 3848/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.0528 - val_loss: 158.7405\n",
      "Epoch 3849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1139 - val_loss: 141.3887\n",
      "Epoch 3850/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 126.3856 - val_loss: 143.4149\n",
      "Epoch 3851/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 119.5636 - val_loss: 134.1063\n",
      "Epoch 3852/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 116.0108 - val_loss: 138.1313\n",
      "Epoch 3853/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 123.4885 - val_loss: 134.6873\n",
      "Epoch 3854/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.0551 - val_loss: 230.4637\n",
      "Epoch 3855/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.2471 - val_loss: 141.9582\n",
      "Epoch 3856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.8961 - val_loss: 211.9388\n",
      "Epoch 3857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2707 - val_loss: 172.0518\n",
      "Epoch 3858/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.4654 - val_loss: 137.3047\n",
      "Epoch 3859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.5332 - val_loss: 131.7960\n",
      "Epoch 3860/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.2827 - val_loss: 155.2696\n",
      "Epoch 3861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.4115 - val_loss: 162.2295\n",
      "Epoch 3862/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0902 - val_loss: 161.5631\n",
      "Epoch 3863/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1249 - val_loss: 195.0241\n",
      "Epoch 3864/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1590 - val_loss: 149.7892\n",
      "Epoch 3865/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.1319 - val_loss: 170.1328\n",
      "Epoch 3866/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7454 - val_loss: 168.7815\n",
      "Epoch 3867/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.3537 - val_loss: 131.2324\n",
      "Epoch 3868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8235 - val_loss: 146.7803\n",
      "Epoch 3869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.5456 - val_loss: 140.0863\n",
      "Epoch 3870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.8357 - val_loss: 148.3296\n",
      "Epoch 3871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.0399 - val_loss: 136.2518\n",
      "Epoch 3872/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 111.0681 - val_loss: 180.3004\n",
      "Epoch 3873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.2007 - val_loss: 139.8906\n",
      "Epoch 3874/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 113.3036 - val_loss: 140.7776\n",
      "Epoch 3875/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.0785 - val_loss: 185.8584\n",
      "Epoch 3876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5777 - val_loss: 132.6381\n",
      "Epoch 3877/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.1160 - val_loss: 155.1499\n",
      "Epoch 3878/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.5882 - val_loss: 151.5876\n",
      "Epoch 3879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3734 - val_loss: 138.2528\n",
      "Epoch 3880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.9219 - val_loss: 182.4917\n",
      "Epoch 3881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9396 - val_loss: 161.4998\n",
      "Epoch 3882/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.4299 - val_loss: 169.0793\n",
      "Epoch 3883/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.1334 - val_loss: 151.1501\n",
      "Epoch 3884/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.5037 - val_loss: 137.4301\n",
      "Epoch 3885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7169 - val_loss: 136.5614\n",
      "Epoch 3886/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 132.305 - 0s 51us/step - loss: 131.7731 - val_loss: 135.5063\n",
      "Epoch 3887/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4147 - val_loss: 182.5541\n",
      "Epoch 3888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.8607 - val_loss: 149.7105\n",
      "Epoch 3889/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.1624 - val_loss: 161.6521\n",
      "Epoch 3890/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.5694 - val_loss: 136.1446\n",
      "Epoch 3891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4456 - val_loss: 142.4375\n",
      "Epoch 3892/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.5904 - val_loss: 135.8811\n",
      "Epoch 3893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2619 - val_loss: 147.5456\n",
      "Epoch 3894/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8714 - val_loss: 164.4845\n",
      "Epoch 3895/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5229 - val_loss: 146.4347\n",
      "Epoch 3896/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 114.3614 - val_loss: 211.6932\n",
      "Epoch 3897/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.4439 - val_loss: 145.4727\n",
      "Epoch 3898/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.1011 - val_loss: 134.0200\n",
      "Epoch 3899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8449 - val_loss: 182.4902\n",
      "Epoch 3900/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6460 - val_loss: 136.2748\n",
      "Epoch 3901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3219 - val_loss: 152.1969\n",
      "Epoch 3902/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.8749 - val_loss: 140.6995\n",
      "Epoch 3903/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0273 - val_loss: 205.2646\n",
      "Epoch 3904/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.6827 - val_loss: 181.1238\n",
      "Epoch 3905/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5607 - val_loss: 140.8290\n",
      "Epoch 3906/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.6046 - val_loss: 172.2668\n",
      "Epoch 3907/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.1706 - val_loss: 134.7048\n",
      "Epoch 3908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.0047 - val_loss: 155.1500\n",
      "Epoch 3909/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 123.1003 - val_loss: 137.7587\n",
      "Epoch 3910/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.4641 - val_loss: 171.8922\n",
      "Epoch 3911/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.7263 - val_loss: 246.9446\n",
      "Epoch 3912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6510 - val_loss: 141.1974\n",
      "Epoch 3913/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.0919 - val_loss: 142.5812\n",
      "Epoch 3914/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8989 - val_loss: 221.7486\n",
      "Epoch 3915/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0953 - val_loss: 157.0230\n",
      "Epoch 3916/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 117.059 - 0s 51us/step - loss: 116.0858 - val_loss: 134.0626\n",
      "Epoch 3917/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.5176 - val_loss: 136.7843\n",
      "Epoch 3918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.5507 - val_loss: 146.1609\n",
      "Epoch 3919/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0146 - val_loss: 162.4348\n",
      "Epoch 3920/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3255 - val_loss: 134.1828\n",
      "Epoch 3921/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8656 - val_loss: 143.4061\n",
      "Epoch 3922/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.3364 - val_loss: 171.9694\n",
      "Epoch 3923/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.9548 - val_loss: 247.1759\n",
      "Epoch 3924/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.4796 - val_loss: 150.4844\n",
      "Epoch 3925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.7739 - val_loss: 159.3808\n",
      "Epoch 3926/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 143.245 - 0s 51us/step - loss: 141.8529 - val_loss: 149.8641\n",
      "Epoch 3927/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4141 - val_loss: 161.0067\n",
      "Epoch 3928/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.1118 - val_loss: 133.2891\n",
      "Epoch 3929/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7041 - val_loss: 145.7584\n",
      "Epoch 3930/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3485 - val_loss: 228.4017\n",
      "Epoch 3931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.2961 - val_loss: 150.7454\n",
      "Epoch 3932/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.9408 - val_loss: 134.8702\n",
      "Epoch 3933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.4078 - val_loss: 143.0658\n",
      "Epoch 3934/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 117.5615 - val_loss: 139.9342\n",
      "Epoch 3935/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 126.0553 - val_loss: 136.7658\n",
      "Epoch 3936/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 114.3123 - val_loss: 136.2556\n",
      "Epoch 3937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.9617 - val_loss: 134.4046\n",
      "Epoch 3938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.7708 - val_loss: 132.3346\n",
      "Epoch 3939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4318 - val_loss: 155.3740\n",
      "Epoch 3940/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.9556 - val_loss: 148.4821\n",
      "Epoch 3941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1805 - val_loss: 202.0534\n",
      "Epoch 3942/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2670 - val_loss: 183.5657\n",
      "Epoch 3943/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.7311 - val_loss: 151.0906\n",
      "Epoch 3944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4428 - val_loss: 138.0865\n",
      "Epoch 3945/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 114.3642 - val_loss: 133.9364\n",
      "Epoch 3946/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.2420 - val_loss: 145.5238\n",
      "Epoch 3947/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.0336 - val_loss: 196.5221\n",
      "Epoch 3948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7897 - val_loss: 137.8101\n",
      "Epoch 3949/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5322 - val_loss: 167.8014\n",
      "Epoch 3950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1640 - val_loss: 192.4760\n",
      "Epoch 3951/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.2981 - val_loss: 146.6446\n",
      "Epoch 3952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1338 - val_loss: 131.7700\n",
      "Epoch 3953/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.8617 - val_loss: 133.3164\n",
      "Epoch 3954/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.1144 - val_loss: 165.7877\n",
      "Epoch 3955/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.3094 - val_loss: 137.1651\n",
      "Epoch 3956/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.7513 - val_loss: 138.8088\n",
      "Epoch 3957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2993 - val_loss: 160.6740\n",
      "Epoch 3958/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0970 - val_loss: 174.2008\n",
      "Epoch 3959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6017 - val_loss: 134.5957\n",
      "Epoch 3960/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.9743 - val_loss: 188.5339\n",
      "Epoch 3961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8159 - val_loss: 150.3629\n",
      "Epoch 3962/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4188 - val_loss: 172.5525\n",
      "Epoch 3963/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2333 - val_loss: 152.2202\n",
      "Epoch 3964/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.0458 - val_loss: 153.7876\n",
      "Epoch 3965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.3576 - val_loss: 143.4766\n",
      "Epoch 3966/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.1205 - val_loss: 142.8242\n",
      "Epoch 3967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9254 - val_loss: 131.6778\n",
      "Epoch 3968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.3882 - val_loss: 168.2783\n",
      "Epoch 3969/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.1191 - val_loss: 137.0614\n",
      "Epoch 3970/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.5452 - val_loss: 135.6651\n",
      "Epoch 3971/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6315 - val_loss: 137.0546\n",
      "Epoch 3972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5893 - val_loss: 151.1967\n",
      "Epoch 3973/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4358 - val_loss: 134.1533\n",
      "Epoch 3974/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1659 - val_loss: 198.9520\n",
      "Epoch 3975/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.0809 - val_loss: 146.6933\n",
      "Epoch 3976/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.0067 - val_loss: 183.8870\n",
      "Epoch 3977/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.5288 - val_loss: 130.7177\n",
      "Epoch 3978/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.1949 - val_loss: 146.4166\n",
      "Epoch 3979/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3457 - val_loss: 147.6986\n",
      "Epoch 3980/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.4678 - val_loss: 138.5712\n",
      "Epoch 3981/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.5775 - val_loss: 145.5035\n",
      "Epoch 3982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4947 - val_loss: 139.7412\n",
      "Epoch 3983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.6376 - val_loss: 166.6252\n",
      "Epoch 3984/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.6766 - val_loss: 178.1648\n",
      "Epoch 3985/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6465 - val_loss: 131.3050\n",
      "Epoch 3986/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.8787 - val_loss: 166.4593\n",
      "Epoch 3987/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.0438 - val_loss: 135.1109\n",
      "Epoch 3988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.8362 - val_loss: 164.4462\n",
      "Epoch 3989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.8409 - val_loss: 253.1637\n",
      "Epoch 3990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.7009 - val_loss: 148.9315\n",
      "Epoch 3991/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0164 - val_loss: 137.2848\n",
      "Epoch 3992/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.1452 - val_loss: 156.5460\n",
      "Epoch 3993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1851 - val_loss: 171.8916\n",
      "Epoch 3994/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 116.6930 - val_loss: 145.1716\n",
      "Epoch 3995/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 114.7656 - val_loss: 177.5972\n",
      "Epoch 3996/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 121.4604 - val_loss: 171.0979\n",
      "Epoch 3997/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 125.7023 - val_loss: 156.6483\n",
      "Epoch 3998/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 139.8505 - val_loss: 129.1124\n",
      "Epoch 3999/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0772 - val_loss: 187.3913\n",
      "Epoch 4000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9475 - val_loss: 149.6312\n",
      "Epoch 4001/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0968 - val_loss: 144.9904\n",
      "Epoch 4002/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.6494 - val_loss: 130.4134\n",
      "Epoch 4003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.8338 - val_loss: 150.1038\n",
      "Epoch 4004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.2002 - val_loss: 195.9031\n",
      "Epoch 4005/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.4164 - val_loss: 200.3548\n",
      "Epoch 4006/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.4117 - val_loss: 151.0414\n",
      "Epoch 4007/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7112 - val_loss: 252.2281\n",
      "Epoch 4008/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.5768 - val_loss: 141.5630\n",
      "Epoch 4009/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.1297 - val_loss: 140.4115\n",
      "Epoch 4010/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9686 - val_loss: 149.4401\n",
      "Epoch 4011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4973 - val_loss: 183.7179\n",
      "Epoch 4012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3487 - val_loss: 144.7537\n",
      "Epoch 4013/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.6299 - val_loss: 138.0253\n",
      "Epoch 4014/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.4849 - val_loss: 145.1529\n",
      "Epoch 4015/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.6013 - val_loss: 136.0775\n",
      "Epoch 4016/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.8480 - val_loss: 158.9533\n",
      "Epoch 4017/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.4986 - val_loss: 147.3711\n",
      "Epoch 4018/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 118.153 - 0s 50us/step - loss: 118.4792 - val_loss: 138.6194\n",
      "Epoch 4019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5898 - val_loss: 139.1696\n",
      "Epoch 4020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5218 - val_loss: 137.1083\n",
      "Epoch 4021/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.0031 - val_loss: 138.3642\n",
      "Epoch 4022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.7756 - val_loss: 143.0149\n",
      "Epoch 4023/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1408 - val_loss: 140.3177\n",
      "Epoch 4024/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.8787 - val_loss: 154.8711\n",
      "Epoch 4025/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.0707 - val_loss: 136.6422\n",
      "Epoch 4026/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.6816 - val_loss: 141.7953\n",
      "Epoch 4027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.7100 - val_loss: 169.8535\n",
      "Epoch 4028/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.0196 - val_loss: 164.1504\n",
      "Epoch 4029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6186 - val_loss: 142.4318\n",
      "Epoch 4030/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.6525 - val_loss: 133.0649\n",
      "Epoch 4031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.3149 - val_loss: 135.2465\n",
      "Epoch 4032/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.3566 - val_loss: 155.3921\n",
      "Epoch 4033/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.8617 - val_loss: 150.4377\n",
      "Epoch 4034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7335 - val_loss: 141.8551\n",
      "Epoch 4035/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.9579 - val_loss: 154.2735\n",
      "Epoch 4036/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.2852 - val_loss: 173.9646\n",
      "Epoch 4037/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 111.7501 - val_loss: 177.1927\n",
      "Epoch 4038/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.2834 - val_loss: 146.2995\n",
      "Epoch 4039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1957 - val_loss: 145.4386\n",
      "Epoch 4040/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.5787 - val_loss: 139.3103\n",
      "Epoch 4041/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.5046 - val_loss: 137.1220\n",
      "Epoch 4042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9335 - val_loss: 143.4399\n",
      "Epoch 4043/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.9305 - val_loss: 169.0458\n",
      "Epoch 4044/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.6348 - val_loss: 132.8352\n",
      "Epoch 4045/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.0523 - val_loss: 136.7560\n",
      "Epoch 4046/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0692 - val_loss: 136.0273\n",
      "Epoch 4047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1622 - val_loss: 144.8198\n",
      "Epoch 4048/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.5876 - val_loss: 143.8502\n",
      "Epoch 4049/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1504 - val_loss: 160.4145\n",
      "Epoch 4050/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.2505 - val_loss: 152.0036\n",
      "Epoch 4051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.6997 - val_loss: 144.3107\n",
      "Epoch 4052/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.8759 - val_loss: 145.7354\n",
      "Epoch 4053/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.3113 - val_loss: 172.5609\n",
      "Epoch 4054/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.2505 - val_loss: 138.1682\n",
      "Epoch 4055/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3555 - val_loss: 152.7000\n",
      "Epoch 4056/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6696 - val_loss: 144.5032\n",
      "Epoch 4057/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.6356 - val_loss: 149.9156\n",
      "Epoch 4058/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.9301 - val_loss: 134.0259\n",
      "Epoch 4059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.9155 - val_loss: 158.3257\n",
      "Epoch 4060/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4618 - val_loss: 168.7017\n",
      "Epoch 4061/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8879 - val_loss: 144.2181\n",
      "Epoch 4062/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4161 - val_loss: 141.2814\n",
      "Epoch 4063/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.1254 - val_loss: 130.2074\n",
      "Epoch 4064/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7492 - val_loss: 161.3291\n",
      "Epoch 4065/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7985 - val_loss: 155.5109\n",
      "Epoch 4066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5142 - val_loss: 167.7966\n",
      "Epoch 4067/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0894 - val_loss: 140.8903\n",
      "Epoch 4068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7616 - val_loss: 143.2073\n",
      "Epoch 4069/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 115.3216 - val_loss: 139.1305\n",
      "Epoch 4070/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 113.8422 - val_loss: 135.2957\n",
      "Epoch 4071/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 115.2419 - val_loss: 138.8501\n",
      "Epoch 4072/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.1330 - val_loss: 134.7579\n",
      "Epoch 4073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0539 - val_loss: 150.1985\n",
      "Epoch 4074/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.9415 - val_loss: 157.3089\n",
      "Epoch 4075/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3088 - val_loss: 135.5306\n",
      "Epoch 4076/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.6116 - val_loss: 263.2472\n",
      "Epoch 4077/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8106 - val_loss: 147.4263\n",
      "Epoch 4078/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5399 - val_loss: 138.2650\n",
      "Epoch 4079/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.2023 - val_loss: 161.8957\n",
      "Epoch 4080/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3697 - val_loss: 155.9205\n",
      "Epoch 4081/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.3143 - val_loss: 140.9665\n",
      "Epoch 4082/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2462 - val_loss: 129.7863\n",
      "Epoch 4083/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3418 - val_loss: 139.5866\n",
      "Epoch 4084/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.6800 - val_loss: 147.1764\n",
      "Epoch 4085/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6409 - val_loss: 135.5395\n",
      "Epoch 4086/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9632 - val_loss: 138.8220\n",
      "Epoch 4087/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7211 - val_loss: 131.6151\n",
      "Epoch 4088/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0837 - val_loss: 137.3293\n",
      "Epoch 4089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.9367 - val_loss: 150.2658\n",
      "Epoch 4090/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.2417 - val_loss: 147.5504\n",
      "Epoch 4091/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1705 - val_loss: 180.7400\n",
      "Epoch 4092/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.2934 - val_loss: 143.4083\n",
      "Epoch 4093/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.1574 - val_loss: 133.0660\n",
      "Epoch 4094/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.0415 - val_loss: 158.7947\n",
      "Epoch 4095/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.1683 - val_loss: 148.8648\n",
      "Epoch 4096/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 113.4990 - val_loss: 189.8184\n",
      "Epoch 4097/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9433 - val_loss: 152.7955\n",
      "Epoch 4098/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.6455 - val_loss: 152.5366\n",
      "Epoch 4099/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.0396 - val_loss: 138.4303\n",
      "Epoch 4100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.0804 - val_loss: 142.9492\n",
      "Epoch 4101/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.8479 - val_loss: 146.0721\n",
      "Epoch 4102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9035 - val_loss: 170.6136\n",
      "Epoch 4103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5828 - val_loss: 131.2644\n",
      "Epoch 4104/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.8849 - val_loss: 135.3435\n",
      "Epoch 4105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.4924 - val_loss: 144.7672\n",
      "Epoch 4106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.4437 - val_loss: 133.4120\n",
      "Epoch 4107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5043 - val_loss: 175.6231\n",
      "Epoch 4108/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.4540 - val_loss: 147.7622\n",
      "Epoch 4109/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5495 - val_loss: 135.6714\n",
      "Epoch 4110/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.8213 - val_loss: 147.1398\n",
      "Epoch 4111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3466 - val_loss: 174.8981\n",
      "Epoch 4112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.8663 - val_loss: 146.0368\n",
      "Epoch 4113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.1725 - val_loss: 191.3594\n",
      "Epoch 4114/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.6152 - val_loss: 137.0985\n",
      "Epoch 4115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.6650 - val_loss: 140.5969\n",
      "Epoch 4116/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.8732 - val_loss: 129.7268\n",
      "Epoch 4117/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.7048 - val_loss: 160.3624\n",
      "Epoch 4118/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0756 - val_loss: 145.4466\n",
      "Epoch 4119/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8356 - val_loss: 137.5515\n",
      "Epoch 4120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7666 - val_loss: 163.5735\n",
      "Epoch 4121/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.5760 - val_loss: 165.1960\n",
      "Epoch 4122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.4241 - val_loss: 144.6118\n",
      "Epoch 4123/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.2852 - val_loss: 145.6210\n",
      "Epoch 4124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7006 - val_loss: 142.3231\n",
      "Epoch 4125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1827 - val_loss: 147.8192\n",
      "Epoch 4126/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.3325 - val_loss: 166.3368\n",
      "Epoch 4127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.6907 - val_loss: 149.0433\n",
      "Epoch 4128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.9605 - val_loss: 156.0163\n",
      "Epoch 4129/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5782 - val_loss: 164.7005\n",
      "Epoch 4130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2650 - val_loss: 165.9139\n",
      "Epoch 4131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.6974 - val_loss: 132.1760\n",
      "Epoch 4132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.7863 - val_loss: 144.5675\n",
      "Epoch 4133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.3238 - val_loss: 151.6838\n",
      "Epoch 4134/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.0116 - val_loss: 145.6545\n",
      "Epoch 4135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0902 - val_loss: 157.2554\n",
      "Epoch 4136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.8827 - val_loss: 135.6194\n",
      "Epoch 4137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.2409 - val_loss: 168.5066\n",
      "Epoch 4138/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.8472 - val_loss: 136.2178\n",
      "Epoch 4139/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 117.195 - 0s 50us/step - loss: 121.9297 - val_loss: 296.4500\n",
      "Epoch 4140/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.7647 - val_loss: 137.9686\n",
      "Epoch 4141/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.8173 - val_loss: 137.5124\n",
      "Epoch 4142/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 110.7210 - val_loss: 137.7069\n",
      "Epoch 4143/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 118.7593 - val_loss: 133.3103\n",
      "Epoch 4144/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 112.7037 - val_loss: 174.9176\n",
      "Epoch 4145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.9340 - val_loss: 154.4562\n",
      "Epoch 4146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.8617 - val_loss: 150.8422\n",
      "Epoch 4147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0435 - val_loss: 138.7525\n",
      "Epoch 4148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0250 - val_loss: 142.0318\n",
      "Epoch 4149/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.2103 - val_loss: 140.9099\n",
      "Epoch 4150/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9064 - val_loss: 179.9824\n",
      "Epoch 4151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4879 - val_loss: 136.4375\n",
      "Epoch 4152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.4462 - val_loss: 137.3948\n",
      "Epoch 4153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5238 - val_loss: 163.0601\n",
      "Epoch 4154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1546 - val_loss: 148.3308\n",
      "Epoch 4155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.8398 - val_loss: 136.8672\n",
      "Epoch 4156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.9060 - val_loss: 136.4825\n",
      "Epoch 4157/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.3215 - val_loss: 136.9195\n",
      "Epoch 4158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.2269 - val_loss: 159.4357\n",
      "Epoch 4159/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 127.0996 - val_loss: 144.6017\n",
      "Epoch 4160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.6441 - val_loss: 139.6445\n",
      "Epoch 4161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3657 - val_loss: 146.6751\n",
      "Epoch 4162/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.1339 - val_loss: 129.6684\n",
      "Epoch 4163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4516 - val_loss: 235.8954\n",
      "Epoch 4164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8469 - val_loss: 139.3845\n",
      "Epoch 4165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6998 - val_loss: 202.8038\n",
      "Epoch 4166/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8343 - val_loss: 182.7430\n",
      "Epoch 4167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8064 - val_loss: 152.8929\n",
      "Epoch 4168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.3680 - val_loss: 128.5548\n",
      "Epoch 4169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.0081 - val_loss: 135.8806\n",
      "Epoch 4170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.3755 - val_loss: 168.0208\n",
      "Epoch 4171/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.8332 - val_loss: 141.1420\n",
      "Epoch 4172/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9461 - val_loss: 193.5896\n",
      "Epoch 4173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0985 - val_loss: 153.4422\n",
      "Epoch 4174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.9329 - val_loss: 156.6035\n",
      "Epoch 4175/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.6443 - val_loss: 139.3782\n",
      "Epoch 4176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5904 - val_loss: 141.9873\n",
      "Epoch 4177/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2171 - val_loss: 158.1441\n",
      "Epoch 4178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.4508 - val_loss: 137.1665\n",
      "Epoch 4179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.6313 - val_loss: 155.2140\n",
      "Epoch 4180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.6556 - val_loss: 153.2464\n",
      "Epoch 4181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.5142 - val_loss: 133.8124\n",
      "Epoch 4182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0348 - val_loss: 214.2457\n",
      "Epoch 4183/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2782 - val_loss: 136.6869\n",
      "Epoch 4184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3297 - val_loss: 136.2208\n",
      "Epoch 4185/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8863 - val_loss: 146.0826\n",
      "Epoch 4186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1811 - val_loss: 143.2243\n",
      "Epoch 4187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0677 - val_loss: 129.6473\n",
      "Epoch 4188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3690 - val_loss: 142.3834\n",
      "Epoch 4189/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.6165 - val_loss: 157.1263\n",
      "Epoch 4190/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.9386 - val_loss: 136.4562\n",
      "Epoch 4191/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0080 - val_loss: 130.8680\n",
      "Epoch 4192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3762 - val_loss: 140.3198\n",
      "Epoch 4193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4476 - val_loss: 187.0775\n",
      "Epoch 4194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0748 - val_loss: 138.5571\n",
      "Epoch 4195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.4036 - val_loss: 187.2579\n",
      "Epoch 4196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.5945 - val_loss: 136.3258\n",
      "Epoch 4197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8666 - val_loss: 164.9349\n",
      "Epoch 4198/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.7979 - val_loss: 168.8071\n",
      "Epoch 4199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.1848 - val_loss: 161.8928\n",
      "Epoch 4200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.8913 - val_loss: 163.2013\n",
      "Epoch 4201/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.5862 - val_loss: 135.8301\n",
      "Epoch 4202/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.5646 - val_loss: 139.3917\n",
      "Epoch 4203/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5291 - val_loss: 147.8117\n",
      "Epoch 4204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5499 - val_loss: 151.9142\n",
      "Epoch 4205/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.2621 - val_loss: 227.4930\n",
      "Epoch 4206/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.7569 - val_loss: 136.7250\n",
      "Epoch 4207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4527 - val_loss: 184.0626\n",
      "Epoch 4208/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9354 - val_loss: 140.6737\n",
      "Epoch 4209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1527 - val_loss: 134.0339\n",
      "Epoch 4210/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5312 - val_loss: 163.4589\n",
      "Epoch 4211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.5912 - val_loss: 140.5872\n",
      "Epoch 4212/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.3811 - val_loss: 133.2423\n",
      "Epoch 4213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4857 - val_loss: 138.5359\n",
      "Epoch 4214/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.4731 - val_loss: 130.6546\n",
      "Epoch 4215/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 123.8609 - val_loss: 148.6303\n",
      "Epoch 4216/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 120.8965 - val_loss: 140.6842\n",
      "Epoch 4217/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 114.8435 - val_loss: 137.5306\n",
      "Epoch 4218/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.1672 - val_loss: 200.0748\n",
      "Epoch 4219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5384 - val_loss: 143.2618\n",
      "Epoch 4220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.9867 - val_loss: 155.7409\n",
      "Epoch 4221/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4665 - val_loss: 145.6753\n",
      "Epoch 4222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8222 - val_loss: 142.7074\n",
      "Epoch 4223/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.2885 - val_loss: 156.5421\n",
      "Epoch 4224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.3600 - val_loss: 140.8990\n",
      "Epoch 4225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.9749 - val_loss: 139.3614\n",
      "Epoch 4226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.5539 - val_loss: 138.0015\n",
      "Epoch 4227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.0193 - val_loss: 255.5972\n",
      "Epoch 4228/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.8902 - val_loss: 140.3079\n",
      "Epoch 4229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6197 - val_loss: 154.8135\n",
      "Epoch 4230/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5401 - val_loss: 179.6086\n",
      "Epoch 4231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.1324 - val_loss: 145.5098\n",
      "Epoch 4232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7029 - val_loss: 143.6467\n",
      "Epoch 4233/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.0919 - val_loss: 149.0270\n",
      "Epoch 4234/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8023 - val_loss: 153.7750\n",
      "Epoch 4235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.2830 - val_loss: 138.7018\n",
      "Epoch 4236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3652 - val_loss: 171.9627\n",
      "Epoch 4237/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.3671 - val_loss: 151.9103\n",
      "Epoch 4238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0107 - val_loss: 154.3412\n",
      "Epoch 4239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9319 - val_loss: 175.3259\n",
      "Epoch 4240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9899 - val_loss: 146.4815\n",
      "Epoch 4241/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.1675 - val_loss: 173.3174\n",
      "Epoch 4242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.0091 - val_loss: 165.8299\n",
      "Epoch 4243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.5841 - val_loss: 139.2155\n",
      "Epoch 4244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5845 - val_loss: 165.2373\n",
      "Epoch 4245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.3947 - val_loss: 221.9804\n",
      "Epoch 4246/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.5384 - val_loss: 138.8458\n",
      "Epoch 4247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8287 - val_loss: 149.4713\n",
      "Epoch 4248/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.3723 - val_loss: 178.3918\n",
      "Epoch 4249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5654 - val_loss: 150.2750\n",
      "Epoch 4250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.1258 - val_loss: 142.1224\n",
      "Epoch 4251/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.2112 - val_loss: 168.5723\n",
      "Epoch 4252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8654 - val_loss: 130.8352\n",
      "Epoch 4253/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6938 - val_loss: 177.1190\n",
      "Epoch 4254/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.4034 - val_loss: 136.0286\n",
      "Epoch 4255/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.2146 - val_loss: 142.1315\n",
      "Epoch 4256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.5038 - val_loss: 136.2115\n",
      "Epoch 4257/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.7611 - val_loss: 163.1067\n",
      "Epoch 4258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.5729 - val_loss: 133.7448\n",
      "Epoch 4259/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0336 - val_loss: 130.1546\n",
      "Epoch 4260/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8526 - val_loss: 134.5400\n",
      "Epoch 4261/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.1821 - val_loss: 152.4252\n",
      "Epoch 4262/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6025 - val_loss: 178.7461\n",
      "Epoch 4263/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.6256 - val_loss: 146.8523\n",
      "Epoch 4264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.1153 - val_loss: 169.2399\n",
      "Epoch 4265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.2349 - val_loss: 150.5502\n",
      "Epoch 4266/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.1133 - val_loss: 151.2320\n",
      "Epoch 4267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1356 - val_loss: 165.6797\n",
      "Epoch 4268/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.4384 - val_loss: 151.5852\n",
      "Epoch 4269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.5572 - val_loss: 134.5544\n",
      "Epoch 4270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3677 - val_loss: 132.8641\n",
      "Epoch 4271/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.0168 - val_loss: 135.5317\n",
      "Epoch 4272/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8944 - val_loss: 155.2586\n",
      "Epoch 4273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.6892 - val_loss: 134.9315\n",
      "Epoch 4274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.8633 - val_loss: 159.5822\n",
      "Epoch 4275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.8493 - val_loss: 138.9334\n",
      "Epoch 4276/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.2990 - val_loss: 146.5246\n",
      "Epoch 4277/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.409 - 0s 50us/step - loss: 129.7691 - val_loss: 139.9866\n",
      "Epoch 4278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1176 - val_loss: 189.2058\n",
      "Epoch 4279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.2894 - val_loss: 164.8008\n",
      "Epoch 4280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.0883 - val_loss: 198.8646\n",
      "Epoch 4281/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.8903 - val_loss: 136.8237\n",
      "Epoch 4282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4158 - val_loss: 131.4587\n",
      "Epoch 4283/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6019 - val_loss: 140.4956\n",
      "Epoch 4284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9203 - val_loss: 147.6910\n",
      "Epoch 4285/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8023 - val_loss: 130.9460\n",
      "Epoch 4286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2017 - val_loss: 196.5608\n",
      "Epoch 4287/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 112.7789 - val_loss: 151.8206\n",
      "Epoch 4288/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 115.6667 - val_loss: 170.5587\n",
      "Epoch 4289/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 133.1121 - val_loss: 157.0505\n",
      "Epoch 4290/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 215.0920 - val_loss: 150.0258\n",
      "Epoch 4291/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2582 - val_loss: 137.5856\n",
      "Epoch 4292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.6446 - val_loss: 161.0549\n",
      "Epoch 4293/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2785 - val_loss: 164.0419\n",
      "Epoch 4294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5098 - val_loss: 142.9701\n",
      "Epoch 4295/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.2439 - val_loss: 134.0888\n",
      "Epoch 4296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0654 - val_loss: 145.7409\n",
      "Epoch 4297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7678 - val_loss: 170.1810\n",
      "Epoch 4298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.3321 - val_loss: 142.6741\n",
      "Epoch 4299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6838 - val_loss: 148.2300\n",
      "Epoch 4300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.6687 - val_loss: 137.5659\n",
      "Epoch 4301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4918 - val_loss: 130.7458\n",
      "Epoch 4302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.6443 - val_loss: 149.7502\n",
      "Epoch 4303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6811 - val_loss: 132.8111\n",
      "Epoch 4304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7883 - val_loss: 139.5253\n",
      "Epoch 4305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3732 - val_loss: 154.0237\n",
      "Epoch 4306/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 119.9934 - val_loss: 138.3812\n",
      "Epoch 4307/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 112.8178 - val_loss: 152.4617\n",
      "Epoch 4308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.1366 - val_loss: 158.8526\n",
      "Epoch 4309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4777 - val_loss: 234.6822\n",
      "Epoch 4310/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5891 - val_loss: 137.6652\n",
      "Epoch 4311/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.4619 - val_loss: 151.6606\n",
      "Epoch 4312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8357 - val_loss: 144.5249\n",
      "Epoch 4313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.6116 - val_loss: 160.3002\n",
      "Epoch 4314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4427 - val_loss: 140.1430\n",
      "Epoch 4315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.9992 - val_loss: 138.8546\n",
      "Epoch 4316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.6461 - val_loss: 146.8815\n",
      "Epoch 4317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.8143 - val_loss: 155.6741\n",
      "Epoch 4318/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.3793 - val_loss: 171.8441\n",
      "Epoch 4319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9214 - val_loss: 145.6512\n",
      "Epoch 4320/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.8037 - val_loss: 142.5114\n",
      "Epoch 4321/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.7813 - val_loss: 150.1294\n",
      "Epoch 4322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4123 - val_loss: 139.3825\n",
      "Epoch 4323/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 112.9299 - val_loss: 142.0628\n",
      "Epoch 4324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3295 - val_loss: 134.7960\n",
      "Epoch 4325/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.4661 - val_loss: 146.5852\n",
      "Epoch 4326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.6371 - val_loss: 165.4958\n",
      "Epoch 4327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.5329 - val_loss: 153.8255\n",
      "Epoch 4328/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.7042 - val_loss: 137.9405\n",
      "Epoch 4329/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.5245 - val_loss: 136.3409\n",
      "Epoch 4330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.8855 - val_loss: 140.1654\n",
      "Epoch 4331/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.2457 - val_loss: 138.1011\n",
      "Epoch 4332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.0549 - val_loss: 211.1209\n",
      "Epoch 4333/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.5752 - val_loss: 164.3538\n",
      "Epoch 4334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.7772 - val_loss: 134.8936\n",
      "Epoch 4335/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.0719 - val_loss: 166.6113\n",
      "Epoch 4336/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.2375 - val_loss: 175.4702\n",
      "Epoch 4337/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.6511 - val_loss: 146.8273\n",
      "Epoch 4338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.6780 - val_loss: 133.3475\n",
      "Epoch 4339/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.9073 - val_loss: 129.6062\n",
      "Epoch 4340/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.7837 - val_loss: 133.0097\n",
      "Epoch 4341/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2288 - val_loss: 133.2896\n",
      "Epoch 4342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.7117 - val_loss: 169.8214\n",
      "Epoch 4343/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.5555 - val_loss: 151.7250\n",
      "Epoch 4344/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8506 - val_loss: 194.8651\n",
      "Epoch 4345/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.3081 - val_loss: 146.1711\n",
      "Epoch 4346/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.0385 - val_loss: 145.2186\n",
      "Epoch 4347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.9316 - val_loss: 140.3486\n",
      "Epoch 4348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.2188 - val_loss: 145.3009\n",
      "Epoch 4349/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.6689 - val_loss: 134.2140\n",
      "Epoch 4350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4602 - val_loss: 135.2750\n",
      "Epoch 4351/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.8835 - val_loss: 172.4564\n",
      "Epoch 4352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.6693 - val_loss: 139.4931\n",
      "Epoch 4353/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.5052 - val_loss: 148.6959\n",
      "Epoch 4354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.8138 - val_loss: 163.5482\n",
      "Epoch 4355/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.8552 - val_loss: 158.5550\n",
      "Epoch 4356/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.0591 - val_loss: 167.7586\n",
      "Epoch 4357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.3064 - val_loss: 146.2397\n",
      "Epoch 4358/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.1761 - val_loss: 141.8295\n",
      "Epoch 4359/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 126.7309 - val_loss: 133.6902\n",
      "Epoch 4360/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 120.7791 - val_loss: 146.8390\n",
      "Epoch 4361/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.8861 - val_loss: 138.8253\n",
      "Epoch 4362/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 118.5476 - val_loss: 136.2180\n",
      "Epoch 4363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4652 - val_loss: 139.9192\n",
      "Epoch 4364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.6727 - val_loss: 149.7377\n",
      "Epoch 4365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.0007 - val_loss: 153.0118\n",
      "Epoch 4366/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9474 - val_loss: 139.6776\n",
      "Epoch 4367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3538 - val_loss: 150.8552\n",
      "Epoch 4368/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.7868 - val_loss: 149.2201\n",
      "Epoch 4369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3847 - val_loss: 141.6365\n",
      "Epoch 4370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.0901 - val_loss: 133.2023\n",
      "Epoch 4371/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.7936 - val_loss: 142.0361\n",
      "Epoch 4372/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.7293 - val_loss: 144.9215\n",
      "Epoch 4373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6484 - val_loss: 154.9752\n",
      "Epoch 4374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.0112 - val_loss: 136.7924\n",
      "Epoch 4375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1959 - val_loss: 191.4215\n",
      "Epoch 4376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6441 - val_loss: 139.3670\n",
      "Epoch 4377/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.1521 - val_loss: 138.1530\n",
      "Epoch 4378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7820 - val_loss: 136.9837\n",
      "Epoch 4379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8520 - val_loss: 138.8317\n",
      "Epoch 4380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.1372 - val_loss: 140.0207\n",
      "Epoch 4381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.2493 - val_loss: 142.1607\n",
      "Epoch 4382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6592 - val_loss: 141.0183\n",
      "Epoch 4383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4872 - val_loss: 140.6602\n",
      "Epoch 4384/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.2029 - val_loss: 157.2419\n",
      "Epoch 4385/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.0808 - val_loss: 143.1251\n",
      "Epoch 4386/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.6771 - val_loss: 129.8503\n",
      "Epoch 4387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6083 - val_loss: 142.1809\n",
      "Epoch 4388/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.9980 - val_loss: 131.4749\n",
      "Epoch 4389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.9980 - val_loss: 158.6189\n",
      "Epoch 4390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.5518 - val_loss: 138.2621\n",
      "Epoch 4391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.8640 - val_loss: 134.7375\n",
      "Epoch 4392/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8257 - val_loss: 141.7594\n",
      "Epoch 4393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.7917 - val_loss: 138.6279\n",
      "Epoch 4394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.2840 - val_loss: 148.0964\n",
      "Epoch 4395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.7330 - val_loss: 155.1102\n",
      "Epoch 4396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.3803 - val_loss: 148.1597\n",
      "Epoch 4397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.8748 - val_loss: 137.6836\n",
      "Epoch 4398/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7061 - val_loss: 164.0642\n",
      "Epoch 4399/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.4161 - val_loss: 145.2621\n",
      "Epoch 4400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2633 - val_loss: 138.3157\n",
      "Epoch 4401/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.4920 - val_loss: 164.4363\n",
      "Epoch 4402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9656 - val_loss: 145.8005\n",
      "Epoch 4403/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.8589 - val_loss: 195.8342\n",
      "Epoch 4404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3739 - val_loss: 164.9351\n",
      "Epoch 4405/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.0190 - val_loss: 145.9134\n",
      "Epoch 4406/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.0429 - val_loss: 142.5892\n",
      "Epoch 4407/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.7904 - val_loss: 184.3296\n",
      "Epoch 4408/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.8006 - val_loss: 140.9707\n",
      "Epoch 4409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.0264 - val_loss: 176.2338\n",
      "Epoch 4410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4878 - val_loss: 185.5620\n",
      "Epoch 4411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.1198 - val_loss: 158.8987\n",
      "Epoch 4412/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1463 - val_loss: 137.1016\n",
      "Epoch 4413/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.2049 - val_loss: 151.1497\n",
      "Epoch 4414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.1400 - val_loss: 157.7131\n",
      "Epoch 4415/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.1286 - val_loss: 149.0896\n",
      "Epoch 4416/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.5478 - val_loss: 139.8203\n",
      "Epoch 4417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.7900 - val_loss: 152.3694\n",
      "Epoch 4418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.2054 - val_loss: 136.1306\n",
      "Epoch 4419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.4041 - val_loss: 148.7025\n",
      "Epoch 4420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.3919 - val_loss: 146.3225\n",
      "Epoch 4421/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 218.5442 - val_loss: 152.7762\n",
      "Epoch 4422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7227 - val_loss: 172.2828\n",
      "Epoch 4423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4023 - val_loss: 149.9341\n",
      "Epoch 4424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4711 - val_loss: 159.8397\n",
      "Epoch 4425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.7690 - val_loss: 148.7807\n",
      "Epoch 4426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.3566 - val_loss: 151.8399\n",
      "Epoch 4427/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9315 - val_loss: 137.9916\n",
      "Epoch 4428/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.3884 - val_loss: 135.9644\n",
      "Epoch 4429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.4631 - val_loss: 195.5041\n",
      "Epoch 4430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.9125 - val_loss: 147.9115\n",
      "Epoch 4431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.0904 - val_loss: 146.6080\n",
      "Epoch 4432/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 123.3357 - val_loss: 185.2035\n",
      "Epoch 4433/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 124.0434 - val_loss: 137.6354\n",
      "Epoch 4434/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 115.3412 - val_loss: 149.7613\n",
      "Epoch 4435/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.8083 - val_loss: 141.9986\n",
      "Epoch 4436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8305 - val_loss: 135.1411\n",
      "Epoch 4437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.1026 - val_loss: 146.5081\n",
      "Epoch 4438/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.9515 - val_loss: 144.8537\n",
      "Epoch 4439/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.8733 - val_loss: 167.5364\n",
      "Epoch 4440/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.1230 - val_loss: 139.9001\n",
      "Epoch 4441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6422 - val_loss: 153.9431\n",
      "Epoch 4442/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7641 - val_loss: 128.7790\n",
      "Epoch 4443/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1253 - val_loss: 131.4478\n",
      "Epoch 4444/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.9692 - val_loss: 139.8992\n",
      "Epoch 4445/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 119.3159 - val_loss: 153.3218\n",
      "Epoch 4446/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.7657 - val_loss: 172.9748\n",
      "Epoch 4447/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5709 - val_loss: 133.5174\n",
      "Epoch 4448/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.9091 - val_loss: 140.8183\n",
      "Epoch 4449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.8926 - val_loss: 142.8422\n",
      "Epoch 4450/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.9278 - val_loss: 146.2462\n",
      "Epoch 4451/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.3186 - val_loss: 169.1994\n",
      "Epoch 4452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.4642 - val_loss: 141.6266\n",
      "Epoch 4453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.3893 - val_loss: 138.3801\n",
      "Epoch 4454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.1535 - val_loss: 143.0392\n",
      "Epoch 4455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8227 - val_loss: 157.8712\n",
      "Epoch 4456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7902 - val_loss: 136.6916\n",
      "Epoch 4457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.2601 - val_loss: 145.2474\n",
      "Epoch 4458/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.9949 - val_loss: 132.8353\n",
      "Epoch 4459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2294 - val_loss: 151.5217\n",
      "Epoch 4460/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.2024 - val_loss: 133.5161\n",
      "Epoch 4461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.9513 - val_loss: 181.1914\n",
      "Epoch 4462/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8633 - val_loss: 170.9110\n",
      "Epoch 4463/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8531 - val_loss: 150.6185\n",
      "Epoch 4464/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8920 - val_loss: 135.2404\n",
      "Epoch 4465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0889 - val_loss: 159.9058\n",
      "Epoch 4466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9207 - val_loss: 173.6659\n",
      "Epoch 4467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.0032 - val_loss: 145.7145\n",
      "Epoch 4468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.5643 - val_loss: 142.1516\n",
      "Epoch 4469/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.2104 - val_loss: 148.7994\n",
      "Epoch 4470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4159 - val_loss: 137.5995\n",
      "Epoch 4471/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.1351 - val_loss: 157.5480\n",
      "Epoch 4472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9819 - val_loss: 170.1567\n",
      "Epoch 4473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3333 - val_loss: 137.7465\n",
      "Epoch 4474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.7762 - val_loss: 138.8338\n",
      "Epoch 4475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6445 - val_loss: 136.1254\n",
      "Epoch 4476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0535 - val_loss: 143.6566\n",
      "Epoch 4477/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.4225 - val_loss: 145.9995\n",
      "Epoch 4478/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3614 - val_loss: 179.5640\n",
      "Epoch 4479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.2080 - val_loss: 137.0071\n",
      "Epoch 4480/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.5196 - val_loss: 147.7428\n",
      "Epoch 4481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.1542 - val_loss: 149.9898\n",
      "Epoch 4482/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.4284 - val_loss: 148.8733\n",
      "Epoch 4483/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9049 - val_loss: 227.4365\n",
      "Epoch 4484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3683 - val_loss: 159.6939\n",
      "Epoch 4485/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3626 - val_loss: 186.8239\n",
      "Epoch 4486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.7709 - val_loss: 137.8911\n",
      "Epoch 4487/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.5391 - val_loss: 166.9209\n",
      "Epoch 4488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4494 - val_loss: 148.9238\n",
      "Epoch 4489/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.2280 - val_loss: 142.0804\n",
      "Epoch 4490/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 116.5058 - val_loss: 145.8725\n",
      "Epoch 4491/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.2855 - val_loss: 140.4650\n",
      "Epoch 4492/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.3012 - val_loss: 141.7963\n",
      "Epoch 4493/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.3717 - val_loss: 151.5622\n",
      "Epoch 4494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.8638 - val_loss: 168.9124\n",
      "Epoch 4495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5800 - val_loss: 151.4986\n",
      "Epoch 4496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.8905 - val_loss: 150.8484\n",
      "Epoch 4497/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4880 - val_loss: 174.4078\n",
      "Epoch 4498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.0508 - val_loss: 145.5424\n",
      "Epoch 4499/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6562 - val_loss: 137.9286\n",
      "Epoch 4500/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.3095 - val_loss: 167.8286\n",
      "Epoch 4501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8445 - val_loss: 134.7663\n",
      "Epoch 4502/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2379 - val_loss: 142.1145\n",
      "Epoch 4503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5002 - val_loss: 170.1692\n",
      "Epoch 4504/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 116.2897 - val_loss: 141.4795\n",
      "Epoch 4505/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 114.2385 - val_loss: 133.7810\n",
      "Epoch 4506/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 111.8221 - val_loss: 140.0723\n",
      "Epoch 4507/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 112.0473 - val_loss: 133.7225\n",
      "Epoch 4508/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8259 - val_loss: 139.8682\n",
      "Epoch 4509/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.1037 - val_loss: 234.7818\n",
      "Epoch 4510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8465 - val_loss: 147.1639\n",
      "Epoch 4511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3127 - val_loss: 135.2780\n",
      "Epoch 4512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.0553 - val_loss: 176.4944\n",
      "Epoch 4513/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.8810 - val_loss: 159.6559\n",
      "Epoch 4514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.5151 - val_loss: 151.1836\n",
      "Epoch 4515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.0646 - val_loss: 158.3787\n",
      "Epoch 4516/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.6544 - val_loss: 157.6521\n",
      "Epoch 4517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.1417 - val_loss: 137.5111\n",
      "Epoch 4518/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.3942 - val_loss: 143.5458\n",
      "Epoch 4519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.4287 - val_loss: 221.4862\n",
      "Epoch 4520/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8874 - val_loss: 150.1156\n",
      "Epoch 4521/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.7046 - val_loss: 162.4403\n",
      "Epoch 4522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.1188 - val_loss: 161.3359\n",
      "Epoch 4523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2917 - val_loss: 132.5793\n",
      "Epoch 4524/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.0025 - val_loss: 137.8769\n",
      "Epoch 4525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.3912 - val_loss: 140.6767\n",
      "Epoch 4526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.0483 - val_loss: 133.8298\n",
      "Epoch 4527/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.4271 - val_loss: 168.9729\n",
      "Epoch 4528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9149 - val_loss: 145.2571\n",
      "Epoch 4529/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6151 - val_loss: 148.7605\n",
      "Epoch 4530/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.1321 - val_loss: 154.7088\n",
      "Epoch 4531/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1871 - val_loss: 142.6221\n",
      "Epoch 4532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.6442 - val_loss: 139.3158\n",
      "Epoch 4533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.9308 - val_loss: 156.7995\n",
      "Epoch 4534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9224 - val_loss: 140.0131\n",
      "Epoch 4535/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9336 - val_loss: 143.0961\n",
      "Epoch 4536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.4796 - val_loss: 164.2940\n",
      "Epoch 4537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.9653 - val_loss: 133.1770\n",
      "Epoch 4538/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.9914 - val_loss: 157.9775\n",
      "Epoch 4539/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.4945 - val_loss: 146.7134\n",
      "Epoch 4540/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6085 - val_loss: 183.0774\n",
      "Epoch 4541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.4651 - val_loss: 153.5173\n",
      "Epoch 4542/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0124 - val_loss: 137.1295\n",
      "Epoch 04542: early stopping\n",
      "Fold score (RMSE): 11.563620567321777\n",
      "Fold #2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 161us/step - loss: 36148.2190 - val_loss: 39545.3841\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 22607.3464 - val_loss: 5074.0658\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 4740.8379 - val_loss: 5074.8832\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 4590.1341 - val_loss: 4995.4495\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 4143.0406 - val_loss: 4667.9331\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 4042.1011 - val_loss: 4321.8067\n",
      "Epoch 7/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 4039.1039 - val_loss: 4412.6256\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3826.8314 - val_loss: 4452.0401\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 3989.2909 - val_loss: 4303.7518\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3770.3858 - val_loss: 3969.9059\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 3617.7653 - val_loss: 3787.9769\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 3485.3059 - val_loss: 3636.6214\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 3446.8688 - val_loss: 3428.6815\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 3355.46 - 0s 51us/step - loss: 3335.3842 - val_loss: 3290.5899\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3155.1325 - val_loss: 3109.1007\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 2933.1725 - val_loss: 2834.0166\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 2455.4831 - val_loss: 2614.1797\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 2202.2650 - val_loss: 1949.8508\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1990.8387 - val_loss: 1742.1706\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 1708.2129 - val_loss: 1626.5550\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1294.6868 - val_loss: 986.5376\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 1261.0561 - val_loss: 848.7503\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 1019.1720 - val_loss: 895.4384\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 969.6809 - val_loss: 730.6063\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 761.1370 - val_loss: 930.7789\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 697.0189 - val_loss: 731.2823\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 662.0828 - val_loss: 447.3087\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 624.6001 - val_loss: 605.8651\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 643.7363 - val_loss: 704.3143\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 611.5144 - val_loss: 525.2397\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 551.2232 - val_loss: 388.3693\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 554.7492 - val_loss: 401.6793\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 508.1220 - val_loss: 394.5959\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 506.9998 - val_loss: 536.7516\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 613.9841 - val_loss: 414.0392\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 596.0414 - val_loss: 1069.1584\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 492.4107 - val_loss: 332.0719\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 458.6137 - val_loss: 413.2710\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 587.8500 - val_loss: 316.9873\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 430.5846 - val_loss: 1138.0981\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 494.0730 - val_loss: 421.0831\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 442.4369 - val_loss: 324.3071\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 388.3032 - val_loss: 384.1789\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 483.0185 - val_loss: 549.9060\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 445.5786 - val_loss: 399.9078\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 409.6174 - val_loss: 339.6476\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 367.5819 - val_loss: 271.3502\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 365.5773 - val_loss: 315.6601\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 454.4805 - val_loss: 546.3382\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 356.7965 - val_loss: 284.2030\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 393.2708 - val_loss: 269.5000\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 359.3621 - val_loss: 358.8130\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 357.9842 - val_loss: 249.1226\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 417.8003 - val_loss: 341.8324\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 299.2827 - val_loss: 252.7788\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 409.3784 - val_loss: 295.8980\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 500.6452 - val_loss: 266.0317\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 340.3525 - val_loss: 269.6851\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 383.8889 - val_loss: 370.3936\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 391.4391 - val_loss: 402.0446\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 398.4613 - val_loss: 245.9704\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 377.6052 - val_loss: 434.0293\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 344.5649 - val_loss: 327.4784\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 306.7398 - val_loss: 446.3337\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 371.2851 - val_loss: 265.4965\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 372.3576 - val_loss: 232.0438\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 378.3926 - val_loss: 304.6682\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 366.4511 - val_loss: 274.0622\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 290.4494 - val_loss: 375.3618\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 313.5588 - val_loss: 250.3605\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 396.3492 - val_loss: 369.0045\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 580.0046 - val_loss: 299.0826\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 272.1739 - val_loss: 358.0446\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 306.0347 - val_loss: 234.0903\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 296.4576 - val_loss: 286.6565\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 360.2979 - val_loss: 236.5061\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 309.6519 - val_loss: 237.1794\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 279.4020 - val_loss: 293.2545\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 342.8047 - val_loss: 264.1413\n",
      "Epoch 80/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 304.3887 - val_loss: 327.2574\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 346.3548 - val_loss: 247.9853\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 341.1075 - val_loss: 278.3087\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 295.7841 - val_loss: 250.3619\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 304.7609 - val_loss: 241.2272\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 278.9889 - val_loss: 226.8227\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 336.2513 - val_loss: 303.9534\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 315.7792 - val_loss: 318.5218\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 316.1010 - val_loss: 346.0505\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 275.2758 - val_loss: 280.3044\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 325.2765 - val_loss: 493.9837\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 315.0401 - val_loss: 216.3997\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 280.7635 - val_loss: 371.5114\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 334.1169 - val_loss: 231.7994\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 260.9197 - val_loss: 244.1714\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 350.8050 - val_loss: 210.9588\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 298.4552 - val_loss: 1249.5017\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 307.7915 - val_loss: 273.5566\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 285.3217 - val_loss: 335.5174\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 395.5555 - val_loss: 438.6333\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 382.4507 - val_loss: 216.6538\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.3768 - val_loss: 342.8924\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 344.3846 - val_loss: 268.9844\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 275.5942 - val_loss: 224.7839\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 301.3459 - val_loss: 373.2645\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 310.9281 - val_loss: 259.9078\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.1973 - val_loss: 284.5133\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 323.1973 - val_loss: 221.4695\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 284.9583 - val_loss: 323.3214\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 255.9963 - val_loss: 239.2830\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 291.8547 - val_loss: 186.3893\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 295.2523 - val_loss: 429.2562\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 239.9937 - val_loss: 262.0246\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 241.0251 - val_loss: 319.7430\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 278.2149 - val_loss: 363.2188\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 264.5444 - val_loss: 669.1190\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 270.7552 - val_loss: 268.4313\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.1581 - val_loss: 254.5980\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 252.4643 - val_loss: 218.7746\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 271.7517 - val_loss: 236.2108\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.9354 - val_loss: 215.3722\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.1071 - val_loss: 237.7527\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.9726 - val_loss: 211.5888\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.2397 - val_loss: 190.9812\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.3148 - val_loss: 189.0024\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 277.0566 - val_loss: 566.6780\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.7869 - val_loss: 228.3174\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 324.0858 - val_loss: 210.1045\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.9270 - val_loss: 208.3580\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 283.1458 - val_loss: 837.7216\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 296.5899 - val_loss: 276.4818\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.0892 - val_loss: 191.1703\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.4548 - val_loss: 204.0844\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 232.0317 - val_loss: 188.6059\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 311.6529 - val_loss: 658.9766\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 282.3577 - val_loss: 296.5623\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.6747 - val_loss: 217.6343\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 296.1666 - val_loss: 190.9433\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.1157 - val_loss: 177.7311\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 275.3850 - val_loss: 181.7802\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 232.1985 - val_loss: 304.5995\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.3415 - val_loss: 183.6021\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.5018 - val_loss: 210.6187\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 252.4884 - val_loss: 370.1241\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.6376 - val_loss: 234.5741\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 235.8912 - val_loss: 175.4821\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 258.7192 - val_loss: 440.6349\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 251.1861 - val_loss: 377.0395\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.7316 - val_loss: 313.9739\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.8389 - val_loss: 201.7287 ETA: 0s - loss: 230\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 266.5799 - val_loss: 212.9343\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 295.2606 - val_loss: 173.0431\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.6226 - val_loss: 174.6570\n",
      "Epoch 153/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.6198 - val_loss: 190.7156\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 217.1275 - val_loss: 332.8385\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 251.6709 - val_loss: 457.3965\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 365.1311 - val_loss: 202.2707\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 220.6828 - val_loss: 211.9964\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 242.5397 - val_loss: 240.3906\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 326.4033 - val_loss: 181.0014\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.8913 - val_loss: 230.4197\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 211.4503 - val_loss: 216.6515\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 263.8432 - val_loss: 193.8186\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 205.9449 - val_loss: 186.5677\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 210.0301 - val_loss: 329.9249\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 213.9430 - val_loss: 190.0023\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.8022 - val_loss: 225.5496\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 263.3791 - val_loss: 352.2004\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 271.4486 - val_loss: 170.6692\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 230.7661 - val_loss: 232.6244\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 235.6541 - val_loss: 253.9178\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 251.4390 - val_loss: 202.5998\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.2772 - val_loss: 1213.3704\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.8045 - val_loss: 241.3306\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 242.8913 - val_loss: 186.1944\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 222.0809 - val_loss: 205.2015\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 198.4367 - val_loss: 180.8352\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 379.6533 - val_loss: 227.1172\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 208.3750 - val_loss: 166.5948\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 252.4707 - val_loss: 368.9795\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 226.8687 - val_loss: 256.5625\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.9077 - val_loss: 221.6157\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.0878 - val_loss: 176.0439\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.9561 - val_loss: 264.9059\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 245.1273 - val_loss: 246.1328\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 247.1427 - val_loss: 254.2164\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.6922 - val_loss: 182.1748\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.3442 - val_loss: 351.1290\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.7720 - val_loss: 245.5421\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 221.0245 - val_loss: 238.0399\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 286.4170 - val_loss: 339.0398\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 336.9256 - val_loss: 416.1906\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.2452 - val_loss: 244.5794\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 244.6708 - val_loss: 233.9635\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 208.5094 - val_loss: 208.6150\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 238.1716 - val_loss: 189.6254\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.5812 - val_loss: 168.1563\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.4921 - val_loss: 172.6924\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.7395 - val_loss: 320.0980\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.3607 - val_loss: 172.4824\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.3616 - val_loss: 190.5176\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 198.8744 - val_loss: 173.0124\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.6422 - val_loss: 293.5497\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 270.3287 - val_loss: 189.7458\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.0841 - val_loss: 196.3087\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.0071 - val_loss: 211.7180\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 177.9161 - val_loss: 162.9820\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.5563 - val_loss: 332.5116\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.6400 - val_loss: 168.2199\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.2238 - val_loss: 200.2514\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 226.5412 - val_loss: 230.2785\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.0298 - val_loss: 278.4448\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 321.1784 - val_loss: 289.8468\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.9439 - val_loss: 170.6220\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 419.6279 - val_loss: 193.4856\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.3120 - val_loss: 169.7623\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.9796 - val_loss: 188.3456\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.9975 - val_loss: 546.3156\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.1310 - val_loss: 163.7013\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.3773 - val_loss: 223.8436\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.8547 - val_loss: 382.1807\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 218.5563 - val_loss: 178.6945\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.9569 - val_loss: 165.6304\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.2680 - val_loss: 205.6940\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.2089 - val_loss: 310.4801\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 261.8393 - val_loss: 231.4235\n",
      "Epoch 226/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.6612 - val_loss: 181.7335\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6648 - val_loss: 162.2681\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.7408 - val_loss: 611.7956\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.4135 - val_loss: 320.3107\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 373.2433 - val_loss: 228.2997\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.5024 - val_loss: 196.6107\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.9825 - val_loss: 179.1724\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.1361 - val_loss: 162.1590\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.7645 - val_loss: 162.0707\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 339.3953 - val_loss: 180.6114\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.0987 - val_loss: 217.5454\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 289.7906 - val_loss: 211.4758\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.9830 - val_loss: 160.3737\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 289.9317 - val_loss: 342.4235\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 258.4825 - val_loss: 207.4655\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 196.7415 - val_loss: 217.0155\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.0198 - val_loss: 240.4215\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 267.3929 - val_loss: 178.6682\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.9185 - val_loss: 230.2959\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.4863 - val_loss: 177.9340\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.8955 - val_loss: 166.1426\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.1074 - val_loss: 282.4371\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 262.1074 - val_loss: 167.1965\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 207.7976 - val_loss: 293.5664\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 197.3434 - val_loss: 303.3123\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 215.2776 - val_loss: 328.5945\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 509.3044 - val_loss: 215.1818\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.4876 - val_loss: 168.7160\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.7618 - val_loss: 173.5751\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.2924 - val_loss: 214.9505\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 193.2370 - val_loss: 279.1546\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.4265 - val_loss: 172.7500\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 284.7851 - val_loss: 243.5344\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 245.1715 - val_loss: 159.4265\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.8168 - val_loss: 188.5676\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 177.3123 - val_loss: 188.0530\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.3600 - val_loss: 187.7961\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 480.6112 - val_loss: 618.8229\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 303.4206 - val_loss: 175.5777\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6271 - val_loss: 163.5250\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.6729 - val_loss: 179.1955\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.8858 - val_loss: 160.5020\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.6663 - val_loss: 177.5569\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.6155 - val_loss: 154.6272\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.1750 - val_loss: 186.5429\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.3826 - val_loss: 223.9027\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.3782 - val_loss: 529.6852- ETA: 0s - loss: 22\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.0338 - val_loss: 224.1834\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 381.3579 - val_loss: 234.1910\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.7267 - val_loss: 160.3540\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.2264 - val_loss: 175.1705\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.5604 - val_loss: 221.8708\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.6744 - val_loss: 429.6042\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 242.1651 - val_loss: 234.0500\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.0745 - val_loss: 217.0630\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.1187 - val_loss: 172.9112\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.4796 - val_loss: 165.2835\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 196.3545 - val_loss: 236.3120\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.3835 - val_loss: 212.4154\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.3042 - val_loss: 250.4764\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.1136 - val_loss: 194.5195\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 270.8236 - val_loss: 176.2491\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.5227 - val_loss: 153.5129\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.5702 - val_loss: 263.3277\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.0017 - val_loss: 155.8668\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 198.4246 - val_loss: 393.0063\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.3654 - val_loss: 296.2286\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 227.1634 - val_loss: 173.7626\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.2152 - val_loss: 172.5213\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.2475 - val_loss: 245.0451\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.0389 - val_loss: 299.0028\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.2291 - val_loss: 167.8839\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.7801 - val_loss: 190.4974\n",
      "Epoch 299/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 328.2781 - val_loss: 189.1218\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.0632 - val_loss: 403.6434\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.9362 - val_loss: 153.9239\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.2021 - val_loss: 223.9465\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 340.3843 - val_loss: 172.1731\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 244.9144 - val_loss: 159.1118\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3804 - val_loss: 184.3408\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3567 - val_loss: 153.9405\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.5380 - val_loss: 216.4635\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7360 - val_loss: 155.8388\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.9385 - val_loss: 151.4725\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.9977 - val_loss: 158.8464\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.7118 - val_loss: 153.0965\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9401 - val_loss: 161.4172\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.8945 - val_loss: 241.6726\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 400.3124 - val_loss: 178.0864\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.8143 - val_loss: 282.6072\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 242.4471 - val_loss: 171.1586\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.7177 - val_loss: 156.2124\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.4202 - val_loss: 230.7023\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.7870 - val_loss: 156.4417\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 275.6678 - val_loss: 160.6530\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.0866 - val_loss: 154.3679\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 180.5410 - val_loss: 163.6999\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 180.0020 - val_loss: 181.4144\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 611.8499 - val_loss: 407.0662\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 355.4684 - val_loss: 189.9459\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 239.7608 - val_loss: 182.0670\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.2423 - val_loss: 196.3049\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.0792 - val_loss: 164.8580\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.1069 - val_loss: 165.5759\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.0978 - val_loss: 301.0935\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 288.5560 - val_loss: 161.7247\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.6800 - val_loss: 180.3547\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 202.4581 - val_loss: 159.3602\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 235.2774 - val_loss: 484.2923\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.4534 - val_loss: 270.1447\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.2081 - val_loss: 177.1818\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.6519 - val_loss: 174.5906\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 206.4347 - val_loss: 185.2129\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 230.8071 - val_loss: 401.1290\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 234.6705 - val_loss: 155.3871\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 623.8253 - val_loss: 196.6883\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.2490 - val_loss: 166.8261\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.2362 - val_loss: 172.8314\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.9441 - val_loss: 224.1773\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.2791 - val_loss: 174.3997\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.0020 - val_loss: 263.7983\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.1703 - val_loss: 261.7830\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.8327 - val_loss: 194.9593\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.6557 - val_loss: 156.8712\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 286.5527 - val_loss: 689.2321\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.5921 - val_loss: 220.7774\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.4130 - val_loss: 189.3755\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0033 - val_loss: 182.6848\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.6594 - val_loss: 161.9233\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.1209 - val_loss: 159.5783\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.7876 - val_loss: 226.1729\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.2739 - val_loss: 214.6057\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.7467 - val_loss: 184.0603\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.1770 - val_loss: 167.6817\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 232.5408 - val_loss: 545.7152\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.1031 - val_loss: 167.1607\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.7983 - val_loss: 262.8942\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.9100 - val_loss: 337.0075\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.1810 - val_loss: 164.7997\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0500 - val_loss: 153.9791\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1939 - val_loss: 307.2254\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.4865 - val_loss: 150.5431\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.2522 - val_loss: 283.4981\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.7197 - val_loss: 244.0790\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1815 - val_loss: 196.3412\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.3633 - val_loss: 185.8643\n",
      "Epoch 372/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.3127 - val_loss: 163.4964\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.6163 - val_loss: 165.7412\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.5450 - val_loss: 177.3603\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.2732 - val_loss: 154.7240\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6212 - val_loss: 146.9730\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.2285 - val_loss: 178.8186\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.5051 - val_loss: 185.1711\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 433.0977 - val_loss: 929.0354\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.0381 - val_loss: 160.9562\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.1411 - val_loss: 162.9343\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.5957 - val_loss: 149.2372\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.2615 - val_loss: 147.3924\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 165.6665 - val_loss: 159.6923\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 180.7015 - val_loss: 186.5848\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.5630 - val_loss: 164.6739\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.5894 - val_loss: 270.7934\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2073 - val_loss: 271.0129\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.9611 - val_loss: 170.6459\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6720 - val_loss: 168.3501\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 550.9325 - val_loss: 260.1505\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 277.8928 - val_loss: 232.9682\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.5829 - val_loss: 169.2131\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 184.7896 - val_loss: 179.0953\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 355.5098 - val_loss: 196.6494\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 198.7276 - val_loss: 161.7475\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 174.1818 - val_loss: 169.5718\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.6544 - val_loss: 157.4252\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0548 - val_loss: 154.7039\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.3237 - val_loss: 157.5637\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.6938 - val_loss: 576.1924\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.9013 - val_loss: 202.0749\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.4781 - val_loss: 170.5945\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6681 - val_loss: 229.5468\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.8578 - val_loss: 168.0951\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.7495 - val_loss: 154.1649\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6510 - val_loss: 243.4665\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.2762 - val_loss: 159.9113\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 309.8490 - val_loss: 668.7372\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 288.0975 - val_loss: 150.2370\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4315 - val_loss: 161.7617\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.6385 - val_loss: 156.1537\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.6252 - val_loss: 186.0638\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3083 - val_loss: 200.1182\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.7326 - val_loss: 153.0152\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.8605 - val_loss: 143.8272\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5624 - val_loss: 185.4397\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.5311 - val_loss: 251.9925\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9486 - val_loss: 156.7292\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.1689 - val_loss: 155.6459\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 447.8999 - val_loss: 161.1674\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0030 - val_loss: 156.3376\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.5530 - val_loss: 152.7543\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.3261 - val_loss: 277.4029\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.6089 - val_loss: 150.8445\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.7627 - val_loss: 169.7318\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4954 - val_loss: 179.5705\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.6468 - val_loss: 240.1779\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.4618 - val_loss: 167.6543\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.1605 - val_loss: 176.0178\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 217.1221 - val_loss: 149.6061\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.9137 - val_loss: 149.3459\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7643 - val_loss: 152.5806\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.0037 - val_loss: 187.0943\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0954 - val_loss: 155.0481\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.1814 - val_loss: 157.4219\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.9019 - val_loss: 171.9926\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.5898 - val_loss: 182.1689\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4269 - val_loss: 152.7122\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.6887 - val_loss: 157.4065\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.2746 - val_loss: 160.6881\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.3698 - val_loss: 150.1434\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.4175 - val_loss: 210.4516\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 165.122 - 0s 51us/step - loss: 165.3569 - val_loss: 148.8422\n",
      "Epoch 445/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4027 - val_loss: 211.3065\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.4444 - val_loss: 152.0819\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.5767 - val_loss: 195.4222\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.5786 - val_loss: 164.6491\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.0963 - val_loss: 246.0658\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.5102 - val_loss: 150.6460\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.8763 - val_loss: 312.1263\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1700 - val_loss: 154.8820\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7713 - val_loss: 174.3701\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 312.1552 - val_loss: 264.6557\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.5906 - val_loss: 200.8936\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 269.5099 - val_loss: 190.2984\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.2991 - val_loss: 171.4826\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 201.2606 - val_loss: 160.5350\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.9085 - val_loss: 174.1870\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.4055 - val_loss: 195.3160\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.9924 - val_loss: 182.0802\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.4748 - val_loss: 157.4239\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.6529 - val_loss: 153.5890\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.9352 - val_loss: 212.5004\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 204.1149 - val_loss: 191.5091\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.4407 - val_loss: 171.4463\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 179.8247 - val_loss: 207.7433\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 181.1587 - val_loss: 170.6962\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 184.3663 - val_loss: 245.7417\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 253.4328 - val_loss: 173.8128\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.2359 - val_loss: 215.7833\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.3845 - val_loss: 165.9223\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3922 - val_loss: 154.1663\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.4130 - val_loss: 153.5787\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2637 - val_loss: 198.0570\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.7136 - val_loss: 257.8967\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.4759 - val_loss: 149.2544\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.7688 - val_loss: 705.1923\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 207.7072 - val_loss: 174.1136\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 180.6056 - val_loss: 221.6349\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 227.1978 - val_loss: 182.7635\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3665 - val_loss: 174.9534\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.5746 - val_loss: 145.7209\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.3023 - val_loss: 261.9901\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.4724 - val_loss: 164.4752\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.6210 - val_loss: 199.6171\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.3568 - val_loss: 154.0792\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.3066 - val_loss: 189.4162\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.2457 - val_loss: 164.6244\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.3281 - val_loss: 151.3718\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 308.0748 - val_loss: 156.7116\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.1478 - val_loss: 167.3353\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2773 - val_loss: 239.1409\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.2341 - val_loss: 171.6889\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7696 - val_loss: 154.0732\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0187 - val_loss: 209.2885\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.6164 - val_loss: 177.1602\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.5247 - val_loss: 176.3109\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.3993 - val_loss: 202.5301\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.9901 - val_loss: 210.7723\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 181.1333 - val_loss: 251.1555\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.1029 - val_loss: 153.3177\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4049 - val_loss: 250.2919\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.2662 - val_loss: 193.4692\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3558 - val_loss: 144.8151\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1042 - val_loss: 151.0768\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.5688 - val_loss: 151.6323\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.1060 - val_loss: 152.5653\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.2744 - val_loss: 231.9836\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.9678 - val_loss: 155.8231\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.2612 - val_loss: 148.4012\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.4253 - val_loss: 159.0559\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.1144 - val_loss: 149.4243\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.0277 - val_loss: 202.8633\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2049 - val_loss: 169.5534\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.0205 - val_loss: 148.2940\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2177 - val_loss: 158.5796\n",
      "Epoch 518/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.4284 - val_loss: 161.4941\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1488 - val_loss: 151.8430\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6090 - val_loss: 174.3993\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.2207 - val_loss: 157.0995\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 310.9093 - val_loss: 174.6221\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.9415 - val_loss: 153.5108\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.5725 - val_loss: 149.6081\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9485 - val_loss: 152.4987\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.5139 - val_loss: 245.1717\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9521 - val_loss: 142.6872\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.9859 - val_loss: 158.0245\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.1061 - val_loss: 141.9331\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8722 - val_loss: 176.3386\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 327.2031 - val_loss: 162.4243\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2641 - val_loss: 220.6704\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.1836 - val_loss: 170.4253\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6563 - val_loss: 153.3023\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7440 - val_loss: 180.6961\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.4587 - val_loss: 158.4231\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2969 - val_loss: 170.1593\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3167 - val_loss: 157.8781\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 156.8907 - val_loss: 144.4367\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 252.9408 - val_loss: 230.1892\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 235.9190 - val_loss: 158.8811\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 150.6172 - val_loss: 175.2020\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3418 - val_loss: 150.1558\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1417 - val_loss: 168.8005\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.9602 - val_loss: 163.8315\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.3845 - val_loss: 141.2209\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.7769 - val_loss: 360.2945\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.6234 - val_loss: 151.7322\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.0460 - val_loss: 142.3019\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0891 - val_loss: 152.9822\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3002 - val_loss: 217.4402\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.9013 - val_loss: 165.9527\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.0211 - val_loss: 149.2945\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5322 - val_loss: 151.2182\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.1443 - val_loss: 247.0976\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.4008 - val_loss: 268.8292\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.2308 - val_loss: 147.5954\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2132 - val_loss: 151.3828\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.6332 - val_loss: 156.3838\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 192.7394 - val_loss: 181.2420\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 139.8693 - val_loss: 146.9108\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 355.3393 - val_loss: 203.8802\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.4092 - val_loss: 149.3644\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5067 - val_loss: 150.4740\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.9535 - val_loss: 354.8779\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.0657 - val_loss: 189.1869\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0850 - val_loss: 200.3739\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 170.0373 - val_loss: 186.3435\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.9378 - val_loss: 144.5673\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3251 - val_loss: 146.2402\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.1994 - val_loss: 206.1731\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.0851 - val_loss: 265.1177\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.8179 - val_loss: 163.9609\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 229.8910 - val_loss: 163.8944\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.9463 - val_loss: 159.7329\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1235 - val_loss: 173.4207\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8356 - val_loss: 175.9807\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.2539 - val_loss: 161.5372\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8017 - val_loss: 195.7077\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8214 - val_loss: 160.9033\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 411.8651 - val_loss: 312.1841\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.2842 - val_loss: 169.3076\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3633 - val_loss: 153.5174\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2474 - val_loss: 148.8203\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 229.6301 - val_loss: 200.9491\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.3704 - val_loss: 155.0372\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.2630 - val_loss: 151.7005\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.9023 - val_loss: 406.2661\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.7560 - val_loss: 215.9135\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.1308 - val_loss: 302.2232\n",
      "Epoch 591/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7074 - val_loss: 142.9410\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.0691 - val_loss: 164.6749\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.0757 - val_loss: 142.8364\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.7483 - val_loss: 147.8457\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.7465 - val_loss: 149.4941\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6350 - val_loss: 141.7675\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.7051 - val_loss: 171.1523\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.1828 - val_loss: 146.9513\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8950 - val_loss: 146.7004\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1283 - val_loss: 439.6736\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 493.5916 - val_loss: 266.8168\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 272.6928 - val_loss: 201.5161\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.4515 - val_loss: 165.4749\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.0117 - val_loss: 404.4275\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 217.7875 - val_loss: 201.0713\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.6700 - val_loss: 168.4949\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.6751 - val_loss: 163.0613\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.9418 - val_loss: 331.2827\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.2350 - val_loss: 160.7226\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.1122 - val_loss: 172.7240\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 177.4370 - val_loss: 161.4443\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 187.2431 - val_loss: 187.5320\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 165.1205 - val_loss: 163.7847\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.5859 - val_loss: 159.7078\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.4025 - val_loss: 161.8021\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 151.5955 - val_loss: 180.6694\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.5481 - val_loss: 195.2993\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.6578 - val_loss: 149.2757\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.6496 - val_loss: 183.4113\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.8860 - val_loss: 201.3076\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.0912 - val_loss: 178.8004\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.1086 - val_loss: 216.4129\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.4429 - val_loss: 149.3140\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.8705 - val_loss: 309.4350\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.2474 - val_loss: 363.8318\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.2718 - val_loss: 200.3549\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.5722 - val_loss: 155.7041\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.5177 - val_loss: 149.5000\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.1676 - val_loss: 160.7462\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8801 - val_loss: 210.6193\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7916 - val_loss: 181.3967\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.1394 - val_loss: 157.9658\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3245 - val_loss: 205.4301\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 173.8622 - val_loss: 198.5390\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.5612 - val_loss: 162.6002\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7699 - val_loss: 158.2660\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.2896 - val_loss: 167.4318\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.9095 - val_loss: 142.5137\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 230.3598 - val_loss: 180.2990\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.3780 - val_loss: 150.2447\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4169 - val_loss: 208.1360\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3104 - val_loss: 294.3476\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7623 - val_loss: 284.7802\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 248.3191 - val_loss: 165.8438\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0010 - val_loss: 168.6575\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.8112 - val_loss: 164.5721\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9942 - val_loss: 150.5246\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.1602 - val_loss: 199.2435\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1211 - val_loss: 179.5187\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 189.0868 - val_loss: 164.3726\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.1939 - val_loss: 144.2966\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.2022 - val_loss: 157.5842\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.3395 - val_loss: 170.5628\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.4246 - val_loss: 144.1628\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.5283 - val_loss: 159.2013\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1745 - val_loss: 150.1721\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.0689 - val_loss: 145.9523\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.7134 - val_loss: 247.0277\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4264 - val_loss: 160.6832\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.5764 - val_loss: 152.6472\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6572 - val_loss: 141.1924\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 264.2122 - val_loss: 227.0309\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.9038 - val_loss: 167.9318\n",
      "Epoch 664/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.1113 - val_loss: 204.6846\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.5102 - val_loss: 316.6467\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5519 - val_loss: 147.6634\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1388 - val_loss: 151.8714\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8334 - val_loss: 163.5081\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5778 - val_loss: 177.8456\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.5719 - val_loss: 146.6371\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.9724 - val_loss: 151.9676\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.6341 - val_loss: 159.5797\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1074 - val_loss: 154.1666\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.5663 - val_loss: 190.9634\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 203.6418 - val_loss: 153.0567\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.0698 - val_loss: 155.8532\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5334 - val_loss: 146.6185\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8397 - val_loss: 163.1327\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.5172 - val_loss: 160.3866\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 152.606 - 0s 51us/step - loss: 151.6585 - val_loss: 156.8073\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 265.3559 - val_loss: 205.1159\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.5463 - val_loss: 150.8124\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 160.8492 - val_loss: 159.2612\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 177.4421 - val_loss: 193.9734\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 205.6968 - val_loss: 210.7089\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 147.5738 - val_loss: 159.5066\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.1507 - val_loss: 159.6901\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.9704 - val_loss: 145.0396\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2281 - val_loss: 151.4142\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 196.8719 - val_loss: 166.7336\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 224.0509 - val_loss: 151.0119\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1894 - val_loss: 223.5667\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.4596 - val_loss: 183.3059\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5727 - val_loss: 146.0493\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.9771 - val_loss: 151.0971\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.2250 - val_loss: 247.4430\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.5046 - val_loss: 437.9793\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5272 - val_loss: 188.1730\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.5223 - val_loss: 152.4314\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9519 - val_loss: 158.8658\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 274.8613 - val_loss: 182.8110\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2642 - val_loss: 158.7558\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7928 - val_loss: 152.9948\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.6909 - val_loss: 158.3702\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7353 - val_loss: 237.2813\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6320 - val_loss: 200.1525\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.5021 - val_loss: 168.7965\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.6404 - val_loss: 155.7630\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 295.5512 - val_loss: 181.6943\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.5997 - val_loss: 151.9933\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.9218 - val_loss: 185.8578\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.5767 - val_loss: 141.2303\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.8185 - val_loss: 139.9196\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6392 - val_loss: 264.1742\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.2274 - val_loss: 146.9675\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 141.929 - 0s 51us/step - loss: 143.3814 - val_loss: 380.0761\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2477 - val_loss: 177.8579\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.5001 - val_loss: 163.9667\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.7140 - val_loss: 163.2513\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7268 - val_loss: 158.5304\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.4219 - val_loss: 220.2372\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.1338 - val_loss: 164.6243\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 306.8102 - val_loss: 265.6497\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9572 - val_loss: 144.2863\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5449 - val_loss: 149.5864\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7576 - val_loss: 148.3986\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5223 - val_loss: 143.8348\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1028 - val_loss: 149.2791\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6283 - val_loss: 144.1007\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.3807 - val_loss: 183.2631\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.8394 - val_loss: 143.7021\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1413 - val_loss: 164.5571\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5664 - val_loss: 138.4210\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.3994 - val_loss: 144.2568\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.3224 - val_loss: 141.0787\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.1196 - val_loss: 305.3402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6473 - val_loss: 148.4997\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.3427 - val_loss: 153.5288\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5653 - val_loss: 146.1559\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4815 - val_loss: 146.3626\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.9003 - val_loss: 217.9451\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4559 - val_loss: 137.3112\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.3891 - val_loss: 211.4730\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6350 - val_loss: 169.3561\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.4392 - val_loss: 146.4699\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.0976 - val_loss: 199.7478\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9699 - val_loss: 137.3800\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.7576 - val_loss: 189.6773\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2911 - val_loss: 278.5495\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.1398 - val_loss: 141.3371\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.1610 - val_loss: 142.1584\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9364 - val_loss: 163.1806\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5437 - val_loss: 148.4206\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7231 - val_loss: 190.5706\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2296 - val_loss: 156.3392\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 138.9863 - val_loss: 139.9916\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.0072 - val_loss: 158.7983\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 207.3716 - val_loss: 143.8062\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4289 - val_loss: 148.2128\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4267 - val_loss: 155.7137\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.7069 - val_loss: 154.4053\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.9621 - val_loss: 182.9037\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9492 - val_loss: 141.0050\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0833 - val_loss: 142.4771\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4060 - val_loss: 168.6441\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.3207 - val_loss: 144.3620\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8728 - val_loss: 152.6814\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7330 - val_loss: 164.2965\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.1429 - val_loss: 154.0908\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.6011 - val_loss: 180.9641\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.1799 - val_loss: 211.4393\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.1610 - val_loss: 150.7610\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6554 - val_loss: 183.9757\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3430 - val_loss: 307.5210\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.4291 - val_loss: 150.9298\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5385 - val_loss: 142.0961\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.7610 - val_loss: 140.5824\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1441 - val_loss: 176.0243\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9421 - val_loss: 185.9875\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.4396 - val_loss: 184.7634\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7494 - val_loss: 195.7003\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.5494 - val_loss: 153.8480\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8860 - val_loss: 144.7423\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.8865 - val_loss: 181.6913\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4060 - val_loss: 280.3837\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.0867 - val_loss: 188.2925\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9426 - val_loss: 143.8156\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1432 - val_loss: 165.6051\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8658 - val_loss: 145.2147\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1528 - val_loss: 543.1837\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8752 - val_loss: 144.3841\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.7181 - val_loss: 180.7687\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.9369 - val_loss: 144.4643\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8706 - val_loss: 149.9359\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.3797 - val_loss: 148.2657\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8074 - val_loss: 221.8478\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.6531 - val_loss: 152.3816\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3537 - val_loss: 141.8914\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.6989 - val_loss: 139.6374\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1973 - val_loss: 139.1528\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9307 - val_loss: 152.6926\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5815 - val_loss: 148.6833\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2036 - val_loss: 183.0860\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2979 - val_loss: 201.6261\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5954 - val_loss: 146.3361\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2056 - val_loss: 233.0469\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.5189 - val_loss: 144.3916\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.8000 - val_loss: 175.0108\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.4317 - val_loss: 159.9329\n",
      "Epoch 810/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.9169 - val_loss: 169.8104\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4619 - val_loss: 172.5855\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.6736 - val_loss: 140.3216\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0455 - val_loss: 151.5206\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 293.3327 - val_loss: 219.3173\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8278 - val_loss: 138.3850\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4189 - val_loss: 136.4139\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3712 - val_loss: 190.4202\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7081 - val_loss: 141.2860\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.0930 - val_loss: 140.3564\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.7323 - val_loss: 224.4106\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5501 - val_loss: 167.1470\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8796 - val_loss: 139.6184\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3457 - val_loss: 170.0785\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 185.8040 - val_loss: 168.9412\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4882 - val_loss: 200.1546\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.5914 - val_loss: 137.1197\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0108 - val_loss: 267.3156\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6648 - val_loss: 160.7814\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.5680 - val_loss: 155.4871\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 199.8109 - val_loss: 263.6636\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.8785 - val_loss: 178.1795\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.8221 - val_loss: 147.8358\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.4535 - val_loss: 150.1989\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.8084 - val_loss: 175.3854\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2885 - val_loss: 138.7296\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8010 - val_loss: 168.1447\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1999 - val_loss: 142.4139\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.1182 - val_loss: 153.5642\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3564 - val_loss: 138.0395\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 143.4922 - val_loss: 143.9586\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.7655 - val_loss: 151.8808\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 165.8890 - val_loss: 140.9124\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.6949 - val_loss: 144.8978\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.9874 - val_loss: 150.1887\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9379 - val_loss: 149.0417\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.8271 - val_loss: 203.5519\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1722 - val_loss: 446.7821\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2694 - val_loss: 145.0455\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.2090 - val_loss: 161.1462\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.9990 - val_loss: 160.1629\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.2723 - val_loss: 134.1415\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7507 - val_loss: 171.3087\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6421 - val_loss: 138.9838\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6797 - val_loss: 149.7889\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.4589 - val_loss: 177.1550\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6446 - val_loss: 154.5307\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.0058 - val_loss: 144.7257\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7715 - val_loss: 177.2569\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5554 - val_loss: 155.3643\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.1331 - val_loss: 272.8296\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4501 - val_loss: 153.5431\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2523 - val_loss: 160.9029\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.3574 - val_loss: 143.3100\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4667 - val_loss: 165.2876\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4546 - val_loss: 163.5455\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6607 - val_loss: 140.5788\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8085 - val_loss: 235.8083\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.4089 - val_loss: 244.1291\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4153 - val_loss: 153.8943\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8614 - val_loss: 172.0391\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9030 - val_loss: 141.9774\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.5260 - val_loss: 181.7481\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1749 - val_loss: 174.6327\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0423 - val_loss: 137.2211\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8857 - val_loss: 163.2434\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7687 - val_loss: 148.6932\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4924 - val_loss: 145.5982\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.9279 - val_loss: 157.2314\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.3582 - val_loss: 145.8711\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.2774 - val_loss: 161.0108\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4396 - val_loss: 176.1088\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2905 - val_loss: 148.1646\n",
      "Epoch 883/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.3635 - val_loss: 145.3470\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5297 - val_loss: 211.3406\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0209 - val_loss: 177.4028\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7240 - val_loss: 146.7084\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3069 - val_loss: 153.1292\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5610 - val_loss: 158.2375\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5118 - val_loss: 164.5302\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0635 - val_loss: 188.2500\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5243 - val_loss: 229.4304\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.7356 - val_loss: 145.7448\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7722 - val_loss: 148.1255\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3418 - val_loss: 168.8049\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.2038 - val_loss: 165.4215\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8707 - val_loss: 142.2198\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.0880 - val_loss: 137.5538\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8817 - val_loss: 138.3970\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.2969 - val_loss: 244.4142\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9576 - val_loss: 151.7882\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2610 - val_loss: 145.7879\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 168.1594 - val_loss: 216.3634\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 137.6596 - val_loss: 177.7104\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 144.2907 - val_loss: 137.8073\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.8172 - val_loss: 141.7193\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.6967 - val_loss: 170.5164\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7098 - val_loss: 145.8960\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.2426 - val_loss: 181.8530\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 284.8903 - val_loss: 181.6235\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5319 - val_loss: 165.6748\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.1232 - val_loss: 161.4360\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.4270 - val_loss: 155.5377\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.5000 - val_loss: 150.3555\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9467 - val_loss: 185.1169\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3931 - val_loss: 156.0943\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1081 - val_loss: 143.4450\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.4632 - val_loss: 161.5269\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.9975 - val_loss: 193.1322\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7378 - val_loss: 172.0722\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1822 - val_loss: 163.7657\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.1359 - val_loss: 174.8305\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2355 - val_loss: 140.6196\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2589 - val_loss: 147.7879\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.6394 - val_loss: 198.5761\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3422 - val_loss: 159.0453\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4468 - val_loss: 144.2008\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4411 - val_loss: 139.9615\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3231 - val_loss: 182.5324\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 143.065 - 0s 50us/step - loss: 142.9259 - val_loss: 156.2272\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4853 - val_loss: 207.4180\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6693 - val_loss: 148.9149\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6891 - val_loss: 154.0806\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.7711 - val_loss: 211.8789\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1934 - val_loss: 140.3361\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.8955 - val_loss: 139.5841\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.3501 - val_loss: 331.5866\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.5495 - val_loss: 142.9905\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5045 - val_loss: 158.0897\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7420 - val_loss: 140.7860\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.5557 - val_loss: 155.5797\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4561 - val_loss: 221.0797\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0041 - val_loss: 148.4745\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5585 - val_loss: 159.4299\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.7143 - val_loss: 173.8905\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8439 - val_loss: 158.9812\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0086 - val_loss: 152.2316\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6211 - val_loss: 138.5010\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.7675 - val_loss: 139.8253\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4259 - val_loss: 156.3962\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5017 - val_loss: 156.7505\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.5674 - val_loss: 222.1176\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3270 - val_loss: 151.8690\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.6868 - val_loss: 142.8968\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.6511 - val_loss: 137.8464\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.1160 - val_loss: 144.9041\n",
      "Epoch 956/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.5419 - val_loss: 151.3744\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.6279 - val_loss: 141.0913\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6265 - val_loss: 139.7997\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3571 - val_loss: 221.3957\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.2936 - val_loss: 145.1063\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6636 - val_loss: 135.3926\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.7593 - val_loss: 191.7094\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.1199 - val_loss: 240.9627\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.1298 - val_loss: 144.7808\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3778 - val_loss: 143.6675\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.6740 - val_loss: 170.5008\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 133.857 - 0s 51us/step - loss: 134.1676 - val_loss: 138.3229\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.5574 - val_loss: 194.5720\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 267.2571 - val_loss: 149.9918\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9730 - val_loss: 148.1534\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.4444 - val_loss: 145.9976\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.6750 - val_loss: 170.5253\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6921 - val_loss: 146.6527\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9567 - val_loss: 170.1248\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.1002 - val_loss: 148.6602\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 147.3889 - val_loss: 144.3583\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.7645 - val_loss: 187.5583\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.2729 - val_loss: 159.3511\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.0200 - val_loss: 149.6723\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0920 - val_loss: 154.6752\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8762 - val_loss: 178.8528\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.5242 - val_loss: 245.3706\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.7697 - val_loss: 195.2548\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6783 - val_loss: 152.8841\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 162.4597 - val_loss: 164.4225\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0965 - val_loss: 142.4149\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0126 - val_loss: 169.0477\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8760 - val_loss: 175.7902\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.4845 - val_loss: 148.0146\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5224 - val_loss: 141.4272\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.1522 - val_loss: 167.6955\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3959 - val_loss: 179.6523\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.5292 - val_loss: 140.7683\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.9272 - val_loss: 187.4065\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.9094 - val_loss: 153.4759\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6742 - val_loss: 164.6796\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1503 - val_loss: 153.6572\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5318 - val_loss: 143.8145\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.6327 - val_loss: 155.0225\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5785 - val_loss: 243.4309\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.6762 - val_loss: 144.5170\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.7149 - val_loss: 137.0950\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.2704 - val_loss: 211.9963\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7072 - val_loss: 173.1276\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7729 - val_loss: 193.8742\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.3438 - val_loss: 170.0807\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1615 - val_loss: 164.8697\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1547 - val_loss: 139.4158\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8174 - val_loss: 150.7194\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.7771 - val_loss: 141.7022\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8994 - val_loss: 141.3417\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.9591 - val_loss: 153.9061\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.2811 - val_loss: 155.7932\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8161 - val_loss: 151.5276\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4370 - val_loss: 163.4635\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 154.967 - 0s 51us/step - loss: 154.3155 - val_loss: 243.2487\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7956 - val_loss: 189.3586\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9694 - val_loss: 146.1192\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.8884 - val_loss: 211.0622\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.9802 - val_loss: 163.8969\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9094 - val_loss: 164.2307\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2659 - val_loss: 144.4060\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.0216 - val_loss: 138.8626\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 132.9387 - val_loss: 163.5513\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.8679 - val_loss: 157.7987\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.1763 - val_loss: 147.6240\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.6634 - val_loss: 156.1308\n",
      "Epoch 1028/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.0083 - val_loss: 144.5557\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7399 - val_loss: 133.9115\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0541 - val_loss: 162.6360\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.6859 - val_loss: 180.6542\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6227 - val_loss: 272.9674\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.5979 - val_loss: 143.9790\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3209 - val_loss: 144.5486\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.1241 - val_loss: 179.9929\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3776 - val_loss: 142.5424\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3833 - val_loss: 140.5560\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0171 - val_loss: 153.5271\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8292 - val_loss: 181.8246\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.0048 - val_loss: 153.7892\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0144 - val_loss: 207.0423\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6977 - val_loss: 139.3600\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7523 - val_loss: 142.3153\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.7476 - val_loss: 162.2488\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.0967 - val_loss: 135.7411\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4297 - val_loss: 206.7502\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3116 - val_loss: 141.9798\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.5242 - val_loss: 140.3591\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 134.4694 - val_loss: 146.9727\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.3520 - val_loss: 136.6361\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.8235 - val_loss: 135.1753\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1355 - val_loss: 148.3696\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.1566 - val_loss: 144.3608\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3353 - val_loss: 144.0024\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7204 - val_loss: 214.0020\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1141 - val_loss: 156.3362\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1610 - val_loss: 152.2076\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.5439 - val_loss: 144.9316\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1295 - val_loss: 141.9970\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.0707 - val_loss: 138.7037\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0712 - val_loss: 144.7931\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1532 - val_loss: 148.4475\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 290.6431 - val_loss: 166.9297\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 280.9816 - val_loss: 195.9741\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7646 - val_loss: 147.7544\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4363 - val_loss: 145.8171\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3415 - val_loss: 147.9725\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.5910 - val_loss: 146.0891\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.6929 - val_loss: 162.6950\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6450 - val_loss: 190.7269\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7744 - val_loss: 153.9257\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7260 - val_loss: 149.8298\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.5449 - val_loss: 180.1791\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8673 - val_loss: 183.4105\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.5267 - val_loss: 142.2862\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.5362 - val_loss: 145.4671\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.5576 - val_loss: 147.1720\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1336 - val_loss: 145.8932\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.7725 - val_loss: 162.7825\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.5522 - val_loss: 154.2801\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.6901 - val_loss: 184.1155\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7816 - val_loss: 276.2741\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.2839 - val_loss: 209.3943\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.1845 - val_loss: 145.7346\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.5356 - val_loss: 157.5079\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3995 - val_loss: 151.8606\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9288 - val_loss: 140.7045\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3710 - val_loss: 140.6546\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.0930 - val_loss: 262.7637\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2586 - val_loss: 159.1417\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.7479 - val_loss: 151.0708\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.3792 - val_loss: 378.5763\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6495 - val_loss: 144.3418\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.9037 - val_loss: 151.3165\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.2372 - val_loss: 147.8533\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0695 - val_loss: 140.3189\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3205 - val_loss: 150.9918\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.5704 - val_loss: 223.6515\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.7251 - val_loss: 146.0243\n",
      "Epoch 1100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3368 - val_loss: 135.7481\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3479 - val_loss: 148.1142\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 133.0343 - val_loss: 136.6820\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7756 - val_loss: 136.6843\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4829 - val_loss: 193.6350\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.2905 - val_loss: 149.5456\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.4730 - val_loss: 227.7781\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5536 - val_loss: 201.9101\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 235.9390 - val_loss: 205.2973\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.9329 - val_loss: 155.6735\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8490 - val_loss: 294.1613\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.1446 - val_loss: 152.3292\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1461 - val_loss: 141.8773\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.1630 - val_loss: 136.6604\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0011 - val_loss: 162.2035\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9577 - val_loss: 175.3437\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1357 - val_loss: 186.9888\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.7055 - val_loss: 139.0624\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.3851 - val_loss: 226.9205\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8670 - val_loss: 591.8811\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.2356 - val_loss: 154.7810\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 148.9493 - val_loss: 204.9763\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 155.1826 - val_loss: 192.8309\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 145.5684 - val_loss: 250.1432\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.0063 - val_loss: 136.1549\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5752 - val_loss: 156.2948\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 328.2934 - val_loss: 389.4610\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 245.7140 - val_loss: 189.9327\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.0840 - val_loss: 161.7851\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.1854 - val_loss: 212.2530\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.0553 - val_loss: 163.9758\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.7692 - val_loss: 299.1271\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.9580 - val_loss: 148.0799\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8232 - val_loss: 142.5216\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5559 - val_loss: 160.2312\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.6233 - val_loss: 209.6976\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.0301 - val_loss: 180.3299\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.6390 - val_loss: 145.6089\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7423 - val_loss: 146.5806\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.9946 - val_loss: 144.4831\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.5018 - val_loss: 154.0805\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1102 - val_loss: 165.3380\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3522 - val_loss: 140.2183\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5081 - val_loss: 162.7339\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4915 - val_loss: 213.3005\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3033 - val_loss: 157.7122\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.3549 - val_loss: 142.7796\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.3341 - val_loss: 155.1802\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5373 - val_loss: 160.3522\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.6258 - val_loss: 166.9796\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5024 - val_loss: 161.1075\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9066 - val_loss: 221.4015\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.0195 - val_loss: 659.6038\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5009 - val_loss: 153.8242\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.9420 - val_loss: 155.9526\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.6222 - val_loss: 148.7426\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2645 - val_loss: 207.6608\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.9530 - val_loss: 161.4577\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8224 - val_loss: 156.6262\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.3979 - val_loss: 147.9551\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.6508 - val_loss: 145.7438\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9777 - val_loss: 137.7816\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.0399 - val_loss: 187.6693\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.5378 - val_loss: 144.5230\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7420 - val_loss: 175.0810\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.6485 - val_loss: 309.6494\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1260 - val_loss: 138.6627\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4705 - val_loss: 144.6050\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2733 - val_loss: 141.5592\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1974 - val_loss: 143.3094\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.9221 - val_loss: 166.3321\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0428 - val_loss: 135.6286\n",
      "Epoch 1172/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.7814 - val_loss: 146.4979\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4170 - val_loss: 139.3200\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6953 - val_loss: 154.4118\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4877 - val_loss: 156.8715\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.4242 - val_loss: 292.1561\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.5483 - val_loss: 196.7761\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.1037 - val_loss: 146.8960\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8647 - val_loss: 250.4849\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3001 - val_loss: 162.5726\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8042 - val_loss: 155.5999\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6790 - val_loss: 137.1317\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8721 - val_loss: 137.2809\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.0236 - val_loss: 2452.7210\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 281.4951 - val_loss: 162.2455\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7953 - val_loss: 157.3963\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4081 - val_loss: 141.8492\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.1013 - val_loss: 154.9654\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.6853 - val_loss: 165.5088\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.6329 - val_loss: 240.7927\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9057 - val_loss: 180.3236\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.1757 - val_loss: 139.6773\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.2075 - val_loss: 221.7779\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 177.7426 - val_loss: 150.6313\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 169.0599 - val_loss: 147.3904\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 139.8737 - val_loss: 148.1200\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8249 - val_loss: 144.3006\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.8776 - val_loss: 147.2982\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0283 - val_loss: 248.3689\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.7499 - val_loss: 148.2555\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5619 - val_loss: 237.7009\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.3569 - val_loss: 230.3741\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5419 - val_loss: 143.4358\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.1882 - val_loss: 209.1229\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.2291 - val_loss: 358.0149\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5990 - val_loss: 184.6193\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.2597 - val_loss: 144.6484\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.4047 - val_loss: 149.2368\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.4346 - val_loss: 140.8462\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0802 - val_loss: 137.0274\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.6345 - val_loss: 166.7507\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.8989 - val_loss: 157.0775\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9584 - val_loss: 146.4332\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1871 - val_loss: 153.5016\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.7590 - val_loss: 206.4598\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.8881 - val_loss: 136.0613\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2721 - val_loss: 142.3659\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1663 - val_loss: 147.9996\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 224.3150 - val_loss: 189.8489\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.2434 - val_loss: 148.5828\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.1492 - val_loss: 142.3802\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 128.3513 - val_loss: 160.4311\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2899 - val_loss: 149.1344\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.5585 - val_loss: 337.2914\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1993 - val_loss: 142.7379\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.9835 - val_loss: 142.0754\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.5380 - val_loss: 148.7900\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.1781 - val_loss: 144.1766\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.2039 - val_loss: 137.4267\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9362 - val_loss: 139.5634\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.4464 - val_loss: 265.2722\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5823 - val_loss: 135.4493\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3369 - val_loss: 150.0565\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.5540 - val_loss: 137.8268\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.4949 - val_loss: 148.2587\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.8924 - val_loss: 143.1879\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7304 - val_loss: 162.0680\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0432 - val_loss: 153.9642\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0365 - val_loss: 153.3784\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1684 - val_loss: 169.8585\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.8776 - val_loss: 207.1528\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.4180 - val_loss: 158.6797\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.0322 - val_loss: 167.7160\n",
      "Epoch 1244/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/step - loss: 165.0761 - val_loss: 144.7250\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.6268 - val_loss: 161.3498\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.0294 - val_loss: 153.6904\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5270 - val_loss: 171.4132\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.7714 - val_loss: 174.9497\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2744 - val_loss: 220.5534\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.3914 - val_loss: 277.0364\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 181.1763 - val_loss: 142.4727\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.0277 - val_loss: 217.9644\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6485 - val_loss: 158.9803\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 137.1691 - val_loss: 151.2375\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 152.2206 - val_loss: 233.1961\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6641 - val_loss: 161.2061\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.9446 - val_loss: 137.0887\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3339 - val_loss: 137.7504\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.5774 - val_loss: 164.2645\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.8547 - val_loss: 172.2584\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9083 - val_loss: 135.9008\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7457 - val_loss: 138.2239\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5164 - val_loss: 154.1524\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8635 - val_loss: 219.0487\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 151.0910 - val_loss: 135.8539\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 279.5516 - val_loss: 362.1355\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 254.6217 - val_loss: 204.2790\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 172.4647 - val_loss: 183.9386\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.4787 - val_loss: 149.4954\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0877 - val_loss: 145.0350\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.8633 - val_loss: 165.8526\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4302 - val_loss: 154.2959\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4686 - val_loss: 165.2308\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.8617 - val_loss: 141.5358\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2348 - val_loss: 138.3960\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.5941 - val_loss: 220.1014\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8714 - val_loss: 148.8687\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.8324 - val_loss: 145.3372\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0375 - val_loss: 161.6195\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6621 - val_loss: 183.3669\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.800 - 0s 51us/step - loss: 144.3086 - val_loss: 141.2451\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.4034 - val_loss: 139.1404\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2775 - val_loss: 144.1454\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.9946 - val_loss: 149.5654\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7754 - val_loss: 150.8055\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.0883 - val_loss: 154.5192\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2055 - val_loss: 136.6078\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5962 - val_loss: 155.5339\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2847 - val_loss: 139.0851\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.2448 - val_loss: 142.2705\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.8775 - val_loss: 173.0709\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.9286 - val_loss: 147.5897\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6050 - val_loss: 167.9273\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.1979 - val_loss: 166.6805\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.0278 - val_loss: 222.6755\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 223.4612 - val_loss: 157.2302\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.7525 - val_loss: 154.6370\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0423 - val_loss: 164.4363\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.2460 - val_loss: 149.8688\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6616 - val_loss: 162.8510\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.6038 - val_loss: 156.8604\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 315.5108 - val_loss: 158.5433\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.6078 - val_loss: 146.2930\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.2691 - val_loss: 162.3185\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2454 - val_loss: 149.4910\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9596 - val_loss: 150.9813\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.1265 - val_loss: 140.5546\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.6529 - val_loss: 142.6467\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9712 - val_loss: 147.0087\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.8978 - val_loss: 172.0289\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9326 - val_loss: 140.9396\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3175 - val_loss: 144.7896\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2734 - val_loss: 179.7285\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.6430 - val_loss: 151.5014\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.7827 - val_loss: 136.6433\n",
      "Epoch 1316/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.3677 - val_loss: 152.3878\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.4151 - val_loss: 264.9243\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9411 - val_loss: 136.7886\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 408.7720 - val_loss: 193.3993\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.0795 - val_loss: 210.3876\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.6450 - val_loss: 159.8861\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3896 - val_loss: 146.4901\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2198 - val_loss: 207.5695\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.2884 - val_loss: 144.8839\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.8168 - val_loss: 163.7622\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7836 - val_loss: 142.9886\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3151 - val_loss: 163.2751\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.2912 - val_loss: 158.6446\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7620 - val_loss: 160.4516\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.0799 - val_loss: 166.9157\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.8073 - val_loss: 166.2307\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7294 - val_loss: 148.4769\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.5245 - val_loss: 144.8292\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6698 - val_loss: 150.1760\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 243.6144 - val_loss: 140.7027\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.0536 - val_loss: 153.3998\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.6583 - val_loss: 167.2297\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.9286 - val_loss: 153.0499\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 137.5368 - val_loss: 146.3390\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 131.2598 - val_loss: 145.7817\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.6591 - val_loss: 140.0062\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2694 - val_loss: 152.1357\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.7583 - val_loss: 162.4221\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 147.9329 - val_loss: 154.0312\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5550 - val_loss: 153.8636\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0912 - val_loss: 191.8433\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.6272 - val_loss: 140.7490\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.3178 - val_loss: 156.1878\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.1039 - val_loss: 318.4746\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.8895 - val_loss: 183.6318\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.9348 - val_loss: 250.0846\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1132 - val_loss: 151.3287\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4811 - val_loss: 144.6166\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2938 - val_loss: 144.1003\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6741 - val_loss: 139.5662\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.4205 - val_loss: 154.0236\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.9114 - val_loss: 213.4049\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6580 - val_loss: 149.7785\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.5768 - val_loss: 136.9429\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9075 - val_loss: 151.3435\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.2303 - val_loss: 149.9814\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2638 - val_loss: 266.6829\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.0471 - val_loss: 149.2904\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.7670 - val_loss: 177.3391\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2344 - val_loss: 156.0170\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.7680 - val_loss: 194.1453\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 293.3881 - val_loss: 146.3872\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9886 - val_loss: 159.0967\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.9945 - val_loss: 148.3226\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.2864 - val_loss: 146.6102\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6029 - val_loss: 185.0143\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.6785 - val_loss: 143.4393\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2601 - val_loss: 142.0048\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1481 - val_loss: 233.6875\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.2487 - val_loss: 156.3255\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7102 - val_loss: 142.0108\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5772 - val_loss: 159.5774\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 153.2983 - val_loss: 144.1278\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.3467 - val_loss: 186.7942\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9454 - val_loss: 164.0593\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 259.3527 - val_loss: 155.9064\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2940 - val_loss: 140.5114\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.5745 - val_loss: 141.0764\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2926 - val_loss: 140.4862\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 314.4033 - val_loss: 145.2887\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.7427 - val_loss: 162.4125\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4749 - val_loss: 183.4896\n",
      "Epoch 1388/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.2924 - val_loss: 136.5457\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6014 - val_loss: 138.1560\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.4585 - val_loss: 170.2447\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.5025 - val_loss: 145.4923\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4984 - val_loss: 145.8422\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0438 - val_loss: 154.2961\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6379 - val_loss: 184.7117\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1017 - val_loss: 136.9225\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.4872 - val_loss: 198.1287\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9093 - val_loss: 140.6173\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 135.5353 - val_loss: 229.0964\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.9744 - val_loss: 141.7520\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.6751 - val_loss: 148.0338\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.4968 - val_loss: 260.1855\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.3544 - val_loss: 174.0854\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.3292 - val_loss: 164.6097\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0506 - val_loss: 160.3723\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.3723 - val_loss: 150.6211\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.2079 - val_loss: 157.6476\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2516 - val_loss: 149.0578\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4648 - val_loss: 160.0799\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.8595 - val_loss: 177.3433\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.2634 - val_loss: 186.8178\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5384 - val_loss: 136.9292\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 186.1292 - val_loss: 144.6575\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 142.6366 - val_loss: 161.2127\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.4093 - val_loss: 151.9678\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7980 - val_loss: 146.7872\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.0900 - val_loss: 163.8405\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 294.5808 - val_loss: 156.1470\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6428 - val_loss: 142.5644\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.3334 - val_loss: 163.5631\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7288 - val_loss: 176.9590\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9556 - val_loss: 146.3204\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.4066 - val_loss: 139.2540\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1019 - val_loss: 199.5403\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9975 - val_loss: 144.2822\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7857 - val_loss: 138.7885\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.4257 - val_loss: 152.8655\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 327.1937 - val_loss: 207.1182\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 295.4728 - val_loss: 280.1339\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 286.5880 - val_loss: 178.3519\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8304 - val_loss: 156.0695\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.6620 - val_loss: 139.6851\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 169.6627 - val_loss: 157.1433\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.0673 - val_loss: 141.5984\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0796 - val_loss: 182.7214\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1917 - val_loss: 149.8237\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0595 - val_loss: 145.7429\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8888 - val_loss: 151.6209\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5459 - val_loss: 160.1385\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 371.0783 - val_loss: 176.4962\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 294.9996 - val_loss: 158.6674\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1110 - val_loss: 149.1455\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8365 - val_loss: 143.2923\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1158 - val_loss: 186.2280\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.9960 - val_loss: 149.5058\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2082 - val_loss: 135.9513\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.2442 - val_loss: 147.9246\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9998 - val_loss: 250.8666\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4282 - val_loss: 160.4272\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7103 - val_loss: 140.2836\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.1397 - val_loss: 137.9143\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.0970 - val_loss: 203.4257\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.0475 - val_loss: 209.4856\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.9003 - val_loss: 166.3199\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.8993 - val_loss: 158.7676\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.9741 - val_loss: 265.5766\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9322 - val_loss: 150.7585\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9124 - val_loss: 136.6183\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3580 - val_loss: 153.1639\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.7174 - val_loss: 147.4360\n",
      "Epoch 1460/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3156 - val_loss: 229.7611\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4988 - val_loss: 146.2302\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1109 - val_loss: 148.5244\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 225.8029 - val_loss: 172.0280\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2307 - val_loss: 141.6403\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.0907 - val_loss: 208.6534\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.9152 - val_loss: 142.2563\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9193 - val_loss: 140.0312\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5853 - val_loss: 149.4575\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8419 - val_loss: 163.3324\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9977 - val_loss: 176.8111\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3661 - val_loss: 149.0062\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.4464 - val_loss: 154.2006\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.0185 - val_loss: 149.6733\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5884 - val_loss: 147.8139\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3163 - val_loss: 154.3682\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.9697 - val_loss: 159.4202\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.3379 - val_loss: 166.1397\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 208.606 - 0s 51us/step - loss: 205.8842 - val_loss: 169.1879\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.9268 - val_loss: 158.4171\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6357 - val_loss: 156.4444\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7164 - val_loss: 152.6185\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0626 - val_loss: 139.5834\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.6847 - val_loss: 166.1683\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 143.8513 - val_loss: 139.3805\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.2560 - val_loss: 240.6104\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 140.6924 - val_loss: 139.7071\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 138.8050 - val_loss: 144.8268\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3564 - val_loss: 137.2439\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 189.7753 - val_loss: 140.4585\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8268 - val_loss: 153.9940\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6090 - val_loss: 142.0216\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9902 - val_loss: 154.3246\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3054 - val_loss: 171.0622\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 394.4700 - val_loss: 208.7348\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4750 - val_loss: 143.7050\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 202.0353 - val_loss: 167.6076\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1101 - val_loss: 139.6891\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6479 - val_loss: 138.5752\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7537 - val_loss: 146.9405\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9829 - val_loss: 136.9432\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4892 - val_loss: 152.6646\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.8814 - val_loss: 196.3232\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9602 - val_loss: 213.1435\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.4204 - val_loss: 149.1617\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2316 - val_loss: 148.1393\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.4677 - val_loss: 147.5051\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2054 - val_loss: 141.3021\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6265 - val_loss: 197.6406\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.5543 - val_loss: 193.5203\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4047 - val_loss: 427.4183\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.8286 - val_loss: 152.3574\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3140 - val_loss: 142.8185\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0417 - val_loss: 142.6348\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0340 - val_loss: 138.8245\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5181 - val_loss: 190.8302\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.7513 - val_loss: 154.4625\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.1221 - val_loss: 174.8249\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 379.2837 - val_loss: 152.3510\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.2935 - val_loss: 144.8142\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.5841 - val_loss: 150.5422\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4490 - val_loss: 144.0980\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3362 - val_loss: 146.1410\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9971 - val_loss: 151.5732\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9284 - val_loss: 137.3220\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.0205 - val_loss: 164.9712\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5659 - val_loss: 137.5446\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2978 - val_loss: 148.0323\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.4970 - val_loss: 146.7059\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4621 - val_loss: 138.8877\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.6232 - val_loss: 162.5885\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.7326 - val_loss: 141.7719\n",
      "Epoch 1532/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.0362 - val_loss: 195.7772\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9259 - val_loss: 158.2717\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.8215 - val_loss: 157.1800\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.3234 - val_loss: 151.8510\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5382 - val_loss: 145.8600\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.0321 - val_loss: 153.6079\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.2430 - val_loss: 159.2801\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0051 - val_loss: 155.0420\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 224.4642 - val_loss: 143.7983\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.0638 - val_loss: 247.8021\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.9496 - val_loss: 145.3755\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.0659 - val_loss: 135.9508\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.2452 - val_loss: 147.0815\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.7545 - val_loss: 150.9462\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.8277 - val_loss: 156.5671\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2332 - val_loss: 146.6155\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7069 - val_loss: 148.3749\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5668 - val_loss: 177.3302\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1864 - val_loss: 174.6072\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.1747 - val_loss: 221.3011\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.9598 - val_loss: 161.6859\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.4527 - val_loss: 172.7153\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2369 - val_loss: 191.1298\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.1735 - val_loss: 143.7089\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.8440 - val_loss: 195.0501\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.0401 - val_loss: 152.7336\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6563 - val_loss: 185.9507\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8145 - val_loss: 153.9869\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0389 - val_loss: 139.8264\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 286.2815 - val_loss: 172.6079\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0558 - val_loss: 167.8657\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.7331 - val_loss: 172.3849\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7524 - val_loss: 180.4422\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.8343 - val_loss: 152.2127\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8414 - val_loss: 142.7169\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.1491 - val_loss: 199.5811\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 133.4732 - val_loss: 149.9804\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 134.9332 - val_loss: 207.3319\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.7414 - val_loss: 168.4882\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8868 - val_loss: 222.7956\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 266.8068 - val_loss: 141.3964\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4835 - val_loss: 141.0185\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0450 - val_loss: 157.5965\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3201 - val_loss: 137.3072\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.6228 - val_loss: 148.8614\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1404 - val_loss: 147.2019\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.3536 - val_loss: 152.8210\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9567 - val_loss: 148.3455\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3792 - val_loss: 151.3542\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7157 - val_loss: 150.1775\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.7032 - val_loss: 162.2777\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3962 - val_loss: 142.8694\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.2691 - val_loss: 206.6502\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8850 - val_loss: 156.1970\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1222 - val_loss: 160.7139\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.7753 - val_loss: 143.0194\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 178.0662 - val_loss: 343.0887\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.3748 - val_loss: 152.3189\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2838 - val_loss: 135.2062\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7115 - val_loss: 168.7243\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6547 - val_loss: 138.6467\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3342 - val_loss: 158.5713\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8156 - val_loss: 150.6638\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2163 - val_loss: 138.3372\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.8436 - val_loss: 141.9046\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.6390 - val_loss: 140.9157\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1018 - val_loss: 145.3319\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.1408 - val_loss: 212.3938\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.0367 - val_loss: 143.0544\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0117 - val_loss: 181.8378\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 229.6244 - val_loss: 158.3187\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.4839 - val_loss: 167.2880\n",
      "Epoch 1604/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9438 - val_loss: 153.0603\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7152 - val_loss: 150.9968\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8883 - val_loss: 256.4448\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.3945 - val_loss: 135.5144\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.5716 - val_loss: 159.4410\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.3389 - val_loss: 166.6575\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.2069 - val_loss: 157.3151\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2953 - val_loss: 148.9848\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.0169 - val_loss: 144.8740\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6296 - val_loss: 179.7884\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9772 - val_loss: 139.6989\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5725 - val_loss: 160.1102\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1423 - val_loss: 141.2259\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6165 - val_loss: 154.9899\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.1712 - val_loss: 164.2302\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0461 - val_loss: 138.4483\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5656 - val_loss: 196.4904\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1044 - val_loss: 141.8854\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.3730 - val_loss: 147.2840\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8562 - val_loss: 143.9049\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.7748 - val_loss: 147.2741\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.6366 - val_loss: 218.1591\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2150 - val_loss: 167.2894\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2411 - val_loss: 158.9993\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.1294 - val_loss: 148.4941\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.1221 - val_loss: 153.7738\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 174.8100 - val_loss: 149.8342\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 165.9457 - val_loss: 149.9884\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 145.8824 - val_loss: 140.7422\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2839 - val_loss: 148.3187\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7604 - val_loss: 148.6250\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.2048 - val_loss: 191.1361\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1052 - val_loss: 186.2619\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7475 - val_loss: 137.3804\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0864 - val_loss: 158.1291\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 332.4841 - val_loss: 147.5837\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.8820 - val_loss: 157.4513\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5325 - val_loss: 172.4451\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3263 - val_loss: 159.0614\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.7759 - val_loss: 145.1341\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0683 - val_loss: 192.1253\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2751 - val_loss: 154.7804\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.6243 - val_loss: 148.5425\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7987 - val_loss: 169.8787\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8579 - val_loss: 149.1837\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5059 - val_loss: 166.7034\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8427 - val_loss: 247.9536\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4523 - val_loss: 146.1864\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.1620 - val_loss: 232.5983\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 397.9146 - val_loss: 165.9324\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 410.6939 - val_loss: 222.2174\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.1262 - val_loss: 151.6270\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2881 - val_loss: 143.8630\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.9902 - val_loss: 169.6698\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.2395 - val_loss: 198.2812\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.3095 - val_loss: 142.4530\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 127.7193 - val_loss: 162.1925\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9713 - val_loss: 136.3694\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.0917 - val_loss: 175.0438\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.7111 - val_loss: 162.3064\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7118 - val_loss: 140.7718\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.1231 - val_loss: 146.4553\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5930 - val_loss: 166.4313\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.7369 - val_loss: 144.1209\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.5288 - val_loss: 145.4152\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0744 - val_loss: 278.4713\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9532 - val_loss: 164.5262\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.2533 - val_loss: 172.7228\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.7638 - val_loss: 166.9309\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8855 - val_loss: 148.9008\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4423 - val_loss: 223.7739\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.7900 - val_loss: 144.1369\n",
      "Epoch 1676/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 0s - loss: 134.640 - 0s 51us/step - loss: 134.8995 - val_loss: 151.9964\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.3122 - val_loss: 139.4971\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1132 - val_loss: 160.5794\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8424 - val_loss: 141.9968\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1231 - val_loss: 169.6397\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7076 - val_loss: 166.2421\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4053 - val_loss: 184.5133\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.0213 - val_loss: 137.4138\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8633 - val_loss: 150.2131\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7773 - val_loss: 140.5572\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.9849 - val_loss: 156.2099\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4967 - val_loss: 159.8897\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.3939 - val_loss: 146.8128\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.8423 - val_loss: 154.2837\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.8646 - val_loss: 144.6827\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3440 - val_loss: 138.1336\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8792 - val_loss: 203.1881\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.6286 - val_loss: 164.4473\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6610 - val_loss: 150.4018\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.3900 - val_loss: 190.3297\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6409 - val_loss: 149.7341\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6892 - val_loss: 136.7361\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7030 - val_loss: 163.1602\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0454 - val_loss: 155.0652\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1247 - val_loss: 135.8330\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3630 - val_loss: 180.2697\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.3145 - val_loss: 147.6447\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 138.4773 - val_loss: 235.3096\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 145.8430 - val_loss: 147.0138\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 227.8741 - val_loss: 226.2878\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.1570 - val_loss: 150.5677\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.3181 - val_loss: 150.9203\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9368 - val_loss: 141.2489\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.5950 - val_loss: 185.9962\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7617 - val_loss: 152.9447\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.1463 - val_loss: 212.4308\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.7834 - val_loss: 142.4052\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.5798 - val_loss: 145.2891\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6572 - val_loss: 146.3834\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.6291 - val_loss: 140.6610\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.2508 - val_loss: 140.7769\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6057 - val_loss: 161.0006\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 358.7849 - val_loss: 234.2323\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5380 - val_loss: 164.6449\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2690 - val_loss: 139.8130\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0562 - val_loss: 157.1953\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7270 - val_loss: 149.7592\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2299 - val_loss: 158.3459\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 135.1375 - val_loss: 137.4058\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.9848 - val_loss: 145.7871\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.9272 - val_loss: 137.6963\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0220 - val_loss: 157.9289\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0301 - val_loss: 142.2296\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1573 - val_loss: 164.4861\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.6258 - val_loss: 164.7044\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.5768 - val_loss: 188.6883\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.3506 - val_loss: 393.7249\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 278.8752 - val_loss: 155.8847\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 154.114 - 0s 51us/step - loss: 152.7890 - val_loss: 141.6420\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.6346 - val_loss: 163.4626\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5017 - val_loss: 177.9965\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.9980 - val_loss: 139.5361\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6999 - val_loss: 138.9371\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0811 - val_loss: 142.7861\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.1272 - val_loss: 145.4487\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0807 - val_loss: 163.8376\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.3454 - val_loss: 138.2446\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3958 - val_loss: 139.4012\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2332 - val_loss: 161.4998\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 266.8677 - val_loss: 203.7495\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.8278 - val_loss: 173.4818\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.8494 - val_loss: 174.3098\n",
      "Epoch 1748/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 0s - loss: 142.510 - 0s 51us/step - loss: 141.5224 - val_loss: 171.8809\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.2337 - val_loss: 143.7711\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5960 - val_loss: 154.0482\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.3010 - val_loss: 168.9285\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1311 - val_loss: 171.5545\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.3618 - val_loss: 147.9058\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3489 - val_loss: 151.8718\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4665 - val_loss: 141.0762\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.8378 - val_loss: 221.8400\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.2865 - val_loss: 139.6122\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8445 - val_loss: 151.1518\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.7143 - val_loss: 152.9225\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7070 - val_loss: 149.5656\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.6521 - val_loss: 166.9090\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.1198 - val_loss: 166.8408\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0117 - val_loss: 141.8063\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9765 - val_loss: 144.0756\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3555 - val_loss: 142.2076\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.6438 - val_loss: 185.1158\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.6120 - val_loss: 142.8693\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8862 - val_loss: 163.7355\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.2168 - val_loss: 145.0925\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.1102 - val_loss: 204.8319\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2262 - val_loss: 156.6635\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1005 - val_loss: 160.6850\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0162 - val_loss: 154.9356\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9673 - val_loss: 147.7178\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.6875 - val_loss: 145.6720\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 142.1213 - val_loss: 139.2148\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 132.7185 - val_loss: 167.4265\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 137.7071 - val_loss: 139.6769\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.7860 - val_loss: 167.9087\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.9559 - val_loss: 146.7556\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9516 - val_loss: 152.3218\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6139 - val_loss: 167.0449\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.0040 - val_loss: 141.6702\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 131.6832 - val_loss: 137.1127\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.7731 - val_loss: 156.0172\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.1299 - val_loss: 143.4066\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9951 - val_loss: 356.9336\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.4671 - val_loss: 146.7873\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9152 - val_loss: 148.4331\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.1839 - val_loss: 155.4309\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.1352 - val_loss: 148.6113\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.9379 - val_loss: 139.6994\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.1643 - val_loss: 170.5102\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6371 - val_loss: 141.4739\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.5437 - val_loss: 151.4457\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 245.5835 - val_loss: 171.3415\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1385 - val_loss: 148.4858\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.0119 - val_loss: 137.5102\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6162 - val_loss: 153.0124\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.0199 - val_loss: 154.7838\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2098 - val_loss: 169.4581\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9829 - val_loss: 137.7476\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2352 - val_loss: 142.3542\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3539 - val_loss: 198.7556\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6165 - val_loss: 151.6264\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1868 - val_loss: 146.0450\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.4193 - val_loss: 145.7954\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.4451 - val_loss: 157.2449\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0498 - val_loss: 153.8177\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2594 - val_loss: 146.8223\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1268 - val_loss: 165.8728\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.0784 - val_loss: 151.2566\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.5564 - val_loss: 191.8387\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9755 - val_loss: 149.6145\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3036 - val_loss: 140.9500\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5598 - val_loss: 163.4847\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9974 - val_loss: 166.0790\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 426.5337 - val_loss: 211.6725\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3981 - val_loss: 155.9063\n",
      "Epoch 1820/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4927 - val_loss: 155.1752\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.0659 - val_loss: 158.9000\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.2001 - val_loss: 181.0506\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0847 - val_loss: 173.6342\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 228.8460 - val_loss: 153.4456\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2227 - val_loss: 176.0213\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.9364 - val_loss: 148.7450\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2595 - val_loss: 149.2797\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.3520 - val_loss: 144.0544\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9562 - val_loss: 189.3972\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6376 - val_loss: 305.2781\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.3087 - val_loss: 144.3004\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.2048 - val_loss: 170.5106\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3698 - val_loss: 153.0585\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.1712 - val_loss: 141.0398\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1520 - val_loss: 141.8543\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 139.7931 - val_loss: 153.5709\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0171 - val_loss: 148.6126\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4433 - val_loss: 147.2313\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3958 - val_loss: 137.0138\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.3814 - val_loss: 159.6502\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1400 - val_loss: 154.0421\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.1566 - val_loss: 154.1032\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.2909 - val_loss: 161.9623\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1894 - val_loss: 189.8242\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4590 - val_loss: 146.2428\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.7014 - val_loss: 166.4330\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 282.9198 - val_loss: 147.8784\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0921 - val_loss: 174.0055\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.3583 - val_loss: 145.6076\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 180.9213 - val_loss: 144.4822\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.9388 - val_loss: 144.4358\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.3317 - val_loss: 151.4592\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4618 - val_loss: 168.2698\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4936 - val_loss: 141.3626\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2846 - val_loss: 143.7861\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9459 - val_loss: 176.0780\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.1220 - val_loss: 155.8548\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.2477 - val_loss: 207.6358\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1223 - val_loss: 142.3873\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0021 - val_loss: 202.3009\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1073 - val_loss: 149.1655\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0899 - val_loss: 150.4075\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4973 - val_loss: 139.5730\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0565 - val_loss: 248.2032\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4461 - val_loss: 138.3742\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.1402 - val_loss: 139.4012\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9204 - val_loss: 160.9505\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0973 - val_loss: 136.1130\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1219 - val_loss: 143.2244\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.4235 - val_loss: 162.9188\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.4456 - val_loss: 145.3131\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3298 - val_loss: 149.7174\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5450 - val_loss: 186.4500\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5087 - val_loss: 145.9589\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2190 - val_loss: 175.2978\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.4735 - val_loss: 177.3302\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5649 - val_loss: 152.0061\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0377 - val_loss: 150.2325\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9405 - val_loss: 143.7837\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5972 - val_loss: 147.5919\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3046 - val_loss: 169.7987\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.9776 - val_loss: 151.6652\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2034 - val_loss: 140.8073\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6211 - val_loss: 179.9317\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7132 - val_loss: 154.6766\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6600 - val_loss: 144.5771\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4240 - val_loss: 144.4544\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6556 - val_loss: 160.2718\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7058 - val_loss: 148.0518\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.1426 - val_loss: 471.7372\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 430.8631 - val_loss: 161.5256\n",
      "Epoch 1892/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.4259 - val_loss: 148.1252\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.3542 - val_loss: 165.5337\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7961 - val_loss: 153.4611\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 251.0571 - val_loss: 214.3420\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1180 - val_loss: 143.7644\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8919 - val_loss: 151.4719\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.6043 - val_loss: 145.0139\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.7327 - val_loss: 142.0136\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2719 - val_loss: 149.5216\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7577 - val_loss: 162.0445\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2633 - val_loss: 146.6208\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.7114 - val_loss: 146.7542\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4457 - val_loss: 161.1479\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4817 - val_loss: 137.2018\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9996 - val_loss: 144.5244\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.0502 - val_loss: 140.4096\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.7201 - val_loss: 164.0266\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3941 - val_loss: 144.0060\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0575 - val_loss: 149.7674\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.7882 - val_loss: 139.2899\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1232 - val_loss: 138.7272\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.0492 - val_loss: 137.3152\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.3850 - val_loss: 159.0201\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3669 - val_loss: 158.0029\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.6851 - val_loss: 157.2914\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1831 - val_loss: 186.0578\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1935 - val_loss: 147.9539\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.1869 - val_loss: 147.9818\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0723 - val_loss: 137.1059\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 322.0738 - val_loss: 148.6099\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 162.1682 - val_loss: 169.3707\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 167.1367 - val_loss: 170.0733\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.7171 - val_loss: 159.2125\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.0579 - val_loss: 146.8962\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.9058 - val_loss: 168.6636\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.2349 - val_loss: 153.1832\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2845 - val_loss: 142.3210\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5208 - val_loss: 139.8594\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3090 - val_loss: 266.6671\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8527 - val_loss: 168.5065\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.0052 - val_loss: 193.3706\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6610 - val_loss: 145.1144\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2289 - val_loss: 141.3597\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6722 - val_loss: 195.0934\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2913 - val_loss: 145.9026\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.6911 - val_loss: 144.1763\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3127 - val_loss: 151.6536\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4367 - val_loss: 166.5531\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6621 - val_loss: 170.8878\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.3887 - val_loss: 148.6711\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8462 - val_loss: 152.2925\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6441 - val_loss: 172.9910\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 247.0238 - val_loss: 143.5941\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1544 - val_loss: 151.4916\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5628 - val_loss: 144.6567\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.9724 - val_loss: 154.2579\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8274 - val_loss: 193.6779\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.1181 - val_loss: 136.3868\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.5376 - val_loss: 182.4918\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.0072 - val_loss: 140.8585\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.7067 - val_loss: 143.0643\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3971 - val_loss: 152.9553\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.8805 - val_loss: 156.4690\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0052 - val_loss: 154.6044\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5307 - val_loss: 141.5183\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2379 - val_loss: 185.6600\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4587 - val_loss: 172.0921\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1030 - val_loss: 158.8322\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2768 - val_loss: 183.1506\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3328 - val_loss: 206.6232\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7998 - val_loss: 148.9106\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.6005 - val_loss: 166.9507\n",
      "Epoch 1964/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2081 - val_loss: 137.4160\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3642 - val_loss: 180.7578\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9289 - val_loss: 142.6975\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.4692 - val_loss: 397.0582\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9405 - val_loss: 147.3743\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5918 - val_loss: 142.2150\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.1371 - val_loss: 220.3711\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 262.3955 - val_loss: 187.9720\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 159.9934 - val_loss: 147.7520\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.3203 - val_loss: 150.6966\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.2414 - val_loss: 147.3164\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.6509 - val_loss: 162.3077\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5449 - val_loss: 146.9134\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2097 - val_loss: 141.2628\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.6124 - val_loss: 162.4695\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.7598 - val_loss: 249.1946\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8788 - val_loss: 155.4477\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.9260 - val_loss: 179.0125\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3414 - val_loss: 146.1591\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8718 - val_loss: 152.5128\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.0458 - val_loss: 152.1375\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.0803 - val_loss: 237.5013\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6835 - val_loss: 143.2386\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.1297 - val_loss: 150.0160\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8053 - val_loss: 191.8875\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 176.9864 - val_loss: 191.6180\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.4216 - val_loss: 173.4467\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.7565 - val_loss: 149.9996\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1573 - val_loss: 163.0333\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3704 - val_loss: 160.9304\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 172.6630 - val_loss: 187.7668\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.6318 - val_loss: 144.5861\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.1418 - val_loss: 156.6766\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.9261 - val_loss: 140.3506\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8672 - val_loss: 153.5068\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8079 - val_loss: 173.3844\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6100 - val_loss: 148.9381\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9135 - val_loss: 143.9960\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 417.8104 - val_loss: 159.5729\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0662 - val_loss: 160.7655\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.3986 - val_loss: 152.3917\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.1533 - val_loss: 183.4555\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.2526 - val_loss: 143.5837\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5891 - val_loss: 181.3039\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.6231 - val_loss: 156.2193\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.2558 - val_loss: 148.2893\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0527 - val_loss: 139.2530\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0102 - val_loss: 156.2053\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3507 - val_loss: 157.1796\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2464 - val_loss: 174.5120\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4244 - val_loss: 142.6594\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.8178 - val_loss: 169.9213\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.0137 - val_loss: 156.4397\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0695 - val_loss: 142.4254\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.7909 - val_loss: 161.0568\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.1072 - val_loss: 142.9024\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5108 - val_loss: 142.8180\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.7587 - val_loss: 142.8583\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.6900 - val_loss: 168.0895\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9880 - val_loss: 180.0383\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0203 - val_loss: 147.9615\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3142 - val_loss: 288.8540\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.8807 - val_loss: 156.5965\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3807 - val_loss: 149.7494\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9680 - val_loss: 163.9097\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8903 - val_loss: 136.8949\n",
      "Epoch 02029: early stopping\n",
      "Fold score (RMSE): 11.491389274597168\n",
      "Fold #3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 5156.7933 - val_loss: 4651.5258\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4341.0496 - val_loss: 4385.5698\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4218.5138 - val_loss: 4349.3100\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4090.0270 - val_loss: 4301.9594\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4099.8884 - val_loss: 4230.2308\n",
      "Epoch 6/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 3926.0381 - val_loss: 4067.8482\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 3923.5962 - val_loss: 4065.4021\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3792.4968 - val_loss: 5494.2869\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3715.1300 - val_loss: 3571.5423\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3668.5477 - val_loss: 3603.9062\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3366.2136 - val_loss: 3220.9843\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3212.8587 - val_loss: 2891.5280\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2855.6377 - val_loss: 3018.4115\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2434.4280 - val_loss: 1766.4297\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 2075.9845 - val_loss: 2013.2836\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1449.0838 - val_loss: 1597.7220\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 1577.2365 - val_loss: 1479.9282\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1477.6579 - val_loss: 1124.0037\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1082.9784 - val_loss: 911.5265\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1056.5048 - val_loss: 813.2129\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 914.1342 - val_loss: 543.9831\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 778.1969 - val_loss: 615.7552\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 729.1163 - val_loss: 816.0800\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 858.0656 - val_loss: 540.1579\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 608.8545 - val_loss: 429.5508\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 669.8552 - val_loss: 467.0885\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 541.7703 - val_loss: 465.3482\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 642.5893 - val_loss: 475.1191\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 526.2806 - val_loss: 686.2737\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 815.7587 - val_loss: 677.9477\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 502.7165 - val_loss: 650.2510\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 512.2092 - val_loss: 399.3621\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 493.6336 - val_loss: 602.8633\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 609.0424 - val_loss: 571.5241\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 526.0128 - val_loss: 354.2481\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 404.0423 - val_loss: 341.4616\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 466.5063 - val_loss: 444.7868\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 508.1938 - val_loss: 1729.0136\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 761.0129 - val_loss: 2017.8989\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 494.4322 - val_loss: 479.7066\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 426.3068 - val_loss: 324.4977\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 486.8275 - val_loss: 332.3929\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 404.3855 - val_loss: 337.4412\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 452.5859 - val_loss: 409.4899\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 385.8189 - val_loss: 336.5650\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 351.8408 - val_loss: 299.1116\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 382.736 - 0s 50us/step - loss: 381.7039 - val_loss: 459.2377\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 419.0182 - val_loss: 284.3046\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 440.2267 - val_loss: 368.0480\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 342.5188 - val_loss: 593.8135\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 370.2877 - val_loss: 250.2673\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 389.1520 - val_loss: 555.8026\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 383.7606 - val_loss: 264.0728\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 480.7579 - val_loss: 288.7988\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 377.0829 - val_loss: 254.3083\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 305.3434 - val_loss: 651.7511\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 352.9235 - val_loss: 411.2626\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 376.2580 - val_loss: 531.3353\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 391.7303 - val_loss: 326.1183\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 348.8918 - val_loss: 268.6592\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 707.0424 - val_loss: 3983.7533\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 533.1764 - val_loss: 404.8181\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 326.1136 - val_loss: 270.7338\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 328.7844 - val_loss: 448.9245\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 330.1726 - val_loss: 240.3034\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 324.8647 - val_loss: 265.1469\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 285.7833 - val_loss: 239.9660\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 360.9254 - val_loss: 217.9567\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.2961 - val_loss: 354.2516\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 335.7780 - val_loss: 415.9620\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 326.8316 - val_loss: 329.5538\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 303.7563 - val_loss: 218.5279\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 323.6322 - val_loss: 443.7938\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 357.8563 - val_loss: 250.3533\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 339.3098 - val_loss: 310.9907\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 301.7785 - val_loss: 275.8898\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 368.8180 - val_loss: 255.1917\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 373.0603 - val_loss: 708.1364\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 297.5838 - val_loss: 356.6269\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 299.8679 - val_loss: 244.3857\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 328.9712 - val_loss: 215.9903\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 307.0387 - val_loss: 212.6389\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 277.9438 - val_loss: 227.6958\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 301.5520 - val_loss: 324.7305\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 268.5557 - val_loss: 259.5763\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 268.0698 - val_loss: 204.3014\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 338.7511 - val_loss: 273.0808\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 300.6564 - val_loss: 556.5656\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 344.7985 - val_loss: 264.1563\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 328.6583 - val_loss: 219.7771\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.3756 - val_loss: 228.0046\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 288.9339 - val_loss: 276.3393\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 316.5844 - val_loss: 277.4816\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 349.2198 - val_loss: 272.7276\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 255.1123 - val_loss: 219.1742\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 287.4674 - val_loss: 200.9283\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 268.2840 - val_loss: 775.9075\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.4048 - val_loss: 258.5721\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 249.2149 - val_loss: 642.7363\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 298.3054 - val_loss: 334.3950\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 301.1951 - val_loss: 246.7874\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.7761 - val_loss: 205.5887\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 346.6018 - val_loss: 216.9175\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 279.0941 - val_loss: 216.0738\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 240.6331 - val_loss: 268.5816\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 247.0926 - val_loss: 177.2140\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 287.9060 - val_loss: 286.2023\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.1503 - val_loss: 196.8357\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 296.3647 - val_loss: 188.6267\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 244.7177 - val_loss: 191.6700\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 406.2335 - val_loss: 343.2093\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 261.4513 - val_loss: 174.2114\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.4162 - val_loss: 315.7102\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 287.7833 - val_loss: 295.1962\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 261.0711 - val_loss: 377.5525\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 240.7601 - val_loss: 310.9953\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.7577 - val_loss: 222.1689\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 277.7297 - val_loss: 673.8710\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.4460 - val_loss: 182.0471\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.3935 - val_loss: 230.1280\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.3677 - val_loss: 329.7880\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.4326 - val_loss: 188.6899\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 347.1436 - val_loss: 223.7913\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 247.2541 - val_loss: 191.0184\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 270.7151 - val_loss: 778.4907\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 268.6441 - val_loss: 280.0526\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 259.2815 - val_loss: 322.5947\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 521.5171 - val_loss: 251.0534\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 268.3188 - val_loss: 207.4791\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.1797 - val_loss: 188.8109\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 386.6679 - val_loss: 379.6397\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 245.6544 - val_loss: 275.9594\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 219.2932 - val_loss: 187.1568\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.0313 - val_loss: 196.8940\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.8836 - val_loss: 239.9338\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 347.5980 - val_loss: 379.1352\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.1576 - val_loss: 247.9925\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.9923 - val_loss: 237.6761\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 282.0989 - val_loss: 271.5979\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.8276 - val_loss: 214.2167\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 253.1703 - val_loss: 624.0265\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.0504 - val_loss: 171.6622\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 227.0446 - val_loss: 304.6257\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 282.5681 - val_loss: 287.1268\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.3664 - val_loss: 198.3299\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.4587 - val_loss: 224.5129\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 260.8415 - val_loss: 174.8265\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.0673 - val_loss: 375.6685\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.2999 - val_loss: 268.5403\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 230.9171 - val_loss: 197.3317\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 282.6674 - val_loss: 240.0013\n",
      "Epoch 152/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.3202 - val_loss: 206.9204\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 323.7123 - val_loss: 200.1788\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 316.2707 - val_loss: 227.7503\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.6704 - val_loss: 161.8935\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 288.2569 - val_loss: 604.5426\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.6191 - val_loss: 233.7637\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.2251 - val_loss: 221.5253\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.7587 - val_loss: 171.1177\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 214.9541 - val_loss: 168.2860\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.6632 - val_loss: 219.3750\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.8306 - val_loss: 541.1740\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.2003 - val_loss: 278.3873\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 225.7560 - val_loss: 304.0777\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 299.9596 - val_loss: 206.0309\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.4395 - val_loss: 160.8904\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.7708 - val_loss: 175.6070\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.7623 - val_loss: 281.0625\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 273.5918 - val_loss: 219.3257\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.6492 - val_loss: 189.9545\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 232.2168 - val_loss: 265.5055\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 305.5766 - val_loss: 202.8944\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.6275 - val_loss: 202.5045\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 257.1638 - val_loss: 439.2051\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.5055 - val_loss: 173.8982\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 243.8059 - val_loss: 337.4398\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 243.9974 - val_loss: 348.4487\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 258.4333 - val_loss: 166.0411\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 444.7426 - val_loss: 328.4115\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 342.2262 - val_loss: 222.3711\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.3915 - val_loss: 338.8184\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.4062 - val_loss: 177.9787\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.3334 - val_loss: 167.9255\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.0735 - val_loss: 201.1399\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.8191 - val_loss: 415.5542\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 274.4947 - val_loss: 248.1288\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 231.3846 - val_loss: 165.7940\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.8119 - val_loss: 205.8612\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.0126 - val_loss: 628.9000\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 314.3832 - val_loss: 178.6576\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.4566 - val_loss: 169.4387\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 214.1231 - val_loss: 259.1754\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 235.2714 - val_loss: 223.8386\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 517.9222 - val_loss: 345.7505\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 354.7034 - val_loss: 207.5263\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 341.3727 - val_loss: 196.2291\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 251.2276 - val_loss: 160.4852\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 234.5138 - val_loss: 157.7113\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 217.8803 - val_loss: 162.7498\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.6921 - val_loss: 180.6195\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 289.4844 - val_loss: 526.6757\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.9034 - val_loss: 188.7284\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 213.1639 - val_loss: 229.2439\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 263.4472 - val_loss: 345.1602\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 323.1647 - val_loss: 280.0071\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 278.0077 - val_loss: 402.1544\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 275.4463 - val_loss: 204.4352\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.7867 - val_loss: 227.6462\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.2983 - val_loss: 361.6444\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 289.4962 - val_loss: 179.7909\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.8110 - val_loss: 211.8845\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 242.5207 - val_loss: 157.3498\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5635 - val_loss: 169.1125\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 332.7906 - val_loss: 269.7186\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 218.688 - 0s 51us/step - loss: 219.2288 - val_loss: 187.3071\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.1874 - val_loss: 212.5961\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 318.6461 - val_loss: 182.4795\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 285.7635 - val_loss: 184.5289\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.4341 - val_loss: 238.1918\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.2401 - val_loss: 252.1322\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 204.3902 - val_loss: 486.2476\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 239.1121 - val_loss: 168.7851\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.8461 - val_loss: 188.9542\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.0650 - val_loss: 178.3206\n",
      "Epoch 225/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 283.0211 - val_loss: 166.8234\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 295.4439 - val_loss: 184.0775\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 202.5584 - val_loss: 169.4844\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.9105 - val_loss: 165.3592\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 251.6781 - val_loss: 229.9700\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.1342 - val_loss: 341.2963\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.6947 - val_loss: 200.4989\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.1809 - val_loss: 216.2433\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 267.0355 - val_loss: 196.4692\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.6141 - val_loss: 393.3573\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 260.5607 - val_loss: 285.3088\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.1505 - val_loss: 225.5955\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.2376 - val_loss: 147.3682\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.4347 - val_loss: 178.2752\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.9535 - val_loss: 149.5332\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 192.7206 - val_loss: 150.5151\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.4196 - val_loss: 277.5170\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 293.0421 - val_loss: 180.8577\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.7884 - val_loss: 279.8511\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.1975 - val_loss: 258.0434\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 217.8828 - val_loss: 1413.1652\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 328.1087 - val_loss: 180.7243\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.3695 - val_loss: 163.4844\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 232.6408 - val_loss: 143.7889\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.4335 - val_loss: 373.0857\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.1191 - val_loss: 155.6321\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 245.310 - 0s 51us/step - loss: 245.2409 - val_loss: 152.6221\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.0748 - val_loss: 144.2857\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.9229 - val_loss: 178.4043\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.5501 - val_loss: 146.3667\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 238.5086 - val_loss: 149.6457\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 210.6590 - val_loss: 222.1917\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.5369 - val_loss: 168.6171\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 235.4980 - val_loss: 173.0085\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 304.0150 - val_loss: 182.2784\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 262.7335 - val_loss: 227.8880\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 364.5903 - val_loss: 425.8306\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 319.7254 - val_loss: 210.9732\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.2168 - val_loss: 184.1666\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.9587 - val_loss: 242.8621\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.2079 - val_loss: 172.1660\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.0362 - val_loss: 168.4727\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 213.6120 - val_loss: 185.1201\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.9766 - val_loss: 336.6108\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 290.8844 - val_loss: 159.8588\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.3552 - val_loss: 340.8092\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.9578 - val_loss: 217.4424\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.9922 - val_loss: 178.4466\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.0533 - val_loss: 393.2718\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.7484 - val_loss: 209.9227\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.7925 - val_loss: 167.9228\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.4294 - val_loss: 199.5514\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 301.7757 - val_loss: 193.8079\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.4090 - val_loss: 177.7843\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.2830 - val_loss: 148.1330\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.7988 - val_loss: 195.9338\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 271.3388 - val_loss: 167.8002\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5640 - val_loss: 160.0622\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.9469 - val_loss: 200.7003\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.8571 - val_loss: 311.0774\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.8703 - val_loss: 230.8865\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.7419 - val_loss: 154.9159\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.0403 - val_loss: 159.7430\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.1909 - val_loss: 185.2994\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.5314 - val_loss: 239.7399\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 338.8185 - val_loss: 170.3666\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.0879 - val_loss: 170.8519\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.0093 - val_loss: 379.1225\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.2387 - val_loss: 150.2516\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.9480 - val_loss: 352.0902\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.8287 - val_loss: 163.6841\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 258.0145 - val_loss: 435.3880\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.3324 - val_loss: 189.7555\n",
      "Epoch 298/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 258.6669 - val_loss: 154.8060\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.7086 - val_loss: 236.4170\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 240.7960 - val_loss: 207.5672\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.6611 - val_loss: 159.8104\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 316.0260 - val_loss: 337.7800\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.4336 - val_loss: 174.4042\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 320.0761 - val_loss: 152.9310\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.8304 - val_loss: 162.4794\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.4439 - val_loss: 554.5674\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 218.6941 - val_loss: 170.4723\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.6074 - val_loss: 200.8158\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.7860 - val_loss: 162.4137\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.3824 - val_loss: 304.3294\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 263.6668 - val_loss: 262.1053\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 276.1409 - val_loss: 178.7025\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.2252 - val_loss: 150.5793\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.5308 - val_loss: 1779.4559\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 346.3082 - val_loss: 198.9059\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9898 - val_loss: 151.5142\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.5108 - val_loss: 222.6786\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.9093 - val_loss: 158.8281\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.3197 - val_loss: 171.8816\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 184.2673 - val_loss: 151.4691\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 266.7824 - val_loss: 155.9133\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 221.9167 - val_loss: 173.3298\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 199.1716 - val_loss: 159.3783\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4778 - val_loss: 174.9819\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.3597 - val_loss: 250.1366\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 211.6404 - val_loss: 177.4472\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.6563 - val_loss: 148.4009\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 246.6422 - val_loss: 197.0123\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.2834 - val_loss: 140.8014\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.4309 - val_loss: 155.3793\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.4897 - val_loss: 171.1804\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.4348 - val_loss: 144.0109\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.2870 - val_loss: 356.9266\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 196.1759 - val_loss: 149.1877\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.4362 - val_loss: 469.2995\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 214.4616 - val_loss: 158.5144\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.2024 - val_loss: 189.9662\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.5941 - val_loss: 216.9455\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.3751 - val_loss: 141.6345\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.6662 - val_loss: 142.6370\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2905 - val_loss: 145.1559\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.9158 - val_loss: 152.8725\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 236.127 - 0s 51us/step - loss: 236.5461 - val_loss: 206.3501\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.0255 - val_loss: 194.4049\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3830 - val_loss: 170.0984\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 216.8971 - val_loss: 377.1521\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.3578 - val_loss: 162.4285\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5579 - val_loss: 205.8452\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 336.9350 - val_loss: 231.9041\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.6205 - val_loss: 204.5229\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.8274 - val_loss: 179.5199\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 203.0007 - val_loss: 190.5203\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.0417 - val_loss: 181.6634\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.3304 - val_loss: 146.2542\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.6374 - val_loss: 325.3640\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.6475 - val_loss: 154.1632\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 262.4937 - val_loss: 203.0579\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.4226 - val_loss: 147.7242\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.0247 - val_loss: 189.8121\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.0530 - val_loss: 285.4110\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.5428 - val_loss: 153.5469\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 318.2619 - val_loss: 161.0195\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 185.6524 - val_loss: 210.7992\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.3051 - val_loss: 382.6674\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5317 - val_loss: 196.7789\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 407.2065 - val_loss: 400.4624\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.3595 - val_loss: 191.1043\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.1198 - val_loss: 146.3082\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.7888 - val_loss: 168.8381\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.3064 - val_loss: 148.6959\n",
      "Epoch 371/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3006 - val_loss: 178.2548\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.7207 - val_loss: 484.5498\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.9854 - val_loss: 143.7332\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.3842 - val_loss: 244.3094\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 266.6277 - val_loss: 184.6107\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.1426 - val_loss: 320.0667\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 209.609 - 0s 51us/step - loss: 209.7300 - val_loss: 164.7879\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.7659 - val_loss: 276.0881\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 214.0435 - val_loss: 156.5488\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.5684 - val_loss: 172.4449\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.0755 - val_loss: 174.3728\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.7179 - val_loss: 147.7162\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.5946 - val_loss: 140.9758\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.8423 - val_loss: 184.1447\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.5943 - val_loss: 285.8220\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.0437 - val_loss: 368.5229\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.3119 - val_loss: 140.6626\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.0793 - val_loss: 167.3575\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.2277 - val_loss: 176.0093\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.2236 - val_loss: 160.3678\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.8485 - val_loss: 140.9353\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 188.1510 - val_loss: 149.1584\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 298.2496 - val_loss: 355.5861\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 303.0956 - val_loss: 299.4074\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 216.3766 - val_loss: 157.3863\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 221.5133 - val_loss: 231.4129\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.1061 - val_loss: 188.2466\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.3308 - val_loss: 366.3264\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 174.217 - 0s 51us/step - loss: 173.9552 - val_loss: 163.2277\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.3405 - val_loss: 149.1152\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.0658 - val_loss: 155.1901\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.0687 - val_loss: 277.2631\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.2768 - val_loss: 177.6442\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.4560 - val_loss: 147.2367\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 259.6450 - val_loss: 1647.5136\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 487.2035 - val_loss: 169.1202\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.1624 - val_loss: 151.8335\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.0666 - val_loss: 137.5639\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.8234 - val_loss: 149.5144\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5065 - val_loss: 143.5536\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 268.2052 - val_loss: 201.5487\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.5898 - val_loss: 146.6571\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.1596 - val_loss: 169.4456\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.0007 - val_loss: 211.3526\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.2386 - val_loss: 135.2020\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.3590 - val_loss: 174.0390\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.0968 - val_loss: 240.7138\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.4535 - val_loss: 166.5037\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.2113 - val_loss: 516.2166\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.9134 - val_loss: 132.4481\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.0624 - val_loss: 136.7065\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.3893 - val_loss: 181.5936\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.4353 - val_loss: 137.6565\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.5489 - val_loss: 182.5203\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.8199 - val_loss: 159.3702\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.5724 - val_loss: 475.4769\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.6569 - val_loss: 161.5054\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.8251 - val_loss: 258.8359\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.8844 - val_loss: 158.6395\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7096 - val_loss: 144.4363\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.0821 - val_loss: 183.7051\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.7163 - val_loss: 190.8761\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7253 - val_loss: 143.8536\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.4078 - val_loss: 575.7690\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.2193 - val_loss: 149.6368\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.4273 - val_loss: 364.2313\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 596.9452 - val_loss: 298.9144\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.3277 - val_loss: 158.2168\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.0529 - val_loss: 198.3906\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.5359 - val_loss: 161.0031\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.3576 - val_loss: 158.3551\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.4116 - val_loss: 178.7388\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.6481 - val_loss: 150.9561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.5879 - val_loss: 152.0224\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.1211 - val_loss: 168.0132\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.6710 - val_loss: 173.4834\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.8454 - val_loss: 219.7003\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.1919 - val_loss: 228.1781\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.4094 - val_loss: 242.2454\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0923 - val_loss: 207.9052\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.9934 - val_loss: 143.7310\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4485 - val_loss: 145.9743\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.5164 - val_loss: 139.3843\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 178.4039 - val_loss: 140.4287\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.8219 - val_loss: 138.7253\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.1496 - val_loss: 148.9581\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.2053 - val_loss: 161.7533\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 243.9900 - val_loss: 158.3163\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.5707 - val_loss: 191.7689\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.4552 - val_loss: 273.5993\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.0566 - val_loss: 146.3969\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 314.6504 - val_loss: 150.7267\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.8989 - val_loss: 148.8798\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 208.6174 - val_loss: 164.5668\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 172.3830 - val_loss: 194.9296\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 182.8611 - val_loss: 166.2213\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 186.8672 - val_loss: 265.4641\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 222.1313 - val_loss: 144.0688\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3392 - val_loss: 170.3315\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.7553 - val_loss: 167.9650\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.3822 - val_loss: 136.0424\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.0409 - val_loss: 138.3676\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.2653 - val_loss: 162.5377\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.8495 - val_loss: 186.2385\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 466.9022 - val_loss: 163.5831\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.1682 - val_loss: 155.3616\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.2162 - val_loss: 157.5087\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.7687 - val_loss: 136.7676\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4884 - val_loss: 146.8784\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1346 - val_loss: 318.4095\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.6661 - val_loss: 159.7146\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6496 - val_loss: 136.7795\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8112 - val_loss: 136.1330\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 342.2017 - val_loss: 329.6329\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.3806 - val_loss: 167.3850\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6293 - val_loss: 343.8103\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.1533 - val_loss: 149.9594\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.7122 - val_loss: 133.5664\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 234.0302 - val_loss: 1288.5328\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.4785 - val_loss: 136.7216\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.1785 - val_loss: 294.5081\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.1317 - val_loss: 158.2294\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.5118 - val_loss: 160.3407\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 272.6104 - val_loss: 160.6909\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.0968 - val_loss: 243.0780\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.2091 - val_loss: 140.8380\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3709 - val_loss: 157.0995\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4963 - val_loss: 217.1053\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.4167 - val_loss: 149.3511\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.9794 - val_loss: 155.0102\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7937 - val_loss: 179.7658\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.0891 - val_loss: 148.4304\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7290 - val_loss: 136.3014\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.2344 - val_loss: 169.7055\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.7798 - val_loss: 143.5976\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.6687 - val_loss: 134.5115\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.8590 - val_loss: 831.3303\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.5902 - val_loss: 136.7150\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.0552 - val_loss: 183.3125\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.2140 - val_loss: 229.9470\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.4424 - val_loss: 148.3978\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.2639 - val_loss: 190.5799\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.2091 - val_loss: 134.4738\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.5203 - val_loss: 169.9168\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6998 - val_loss: 135.3299\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.2357 - val_loss: 153.9142\n",
      "Epoch 517/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4393 - val_loss: 143.6232\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6881 - val_loss: 183.8006\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.8728 - val_loss: 249.1332\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.2659 - val_loss: 146.3421\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.5477 - val_loss: 149.6726\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.9143 - val_loss: 133.7818\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6664 - val_loss: 194.6380\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.7496 - val_loss: 168.8134\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.7300 - val_loss: 136.5045\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 199.2064 - val_loss: 190.8670\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.3232 - val_loss: 204.5188\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1542 - val_loss: 165.7785\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 478.1624 - val_loss: 164.9341\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4160 - val_loss: 150.3733\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.3710 - val_loss: 156.9009\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0801 - val_loss: 142.4295\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.6579 - val_loss: 156.8822\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.8169 - val_loss: 141.7299\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.5242 - val_loss: 736.1614\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 254.2771 - val_loss: 620.6973\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 292.0301 - val_loss: 141.1706\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 154.6153 - val_loss: 190.1194\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.1294 - val_loss: 132.4974\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 174.4470 - val_loss: 152.3445\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.6484 - val_loss: 178.3703\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5698 - val_loss: 164.0842\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.4464 - val_loss: 152.8319\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.7246 - val_loss: 133.0267\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.3102 - val_loss: 167.0933\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6452 - val_loss: 148.0641\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 281.4612 - val_loss: 194.1071\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.0482 - val_loss: 143.4595\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.9302 - val_loss: 143.3991\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.5229 - val_loss: 145.2058\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4408 - val_loss: 148.8663\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2985 - val_loss: 156.5082\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1438 - val_loss: 162.5451\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.6153 - val_loss: 131.3675\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4556 - val_loss: 133.4383\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.1594 - val_loss: 168.7481\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.5015 - val_loss: 214.3719\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0305 - val_loss: 139.9656\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.1270 - val_loss: 192.8462\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 596.8143 - val_loss: 194.3332\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.5473 - val_loss: 154.2282\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.1299 - val_loss: 263.9018\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.8118 - val_loss: 142.6552\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8196 - val_loss: 143.6390\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2702 - val_loss: 144.1815\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.0833 - val_loss: 143.2459\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.6263 - val_loss: 141.0907\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.9061 - val_loss: 262.6365\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 178.6393 - val_loss: 136.5542\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 656.8820 - val_loss: 446.2530\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 364.5059 - val_loss: 195.8798\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.6659 - val_loss: 187.3109\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 291.7097 - val_loss: 167.4253\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.6414 - val_loss: 942.6055\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.4177 - val_loss: 147.3056\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.5639 - val_loss: 204.7538\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.1612 - val_loss: 214.3417\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.0274 - val_loss: 211.6432\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2848 - val_loss: 159.3775\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.8136 - val_loss: 143.0695\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 481.3952 - val_loss: 198.7380\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.8196 - val_loss: 159.4065\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.6533 - val_loss: 213.5140\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.8103 - val_loss: 152.0915\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.8948 - val_loss: 168.2929\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.1682 - val_loss: 158.1518\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.4219 - val_loss: 190.9801\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.2418 - val_loss: 139.6986\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.4509 - val_loss: 160.5926\n",
      "Epoch 590/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.5143 - val_loss: 247.7989\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.3965 - val_loss: 164.9918\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.9125 - val_loss: 156.2628\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.4550 - val_loss: 202.0481\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5477 - val_loss: 147.8070\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.0068 - val_loss: 140.7967\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.4701 - val_loss: 210.8243\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.8444 - val_loss: 144.3405\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.1830 - val_loss: 174.8220\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.3587 - val_loss: 166.3095\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.4050 - val_loss: 173.0731\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 235.8683 - val_loss: 140.3421\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.5735 - val_loss: 154.0391\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.3360 - val_loss: 146.0078\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.9100 - val_loss: 173.3272\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.1272 - val_loss: 243.9364\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.6197 - val_loss: 160.6186\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0186 - val_loss: 144.0406\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 356.7546 - val_loss: 179.5367\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 178.5382 - val_loss: 199.5004\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 234.9444 - val_loss: 156.7294\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 170.7047 - val_loss: 139.3517\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 165.9625 - val_loss: 154.2276\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.3444 - val_loss: 159.8561\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.4197 - val_loss: 156.6235\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.5221 - val_loss: 153.0847\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1361 - val_loss: 135.4821\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.7546 - val_loss: 168.9412\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.3537 - val_loss: 137.3986\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.4760 - val_loss: 150.3827\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.5022 - val_loss: 163.4376\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.4440 - val_loss: 157.5533\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7814 - val_loss: 354.5386\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.3200 - val_loss: 164.5091\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.1606 - val_loss: 149.6414\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.6576 - val_loss: 173.1790\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.7148 - val_loss: 135.7345\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.8732 - val_loss: 195.7373\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.7662 - val_loss: 211.9989\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.3704 - val_loss: 141.9800\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9653 - val_loss: 159.7266\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2291 - val_loss: 136.5583\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7522 - val_loss: 144.2386\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6472 - val_loss: 247.9017\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.9375 - val_loss: 190.2288\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.9751 - val_loss: 150.2028\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1082 - val_loss: 140.2362\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.0440 - val_loss: 185.3187\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 260.7700 - val_loss: 159.3482\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.3064 - val_loss: 207.7697\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.0665 - val_loss: 172.9835\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2982 - val_loss: 138.2529\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9606 - val_loss: 145.3379\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7369 - val_loss: 219.0157\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.1038 - val_loss: 138.8665\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.8911 - val_loss: 281.1313\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7983 - val_loss: 164.0561\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.0309 - val_loss: 711.3559\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.6632 - val_loss: 139.6251\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4255 - val_loss: 142.9853\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5784 - val_loss: 179.9388\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.8613 - val_loss: 156.7670\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.3792 - val_loss: 250.8752\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.0504 - val_loss: 158.5829\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0237 - val_loss: 174.9989\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.7400 - val_loss: 618.7245\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.2340 - val_loss: 151.3491\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5263 - val_loss: 187.4032\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1652 - val_loss: 141.3215\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0113 - val_loss: 143.0191\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.0041 - val_loss: 193.4778\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.2525 - val_loss: 161.6182\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.4511 - val_loss: 162.9818\n",
      "Epoch 663/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.5924 - val_loss: 198.7310\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.5229 - val_loss: 147.6468\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 228.6313 - val_loss: 786.3736\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 255.3060 - val_loss: 180.3052\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 160.7098 - val_loss: 192.6678\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.1112 - val_loss: 145.8102\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.6784 - val_loss: 134.6923\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.2900 - val_loss: 166.1473\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.4642 - val_loss: 160.2660\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1018 - val_loss: 133.5894\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3278 - val_loss: 173.2722\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8535 - val_loss: 176.7989\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.4339 - val_loss: 263.0678\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4810 - val_loss: 130.3374\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.5519 - val_loss: 174.9010\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.2580 - val_loss: 157.2455\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.6111 - val_loss: 130.5847\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.7769 - val_loss: 140.0247\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 313.7910 - val_loss: 165.6586\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 151.5171 - val_loss: 246.2100\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 160.1596 - val_loss: 144.2721\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 181.9719 - val_loss: 348.1963\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.1228 - val_loss: 129.4953\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8036 - val_loss: 158.0412\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.3267 - val_loss: 138.4710\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.0758 - val_loss: 225.0359\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8086 - val_loss: 154.3487\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8331 - val_loss: 132.9501\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8100 - val_loss: 184.0820\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.8817 - val_loss: 139.7949\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3242 - val_loss: 144.1178\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3936 - val_loss: 170.3282\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0784 - val_loss: 136.6171\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9613 - val_loss: 170.7722\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.4124 - val_loss: 484.2449\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.4378 - val_loss: 163.8864\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 213.3219 - val_loss: 141.5325\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4105 - val_loss: 173.3105\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.0089 - val_loss: 131.5498\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 320.3726 - val_loss: 1636.5202\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 370.2796 - val_loss: 206.1374\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.9618 - val_loss: 136.9466\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.8932 - val_loss: 280.6791\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.4559 - val_loss: 132.4007\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7907 - val_loss: 131.7598\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.4385 - val_loss: 131.6731\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7485 - val_loss: 180.9475\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.5792 - val_loss: 139.5348\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2957 - val_loss: 169.2845\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3575 - val_loss: 133.1218\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.3991 - val_loss: 282.6543\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.3641 - val_loss: 144.0836\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 380.3643 - val_loss: 165.5399\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.7625 - val_loss: 240.4821\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3533 - val_loss: 132.4336\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3219 - val_loss: 151.4616\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5154 - val_loss: 129.9353\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.4248 - val_loss: 154.6935\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9958 - val_loss: 137.4908\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6862 - val_loss: 135.6614\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4249 - val_loss: 348.8360\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.5786 - val_loss: 171.2726\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2661 - val_loss: 158.9314\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4354 - val_loss: 132.6477\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7504 - val_loss: 135.5612\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7449 - val_loss: 130.2673\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.2419 - val_loss: 149.2869\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9819 - val_loss: 140.9868\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4036 - val_loss: 159.9836\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4197 - val_loss: 132.7556\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4712 - val_loss: 140.5645\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6283 - val_loss: 166.3768\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.1487 - val_loss: 194.3179\n",
      "Epoch 736/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.3937 - val_loss: 129.6844\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6187 - val_loss: 128.8967\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.5200 - val_loss: 133.9892\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3142 - val_loss: 144.9683\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4073 - val_loss: 140.3061\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 145.004 - 0s 51us/step - loss: 145.6078 - val_loss: 168.7803\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.7691 - val_loss: 179.3236\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.3229 - val_loss: 128.8678\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7001 - val_loss: 144.0277\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.8143 - val_loss: 138.2680\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3593 - val_loss: 148.8024\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9633 - val_loss: 139.2880\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.0746 - val_loss: 162.7386\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1169 - val_loss: 163.4866\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.4831 - val_loss: 135.5328\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 137.8582 - val_loss: 127.3496\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9383 - val_loss: 142.1570\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 154.4211 - val_loss: 278.2747\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 207.1865 - val_loss: 169.3275\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 150.9554 - val_loss: 145.1864\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.2698 - val_loss: 191.2235\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.5463 - val_loss: 193.3104\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.8258 - val_loss: 130.1953\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.6518 - val_loss: 142.6501\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1196 - val_loss: 169.4764\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3526 - val_loss: 139.6386\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.5812 - val_loss: 152.7782\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.8760 - val_loss: 126.9824\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7285 - val_loss: 140.7742\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8045 - val_loss: 141.5550\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3283 - val_loss: 142.5583\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4921 - val_loss: 144.4299\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 181.6711 - val_loss: 136.5192\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1045 - val_loss: 132.3791\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.2761 - val_loss: 135.3836\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 309.9145 - val_loss: 143.3589\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.4489 - val_loss: 144.2789\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.8483 - val_loss: 172.9905\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.8657 - val_loss: 228.5982\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 338.5385 - val_loss: 208.3765\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.7864 - val_loss: 211.5631\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9993 - val_loss: 133.3150\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8052 - val_loss: 131.0101\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2066 - val_loss: 631.4447\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.9258 - val_loss: 154.2752\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.5874 - val_loss: 126.6415\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4352 - val_loss: 136.5974\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.8603 - val_loss: 162.0372\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.6255 - val_loss: 183.5429\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.9081 - val_loss: 154.1480\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 257.5748 - val_loss: 148.2502\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.7612 - val_loss: 161.4390\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.3248 - val_loss: 189.4084\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7241 - val_loss: 138.9303\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4955 - val_loss: 141.4528\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.3792 - val_loss: 124.5628\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4722 - val_loss: 140.8186\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4258 - val_loss: 149.9283\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4733 - val_loss: 210.9775\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.0721 - val_loss: 146.4676\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5783 - val_loss: 148.4410\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4133 - val_loss: 178.4889\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3823 - val_loss: 188.9386\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.1291 - val_loss: 165.1993\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.8474 - val_loss: 135.1710\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.4161 - val_loss: 180.6696\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 156.3741 - val_loss: 133.0298\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.4438 - val_loss: 134.3269\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1933 - val_loss: 175.9574\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 517.0514 - val_loss: 334.5770\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.8118 - val_loss: 160.8813\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.1260 - val_loss: 215.3569\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.5960 - val_loss: 163.4097\n",
      "Epoch 809/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3268 - val_loss: 148.0502\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 184.1700 - val_loss: 186.0952\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.0088 - val_loss: 161.7861\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.1928 - val_loss: 132.5483\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.7316 - val_loss: 139.7985\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4020 - val_loss: 139.6453\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.9847 - val_loss: 316.0231\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.8461 - val_loss: 312.9730\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.6077 - val_loss: 141.0149\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.1553 - val_loss: 132.6867\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.2951 - val_loss: 158.0006\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.0297 - val_loss: 190.7691\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.9612 - val_loss: 182.4225\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6216 - val_loss: 160.2540\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0226 - val_loss: 153.7052\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 149.9858 - val_loss: 160.0046\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 170.4319 - val_loss: 143.3712\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 146.3040 - val_loss: 136.8206\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 160.9721 - val_loss: 172.3533\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7637 - val_loss: 151.4396\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7636 - val_loss: 166.2645\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5080 - val_loss: 135.2750\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3663 - val_loss: 130.7701\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.0189 - val_loss: 139.1882\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4451 - val_loss: 151.2582\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5834 - val_loss: 168.8952\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2253 - val_loss: 129.1226\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2091 - val_loss: 133.6235\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.4057 - val_loss: 141.3196\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9650 - val_loss: 149.5777\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1748 - val_loss: 148.1979\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7907 - val_loss: 142.5147\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9546 - val_loss: 144.0417\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7155 - val_loss: 132.0208\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1480 - val_loss: 132.6303\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.4850 - val_loss: 264.3552\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6700 - val_loss: 170.4690\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1582 - val_loss: 131.6408\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2017 - val_loss: 134.3632\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.7498 - val_loss: 184.3388\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 227.8474 - val_loss: 136.8680\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1606 - val_loss: 145.5639\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5423 - val_loss: 130.6484\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.3454 - val_loss: 127.3229\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.8485 - val_loss: 160.1804\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6911 - val_loss: 155.0189\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9842 - val_loss: 135.6202\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7045 - val_loss: 141.7219\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.3132 - val_loss: 141.1798\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.3550 - val_loss: 169.8446\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.3289 - val_loss: 145.7797\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3478 - val_loss: 144.3130\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6599 - val_loss: 133.0506\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.6162 - val_loss: 134.4511\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7382 - val_loss: 160.1731\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.0549 - val_loss: 158.4145\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.4001 - val_loss: 148.5309\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.8066 - val_loss: 178.6646\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.4172 - val_loss: 151.3367\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2016 - val_loss: 175.3248\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 187.2408 - val_loss: 218.6868\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6843 - val_loss: 173.7821\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9853 - val_loss: 132.4710\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.2702 - val_loss: 158.9023\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0856 - val_loss: 131.3356\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.0871 - val_loss: 147.3098\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4913 - val_loss: 160.8704\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.4092 - val_loss: 137.3230\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.6519 - val_loss: 138.0697\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6941 - val_loss: 148.1545\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9958 - val_loss: 151.6981\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8319 - val_loss: 343.0089\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.1451 - val_loss: 133.1816\n",
      "Epoch 882/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.7100 - val_loss: 147.2252\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.6047 - val_loss: 160.1884\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4363 - val_loss: 146.6957\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9670 - val_loss: 134.6112\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7459 - val_loss: 132.3110\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1315 - val_loss: 145.6444\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1130 - val_loss: 127.3493\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3118 - val_loss: 202.6409\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3140 - val_loss: 141.0972\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3753 - val_loss: 156.4210\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7015 - val_loss: 179.8633\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5218 - val_loss: 160.2355\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7737 - val_loss: 155.3290\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4627 - val_loss: 130.7297\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.1882 - val_loss: 137.9207\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 139.0141 - val_loss: 232.7451\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 156.5129 - val_loss: 137.8077\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 186.2860 - val_loss: 154.3427\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.0426 - val_loss: 136.3890\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0283 - val_loss: 137.7526\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5586 - val_loss: 192.7640\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2335 - val_loss: 134.8330\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.7192 - val_loss: 138.7146\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 245.6519 - val_loss: 130.8140\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8914 - val_loss: 134.9918\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7827 - val_loss: 130.8692\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6331 - val_loss: 160.9767\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 154.563 - 0s 51us/step - loss: 153.9785 - val_loss: 135.5504\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3664 - val_loss: 144.6006\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9277 - val_loss: 144.5738\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2109 - val_loss: 220.1568\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.9100 - val_loss: 139.2344\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3920 - val_loss: 135.0406\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3302 - val_loss: 130.6181\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.8349 - val_loss: 222.5713\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5395 - val_loss: 142.7615\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.1926 - val_loss: 130.0021\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5162 - val_loss: 137.3794\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6938 - val_loss: 129.7739\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5170 - val_loss: 143.0278\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3030 - val_loss: 161.8309\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.3855 - val_loss: 198.4497\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7046 - val_loss: 156.1869\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4607 - val_loss: 141.9322\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1121 - val_loss: 137.5374\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.3594 - val_loss: 164.5391\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0365 - val_loss: 141.1467\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0258 - val_loss: 127.3915\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9213 - val_loss: 142.4137\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7203 - val_loss: 141.4379\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7346 - val_loss: 130.9839\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1807 - val_loss: 189.8250\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6405 - val_loss: 333.1879\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.7593 - val_loss: 184.3622\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7543 - val_loss: 164.7075\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2184 - val_loss: 202.0196\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6703 - val_loss: 148.1568\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2740 - val_loss: 146.4168\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.4223 - val_loss: 129.5628\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.8875 - val_loss: 150.3194\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.3548 - val_loss: 151.1731\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.5643 - val_loss: 159.0574\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7416 - val_loss: 134.5698\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5237 - val_loss: 133.7679\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.4064 - val_loss: 148.1724\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2329 - val_loss: 158.4933\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5635 - val_loss: 149.1767\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5659 - val_loss: 273.7596\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7440 - val_loss: 155.0469\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.9892 - val_loss: 132.4198\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6063 - val_loss: 133.0765\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.4732 - val_loss: 191.2731\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 148.116 - 0s 51us/step - loss: 149.3390 - val_loss: 156.7895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 141.8986 - val_loss: 143.5330\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 166.2453 - val_loss: 190.9421\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 149.6943 - val_loss: 154.4387\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.1607 - val_loss: 162.4451\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.0665 - val_loss: 148.5212\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0222 - val_loss: 131.5966\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7472 - val_loss: 161.3834\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3704 - val_loss: 151.7644\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5531 - val_loss: 153.8288\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.5875 - val_loss: 137.4211\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.5943 - val_loss: 126.6113\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0225 - val_loss: 148.1689\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2140 - val_loss: 171.7740\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.9993 - val_loss: 138.6820\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3955 - val_loss: 132.4186\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.2178 - val_loss: 135.4645\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 190.6304 - val_loss: 141.7601\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 150.3153 - val_loss: 130.9682\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.7668 - val_loss: 127.8556\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3545 - val_loss: 155.4416\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2203 - val_loss: 145.5492\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2381 - val_loss: 138.7488\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0564 - val_loss: 144.1761\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 161.3934 - val_loss: 139.1755\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 142.1699 - val_loss: 130.9226\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 152.3758 - val_loss: 136.3924\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 147.7806 - val_loss: 152.7226\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 145.3272 - val_loss: 132.3287\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3403 - val_loss: 193.9147\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6446 - val_loss: 138.1636\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.7269 - val_loss: 194.5206\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6113 - val_loss: 132.9547\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 159.3143 - val_loss: 261.5644\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9699 - val_loss: 134.1752\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.3034 - val_loss: 159.5877\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5061 - val_loss: 135.9511\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3215 - val_loss: 127.0074\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.2307 - val_loss: 353.1933\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7300 - val_loss: 126.9975\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.0001 - val_loss: 208.4377\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1871 - val_loss: 132.6005\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8617 - val_loss: 194.7909\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.4184 - val_loss: 191.3557\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2582 - val_loss: 128.1878\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4826 - val_loss: 137.6536\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5375 - val_loss: 143.2704\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 223.056 - 0s 51us/step - loss: 221.2408 - val_loss: 141.7059\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1135 - val_loss: 136.9905\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8580 - val_loss: 132.2055\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9065 - val_loss: 131.1458\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.2525 - val_loss: 151.7840\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.5725 - val_loss: 141.2913\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8689 - val_loss: 135.3314\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.1232 - val_loss: 244.1889\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.0070 - val_loss: 136.5319\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1659 - val_loss: 173.4806\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.2617 - val_loss: 153.8160\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7556 - val_loss: 244.4296\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.1937 - val_loss: 398.8840\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.2552 - val_loss: 159.3447\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6979 - val_loss: 188.1605\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5731 - val_loss: 134.2201\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7142 - val_loss: 143.2048\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5954 - val_loss: 145.3853\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.2491 - val_loss: 262.2649\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 285.9200 - val_loss: 146.5857\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.7598 - val_loss: 139.8247\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5872 - val_loss: 184.6534\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.1986 - val_loss: 144.9665\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.1286 - val_loss: 137.5821\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.6334 - val_loss: 146.6721\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.0793 - val_loss: 271.6470\n",
      "Epoch 1027/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.4565 - val_loss: 141.6988\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.8126 - val_loss: 202.7107\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.2922 - val_loss: 194.5370\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.4685 - val_loss: 209.5399\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.3415 - val_loss: 216.3955\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.8376 - val_loss: 129.8182\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7719 - val_loss: 130.5175\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4267 - val_loss: 147.4128\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.6466 - val_loss: 169.8392\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9548 - val_loss: 171.1379\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3501 - val_loss: 148.3797\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5617 - val_loss: 129.2090\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 212.058 - 0s 57us/step - loss: 211.8111 - val_loss: 144.4608\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 170.8309 - val_loss: 140.0300\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 160.6912 - val_loss: 220.7746\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 157.1386 - val_loss: 137.0743\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.9788 - val_loss: 128.5247\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2783 - val_loss: 149.3735\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 330.2050 - val_loss: 237.2876\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.0183 - val_loss: 144.8492\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9798 - val_loss: 131.4937\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.7984 - val_loss: 134.5646\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4834 - val_loss: 164.3873\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5040 - val_loss: 152.7582\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5530 - val_loss: 132.3001\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3561 - val_loss: 130.4902\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6197 - val_loss: 145.9679\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 230.8172 - val_loss: 145.0469\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 175.8767 - val_loss: 138.8109\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.1003 - val_loss: 199.6322\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 137.2694 - val_loss: 154.1381\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.7154 - val_loss: 157.0230\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.7213 - val_loss: 130.1239\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.2832 - val_loss: 287.8398\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.8344 - val_loss: 145.8742\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.8061 - val_loss: 131.6588\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1280 - val_loss: 148.8555\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7156 - val_loss: 167.6201\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 214.2619 - val_loss: 173.6984\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8636 - val_loss: 232.4507\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6792 - val_loss: 133.3307\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.6874 - val_loss: 148.1403\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5934 - val_loss: 131.8373\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0615 - val_loss: 170.8456\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8342 - val_loss: 151.6662\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7576 - val_loss: 156.6116\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.3299 - val_loss: 155.1056\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.1537 - val_loss: 595.1728\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.1668 - val_loss: 382.0637\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.2618 - val_loss: 148.6388\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0881 - val_loss: 129.2350\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3570 - val_loss: 172.5199\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.8476 - val_loss: 131.8494\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9728 - val_loss: 141.1945\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9563 - val_loss: 161.5736\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5455 - val_loss: 159.5258\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.1233 - val_loss: 124.3601\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3313 - val_loss: 128.1842\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8917 - val_loss: 179.3704\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3759 - val_loss: 146.6107\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 229.5731 - val_loss: 257.2913\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.5788 - val_loss: 173.0142\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8690 - val_loss: 165.9845\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0271 - val_loss: 213.8636\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9032 - val_loss: 129.3043\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8544 - val_loss: 167.3044\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1743 - val_loss: 136.0466\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9701 - val_loss: 152.5469\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3424 - val_loss: 150.6637\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7061 - val_loss: 169.3516\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.9919 - val_loss: 133.3901\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8741 - val_loss: 130.2370\n",
      "Epoch 1099/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4107 - val_loss: 144.2710\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.3936 - val_loss: 130.8246\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.1184 - val_loss: 177.8065\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0780 - val_loss: 141.4782\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.2633 - val_loss: 144.6726\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.6173 - val_loss: 139.4484\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0673 - val_loss: 147.9898\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5029 - val_loss: 138.2279\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5421 - val_loss: 144.6022\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1642 - val_loss: 146.5102\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2118 - val_loss: 132.0906\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.0690 - val_loss: 153.5969\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 144.7807 - val_loss: 216.5262\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 285.4181 - val_loss: 149.0889\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 132.7792 - val_loss: 129.1164\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.9371 - val_loss: 168.5630\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9338 - val_loss: 137.8266\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6954 - val_loss: 173.0998\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8491 - val_loss: 204.3850\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.3597 - val_loss: 129.9840\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5029 - val_loss: 143.7885\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9874 - val_loss: 125.5655\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9106 - val_loss: 130.0366\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2953 - val_loss: 160.1894\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4707 - val_loss: 143.9788\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.9455 - val_loss: 145.6535\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.2557 - val_loss: 137.6472\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.4712 - val_loss: 176.4548\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1273 - val_loss: 145.9302\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0680 - val_loss: 168.2656\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 260.0986 - val_loss: 158.5658\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.9947 - val_loss: 132.8374\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2682 - val_loss: 130.0108\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5601 - val_loss: 132.4535\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1534 - val_loss: 131.0926\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9269 - val_loss: 153.9657\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5253 - val_loss: 136.7053\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.2403 - val_loss: 146.4232\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.2052 - val_loss: 132.1925\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4732 - val_loss: 149.4254\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6912 - val_loss: 134.9045\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8981 - val_loss: 131.0193\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9905 - val_loss: 155.5099\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5566 - val_loss: 135.5730\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9873 - val_loss: 140.8553\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3102 - val_loss: 132.9529\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5570 - val_loss: 141.1966\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7169 - val_loss: 131.5577\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0723 - val_loss: 133.9055\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7966 - val_loss: 134.8516\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6219 - val_loss: 174.9765\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.1033 - val_loss: 167.1057\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6065 - val_loss: 148.8920\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8435 - val_loss: 150.6241\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9494 - val_loss: 148.3441\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8468 - val_loss: 135.2746\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.1445 - val_loss: 167.0429\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.1850 - val_loss: 214.8980\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3409 - val_loss: 198.0708\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3187 - val_loss: 151.6780\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6532 - val_loss: 162.2403\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7224 - val_loss: 128.6465\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1520 - val_loss: 144.3437\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9365 - val_loss: 134.1143\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7397 - val_loss: 163.9475\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4275 - val_loss: 176.0497\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7415 - val_loss: 157.9330\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5437 - val_loss: 183.3647\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.1350 - val_loss: 142.4446\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.1352 - val_loss: 127.3235\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3314 - val_loss: 153.2025\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2122 - val_loss: 150.6321\n",
      "Epoch 1171/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5599 - val_loss: 189.1016\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0726 - val_loss: 256.0582\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1251 - val_loss: 236.8879\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0121 - val_loss: 167.6480\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3089 - val_loss: 154.0931\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.5744 - val_loss: 176.4412\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6872 - val_loss: 128.0498\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9769 - val_loss: 148.7851\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1432 - val_loss: 155.4021\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0090 - val_loss: 131.2562\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.4009 - val_loss: 164.2554\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0720 - val_loss: 160.3079\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 152.7637 - val_loss: 234.6572\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 130.4665 - val_loss: 131.0826\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 138.2841 - val_loss: 135.1929\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 146.3040 - val_loss: 270.5714\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7416 - val_loss: 198.3881\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.6459 - val_loss: 129.9479\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.0407 - val_loss: 124.1787\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9922 - val_loss: 154.4197\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1454 - val_loss: 139.0595\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3163 - val_loss: 148.4925\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1373 - val_loss: 334.2237\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3995 - val_loss: 137.3171\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.3688 - val_loss: 148.5675\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6716 - val_loss: 133.7297\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0250 - val_loss: 128.6169\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1206 - val_loss: 160.7991\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.0196 - val_loss: 137.5497\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5513 - val_loss: 154.8135\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2250 - val_loss: 152.5029\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6477 - val_loss: 137.1610\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9998 - val_loss: 133.9577\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1978 - val_loss: 146.2950\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3913 - val_loss: 327.1383\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 205.4723 - val_loss: 147.3399\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.4563 - val_loss: 149.4383\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.2345 - val_loss: 126.5930\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 195.1064 - val_loss: 126.9942\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5438 - val_loss: 166.9967\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.0988 - val_loss: 144.2401\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4423 - val_loss: 134.4262\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4355 - val_loss: 130.0255\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9877 - val_loss: 148.5195\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9090 - val_loss: 168.7191\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1564 - val_loss: 245.0257\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7929 - val_loss: 130.8778\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7291 - val_loss: 217.0755\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2915 - val_loss: 154.9667\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3352 - val_loss: 168.9266\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8141 - val_loss: 130.5216\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5766 - val_loss: 140.8973\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3223 - val_loss: 168.0111\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6487 - val_loss: 163.7101\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1174 - val_loss: 126.2339\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.2137 - val_loss: 137.5329\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8065 - val_loss: 159.6909\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3329 - val_loss: 140.4427\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8591 - val_loss: 139.6662\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3161 - val_loss: 129.3663\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2027 - val_loss: 149.3810\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7497 - val_loss: 128.4935\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.4194 - val_loss: 142.0177\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5932 - val_loss: 129.0035\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5562 - val_loss: 131.5789\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8821 - val_loss: 127.3615\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.9004 - val_loss: 130.0677\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3326 - val_loss: 260.0318\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.9109 - val_loss: 158.0519\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.0276 - val_loss: 149.7170\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7692 - val_loss: 125.9569\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4395 - val_loss: 141.7051\n",
      "Epoch 1243/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3355 - val_loss: 145.7609\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.6839 - val_loss: 126.5627\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0328 - val_loss: 139.0554\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.4941 - val_loss: 136.4710\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5294 - val_loss: 136.5576\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2998 - val_loss: 131.6941\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.1041 - val_loss: 946.3943\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.9430 - val_loss: 129.0659\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2084 - val_loss: 129.6142\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8185 - val_loss: 156.7252\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0191 - val_loss: 150.2491\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2398 - val_loss: 135.5350\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.8586 - val_loss: 167.9954\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 134.3231 - val_loss: 127.8051\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.1915 - val_loss: 171.5194\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.0818 - val_loss: 145.2330\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7745 - val_loss: 224.8021\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.9549 - val_loss: 143.0472\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3525 - val_loss: 176.9885\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1810 - val_loss: 151.9476\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0725 - val_loss: 138.8527\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9044 - val_loss: 140.5967\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6187 - val_loss: 131.8583\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 267.3124 - val_loss: 168.5750\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 278.0946 - val_loss: 157.1361\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1099 - val_loss: 140.5482\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4478 - val_loss: 149.4318\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8725 - val_loss: 144.6348\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 202.1559 - val_loss: 158.1770\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.2505 - val_loss: 135.5638\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2266 - val_loss: 148.4252\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2722 - val_loss: 138.7144\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4151 - val_loss: 145.0669\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5164 - val_loss: 126.0702\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7029 - val_loss: 147.5015\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.3065 - val_loss: 144.5831\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1089 - val_loss: 183.8359\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.0377 - val_loss: 127.6014\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.8806 - val_loss: 146.2758\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.0560 - val_loss: 167.6992\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.0463 - val_loss: 139.1119\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1130 - val_loss: 153.0539\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9884 - val_loss: 134.6536\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1405 - val_loss: 135.1211\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1906 - val_loss: 134.5683\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9521 - val_loss: 163.4130\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 293.4411 - val_loss: 141.5201\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.0055 - val_loss: 195.8618\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2253 - val_loss: 135.1894\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4338 - val_loss: 133.7607\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.7582 - val_loss: 217.5191\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.7665 - val_loss: 187.1371\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.9611 - val_loss: 132.0833\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9231 - val_loss: 140.5516\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6202 - val_loss: 131.2735\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2555 - val_loss: 149.0231\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0047 - val_loss: 149.3730\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.9388 - val_loss: 144.6532\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7546 - val_loss: 137.0440\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7816 - val_loss: 140.7387\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.0417 - val_loss: 164.6754\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.7855 - val_loss: 141.2564\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0955 - val_loss: 146.8118\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6187 - val_loss: 174.0066\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5282 - val_loss: 130.0390\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5982 - val_loss: 148.4207\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1198 - val_loss: 156.2000\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.0966 - val_loss: 126.1435\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.0355 - val_loss: 127.4786\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.2093 - val_loss: 131.6086\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.0305 - val_loss: 140.8740\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7295 - val_loss: 145.8403\n",
      "Epoch 1315/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 0s - loss: 140.671 - 0s 51us/step - loss: 142.6468 - val_loss: 180.4885\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.2636 - val_loss: 137.9814\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2940 - val_loss: 157.2387\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8445 - val_loss: 149.4187\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.9808 - val_loss: 173.9800\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7456 - val_loss: 131.1927\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6434 - val_loss: 132.0468\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2161 - val_loss: 142.2905\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9236 - val_loss: 144.5971\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6356 - val_loss: 139.7324\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2245 - val_loss: 141.7093\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2108 - val_loss: 141.6339\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.7821 - val_loss: 189.1921\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 150.3435 - val_loss: 160.4877\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 133.4463 - val_loss: 132.4937\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.6802 - val_loss: 137.6475\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8528 - val_loss: 131.9396\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.8455 - val_loss: 215.2681\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.9214 - val_loss: 136.7900\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7021 - val_loss: 316.2090\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5562 - val_loss: 139.2044\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6115 - val_loss: 128.6725\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0765 - val_loss: 127.1402\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.4664 - val_loss: 232.7653\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9523 - val_loss: 165.1975\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3197 - val_loss: 125.9117\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3185 - val_loss: 135.9747\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5759 - val_loss: 165.3137\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9555 - val_loss: 128.8608\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4267 - val_loss: 136.4329\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6761 - val_loss: 131.2029\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0836 - val_loss: 145.8293\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4517 - val_loss: 135.2718\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7303 - val_loss: 148.5575\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7938 - val_loss: 133.9700\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.0087 - val_loss: 137.5795\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7772 - val_loss: 148.5171\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9717 - val_loss: 126.2068\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.3353 - val_loss: 206.6627\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.2760 - val_loss: 130.9535\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8911 - val_loss: 133.7545\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2330 - val_loss: 172.4591\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 146.778 - 0s 51us/step - loss: 145.5141 - val_loss: 125.5098\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2231 - val_loss: 159.2313\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1199 - val_loss: 159.0016\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4937 - val_loss: 137.5439\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0610 - val_loss: 147.2405\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6516 - val_loss: 129.9309\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.4904 - val_loss: 324.2988\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 185.5830 - val_loss: 137.2483\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4062 - val_loss: 132.8836\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9484 - val_loss: 137.0503\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1059 - val_loss: 161.5801\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8862 - val_loss: 164.7945\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0773 - val_loss: 148.2473\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8560 - val_loss: 141.0645\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8918 - val_loss: 154.4517\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7980 - val_loss: 203.0957\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1594 - val_loss: 148.5659\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0483 - val_loss: 127.0672\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0417 - val_loss: 164.5295\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3225 - val_loss: 174.6630\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.9246 - val_loss: 130.0982\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.5320 - val_loss: 127.2513\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.7347 - val_loss: 163.9015\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.4413 - val_loss: 226.8024\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3106 - val_loss: 143.9875\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5681 - val_loss: 135.2303\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.7459 - val_loss: 123.2910\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 128.6670 - val_loss: 144.2740\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.2465 - val_loss: 137.1828\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.3966 - val_loss: 141.5647\n",
      "Epoch 1387/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.9635 - val_loss: 230.0472\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.2519 - val_loss: 160.8536\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.8633 - val_loss: 165.1741\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.0675 - val_loss: 144.2762\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9491 - val_loss: 138.9851\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.8235 - val_loss: 134.3357\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3322 - val_loss: 126.3729\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8040 - val_loss: 123.3181\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1667 - val_loss: 133.3391\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 334.1653 - val_loss: 152.6703\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.2884 - val_loss: 223.2940\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.4805 - val_loss: 196.4957\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 166.6029 - val_loss: 139.3442\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 155.3968 - val_loss: 153.0323\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 149.3427 - val_loss: 128.7121\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 141.2914 - val_loss: 131.2709\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 136.3213 - val_loss: 219.2664\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.4011 - val_loss: 133.9098\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7573 - val_loss: 128.2802\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 143.183 - 0s 51us/step - loss: 143.2359 - val_loss: 151.0376\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.1069 - val_loss: 163.6724\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.1155 - val_loss: 130.5592\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2429 - val_loss: 129.9398\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3562 - val_loss: 138.5125\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8653 - val_loss: 129.8715\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.0582 - val_loss: 164.7747\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0446 - val_loss: 130.4941\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6699 - val_loss: 143.8763\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.0249 - val_loss: 143.5095\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2147 - val_loss: 147.0265\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6810 - val_loss: 156.0030\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.1310 - val_loss: 127.8595\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.5060 - val_loss: 137.2224\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.4023 - val_loss: 126.7679\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8795 - val_loss: 142.4094\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4178 - val_loss: 132.4570\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2719 - val_loss: 130.2365\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1251 - val_loss: 193.7659\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7386 - val_loss: 149.5661\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2442 - val_loss: 177.3772\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.1731 - val_loss: 134.1582\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2963 - val_loss: 150.5155\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8594 - val_loss: 132.1394\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2271 - val_loss: 175.0072\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1214 - val_loss: 140.3281\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5031 - val_loss: 130.1429\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0193 - val_loss: 130.3590\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4107 - val_loss: 130.2491\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6229 - val_loss: 131.4856\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.6197 - val_loss: 135.1500\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6779 - val_loss: 151.9378\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.8595 - val_loss: 176.9084\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8804 - val_loss: 138.3734\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9694 - val_loss: 152.0922\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2392 - val_loss: 163.2238\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4556 - val_loss: 159.4327\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5379 - val_loss: 187.3428\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7009 - val_loss: 144.1417\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.6085 - val_loss: 143.7112\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3795 - val_loss: 136.9843\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.4048 - val_loss: 130.7802\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.2745 - val_loss: 164.1449\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.2401 - val_loss: 138.8254\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8831 - val_loss: 131.4528\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2726 - val_loss: 133.9364\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8214 - val_loss: 135.8877\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.7113 - val_loss: 139.7258\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.9832 - val_loss: 144.6363\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.0433 - val_loss: 137.8343\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2763 - val_loss: 135.6147\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.6038 - val_loss: 148.9438\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.8520 - val_loss: 188.8206\n",
      "Epoch 1459/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.9440 - val_loss: 157.6108\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2163 - val_loss: 204.7973\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7375 - val_loss: 134.0995\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.4321 - val_loss: 136.5662\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1079 - val_loss: 175.3065\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7013 - val_loss: 134.1114\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 199.1637 - val_loss: 183.9887\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3042 - val_loss: 133.1162\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8805 - val_loss: 147.5873\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 155.0217 - val_loss: 139.2838\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 137.4085 - val_loss: 134.3971\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 126.5767 - val_loss: 146.4706\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 132.4922 - val_loss: 149.6908\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.1292 - val_loss: 221.0683\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.4200 - val_loss: 131.7176\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.0402 - val_loss: 133.2000\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9775 - val_loss: 163.5041\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7020 - val_loss: 140.0918\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.0830 - val_loss: 133.1189\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9544 - val_loss: 134.1536\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6181 - val_loss: 190.2886\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0999 - val_loss: 135.7485\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2749 - val_loss: 129.2278\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.9811 - val_loss: 144.4391\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.4206 - val_loss: 146.9854\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5671 - val_loss: 185.1231\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5382 - val_loss: 152.4912\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6826 - val_loss: 137.6432\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2561 - val_loss: 158.6774\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7903 - val_loss: 251.0607\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.2059 - val_loss: 200.5242\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3288 - val_loss: 145.3657\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0983 - val_loss: 140.4527\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7522 - val_loss: 140.3690\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.8281 - val_loss: 135.4915\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4638 - val_loss: 149.8492\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.5848 - val_loss: 171.0579\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2052 - val_loss: 155.4513\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7988 - val_loss: 138.5820\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.4484 - val_loss: 150.9992\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5162 - val_loss: 140.3681\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9661 - val_loss: 175.6668\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4730 - val_loss: 133.3541\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5398 - val_loss: 132.3043\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4469 - val_loss: 129.9830\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.9753 - val_loss: 150.9907\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4330 - val_loss: 132.9575\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7159 - val_loss: 194.5538\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.1155 - val_loss: 141.7503\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3881 - val_loss: 136.6761\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4681 - val_loss: 148.0322\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2891 - val_loss: 225.2652\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1905 - val_loss: 308.8202\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6597 - val_loss: 129.3663\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3781 - val_loss: 142.2092\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4685 - val_loss: 128.8246\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.2821 - val_loss: 140.4468\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.3914 - val_loss: 128.8417\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7816 - val_loss: 162.2219\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2691 - val_loss: 133.2097\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4494 - val_loss: 145.3834\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3916 - val_loss: 158.8055\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2284 - val_loss: 222.7852\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1525 - val_loss: 191.6825\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5941 - val_loss: 133.4899\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.7401 - val_loss: 190.0704\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2922 - val_loss: 126.8517\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.5358 - val_loss: 132.1402\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.8057 - val_loss: 129.5056\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0010 - val_loss: 174.7583\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0131 - val_loss: 146.2698\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.0672 - val_loss: 154.9845\n",
      "Epoch 1531/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2293 - val_loss: 180.4809\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0151 - val_loss: 138.4724\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8270 - val_loss: 126.9207\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7518 - val_loss: 135.1550\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8081 - val_loss: 159.3265\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5168 - val_loss: 134.4656\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4192 - val_loss: 171.1177\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8292 - val_loss: 177.9302\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5545 - val_loss: 126.8782\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.5513 - val_loss: 167.3526\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 154.8186 - val_loss: 148.9995\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 153.9243 - val_loss: 166.4674\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.0946 - val_loss: 130.8316\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2004 - val_loss: 126.1334\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4318 - val_loss: 128.1160\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5653 - val_loss: 133.3638\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3569 - val_loss: 317.6155\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4639 - val_loss: 151.0213\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2513 - val_loss: 137.7426\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.0889 - val_loss: 147.6619\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3021 - val_loss: 137.2744\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1361 - val_loss: 129.1391\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4053 - val_loss: 133.1152\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3533 - val_loss: 185.1832\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.4712 - val_loss: 126.0379\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.9923 - val_loss: 133.3987\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4377 - val_loss: 148.8819\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5991 - val_loss: 221.7505\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8807 - val_loss: 141.9575\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4364 - val_loss: 174.1114\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5393 - val_loss: 158.4781\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.0575 - val_loss: 137.2864\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4524 - val_loss: 134.2793\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.1346 - val_loss: 136.2325\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4353 - val_loss: 134.2755\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0993 - val_loss: 140.5677\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0647 - val_loss: 146.9325\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.6780 - val_loss: 133.7754\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.1257 - val_loss: 132.9328\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.5178 - val_loss: 148.9960\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4231 - val_loss: 153.2815\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3542 - val_loss: 131.6732\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4997 - val_loss: 137.8633\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4432 - val_loss: 127.9848\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.4932 - val_loss: 143.8119\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8465 - val_loss: 132.7659\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.2114 - val_loss: 142.4886\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0889 - val_loss: 129.2822\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.1859 - val_loss: 193.4386\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9143 - val_loss: 213.1172\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4093 - val_loss: 177.8251\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3802 - val_loss: 132.8661\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1519 - val_loss: 130.5157\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6645 - val_loss: 206.2425\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0960 - val_loss: 140.1555\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4422 - val_loss: 135.5333\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 137.709 - 0s 51us/step - loss: 136.8623 - val_loss: 131.1958\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8547 - val_loss: 170.0281\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.4169 - val_loss: 158.0056\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2474 - val_loss: 155.2763\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.8075 - val_loss: 152.9635\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.7807 - val_loss: 168.6540\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6955 - val_loss: 153.3138\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 249.0564 - val_loss: 171.2123\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.5554 - val_loss: 204.9537\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.9090 - val_loss: 181.4325\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 162.3494 - val_loss: 161.2217\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.5182 - val_loss: 176.6751\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.8150 - val_loss: 145.6823\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.2695 - val_loss: 146.1049\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.7267 - val_loss: 158.9962\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.3093 - val_loss: 263.5643\n",
      "Epoch 1603/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.5546 - val_loss: 130.6575\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7115 - val_loss: 173.1575\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.8999 - val_loss: 156.6471\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2575 - val_loss: 133.7661\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4715 - val_loss: 151.0723\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2083 - val_loss: 196.0686\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.7992 - val_loss: 183.9639\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0342 - val_loss: 138.4741\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 146.857 - 0s 51us/step - loss: 147.6614 - val_loss: 181.8689\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 159.4236 - val_loss: 138.7442\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 133.3030 - val_loss: 271.8557\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 142.6558 - val_loss: 139.6648\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 159.2216 - val_loss: 170.8213\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.6466 - val_loss: 156.6102\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.5614 - val_loss: 148.2548\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.9816 - val_loss: 169.5930\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.2681 - val_loss: 200.7374\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7535 - val_loss: 224.9443\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3564 - val_loss: 163.1802\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.3921 - val_loss: 145.7610\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1600 - val_loss: 148.9974\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8637 - val_loss: 161.9538\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.0927 - val_loss: 139.2503\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3388 - val_loss: 159.3675\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.4776 - val_loss: 128.2343\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2580 - val_loss: 492.3156\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8109 - val_loss: 147.6473\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4304 - val_loss: 192.3115\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1422 - val_loss: 143.3215\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8883 - val_loss: 147.0164\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6798 - val_loss: 206.8243\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1453 - val_loss: 138.9765\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2769 - val_loss: 152.9318\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.5339 - val_loss: 153.7443\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.4918 - val_loss: 139.5137\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3265 - val_loss: 137.9256\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0220 - val_loss: 158.3568\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4809 - val_loss: 134.0081\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9498 - val_loss: 181.2662\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3239 - val_loss: 145.9548\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.8759 - val_loss: 156.0678\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.1312 - val_loss: 143.2618\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7837 - val_loss: 135.4025\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6807 - val_loss: 131.0155\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3805 - val_loss: 136.3285\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1953 - val_loss: 154.6959\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.7613 - val_loss: 145.5086\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5403 - val_loss: 133.1293\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.6232 - val_loss: 132.7107\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1979 - val_loss: 134.6472\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8880 - val_loss: 135.3117\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.1076 - val_loss: 262.8123\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.1345 - val_loss: 135.8938\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7679 - val_loss: 149.6779\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1552 - val_loss: 148.2712\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4311 - val_loss: 142.4588\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4558 - val_loss: 131.6759\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2477 - val_loss: 136.4841\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4160 - val_loss: 139.2084\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3854 - val_loss: 147.2196\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9456 - val_loss: 138.2747\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1025 - val_loss: 183.4566\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.5453 - val_loss: 141.9401\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4498 - val_loss: 157.6126\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4538 - val_loss: 135.7518\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.8271 - val_loss: 132.8865\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1446 - val_loss: 141.8230\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3415 - val_loss: 167.0056\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.6921 - val_loss: 131.0631\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9309 - val_loss: 133.6002\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7655 - val_loss: 143.3494\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.2736 - val_loss: 252.1285\n",
      "Epoch 1675/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.1899 - val_loss: 150.3347\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4556 - val_loss: 167.1891\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9032 - val_loss: 143.0855\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1596 - val_loss: 128.5133\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3754 - val_loss: 138.0420\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6793 - val_loss: 136.1924\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0944 - val_loss: 161.6176\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.0368 - val_loss: 132.9555\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5727 - val_loss: 179.3458\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 192.5787 - val_loss: 128.7358\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.9795 - val_loss: 133.8516\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 133.1662 - val_loss: 165.1397\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 172.2227 - val_loss: 142.6299\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.3537 - val_loss: 138.6403\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.4956 - val_loss: 139.4350\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.6947 - val_loss: 151.5856\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8120 - val_loss: 127.6971\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3700 - val_loss: 139.7334\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2223 - val_loss: 128.8291\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.1612 - val_loss: 128.8558\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.8915 - val_loss: 152.1689\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.3152 - val_loss: 180.0515\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.5957 - val_loss: 147.9986\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3201 - val_loss: 138.3737\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2938 - val_loss: 134.9275\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.8305 - val_loss: 137.1109\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.1421 - val_loss: 132.0758\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6227 - val_loss: 130.8576\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.6150 - val_loss: 144.5520\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7138 - val_loss: 143.8322\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.5552 - val_loss: 130.4484\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.8430 - val_loss: 134.6173\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3785 - val_loss: 127.1061\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8925 - val_loss: 142.7571\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3487 - val_loss: 178.4929\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0589 - val_loss: 125.6255\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0318 - val_loss: 130.2668\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.7160 - val_loss: 140.8460\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.3379 - val_loss: 131.0832\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0053 - val_loss: 132.6221\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9764 - val_loss: 128.8760\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2229 - val_loss: 185.4642\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2707 - val_loss: 133.4967\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0409 - val_loss: 136.7079\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0838 - val_loss: 133.7652\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7829 - val_loss: 138.9313\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6374 - val_loss: 291.9824\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7655 - val_loss: 172.7751\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9731 - val_loss: 125.8700\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2359 - val_loss: 153.0917\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5265 - val_loss: 141.5859\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0135 - val_loss: 170.0877\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6387 - val_loss: 137.6681\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6282 - val_loss: 253.3763\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5571 - val_loss: 140.0778\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.9082 - val_loss: 137.2633\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4294 - val_loss: 131.5239\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6276 - val_loss: 128.3416\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5945 - val_loss: 230.6761\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6162 - val_loss: 136.4842\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.4205 - val_loss: 129.5825\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6715 - val_loss: 142.9308\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7168 - val_loss: 151.4450\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5232 - val_loss: 142.5263\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 243.3268 - val_loss: 227.1827\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.3012 - val_loss: 129.7279\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.2090 - val_loss: 138.0505\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5144 - val_loss: 196.8542\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5518 - val_loss: 134.6153\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7442 - val_loss: 141.0565\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.9330 - val_loss: 147.0694\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6190 - val_loss: 129.2384\n",
      "Epoch 1747/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8310 - val_loss: 130.7274\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8353 - val_loss: 173.3749\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 383.3557 - val_loss: 152.9945\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1531 - val_loss: 136.6334\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3912 - val_loss: 192.4369\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0749 - val_loss: 139.6890\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4421 - val_loss: 137.2500\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9931 - val_loss: 133.2156\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.1677 - val_loss: 138.1760\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 137.9869 - val_loss: 152.7319\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 134.5824 - val_loss: 139.8866\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 126.2686 - val_loss: 127.5650\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 149.5548 - val_loss: 144.4986\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7424 - val_loss: 204.9306\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5857 - val_loss: 157.0219\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7132 - val_loss: 138.2602\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2166 - val_loss: 132.0439\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1397 - val_loss: 139.3072\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5489 - val_loss: 171.1532\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4978 - val_loss: 150.8613\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8865 - val_loss: 218.0420\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.1487 - val_loss: 141.1298\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9349 - val_loss: 159.9089\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6322 - val_loss: 179.4310\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5655 - val_loss: 139.4906\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5137 - val_loss: 151.9549\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 199.2420 - val_loss: 152.6225\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6585 - val_loss: 133.7439\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.6712 - val_loss: 137.6952\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.0104 - val_loss: 152.5450\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1175 - val_loss: 161.3410\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.1957 - val_loss: 133.9992\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4597 - val_loss: 132.3936\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.4016 - val_loss: 131.7402\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2643 - val_loss: 140.6828\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0721 - val_loss: 160.8180\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1831 - val_loss: 128.7455\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3579 - val_loss: 146.7503\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7827 - val_loss: 145.9138\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5476 - val_loss: 151.9576\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.7948 - val_loss: 137.6326\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.1440 - val_loss: 148.5625\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6484 - val_loss: 128.8479\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.7435 - val_loss: 142.0410\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8130 - val_loss: 126.5069\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5823 - val_loss: 158.4075\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5679 - val_loss: 157.8171\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.6867 - val_loss: 137.6894\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6747 - val_loss: 191.5466\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3211 - val_loss: 157.9283\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 210.3046 - val_loss: 167.0580\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8710 - val_loss: 233.8255\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3705 - val_loss: 125.5148\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4527 - val_loss: 169.8687\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5535 - val_loss: 185.4614\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6213 - val_loss: 214.6052\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3012 - val_loss: 125.8670\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7240 - val_loss: 168.3557\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6526 - val_loss: 126.1742\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4321 - val_loss: 180.9457\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6516 - val_loss: 128.5099\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.5875 - val_loss: 155.9289\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5193 - val_loss: 199.7220\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2537 - val_loss: 253.6650\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2887 - val_loss: 138.7285\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0519 - val_loss: 135.5023\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2578 - val_loss: 128.5458\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2273 - val_loss: 130.3975\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1463 - val_loss: 151.3417\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.3858 - val_loss: 190.9824\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4873 - val_loss: 138.3387\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.2695 - val_loss: 146.5159\n",
      "Epoch 1819/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6629 - val_loss: 127.7949\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8145 - val_loss: 149.9582\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.2441 - val_loss: 138.8992\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4577 - val_loss: 155.0412\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7236 - val_loss: 150.2425\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3111 - val_loss: 137.8138\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.3916 - val_loss: 137.0459\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2146 - val_loss: 133.0485\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7463 - val_loss: 176.1017\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 190.7014 - val_loss: 175.0348\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.7380 - val_loss: 124.6760\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 123.5778 - val_loss: 134.8854\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 135.0590 - val_loss: 180.8216\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.7877 - val_loss: 130.1261\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0189 - val_loss: 180.2298\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6581 - val_loss: 142.1045\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5411 - val_loss: 152.9042\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2921 - val_loss: 123.8179\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6239 - val_loss: 181.5822\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.5195 - val_loss: 152.1576\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.7171 - val_loss: 130.6527\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2712 - val_loss: 125.3209\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4875 - val_loss: 156.1585\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4480 - val_loss: 148.7376\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5916 - val_loss: 127.1239\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.3620 - val_loss: 152.7566\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4441 - val_loss: 134.9948\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.2084 - val_loss: 173.2337\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.6353 - val_loss: 138.1609\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3018 - val_loss: 130.0775\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7985 - val_loss: 132.4173\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5012 - val_loss: 131.4172\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5693 - val_loss: 143.7290\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5279 - val_loss: 164.2171\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.0367 - val_loss: 135.9788\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8344 - val_loss: 124.7856\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.4130 - val_loss: 141.3836\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0452 - val_loss: 144.9166\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.3426 - val_loss: 170.8243\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.7461 - val_loss: 131.4946\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0274 - val_loss: 153.9852\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0716 - val_loss: 142.9569\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5860 - val_loss: 147.1904\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9873 - val_loss: 125.7647\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1177 - val_loss: 146.1942\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.7726 - val_loss: 204.1772\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6076 - val_loss: 133.2582\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9183 - val_loss: 151.2206\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7427 - val_loss: 128.4155\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4569 - val_loss: 153.8977\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.1475 - val_loss: 144.4190\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9141 - val_loss: 140.9806\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6810 - val_loss: 131.7412\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2514 - val_loss: 187.1423\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7635 - val_loss: 177.1219\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0560 - val_loss: 142.8563\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2183 - val_loss: 177.1221\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.5439 - val_loss: 208.7799\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7484 - val_loss: 136.1965\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.8822 - val_loss: 140.9070\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1407 - val_loss: 127.1952\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3866 - val_loss: 153.2154\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2514 - val_loss: 155.7922\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.5753 - val_loss: 193.4856\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.2487 - val_loss: 140.5802\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.4169 - val_loss: 126.9137\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.2329 - val_loss: 136.4607\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.8697 - val_loss: 183.7723\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6074 - val_loss: 253.4433\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9983 - val_loss: 137.1648\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.5416 - val_loss: 133.8790\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2066 - val_loss: 217.0390\n",
      "Epoch 1891/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4257 - val_loss: 146.7782\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0949 - val_loss: 156.4046\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0407 - val_loss: 144.1257\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5962 - val_loss: 138.4488\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 217.3702 - val_loss: 141.3068\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 145.0930 - val_loss: 166.2143\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5299 - val_loss: 170.9866\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6075 - val_loss: 147.7061\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3896 - val_loss: 139.4486\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.8100 - val_loss: 128.8477\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 160.0490 - val_loss: 163.7076\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.0473 - val_loss: 129.8779\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 144.4448 - val_loss: 133.6634\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5309 - val_loss: 133.2353\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1856 - val_loss: 135.3356\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7210 - val_loss: 130.9092\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5314 - val_loss: 137.7525\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6169 - val_loss: 150.1377\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.8536 - val_loss: 186.7500\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8540 - val_loss: 152.2614\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7957 - val_loss: 131.4295\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6904 - val_loss: 158.9503\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7671 - val_loss: 154.8184\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1755 - val_loss: 161.1005\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.9993 - val_loss: 166.0885\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.4360 - val_loss: 147.8401\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3773 - val_loss: 133.9087\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6341 - val_loss: 141.5174\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.4529 - val_loss: 146.5135\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6259 - val_loss: 128.2156\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1880 - val_loss: 137.5645\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0637 - val_loss: 132.3177\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1012 - val_loss: 132.5315\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7290 - val_loss: 195.5686\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8462 - val_loss: 140.7740\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1350 - val_loss: 188.3968\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.6932 - val_loss: 178.1830\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1947 - val_loss: 142.0330\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1501 - val_loss: 143.0082\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.9689 - val_loss: 141.7249\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3921 - val_loss: 152.4747\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7122 - val_loss: 147.2221\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0560 - val_loss: 137.4075\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9197 - val_loss: 161.9561\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2249 - val_loss: 134.0325\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0978 - val_loss: 133.5968\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7210 - val_loss: 150.9193\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.9906 - val_loss: 138.2551\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3321 - val_loss: 131.4006\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5242 - val_loss: 145.3581\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.0617 - val_loss: 173.9608\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6198 - val_loss: 135.9460\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8826 - val_loss: 159.0399\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7468 - val_loss: 159.0805\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6893 - val_loss: 147.6893\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9972 - val_loss: 130.2713\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6962 - val_loss: 268.1800\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6079 - val_loss: 134.3011\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0702 - val_loss: 128.8337\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0930 - val_loss: 188.7260\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3468 - val_loss: 131.8506\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 160.020 - 0s 51us/step - loss: 159.8256 - val_loss: 179.6170\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9897 - val_loss: 151.2405\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.8805 - val_loss: 140.4076\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4213 - val_loss: 136.5933\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.5357 - val_loss: 130.1952\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7494 - val_loss: 149.0316\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.8754 - val_loss: 141.1940\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1229 - val_loss: 205.9987\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0206 - val_loss: 141.1923\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7081 - val_loss: 146.1583\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7473 - val_loss: 139.3823\n",
      "Epoch 1963/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3160 - val_loss: 185.0387\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8594 - val_loss: 139.0539\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5931 - val_loss: 172.2449\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0841 - val_loss: 135.0314\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4886 - val_loss: 156.2920\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9361 - val_loss: 135.6079\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0679 - val_loss: 147.6605\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6152 - val_loss: 132.0657\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7623 - val_loss: 134.0170\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6396 - val_loss: 133.6601\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 222.5770 - val_loss: 211.1177\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 141.4245 - val_loss: 131.9615\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 124.8158 - val_loss: 133.4481\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.0534 - val_loss: 157.9663\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9393 - val_loss: 134.3849\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9165 - val_loss: 176.8744\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6023 - val_loss: 134.3052\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0635 - val_loss: 177.6114\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0290 - val_loss: 139.5271\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4170 - val_loss: 147.6530\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4732 - val_loss: 128.0071\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7262 - val_loss: 213.0448\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0245 - val_loss: 156.0200\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1841 - val_loss: 141.8181\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9041 - val_loss: 132.9699\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.6917 - val_loss: 138.5881\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.3276 - val_loss: 215.6298\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9280 - val_loss: 154.0401\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.5066 - val_loss: 150.0516\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2426 - val_loss: 169.3196\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5074 - val_loss: 131.1922\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.0656 - val_loss: 131.2906\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2345 - val_loss: 128.9453\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.3849 - val_loss: 165.4329\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9119 - val_loss: 136.9248\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4364 - val_loss: 135.4082\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0880 - val_loss: 238.1765\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5608 - val_loss: 156.9975\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.1693 - val_loss: 150.3021\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.1150 - val_loss: 144.3932\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8588 - val_loss: 146.4475\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.9328 - val_loss: 134.9832\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.9393 - val_loss: 177.7982\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2147 - val_loss: 128.8247\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.0947 - val_loss: 167.3497\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8666 - val_loss: 155.6975\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.8268 - val_loss: 135.0701\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3276 - val_loss: 130.0709\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9337 - val_loss: 140.0737\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7379 - val_loss: 133.5999\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5645 - val_loss: 140.4433\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9237 - val_loss: 137.9180\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1162 - val_loss: 150.7718\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4469 - val_loss: 155.4444\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8875 - val_loss: 137.6553\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9835 - val_loss: 153.7938\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9326 - val_loss: 175.1573\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8337 - val_loss: 139.5391\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5939 - val_loss: 135.1483\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1552 - val_loss: 219.7950\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9871 - val_loss: 204.6848\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3782 - val_loss: 138.1648\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4334 - val_loss: 203.3646\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3617 - val_loss: 198.0446\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3540 - val_loss: 136.5156\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7890 - val_loss: 142.2638\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8980 - val_loss: 126.2240\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2896 - val_loss: 155.7609\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6987 - val_loss: 137.8938\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6417 - val_loss: 130.8194\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.3383 - val_loss: 146.0314\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4693 - val_loss: 174.7962\n",
      "Epoch 2035/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7390 - val_loss: 124.8831\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5511 - val_loss: 139.4557\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9607 - val_loss: 148.4043\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8937 - val_loss: 132.0314\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4641 - val_loss: 141.1146\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1926 - val_loss: 131.8528\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1233 - val_loss: 157.0709\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7054 - val_loss: 154.1537\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8161 - val_loss: 157.0726\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 128.637 - 0s 50us/step - loss: 127.5986 - val_loss: 131.9607\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 170.6624 - val_loss: 264.8320\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 137.1574 - val_loss: 137.5842\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 122.2932 - val_loss: 135.1468\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 128.1814 - val_loss: 148.0978\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4775 - val_loss: 166.6794\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.1405 - val_loss: 147.4244\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2887 - val_loss: 163.6885\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.1526 - val_loss: 137.4113\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5053 - val_loss: 129.7243\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.2092 - val_loss: 203.8664\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.7567 - val_loss: 140.6148\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.5282 - val_loss: 127.1313\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3453 - val_loss: 150.2862\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6636 - val_loss: 132.8742\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8537 - val_loss: 164.2526\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5953 - val_loss: 170.1073\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.5063 - val_loss: 138.8623\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3104 - val_loss: 191.6188\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.8886 - val_loss: 136.3230\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.5574 - val_loss: 143.6814\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1612 - val_loss: 251.8355\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0642 - val_loss: 132.8426\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9630 - val_loss: 184.4538\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.8185 - val_loss: 139.2941\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1227 - val_loss: 153.6668\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6527 - val_loss: 124.2060\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1953 - val_loss: 148.8023\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.8628 - val_loss: 186.2293\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2585 - val_loss: 153.0695\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.4846 - val_loss: 132.7268\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1103 - val_loss: 149.5421\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8447 - val_loss: 210.7309\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9524 - val_loss: 146.3228\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2341 - val_loss: 128.5621\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.0917 - val_loss: 140.8871\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2710 - val_loss: 139.2611\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9848 - val_loss: 134.0626\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.3890 - val_loss: 134.1912\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0462 - val_loss: 130.1174\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5201 - val_loss: 184.9573\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8057 - val_loss: 131.7939\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.2746 - val_loss: 132.8499\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.0351 - val_loss: 133.6180\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7978 - val_loss: 130.0551\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6113 - val_loss: 151.6611\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9275 - val_loss: 136.3489\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.5613 - val_loss: 132.7961\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.9605 - val_loss: 133.0544\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.1961 - val_loss: 163.1444\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.8020 - val_loss: 189.6390\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.1453 - val_loss: 215.4720\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0851 - val_loss: 158.8353\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2183 - val_loss: 199.9473\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4053 - val_loss: 145.8978\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.3862 - val_loss: 129.1213\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4558 - val_loss: 143.7071\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4582 - val_loss: 135.5016\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.2882 - val_loss: 133.2262\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.4461 - val_loss: 160.1495\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4357 - val_loss: 125.1676\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.1863 - val_loss: 148.8284\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0334 - val_loss: 135.2023\n",
      "Epoch 2107/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3551 - val_loss: 136.9578\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.5385 - val_loss: 142.7357\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.6955 - val_loss: 140.5699\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4565 - val_loss: 140.4307\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4159 - val_loss: 146.7114\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0116 - val_loss: 126.1691\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9408 - val_loss: 137.8055\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.4935 - val_loss: 157.1956\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7080 - val_loss: 278.9047\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.4374 - val_loss: 188.8085\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 141.3658 - val_loss: 160.7507\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 158.5353 - val_loss: 151.4250\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 229.8406 - val_loss: 149.6625\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 138.2893 - val_loss: 162.3362\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3356 - val_loss: 130.1584\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3818 - val_loss: 148.0818\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0965 - val_loss: 150.3106\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.2356 - val_loss: 152.0750\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 129.8624 - val_loss: 146.9742\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 126.7117 - val_loss: 146.0402\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0547 - val_loss: 153.3336\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.0879 - val_loss: 160.6013\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.2475 - val_loss: 167.1906\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2956 - val_loss: 141.1562\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8994 - val_loss: 185.9710\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6255 - val_loss: 128.7713\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8489 - val_loss: 140.0682\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2593 - val_loss: 265.0539\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6425 - val_loss: 134.8043\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6527 - val_loss: 127.2643\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4566 - val_loss: 148.6552\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.5383 - val_loss: 138.8814\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2852 - val_loss: 154.1322\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.5209 - val_loss: 146.9065\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.2626 - val_loss: 199.8167\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.1116 - val_loss: 137.0266\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.7417 - val_loss: 146.1348\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 128.9214 - val_loss: 180.4095\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2196 - val_loss: 124.5822\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4582 - val_loss: 169.3285\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.3357 - val_loss: 128.6403\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.9141 - val_loss: 125.5892\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.3626 - val_loss: 135.9908\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1310 - val_loss: 136.3950\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1547 - val_loss: 166.3589\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7953 - val_loss: 146.2551\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3793 - val_loss: 139.8044\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0565 - val_loss: 134.3999\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.3609 - val_loss: 165.2934\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.8076 - val_loss: 154.6445\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6347 - val_loss: 133.3724\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.5504 - val_loss: 144.6400\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.0935 - val_loss: 124.5253\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.3191 - val_loss: 141.7121\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3987 - val_loss: 142.1154\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5375 - val_loss: 134.0977\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5387 - val_loss: 137.0296\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.0673 - val_loss: 176.9869\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6807 - val_loss: 156.2815\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5386 - val_loss: 125.4858\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4916 - val_loss: 175.8828\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6722 - val_loss: 127.6329\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5211 - val_loss: 148.4269\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.0842 - val_loss: 131.1139\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6483 - val_loss: 154.9067\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1201 - val_loss: 237.2445\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2042 - val_loss: 147.0812\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.2136 - val_loss: 129.9649\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.9014 - val_loss: 386.0388\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6626 - val_loss: 132.1647\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7931 - val_loss: 136.3863\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4831 - val_loss: 165.8592\n",
      "Epoch 2179/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8136 - val_loss: 132.8371\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6270 - val_loss: 136.2151\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5767 - val_loss: 152.8103\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3720 - val_loss: 148.4076\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5905 - val_loss: 143.9594\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2165 - val_loss: 157.9880\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3642 - val_loss: 135.9421\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7525 - val_loss: 130.8423\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2109 - val_loss: 144.7180\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 130.7667 - val_loss: 155.5912\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.9536 - val_loss: 166.8962\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.0833 - val_loss: 260.4992\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.7534 - val_loss: 253.2388\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4070 - val_loss: 131.0700\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7816 - val_loss: 149.5975\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 206.8011 - val_loss: 141.4128\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4482 - val_loss: 130.3335\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9758 - val_loss: 131.7105\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2975 - val_loss: 142.5199\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5412 - val_loss: 132.6062\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7804 - val_loss: 139.9397\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2609 - val_loss: 139.1611\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7467 - val_loss: 151.7667\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.6713 - val_loss: 162.1493\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8749 - val_loss: 145.2541\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1687 - val_loss: 171.9831\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2284 - val_loss: 137.4736\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.7288 - val_loss: 208.4316\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8431 - val_loss: 137.1830\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.1430 - val_loss: 147.1106\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4025 - val_loss: 140.1858\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1967 - val_loss: 180.5746\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4956 - val_loss: 134.7560\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3910 - val_loss: 128.8573\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2745 - val_loss: 214.0499\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0821 - val_loss: 144.1160\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4913 - val_loss: 141.2476\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5368 - val_loss: 132.3547\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8178 - val_loss: 165.9049\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.2221 - val_loss: 141.5554\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5875 - val_loss: 144.1284\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6209 - val_loss: 155.5397\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.2738 - val_loss: 127.9949\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4600 - val_loss: 133.7054\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9335 - val_loss: 134.6479\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.9232 - val_loss: 134.3061\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1092 - val_loss: 140.4066\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2046 - val_loss: 131.9638\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0440 - val_loss: 149.9120\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3864 - val_loss: 140.9946\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.5326 - val_loss: 134.0255\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8360 - val_loss: 138.6672\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0593 - val_loss: 141.5231\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.2239 - val_loss: 141.9528\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8863 - val_loss: 227.8992\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8709 - val_loss: 132.0905\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4153 - val_loss: 151.2025\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5921 - val_loss: 191.0247\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4316 - val_loss: 133.4651\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4924 - val_loss: 154.7257\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.7708 - val_loss: 146.6101\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7518 - val_loss: 150.1941\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8566 - val_loss: 140.6888\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6044 - val_loss: 259.1844\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.3866 - val_loss: 133.6778\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2908 - val_loss: 137.0410\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2526 - val_loss: 165.0268\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2657 - val_loss: 144.6080\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.5180 - val_loss: 160.5875\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 120.0673 - val_loss: 154.8732\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.9694 - val_loss: 127.7545\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2092 - val_loss: 167.8479\n",
      "Epoch 2251/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4729 - val_loss: 136.0265\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0029 - val_loss: 139.2198\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8337 - val_loss: 137.3697\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1736 - val_loss: 136.5217\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.6833 - val_loss: 203.8364\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9627 - val_loss: 141.8795\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.2698 - val_loss: 131.9079\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1089 - val_loss: 133.8480\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 126.1620 - val_loss: 138.6887\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 129.6632 - val_loss: 132.2900\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 129.9564 - val_loss: 131.1092\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 138.7737 - val_loss: 145.1992\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 149.5635 - val_loss: 151.8812\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.3783 - val_loss: 228.0211\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4679 - val_loss: 135.2979\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6445 - val_loss: 138.2204\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3404 - val_loss: 131.7808\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8996 - val_loss: 131.5360\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.5083 - val_loss: 187.6579\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8759 - val_loss: 160.8187\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7350 - val_loss: 140.4400\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3302 - val_loss: 127.2150\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3569 - val_loss: 169.4195\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.6472 - val_loss: 137.7340\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4480 - val_loss: 134.9002\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3684 - val_loss: 144.9490\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.3570 - val_loss: 126.9176\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9985 - val_loss: 181.9851\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3008 - val_loss: 129.9743\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.1490 - val_loss: 160.6310\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5655 - val_loss: 150.0218\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1664 - val_loss: 155.2625\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9634 - val_loss: 166.7385\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3087 - val_loss: 137.4932\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3432 - val_loss: 129.7813\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3850 - val_loss: 187.9630\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1585 - val_loss: 158.2203\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5284 - val_loss: 133.4877\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7243 - val_loss: 139.8422\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.9306 - val_loss: 125.0570\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8139 - val_loss: 182.3170\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3358 - val_loss: 173.2278\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.4816 - val_loss: 127.8851\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5376 - val_loss: 127.6135\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7833 - val_loss: 190.9674\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.7480 - val_loss: 137.9395\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1739 - val_loss: 159.8975\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9458 - val_loss: 130.5787\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1141 - val_loss: 136.1157\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4666 - val_loss: 135.2747\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5558 - val_loss: 128.1332\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0170 - val_loss: 163.8605\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.3664 - val_loss: 146.1061\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6694 - val_loss: 129.4702\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8385 - val_loss: 150.8400\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9504 - val_loss: 142.7690\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6539 - val_loss: 190.1539\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4803 - val_loss: 149.9373\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4828 - val_loss: 188.7353\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6113 - val_loss: 144.2655\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1923 - val_loss: 143.6750\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.6709 - val_loss: 131.8240\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.8803 - val_loss: 127.7523\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.4724 - val_loss: 137.9596\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3063 - val_loss: 166.4932\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3799 - val_loss: 137.6915\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3033 - val_loss: 142.8338\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0400 - val_loss: 190.4172\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6564 - val_loss: 135.5242\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0959 - val_loss: 172.8530\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0465 - val_loss: 130.4626\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4364 - val_loss: 130.5524\n",
      "Epoch 2323/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8530 - val_loss: 171.8177\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 251.4739 - val_loss: 153.0264\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9561 - val_loss: 132.8960\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6144 - val_loss: 156.6077\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.6422 - val_loss: 128.3715\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0447 - val_loss: 133.9863\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.2220 - val_loss: 138.5775\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5476 - val_loss: 145.3469\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5960 - val_loss: 132.5605\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.8769 - val_loss: 128.5715\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.2635 - val_loss: 202.1306\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 156.0688 - val_loss: 135.8513\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 130.9782 - val_loss: 147.5888\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9716 - val_loss: 134.4433\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8019 - val_loss: 177.7993\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.7395 - val_loss: 153.6461\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9583 - val_loss: 126.2515\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4892 - val_loss: 143.6342\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0461 - val_loss: 166.6518\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.7994 - val_loss: 179.7674\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5939 - val_loss: 130.1279\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8048 - val_loss: 160.6023\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.0335 - val_loss: 210.4832\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0569 - val_loss: 183.7065\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3694 - val_loss: 149.9151\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2321 - val_loss: 165.1112\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 275.2307 - val_loss: 228.9275\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.7458 - val_loss: 192.5505\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3378 - val_loss: 143.2022\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7003 - val_loss: 172.1823\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2924 - val_loss: 137.9478\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7878 - val_loss: 140.5624\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4629 - val_loss: 260.6198\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.0185 - val_loss: 131.7985\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.9574 - val_loss: 204.9692\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.6016 - val_loss: 236.9139\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2346 - val_loss: 170.2051\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 130.2786 - val_loss: 145.8444\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 156.5324 - val_loss: 133.6282\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.9603 - val_loss: 143.6911\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.9216 - val_loss: 130.9690\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.6653 - val_loss: 155.4601\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.8297 - val_loss: 127.4098\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1201 - val_loss: 128.9879\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6573 - val_loss: 155.3945\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1907 - val_loss: 131.2945\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7079 - val_loss: 140.4591\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7669 - val_loss: 145.9518\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2793 - val_loss: 137.5500\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.8324 - val_loss: 163.4932\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3165 - val_loss: 135.1513\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9048 - val_loss: 135.5225\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2876 - val_loss: 145.9579\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1976 - val_loss: 136.5272\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 192.2167 - val_loss: 1146.3349\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.6777 - val_loss: 130.9205\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.8690 - val_loss: 160.4604\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0963 - val_loss: 191.9166\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4705 - val_loss: 160.2603\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3933 - val_loss: 167.0515\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7094 - val_loss: 129.4367\n",
      "Epoch 02383: early stopping\n",
      "Fold score (RMSE): 11.233789443969727\n",
      "Fold #4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 4989.5313 - val_loss: 6738.9385\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4612.5076 - val_loss: 5106.5687\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 4267.9496 - val_loss: 5442.4948\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 4190.8009 - val_loss: 4085.6495\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 4120.5436 - val_loss: 3918.6024\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4014.9017 - val_loss: 4021.7492\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 4000.4027 - val_loss: 3763.1725\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 3755.3411 - val_loss: 3591.2974\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3581.9222 - val_loss: 4958.0485\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3555.8268 - val_loss: 3141.8802\n",
      "Epoch 11/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 3236.0494 - val_loss: 2929.8022\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 2983.4519 - val_loss: 2507.4754\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3093.4585 - val_loss: 3073.7393\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2502.6070 - val_loss: 2229.5770\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2560.8747 - val_loss: 1696.6027\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1906.7169 - val_loss: 1752.5757\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 1571.1834 - val_loss: 1265.2230\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 1207.5111 - val_loss: 1119.6044\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 1212.5440 - val_loss: 695.3765\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 926.8238 - val_loss: 651.4503\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 907.5455 - val_loss: 516.7187\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 955.5384 - val_loss: 991.5952\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 705.7902 - val_loss: 379.9677\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 825.0881 - val_loss: 601.8411\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 723.5345 - val_loss: 398.8396\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 813.5821 - val_loss: 603.6229\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 694.2568 - val_loss: 412.6342\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 602.9684 - val_loss: 440.4297\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 656.9401 - val_loss: 434.0067\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 580.6263 - val_loss: 364.7609\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 620.0266 - val_loss: 437.1154\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 534.6309 - val_loss: 296.1513\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 538.6518 - val_loss: 350.1479\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 546.8843 - val_loss: 435.4670\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 442.9243 - val_loss: 619.6882\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 474.9316 - val_loss: 270.9528\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 557.5014 - val_loss: 273.4515\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 428.7022 - val_loss: 761.7092\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 501.0565 - val_loss: 335.0780\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 499.9866 - val_loss: 1329.9991\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 587.7598 - val_loss: 331.9519\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 465.2527 - val_loss: 290.7448\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 567.2060 - val_loss: 681.4751\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 580.8140 - val_loss: 252.9722\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 375.5960 - val_loss: 239.8551\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 406.7871 - val_loss: 316.4323\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 400.0720 - val_loss: 239.0343\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 468.7082 - val_loss: 462.1534\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 395.8151 - val_loss: 248.5720\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 366.0940 - val_loss: 324.3958\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 402.3364 - val_loss: 468.0631\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 505.2678 - val_loss: 284.0821\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 417.4373 - val_loss: 221.4114\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 407.9185 - val_loss: 207.3254\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 405.7568 - val_loss: 308.4805\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 378.9355 - val_loss: 360.3814\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 451.5554 - val_loss: 348.6944\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 505.6105 - val_loss: 282.2005\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 427.0281 - val_loss: 273.2476 ETA: 0s - loss: 380\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 313.6038 - val_loss: 357.6891\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 423.6578 - val_loss: 241.2387\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 328.0792 - val_loss: 189.5929\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 364.9544 - val_loss: 264.1689\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 376.6041 - val_loss: 611.8755\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 335.5415 - val_loss: 233.3793\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 460.5038 - val_loss: 356.3673\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 516.1426 - val_loss: 247.1762\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 302.5909 - val_loss: 257.7723\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 320.1470 - val_loss: 270.3353\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 341.4254 - val_loss: 242.2829\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 347.6315 - val_loss: 287.9948\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 387.7980 - val_loss: 190.5280\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 376.9675 - val_loss: 266.7748\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 375.7972 - val_loss: 285.8459\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 388.1881 - val_loss: 373.5851\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 314.9702 - val_loss: 229.7801\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 389.4343 - val_loss: 191.8851\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 307.3984 - val_loss: 263.6489\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 347.7814 - val_loss: 185.8243\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 383.6781 - val_loss: 173.8897\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 305.0652 - val_loss: 248.0384\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 341.6450 - val_loss: 183.1898\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 372.2573 - val_loss: 395.4470\n",
      "Epoch 84/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 403.0276 - val_loss: 433.1579\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 372.3604 - val_loss: 166.4465\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.2645 - val_loss: 192.4764\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 294.2874 - val_loss: 180.8026\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 369.0944 - val_loss: 183.6319\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 296.7007 - val_loss: 258.5720\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 304.0821 - val_loss: 895.3007\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 312.4273 - val_loss: 578.7716\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 336.6546 - val_loss: 177.6494\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 470.2365 - val_loss: 166.7514\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 280.0970 - val_loss: 210.8578\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 297.9167 - val_loss: 155.2129\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 283.5851 - val_loss: 183.4248\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 381.3998 - val_loss: 585.2210\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 280.3124 - val_loss: 225.9170\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 563.7903 - val_loss: 575.8891\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.5692 - val_loss: 170.0772\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.9582 - val_loss: 234.0359\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.8264 - val_loss: 177.3872\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.6617 - val_loss: 172.4105\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 296.3259 - val_loss: 180.2049\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 287.8107 - val_loss: 241.6353\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 314.6870 - val_loss: 481.3041\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 646.0749 - val_loss: 891.8344\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 372.1578 - val_loss: 213.6708\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.4831 - val_loss: 285.3578\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 283.4648 - val_loss: 290.6509\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 257.3495 - val_loss: 161.4920\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 250.3555 - val_loss: 155.4780\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 291.0631 - val_loss: 268.3386\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 234.1058 - val_loss: 1198.4559\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 342.2563 - val_loss: 175.9791\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 252.7155 - val_loss: 154.5885\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 327.5129 - val_loss: 523.0449\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 403.3924 - val_loss: 800.9081\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 318.5652 - val_loss: 389.5437\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 354.4482 - val_loss: 429.9088\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.0051 - val_loss: 224.9154\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 244.1939 - val_loss: 189.4858\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 253.3942 - val_loss: 238.8493\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 461.5458 - val_loss: 550.8152\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 343.3301 - val_loss: 176.4902\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 260.2573 - val_loss: 210.4799\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 304.0392 - val_loss: 160.0540\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 230.9491 - val_loss: 175.9016\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 237.3488 - val_loss: 270.6318\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 247.9784 - val_loss: 186.6255\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 270.7441 - val_loss: 271.4383\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.5429 - val_loss: 198.0932\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.6353 - val_loss: 173.3734\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.1734 - val_loss: 357.3112\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 279.6816 - val_loss: 182.7441\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.8360 - val_loss: 395.4707\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 249.8511 - val_loss: 239.8815\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 249.1916 - val_loss: 154.9280\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 274.3148 - val_loss: 140.9343\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 304.9810 - val_loss: 156.8544\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 239.6445 - val_loss: 177.7407\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 289.939 - 0s 51us/step - loss: 290.6440 - val_loss: 167.3568\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 242.5325 - val_loss: 152.7327\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.9101 - val_loss: 244.9520\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 245.3999 - val_loss: 234.8928\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 225.8966 - val_loss: 157.6234\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.6670 - val_loss: 169.3662\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 259.7564 - val_loss: 149.5462\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.7686 - val_loss: 140.2973\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.9545 - val_loss: 141.3170\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.7710 - val_loss: 141.9513\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 304.1640 - val_loss: 480.6573\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.8352 - val_loss: 435.8458\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 245.3754 - val_loss: 143.6459\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 244.9236 - val_loss: 149.9386\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.4436 - val_loss: 298.4392\n",
      "Epoch 157/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 255.2059 - val_loss: 160.4496\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 268.7195 - val_loss: 148.9173\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 345.6665 - val_loss: 175.0755\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 258.5948 - val_loss: 161.9587\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 257.6926 - val_loss: 134.3828\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 296.7515 - val_loss: 243.3949\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.9303 - val_loss: 161.4372\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.7275 - val_loss: 222.9071\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.2011 - val_loss: 191.1221\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 255.2697 - val_loss: 133.1069\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 330.8313 - val_loss: 140.6867\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 221.4637 - val_loss: 517.1686\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 263.7998 - val_loss: 191.6184\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 234.8856 - val_loss: 822.0537\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 345.5378 - val_loss: 141.6691\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.5142 - val_loss: 170.2506\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.3008 - val_loss: 186.9980\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.0299 - val_loss: 220.1484\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.8229 - val_loss: 178.7904\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 263.9234 - val_loss: 180.4934\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.8736 - val_loss: 241.3774\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.9952 - val_loss: 155.2292\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.6679 - val_loss: 171.4260\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 503.1446 - val_loss: 678.6682\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 280.1660 - val_loss: 239.8906\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.0329 - val_loss: 299.6569\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 258.1035 - val_loss: 223.8447\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.3468 - val_loss: 202.4700\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.8417 - val_loss: 135.2100\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.2208 - val_loss: 181.1478\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.9381 - val_loss: 208.3797\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.3074 - val_loss: 213.4561\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 270.2180 - val_loss: 192.6028\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 289.9117 - val_loss: 215.3927\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.9714 - val_loss: 252.2391\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.9818 - val_loss: 581.3890\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 298.6444 - val_loss: 170.0795\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 255.4381 - val_loss: 440.0563\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 296.2599 - val_loss: 151.8445\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 206.4351 - val_loss: 198.9352\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.1553 - val_loss: 227.0534\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.1109 - val_loss: 136.2468\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.3332 - val_loss: 144.8051\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 282.1407 - val_loss: 161.5069\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.2386 - val_loss: 138.6729\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.1173 - val_loss: 266.8385\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.8297 - val_loss: 143.1783\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 300.0871 - val_loss: 159.1128\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.4249 - val_loss: 225.2244\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.7095 - val_loss: 179.8926\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.4428 - val_loss: 168.9323\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.6231 - val_loss: 222.1465\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 249.0216 - val_loss: 142.6546\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.9329 - val_loss: 172.5220\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 255.0067 - val_loss: 128.0706\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.2113 - val_loss: 142.6798\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.7752 - val_loss: 164.2803\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 229.7542 - val_loss: 144.7728\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.8257 - val_loss: 1114.2968\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 230.4145 - val_loss: 237.9650\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.5593 - val_loss: 147.2357\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.4700 - val_loss: 128.6731\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.2134 - val_loss: 174.9753\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.0141 - val_loss: 342.7744\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 358.6235 - val_loss: 144.1400\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.5591 - val_loss: 130.3668\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.8947 - val_loss: 136.7945\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.1849 - val_loss: 157.7829\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 285.4702 - val_loss: 452.7047\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 255.0112 - val_loss: 152.6976\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.3705 - val_loss: 129.5201\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.7319 - val_loss: 126.8419\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.8107 - val_loss: 126.6283\n",
      "Epoch 230/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.9461 - val_loss: 123.9382\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.3988 - val_loss: 143.3063\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 462.8354 - val_loss: 225.1165\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 254.8439 - val_loss: 251.8010\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 233.2459 - val_loss: 299.7502\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.7076 - val_loss: 163.9354\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 292.1592 - val_loss: 148.2811\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 237.5526 - val_loss: 129.2153\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.6254 - val_loss: 134.6838\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 338.0756 - val_loss: 176.2385\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.7804 - val_loss: 166.1223\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 285.5636 - val_loss: 245.2783\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 200.3929 - val_loss: 131.1371\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.7306 - val_loss: 205.5594\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 283.4158 - val_loss: 122.2527\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6704 - val_loss: 128.0837\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.1428 - val_loss: 219.6809\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.9242 - val_loss: 158.1830\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.4369 - val_loss: 184.0462\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.8783 - val_loss: 132.0722\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.5183 - val_loss: 234.3963\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.2085 - val_loss: 134.4663\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.4838 - val_loss: 127.1952\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.9617 - val_loss: 194.9074\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 272.6872 - val_loss: 123.7352\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.7980 - val_loss: 176.8259\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 336.9827 - val_loss: 171.2260\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.4982 - val_loss: 142.5988\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 220.2936 - val_loss: 132.1772\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.3857 - val_loss: 171.1390\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.2430 - val_loss: 193.4621\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.3442 - val_loss: 299.9251\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.3893 - val_loss: 156.7791\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.3642 - val_loss: 310.2100\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.7171 - val_loss: 127.2241\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.7422 - val_loss: 124.5609\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.0491 - val_loss: 167.2659\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.9851 - val_loss: 361.2595\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.2219 - val_loss: 155.6693\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.3279 - val_loss: 352.0484\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.8152 - val_loss: 168.8329\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 268.7160 - val_loss: 242.0470\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.1180 - val_loss: 141.5313\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 287.5589 - val_loss: 254.1715\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 195.4551 - val_loss: 121.5527\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7022 - val_loss: 124.9113\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.6039 - val_loss: 141.1664\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.4711 - val_loss: 115.2711\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.7364 - val_loss: 223.4661\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.8811 - val_loss: 145.2817\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.7025 - val_loss: 123.5025\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.7095 - val_loss: 170.6231\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.2801 - val_loss: 136.4221\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.2263 - val_loss: 183.0892\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.7546 - val_loss: 131.6394\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.2918 - val_loss: 324.9286\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.4447 - val_loss: 201.0510\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.9926 - val_loss: 118.9396\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4568 - val_loss: 125.6049\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.2666 - val_loss: 248.2228\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 196.0842 - val_loss: 165.0161\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 180.8814 - val_loss: 117.9751\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 168.2949 - val_loss: 152.3469\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 177.7315 - val_loss: 134.1698\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 300.9416 - val_loss: 699.6830\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 228.6075 - val_loss: 150.5839\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 169.7379 - val_loss: 115.4520\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4789 - val_loss: 168.5774\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.8458 - val_loss: 124.0148\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.6205 - val_loss: 116.7543\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 318.9483 - val_loss: 139.3955\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.9428 - val_loss: 142.4292\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 270.8830 - val_loss: 194.1233\n",
      "Epoch 303/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 61us/step - loss: 177.6406 - val_loss: 136.8217\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 180.3806 - val_loss: 142.1314\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.5468 - val_loss: 120.8907\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6770 - val_loss: 123.1158\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8474 - val_loss: 116.4368\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9693 - val_loss: 130.9716\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3506 - val_loss: 232.7501\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.9275 - val_loss: 164.9648\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 205.0435 - val_loss: 254.0875\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 172.7697 - val_loss: 224.7676\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.3161 - val_loss: 115.6782\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.2721 - val_loss: 137.1100\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.8475 - val_loss: 158.2550\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9040 - val_loss: 117.6506\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.7048 - val_loss: 319.2979\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5011 - val_loss: 144.1564\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 306.7398 - val_loss: 118.9556\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9222 - val_loss: 137.9779\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 264.2211 - val_loss: 163.6095\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 255.1719 - val_loss: 202.1276\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.3556 - val_loss: 122.7255\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.6175 - val_loss: 1378.2387\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 242.4918 - val_loss: 124.5538\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.4441 - val_loss: 125.7321\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.2311 - val_loss: 126.7939\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 183.7126 - val_loss: 366.8155\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7104 - val_loss: 122.3533\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.0371 - val_loss: 119.5755\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.6570 - val_loss: 119.0199\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.2219 - val_loss: 116.3257\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.0019 - val_loss: 122.5681\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.0263 - val_loss: 142.7912\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 222.0349 - val_loss: 126.9544\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3019 - val_loss: 168.4937\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.2564 - val_loss: 132.5237\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 517.6526 - val_loss: 229.2168\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 335.0694 - val_loss: 161.7686\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 272.6477 - val_loss: 168.9936\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.8876 - val_loss: 188.7597\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.5852 - val_loss: 141.5724\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 508.2451 - val_loss: 452.9882\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 252.3397 - val_loss: 137.5898\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.7676 - val_loss: 138.6587\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.4605 - val_loss: 138.1207\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.5469 - val_loss: 157.2375\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.0276 - val_loss: 140.1664\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.2474 - val_loss: 297.3267\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5500 - val_loss: 121.7766\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.6562 - val_loss: 121.4293\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.2516 - val_loss: 221.1846\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 281.7551 - val_loss: 211.2000\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.0766 - val_loss: 337.2984\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 272.7786 - val_loss: 950.7785\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 308.3025 - val_loss: 129.6612\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8127 - val_loss: 144.3464\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.9971 - val_loss: 119.5978\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.8964 - val_loss: 128.6548\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8187 - val_loss: 142.0884\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.5421 - val_loss: 179.7504\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.5373 - val_loss: 118.3905\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.4509 - val_loss: 136.1394\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.1397 - val_loss: 151.8456\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.2747 - val_loss: 288.2405\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.9308 - val_loss: 147.7072\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.1587 - val_loss: 130.4250\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 393.6131 - val_loss: 135.9088\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6351 - val_loss: 167.2711\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 160.9535 - val_loss: 166.2528\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.2996 - val_loss: 125.9635\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.6603 - val_loss: 130.5196\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.5447 - val_loss: 122.5381\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 231.0275 - val_loss: 154.5347\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 173.2637 - val_loss: 146.5015\n",
      "Epoch 376/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.0648 - val_loss: 121.1530\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0155 - val_loss: 191.7070\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.4961 - val_loss: 222.7334\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.4605 - val_loss: 150.6527\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.6653 - val_loss: 168.1371\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.3230 - val_loss: 217.2147\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.7292 - val_loss: 294.6137\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 434.5653 - val_loss: 117.2917\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.9640 - val_loss: 152.6757\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 174.6426 - val_loss: 133.1631\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.8608 - val_loss: 112.6792\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7553 - val_loss: 143.3888\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.0019 - val_loss: 130.8479\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.4008 - val_loss: 252.4331\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1297 - val_loss: 117.0532\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.7584 - val_loss: 122.7285\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.6150 - val_loss: 202.1099\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.5362 - val_loss: 130.3109\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.3037 - val_loss: 132.2496\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.0077 - val_loss: 137.0890\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.2211 - val_loss: 150.9748\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.9761 - val_loss: 122.7686\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5184 - val_loss: 119.7795\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.4718 - val_loss: 127.1771\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.8414 - val_loss: 123.0327\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6755 - val_loss: 136.0924\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.3605 - val_loss: 133.7308\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 418.8216 - val_loss: 191.4546\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.7284 - val_loss: 165.0426\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0602 - val_loss: 112.7518\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.4311 - val_loss: 146.4604\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.6382 - val_loss: 113.7668\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2828 - val_loss: 143.6328\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.3430 - val_loss: 122.1282\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2209 - val_loss: 164.6828\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.1332 - val_loss: 119.3085\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.4733 - val_loss: 130.9526\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 231.0491 - val_loss: 128.5366\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.5467 - val_loss: 361.5555\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 489.1749 - val_loss: 229.5454\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.1536 - val_loss: 141.0417\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.5022 - val_loss: 132.5837\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 226.9468 - val_loss: 129.0735\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.9339 - val_loss: 129.4470\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.1833 - val_loss: 156.3633\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.1539 - val_loss: 161.3820\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.9843 - val_loss: 120.9839\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.8035 - val_loss: 138.9228\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.1420 - val_loss: 128.3613\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.9839 - val_loss: 212.6206\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 407.5327 - val_loss: 257.6100\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.8922 - val_loss: 118.6629\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.5582 - val_loss: 131.7408\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.8512 - val_loss: 129.4219\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 171.2424 - val_loss: 126.4467\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.9832 - val_loss: 213.1252\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.8293 - val_loss: 168.0858\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2190 - val_loss: 145.9277\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.2710 - val_loss: 157.9047\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5217 - val_loss: 124.4246\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.3980 - val_loss: 138.7112\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.7645 - val_loss: 187.7168\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.5267 - val_loss: 119.8053\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.6486 - val_loss: 314.1316\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.5298 - val_loss: 116.4548\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.8148 - val_loss: 199.6671\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.2370 - val_loss: 116.2843\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.8139 - val_loss: 121.5311\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 189.9813 - val_loss: 153.0081\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 155.2090 - val_loss: 208.0224\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 170.9137 - val_loss: 251.0917\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 419.8915 - val_loss: 172.9899\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 181.6302 - val_loss: 135.7066\n",
      "Epoch 449/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 167.5171 - val_loss: 135.1407\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3268 - val_loss: 117.9479\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0891 - val_loss: 191.2405\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.8516 - val_loss: 119.9356\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.0316 - val_loss: 172.9182\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.2856 - val_loss: 119.1012\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 316.0174 - val_loss: 160.4372\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 154.2846 - val_loss: 123.0308\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4502 - val_loss: 141.6103\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0427 - val_loss: 175.6761\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.0644 - val_loss: 150.7226\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.8878 - val_loss: 124.2744\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.1050 - val_loss: 115.6810\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8452 - val_loss: 130.2317\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6919 - val_loss: 125.8729\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8668 - val_loss: 121.5295\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.8368 - val_loss: 121.1915\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0803 - val_loss: 134.5110\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 302.5521 - val_loss: 177.4017\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.3812 - val_loss: 123.8507\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.7381 - val_loss: 132.5449\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0984 - val_loss: 119.6429\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.3290 - val_loss: 124.9619\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3058 - val_loss: 194.8601\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 226.3619 - val_loss: 290.2286\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0144 - val_loss: 120.4891\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1675 - val_loss: 115.1092\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.0244 - val_loss: 137.9850\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.3357 - val_loss: 153.7687\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.2567 - val_loss: 118.7073\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 424.6265 - val_loss: 120.7459\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0800 - val_loss: 120.9396\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.6653 - val_loss: 118.8252\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.5673 - val_loss: 148.3179\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 547.2481 - val_loss: 316.1245\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 289.7405 - val_loss: 172.7863\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.3795 - val_loss: 171.0209\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.0460 - val_loss: 143.8013\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.6476 - val_loss: 122.7911\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.9109 - val_loss: 124.4349\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.3791 - val_loss: 236.4918\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4324 - val_loss: 135.7770\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.2182 - val_loss: 162.2618\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.9296 - val_loss: 130.4760\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 239.8026 - val_loss: 275.2073\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.3047 - val_loss: 125.8112\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.4813 - val_loss: 268.6848\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6367 - val_loss: 123.1235\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2461 - val_loss: 124.1417\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.2316 - val_loss: 195.5723\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9907 - val_loss: 165.9334\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.5766 - val_loss: 123.5692\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.6114 - val_loss: 119.0184\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.1314 - val_loss: 263.1566\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 411.1639 - val_loss: 122.7607\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.7094 - val_loss: 194.5561\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.5474 - val_loss: 118.9308\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2193 - val_loss: 184.1006\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.6748 - val_loss: 117.5384\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.5445 - val_loss: 118.4165\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.2989 - val_loss: 128.6496\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.6825 - val_loss: 161.6672\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 308.8112 - val_loss: 576.9004\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.0969 - val_loss: 122.4248\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 199.6034 - val_loss: 126.7328\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5922 - val_loss: 135.2803\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 165.9995 - val_loss: 131.6198\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 181.4417 - val_loss: 130.3654\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 175.1418 - val_loss: 133.4055\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 164.1429 - val_loss: 119.7151\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.8696 - val_loss: 137.1305\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.5385 - val_loss: 134.1824\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3191 - val_loss: 115.1669\n",
      "Epoch 522/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.2904 - val_loss: 146.6895\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.3713 - val_loss: 138.0915\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 456.1296 - val_loss: 133.2244\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.4375 - val_loss: 122.1493\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5110 - val_loss: 146.2485\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1583 - val_loss: 144.4040\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.6725 - val_loss: 136.2934\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.2940 - val_loss: 135.9128\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 197.2754 - val_loss: 174.6803\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.0772 - val_loss: 133.8332\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.9653 - val_loss: 119.7146\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6697 - val_loss: 169.8484\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 250.3364 - val_loss: 140.5993\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.2893 - val_loss: 116.6695\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5653 - val_loss: 211.2347\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.7574 - val_loss: 117.8416\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 178.9050 - val_loss: 117.1385\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.6145 - val_loss: 120.7344\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.7434 - val_loss: 132.7245\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.2579 - val_loss: 124.9316\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 163.7540 - val_loss: 138.8069\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.0120 - val_loss: 224.8937\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 194.2694 - val_loss: 443.9591\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.8168 - val_loss: 117.9958\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1885 - val_loss: 156.0415\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.0174 - val_loss: 119.6851\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 169.3152 - val_loss: 117.1257\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.7055 - val_loss: 165.0554\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.0489 - val_loss: 124.2134\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 285.9451 - val_loss: 119.0245\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9775 - val_loss: 139.3239\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.9992 - val_loss: 128.4782\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.9156 - val_loss: 153.0572\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.7176 - val_loss: 120.3408\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.9503 - val_loss: 127.9600\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1191 - val_loss: 114.3433\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.4623 - val_loss: 119.5147\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.7480 - val_loss: 120.5177\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 357.6175 - val_loss: 382.4365\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 309.7692 - val_loss: 154.8485\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.6741 - val_loss: 131.2122\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.2996 - val_loss: 143.0491\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.3043 - val_loss: 114.4037\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.3671 - val_loss: 228.3213\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.9577 - val_loss: 113.1811\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.6396 - val_loss: 116.8604\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.8665 - val_loss: 150.4639\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5839 - val_loss: 114.6313\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.4390 - val_loss: 114.9407\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.5433 - val_loss: 127.1650\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 167.0300 - val_loss: 154.5713\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.2259 - val_loss: 159.5995\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 246.2094 - val_loss: 148.9527\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.7949 - val_loss: 129.4733\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 200.7016 - val_loss: 136.1427\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 184.1656 - val_loss: 127.5773\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 159.7753 - val_loss: 144.0003\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.1651 - val_loss: 117.9179\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.7886 - val_loss: 115.5396\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.5530 - val_loss: 188.2486\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 170.3316 - val_loss: 151.6036\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 173.4828 - val_loss: 126.4333\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1223 - val_loss: 120.7524\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 217.8635 - val_loss: 1380.8520\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 305.2164 - val_loss: 182.5363\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 158.2386 - val_loss: 110.4372\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.0389 - val_loss: 120.8341\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.5812 - val_loss: 120.5748\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.7002 - val_loss: 122.2342\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6658 - val_loss: 177.3608\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7995 - val_loss: 118.2221\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6234 - val_loss: 126.6776\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8815 - val_loss: 127.2489\n",
      "Epoch 595/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.2584 - val_loss: 128.1263\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.8906 - val_loss: 170.0496\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.0934 - val_loss: 155.0446\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7608 - val_loss: 118.3687\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.9223 - val_loss: 137.0299\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.0271 - val_loss: 122.7018\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0495 - val_loss: 136.7731\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2504 - val_loss: 151.6428\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.8620 - val_loss: 123.7090\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3558 - val_loss: 127.5496\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8683 - val_loss: 143.7148\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7002 - val_loss: 131.8356\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.0487 - val_loss: 139.2124\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.2164 - val_loss: 122.5232\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.9218 - val_loss: 118.1411\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.0460 - val_loss: 132.0021\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.8156 - val_loss: 147.9618\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8514 - val_loss: 132.5187\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.0629 - val_loss: 149.2062\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.7975 - val_loss: 157.3560\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5417 - val_loss: 115.4466\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.6868 - val_loss: 133.3355\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 165.0882 - val_loss: 118.1103\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.2585 - val_loss: 123.2644\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2333 - val_loss: 133.7823\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5418 - val_loss: 118.9532\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.4094 - val_loss: 172.0832\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6219 - val_loss: 112.5514\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.8011 - val_loss: 111.5818\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.0245 - val_loss: 128.2430\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2275 - val_loss: 153.7168\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7572 - val_loss: 139.0816\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.0815 - val_loss: 179.3246\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.0975 - val_loss: 118.4589\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.5081 - val_loss: 140.6375\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.6988 - val_loss: 112.1454\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.3381 - val_loss: 135.9325\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 279.2560 - val_loss: 232.8702\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.9304 - val_loss: 195.1109\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.9570 - val_loss: 117.4165\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.7410 - val_loss: 123.4914\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.7161 - val_loss: 135.2233\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.4040 - val_loss: 131.9719\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9236 - val_loss: 186.7160\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4389 - val_loss: 116.5895\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.6196 - val_loss: 111.0050\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.7112 - val_loss: 126.5209\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.8925 - val_loss: 117.7309\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8329 - val_loss: 151.0216\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.2753 - val_loss: 118.1670\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.6013 - val_loss: 139.1293\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.8172 - val_loss: 153.8820\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.4138 - val_loss: 131.4110\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.4593 - val_loss: 145.9710\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.4281 - val_loss: 282.6919\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.2044 - val_loss: 118.8870\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7353 - val_loss: 135.8433\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.5928 - val_loss: 128.4947\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.5844 - val_loss: 116.7897\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.8483 - val_loss: 146.3652\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 153.0154 - val_loss: 190.8014\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 293.8140 - val_loss: 970.4375\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 179.9900 - val_loss: 124.2708\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.0341 - val_loss: 134.4969\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4333 - val_loss: 133.4328\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8290 - val_loss: 127.9060\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5128 - val_loss: 116.2833\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 310.2303 - val_loss: 161.5565\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.4099 - val_loss: 124.8301\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.2855 - val_loss: 143.3934\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4283 - val_loss: 126.6082\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.9578 - val_loss: 135.6978\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.5228 - val_loss: 152.8996\n",
      "Epoch 668/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.7091 - val_loss: 122.0960\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.1536 - val_loss: 119.4863\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 233.4400 - val_loss: 130.7908\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.9287 - val_loss: 116.2275\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4355 - val_loss: 115.4851\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.4487 - val_loss: 125.0664\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 682.7137 - val_loss: 187.9923\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.9721 - val_loss: 133.2491\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.2302 - val_loss: 120.8496\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.7574 - val_loss: 123.7651\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.8159 - val_loss: 127.8915\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.4930 - val_loss: 129.3770\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.4224 - val_loss: 127.8776\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5905 - val_loss: 123.6741\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3219 - val_loss: 139.1455\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 323.4704 - val_loss: 185.8089\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 289.5255 - val_loss: 133.1590\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.4229 - val_loss: 167.4169\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 197.8362 - val_loss: 127.6130\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 167.5595 - val_loss: 115.6464\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 170.6270 - val_loss: 117.2353\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.2671 - val_loss: 141.7129\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.5359 - val_loss: 113.1273\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7743 - val_loss: 122.0750\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.5699 - val_loss: 113.8993\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6874 - val_loss: 172.4541\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3302 - val_loss: 138.1703\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 266.8400 - val_loss: 133.8922\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.3877 - val_loss: 118.4790\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9557 - val_loss: 174.3214\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2419 - val_loss: 120.3777\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.2246 - val_loss: 127.7533\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.2301 - val_loss: 253.8654\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 230.2773 - val_loss: 131.3559\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.7358 - val_loss: 138.8774\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4219 - val_loss: 118.4043\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 157.0043 - val_loss: 112.9122\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 167.0156 - val_loss: 116.6092\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.0841 - val_loss: 148.9575\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 364.2080 - val_loss: 312.7610\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.0095 - val_loss: 144.9702\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.5376 - val_loss: 140.9800\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7598 - val_loss: 116.3973\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3170 - val_loss: 128.7171\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.9617 - val_loss: 143.3629\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.6375 - val_loss: 167.2003\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.2257 - val_loss: 545.9593\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.8568 - val_loss: 150.4646\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.5817 - val_loss: 140.5790\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.0087 - val_loss: 126.4378\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.2806 - val_loss: 112.8506\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.8926 - val_loss: 115.8028\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 473.0298 - val_loss: 373.7613\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 361.7015 - val_loss: 166.3511\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 251.6919 - val_loss: 245.2964\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.4199 - val_loss: 212.8039\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.7146 - val_loss: 144.7442\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.9639 - val_loss: 122.0636\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 195.2491 - val_loss: 122.2031\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.5277 - val_loss: 144.0649\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 201.8228 - val_loss: 149.2827\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.1113 - val_loss: 132.3138\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.5202 - val_loss: 151.2827\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.0647 - val_loss: 181.9870\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.8660 - val_loss: 141.4569\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.2428 - val_loss: 113.1001\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.6381 - val_loss: 121.1247\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.6446 - val_loss: 114.1026\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 276.3032 - val_loss: 172.1041\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 163.1501 - val_loss: 147.2608\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 160.7319 - val_loss: 116.0253\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 154.8915 - val_loss: 133.9882\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6537 - val_loss: 124.1305\n",
      "Epoch 741/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.6031 - val_loss: 120.4882\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0560 - val_loss: 128.0626\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.9487 - val_loss: 118.2082\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.4424 - val_loss: 122.5928\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.6697 - val_loss: 118.8250\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7935 - val_loss: 116.1053\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8663 - val_loss: 113.8951\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.5153 - val_loss: 120.4321\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 411.4216 - val_loss: 120.9243\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.4545 - val_loss: 116.8349\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.2884 - val_loss: 139.1236\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.9713 - val_loss: 120.6714\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9680 - val_loss: 132.9120\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5949 - val_loss: 128.9190\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.7160 - val_loss: 130.2929\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.3847 - val_loss: 115.0158\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.4430 - val_loss: 177.5373\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.3883 - val_loss: 117.0257\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.9188 - val_loss: 122.4327\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.5090 - val_loss: 115.3058\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.7222 - val_loss: 123.5143\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 315.0945 - val_loss: 125.9794\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.1421 - val_loss: 126.5066\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4600 - val_loss: 115.7934\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.1781 - val_loss: 153.0287\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3934 - val_loss: 140.6633\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6668 - val_loss: 285.0929\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 252.7017 - val_loss: 153.0079\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 174.376 - 0s 51us/step - loss: 174.9045 - val_loss: 112.6980\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1302 - val_loss: 132.9965\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 157.259 - 0s 51us/step - loss: 156.3043 - val_loss: 150.2569\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5329 - val_loss: 110.9179\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1832 - val_loss: 144.7988\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.5310 - val_loss: 111.8158\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.5606 - val_loss: 133.5763\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2874 - val_loss: 128.5672\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8944 - val_loss: 165.7037\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.5948 - val_loss: 187.5854\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5770 - val_loss: 126.1543\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 292.7851 - val_loss: 133.4458\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2914 - val_loss: 127.3482\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3670 - val_loss: 131.9085\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5916 - val_loss: 115.9060\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2686 - val_loss: 115.3837\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 148.7525 - val_loss: 144.3452\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 392.5103 - val_loss: 123.9119\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.2358 - val_loss: 124.8778\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.0364 - val_loss: 113.4854\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2796 - val_loss: 143.0503\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5695 - val_loss: 112.2636\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.6047 - val_loss: 116.4625\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.0388 - val_loss: 185.1828\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.5003 - val_loss: 126.6808\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5469 - val_loss: 123.5051\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4165 - val_loss: 176.1001\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 145.821 - 0s 51us/step - loss: 147.3170 - val_loss: 117.4877\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 147.7882 - val_loss: 108.6644\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 153.7680 - val_loss: 116.3787\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 159.6263 - val_loss: 118.9710\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 155.9470 - val_loss: 268.2901\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.6140 - val_loss: 121.9702\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1306 - val_loss: 119.5096\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.9996 - val_loss: 118.5663\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5440 - val_loss: 114.6780\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7500 - val_loss: 138.8401\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9330 - val_loss: 119.0118\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5438 - val_loss: 111.4601\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.3016 - val_loss: 119.1896\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.1738 - val_loss: 215.2951\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.0251 - val_loss: 112.8220\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8298 - val_loss: 163.2341\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.8638 - val_loss: 109.9162\n",
      "Epoch 813/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9957 - val_loss: 114.8882\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1079 - val_loss: 116.9602\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4285 - val_loss: 123.7534\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0642 - val_loss: 120.0371\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.8047 - val_loss: 112.2596\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1919 - val_loss: 109.4989\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.6151 - val_loss: 136.2149\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1091 - val_loss: 117.0452\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.7483 - val_loss: 112.0603\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.0070 - val_loss: 134.1575\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.9717 - val_loss: 175.6870\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 225.2423 - val_loss: 145.4522\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.516 - 0s 51us/step - loss: 143.5553 - val_loss: 122.0226\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.3548 - val_loss: 125.7367\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6549 - val_loss: 127.4943\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.9630 - val_loss: 142.2024\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.1540 - val_loss: 122.0369\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 148.3425 - val_loss: 108.4882\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5784 - val_loss: 135.3290\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 274.5697 - val_loss: 152.9763\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.0433 - val_loss: 114.7809\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.3938 - val_loss: 110.7207\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.8188 - val_loss: 121.1444\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.5066 - val_loss: 132.9723\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0252 - val_loss: 114.3570\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7248 - val_loss: 120.6707\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5588 - val_loss: 111.4956\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2212 - val_loss: 125.4806\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8653 - val_loss: 125.9406\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2451 - val_loss: 114.7384\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5963 - val_loss: 131.3001\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3582 - val_loss: 116.6396\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6608 - val_loss: 119.9618\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3132 - val_loss: 170.9153\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.9271 - val_loss: 116.7486\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 179.1482 - val_loss: 176.4839\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.1586 - val_loss: 114.0874\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3180 - val_loss: 116.6961\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5256 - val_loss: 125.4395\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9733 - val_loss: 137.5493\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.6761 - val_loss: 107.9809\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 336.9647 - val_loss: 127.3809\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.0323 - val_loss: 113.9503\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.4802 - val_loss: 133.4467\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 145.4367 - val_loss: 110.0931\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.1779 - val_loss: 116.0142\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 165.9011 - val_loss: 115.9535\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.9205 - val_loss: 150.3147\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6574 - val_loss: 108.3802\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.4556 - val_loss: 139.2859\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2288 - val_loss: 175.1171\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1933 - val_loss: 324.7789\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0071 - val_loss: 156.1018\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 351.0499 - val_loss: 147.7353\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.2126 - val_loss: 129.4168\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.6288 - val_loss: 138.4563\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.6242 - val_loss: 223.5147\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 157.0114 - val_loss: 136.5216\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 146.4923 - val_loss: 116.2124\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7778 - val_loss: 113.8743\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4945 - val_loss: 201.1043\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 264.9179 - val_loss: 150.6246\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.4085 - val_loss: 115.7802\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.1231 - val_loss: 111.5066\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.7722 - val_loss: 109.1302\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.5575 - val_loss: 108.5598\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7157 - val_loss: 123.4599\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6747 - val_loss: 109.8937\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.4812 - val_loss: 159.5883\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.9963 - val_loss: 115.4922\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6909 - val_loss: 117.5012\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.7905 - val_loss: 106.7832\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3712 - val_loss: 140.2835\n",
      "Epoch 886/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2680 - val_loss: 120.0600\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1079 - val_loss: 119.0503\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.2672 - val_loss: 112.8072\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.3000 - val_loss: 120.6103\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9906 - val_loss: 129.1038\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.2934 - val_loss: 115.3785\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3304 - val_loss: 149.5098\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7558 - val_loss: 118.2413\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7917 - val_loss: 117.1008\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.3082 - val_loss: 124.5486\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 226.1831 - val_loss: 173.8152\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.3520 - val_loss: 108.2551\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9099 - val_loss: 114.1494\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8929 - val_loss: 123.8787\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1167 - val_loss: 120.5222\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6804 - val_loss: 119.1337\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.3468 - val_loss: 119.9347\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2991 - val_loss: 132.8522\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.1029 - val_loss: 123.6551\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.3411 - val_loss: 114.6524\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 316.2390 - val_loss: 119.0315\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.7553 - val_loss: 291.6297\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.5700 - val_loss: 109.3307\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3470 - val_loss: 109.7517\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1561 - val_loss: 171.7870\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1614 - val_loss: 165.8487\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9222 - val_loss: 115.8762\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5139 - val_loss: 132.0147\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2649 - val_loss: 111.1995\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0545 - val_loss: 121.3405\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.6294 - val_loss: 116.9647\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 322.4665 - val_loss: 132.1120\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.9582 - val_loss: 111.5158\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.7690 - val_loss: 111.0742\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9531 - val_loss: 113.0021\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2984 - val_loss: 118.5967\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9485 - val_loss: 107.6282\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.6371 - val_loss: 162.5595\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.8514 - val_loss: 117.5811\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2345 - val_loss: 109.1465\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6186 - val_loss: 118.2320\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1542 - val_loss: 131.7397\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 146.0683 - val_loss: 115.4274\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.2560 - val_loss: 115.1316\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.9557 - val_loss: 139.5224\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 188.5864 - val_loss: 146.5584\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6973 - val_loss: 252.8114\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.1988 - val_loss: 131.0580\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.3272 - val_loss: 125.0657\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 133.4919 - val_loss: 115.5416\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8873 - val_loss: 116.8242\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.5218 - val_loss: 110.8293\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.0760 - val_loss: 121.6664\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 141.1252 - val_loss: 111.4401\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 143.6833 - val_loss: 174.0230\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 1s 171us/step - loss: 150.8661 - val_loss: 114.2342\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 153.0758 - val_loss: 122.3025\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 193.6814 - val_loss: 196.4776\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 173.9630 - val_loss: 127.6993\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 188.6025 - val_loss: 194.1877\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 146.5952 - val_loss: 112.9095\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 145.9473 - val_loss: 110.9234\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 152.4778 - val_loss: 126.4719\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 154.5482 - val_loss: 111.8754\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.5389 - val_loss: 116.4482\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 164.3932 - val_loss: 128.2656\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 154.3147 - val_loss: 114.5501\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 154.7284 - val_loss: 133.3707\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 208.1262 - val_loss: 108.6105\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 138.5134 - val_loss: 117.4790\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.3289 - val_loss: 116.6895\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 142.7707 - val_loss: 139.8695\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 158.6350 - val_loss: 190.4780\n",
      "Epoch 959/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 62us/step - loss: 143.1534 - val_loss: 123.1571\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 150.3873 - val_loss: 127.8143\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 213.2970 - val_loss: 134.0685\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.6919 - val_loss: 131.1327\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 145.0757 - val_loss: 115.5914\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.8836 - val_loss: 121.9206\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 160.8548 - val_loss: 128.5996\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 146.0647 - val_loss: 113.2315\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.6541 - val_loss: 148.5067\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 255.9000 - val_loss: 438.3283\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 165.6133 - val_loss: 157.4547\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.5199 - val_loss: 110.1511\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 143.0373 - val_loss: 127.4545\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.6658 - val_loss: 109.5867\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.7328 - val_loss: 124.4589\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 150.5196 - val_loss: 108.5809\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 200.5670 - val_loss: 251.1618\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 168.3502 - val_loss: 127.3455\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 155.1380 - val_loss: 145.0658\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 160.8387 - val_loss: 134.4829\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 386.3619 - val_loss: 499.4632\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 380.2324 - val_loss: 128.7697\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 176.7828 - val_loss: 138.4094\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 178.1793 - val_loss: 111.9173\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 174.6661 - val_loss: 140.0602\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 163.8753 - val_loss: 114.8645\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 174.1850 - val_loss: 123.3657\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 158.8966 - val_loss: 124.3723\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 155.0528 - val_loss: 113.2962\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 144.6602 - val_loss: 119.4457\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 155.8177 - val_loss: 116.5942\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 212.6763 - val_loss: 126.4569\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.4506 - val_loss: 131.8666\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 138.0187 - val_loss: 115.7777\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 144.4297 - val_loss: 108.0476\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 146.5614 - val_loss: 110.9827\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.1508 - val_loss: 110.6819\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 153.7126 - val_loss: 146.0537\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 145.0131 - val_loss: 126.5700\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 187.6411 - val_loss: 128.1797\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 148.0710 - val_loss: 137.5962\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 137.3424 - val_loss: 148.1714\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 250.1216 - val_loss: 694.4241\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 232.2324 - val_loss: 126.4870\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 171.5929 - val_loss: 177.1704\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 155.8317 - val_loss: 122.4225\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 171.2060 - val_loss: 225.4402\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 153.5849 - val_loss: 116.8014\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 148.4572 - val_loss: 151.5288\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 150.0871 - val_loss: 117.0292\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 143.8380 - val_loss: 189.9112\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.3638 - val_loss: 181.1411\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.2298 - val_loss: 147.3770\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 147.7225 - val_loss: 132.9181\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 155.7720 - val_loss: 151.5006\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 233.8570 - val_loss: 120.2904\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 151.2778 - val_loss: 116.1014\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 150.0073 - val_loss: 158.6633\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 149.9411 - val_loss: 229.6767\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 268.2820 - val_loss: 110.0924\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.5523 - val_loss: 114.1468\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.8462 - val_loss: 136.0966\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 155.9833 - val_loss: 111.4319\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 156.1212 - val_loss: 151.9626\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 139.2851 - val_loss: 115.6860\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 143.0415 - val_loss: 142.2182\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 141.4745 - val_loss: 108.8259\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 264.1953 - val_loss: 285.7101\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 174.0954 - val_loss: 133.1908\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.2402 - val_loss: 136.4113\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 131.9079 - val_loss: 114.6853\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.9196 - val_loss: 116.2663\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.5443 - val_loss: 209.4432\n",
      "Epoch 1032/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 155.9596 - val_loss: 115.4370\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 161.3678 - val_loss: 118.1850\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 144.9633 - val_loss: 112.8306\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 141.0655 - val_loss: 106.9067\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 143.6814 - val_loss: 116.2901\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.3660 - val_loss: 144.2952\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 147.0715 - val_loss: 133.1053\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 145.4504 - val_loss: 112.2512\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 146.7654 - val_loss: 166.9950\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 138.2936 - val_loss: 113.2696\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 158.8002 - val_loss: 139.4882\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 170.5464 - val_loss: 187.0060\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 168.4983 - val_loss: 118.0489\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 136.2445 - val_loss: 117.4602\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 135.8929 - val_loss: 116.7278\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 171.2692 - val_loss: 128.9287\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 138.6703 - val_loss: 145.8658\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 136.1944 - val_loss: 129.6657\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 703.6529 - val_loss: 238.8885\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 181.5754 - val_loss: 117.8810\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 282.7467 - val_loss: 120.5953\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.3847 - val_loss: 116.0514\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 147.6979 - val_loss: 228.2834\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 176.7246 - val_loss: 119.4494\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 208.0819 - val_loss: 119.7103\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 166.5249 - val_loss: 137.0728\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 251.7626 - val_loss: 114.8436\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 139.0948 - val_loss: 109.5592\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 134.5672 - val_loss: 115.0192\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 137.4249 - val_loss: 110.7408\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 146.2649 - val_loss: 133.3594\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.5692 - val_loss: 116.7050\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 167.9094 - val_loss: 111.1238\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 164.1176 - val_loss: 109.7654\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 200.3469 - val_loss: 199.2342\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 167.9719 - val_loss: 156.8741\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 156.0659 - val_loss: 113.9798\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.3000 - val_loss: 1535.0172\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 312.3469 - val_loss: 114.4328\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.7079 - val_loss: 109.9037\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 133.2153 - val_loss: 122.8932\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 156.5876 - val_loss: 129.5854\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 139.6602 - val_loss: 113.4219\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.7287 - val_loss: 141.6504\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 273.1587 - val_loss: 163.0122\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 161.3538 - val_loss: 116.7269\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.8789 - val_loss: 110.6515\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.9906 - val_loss: 157.3217\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 152.8472 - val_loss: 113.5973\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 152.2638 - val_loss: 111.2879\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 162.5673 - val_loss: 163.3716\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 183.5276 - val_loss: 133.3172\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 140.1133 - val_loss: 130.0305\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 147.8537 - val_loss: 130.8174\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 137.4299 - val_loss: 131.9103\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 146.4750 - val_loss: 112.0886\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.2058 - val_loss: 109.7478\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 143.7563 - val_loss: 114.1137\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.8356 - val_loss: 137.7868\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 253.3488 - val_loss: 122.0225\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.0516 - val_loss: 120.8267\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 154.2500 - val_loss: 173.1744\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.6825 - val_loss: 118.0995\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 199.2456 - val_loss: 116.7206\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.7704 - val_loss: 131.9179\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 152.5404 - val_loss: 122.5168\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 166.0044 - val_loss: 121.6710\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 148.4084 - val_loss: 115.0428\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.8002 - val_loss: 113.8569\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.4030 - val_loss: 116.7357\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 136.8355 - val_loss: 124.6508\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.3005 - val_loss: 113.4438\n",
      "Epoch 1104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 84us/step - loss: 138.4491 - val_loss: 132.7050\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 143.4923 - val_loss: 127.2096\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 157.3709 - val_loss: 133.3338\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 178.6917 - val_loss: 121.0394\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 147.8363 - val_loss: 108.1057\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 232.4406 - val_loss: 1315.4889\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 294.6636 - val_loss: 110.8991\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 136.0038 - val_loss: 127.3380\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.7961 - val_loss: 117.3303\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.5830 - val_loss: 156.3106\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.6218 - val_loss: 123.7472\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 132.1908 - val_loss: 110.2949\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 183.0099 - val_loss: 105.9471\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.9713 - val_loss: 118.8803\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 132.6706 - val_loss: 129.0535\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 142.2649 - val_loss: 124.7031\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 141.7048 - val_loss: 123.4273\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 190.2475 - val_loss: 118.7048\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 154.1781 - val_loss: 108.5228\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.5157 - val_loss: 117.7707\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.3169 - val_loss: 134.0648\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.1107 - val_loss: 122.9557\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 142.4738 - val_loss: 124.6777\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 144.2592 - val_loss: 112.3058\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 144.4259 - val_loss: 240.7219\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 169.2967 - val_loss: 109.1670\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 327.8378 - val_loss: 134.3377\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.5701 - val_loss: 121.6517\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 135.9886 - val_loss: 107.2110\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.1612 - val_loss: 122.0017\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 155.1364 - val_loss: 149.4999\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 180.2373 - val_loss: 136.3235\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 172.0237 - val_loss: 127.3255\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.0810 - val_loss: 125.8955\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.5349 - val_loss: 112.2027\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.0681 - val_loss: 138.5466\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 150.5766 - val_loss: 126.0256\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 239.2735 - val_loss: 128.8655\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 150.6001 - val_loss: 114.5313\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.1469 - val_loss: 220.1016\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 143.2516 - val_loss: 110.2984\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 146.8131 - val_loss: 123.0345\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 179.9758 - val_loss: 121.9602\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.9454 - val_loss: 136.4598\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.7344 - val_loss: 113.6086\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 151.1405 - val_loss: 126.3074\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 146.2087 - val_loss: 110.9289\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.2055 - val_loss: 142.6650\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 188.7222 - val_loss: 160.5335\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 477.3852 - val_loss: 195.3470\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 147.9286 - val_loss: 112.3099\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.8657 - val_loss: 171.5166\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 140.4039 - val_loss: 118.6827\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 166.1238 - val_loss: 115.3706\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 147.9598 - val_loss: 166.2296\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 144.6028 - val_loss: 110.6009\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.0584 - val_loss: 116.1801\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 151.6265 - val_loss: 112.2429\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 138.3893 - val_loss: 113.4611\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 148.5393 - val_loss: 116.3637\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 142.3285 - val_loss: 128.4606\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 140.8673 - val_loss: 125.3525\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 141.5932 - val_loss: 137.8154\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 147.7015 - val_loss: 106.6646\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 237.3057 - val_loss: 202.9412\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 165.7614 - val_loss: 132.8260\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 194.9849 - val_loss: 147.0932\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.0677 - val_loss: 118.6185\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.3877 - val_loss: 109.6599\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.9667 - val_loss: 113.3966\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.9057 - val_loss: 148.4174\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 164.4410 - val_loss: 189.3909\n",
      "Epoch 1176/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 59us/step - loss: 147.0734 - val_loss: 152.9526\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.6115 - val_loss: 116.5116\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 335.4964 - val_loss: 136.3859\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 196.3748 - val_loss: 277.1726\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 157.8361 - val_loss: 129.9654\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 172.3823 - val_loss: 188.5467\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 147.6650 - val_loss: 113.2746\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 138.1720 - val_loss: 117.5403\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.4212 - val_loss: 136.1841\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.3398 - val_loss: 107.2082\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 167.4444 - val_loss: 110.2938\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.5865 - val_loss: 158.6789\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.8530 - val_loss: 110.3657\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.9936 - val_loss: 126.9892\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.9781 - val_loss: 132.3505\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 239.3918 - val_loss: 109.6838\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 133.3312 - val_loss: 163.2948\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 138.8885 - val_loss: 126.1003\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 146.5016 - val_loss: 116.7397\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 133.4006 - val_loss: 134.2742\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 142.7350 - val_loss: 124.8110\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 144.6989 - val_loss: 124.7273\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 147.9896 - val_loss: 116.9257\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 146.4102 - val_loss: 108.7030\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 247.9988 - val_loss: 123.9084\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 167.1459 - val_loss: 121.5719\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 147.8866 - val_loss: 108.8265\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 137.4913 - val_loss: 109.3834\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.7938 - val_loss: 115.1550\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 138.2523 - val_loss: 129.3538\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 156.7317 - val_loss: 157.7093\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 144.8417 - val_loss: 124.3863\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 206.5446 - val_loss: 112.2813\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.4293 - val_loss: 144.9153\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 143.6525 - val_loss: 125.6355\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.0618 - val_loss: 120.7509\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 146.4207 - val_loss: 125.1231\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 212.0387 - val_loss: 119.2567\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 161.6537 - val_loss: 124.5324\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 134.6012 - val_loss: 113.1117\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 300.3187 - val_loss: 115.3647\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.4918 - val_loss: 121.5765\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.4336 - val_loss: 117.1084\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 136.8179 - val_loss: 110.5226\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 136.0095 - val_loss: 114.1666\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 138.6593 - val_loss: 167.6809\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 139.2067 - val_loss: 115.5943\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 141.3742 - val_loss: 156.3905\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.0063 - val_loss: 116.1286\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.7599 - val_loss: 156.6171\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 140.7669 - val_loss: 119.1911\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 460.5282 - val_loss: 329.1258\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 159.8044 - val_loss: 114.3171\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 141.4991 - val_loss: 129.3709\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 152.8735 - val_loss: 119.5564\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 143.3408 - val_loss: 117.2100\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.4599 - val_loss: 126.8572\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 141.6476 - val_loss: 127.1309\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 144.7122 - val_loss: 258.9641\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 166.0077 - val_loss: 290.5906\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 166.1340 - val_loss: 110.4329\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 135.9064 - val_loss: 142.0292\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 155.3581 - val_loss: 125.5299\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 155.4236 - val_loss: 137.9165\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.6113 - val_loss: 131.3533\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 240.3793 - val_loss: 122.4450\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 157.1999 - val_loss: 117.8121\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 146.9385 - val_loss: 111.4075\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 132.9434 - val_loss: 108.8052\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 135.8377 - val_loss: 148.6619\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 145.8667 - val_loss: 115.2162\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 134.2403 - val_loss: 121.3959\n",
      "Epoch 1248/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 75us/step - loss: 143.7757 - val_loss: 112.2921\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 149.7335 - val_loss: 116.2013\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 143.5123 - val_loss: 107.8105\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 138.4958 - val_loss: 109.1084\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 142.1556 - val_loss: 117.8915\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 141.7202 - val_loss: 108.3867\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 137.9021 - val_loss: 107.3858\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 194.5019 - val_loss: 117.4324\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 143.5037 - val_loss: 174.2945\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 153.0509 - val_loss: 138.0432\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 153.6370 - val_loss: 118.2704\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.8857 - val_loss: 110.1302\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 141.2630 - val_loss: 111.9038\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 144.6419 - val_loss: 114.9270\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.2658 - val_loss: 109.7386\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 427.7795 - val_loss: 173.9379\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 205.8649 - val_loss: 137.4298\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 144.9210 - val_loss: 149.7899\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.0345 - val_loss: 112.1070\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 192.6055 - val_loss: 162.6722\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 164.5749 - val_loss: 127.4676\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 143.5920 - val_loss: 119.2317\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 148.3195 - val_loss: 112.4370\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 150.1830 - val_loss: 144.7494\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 208.2031 - val_loss: 228.7265\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 183.9874 - val_loss: 139.6326\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 163.0055 - val_loss: 120.0757\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 137.5467 - val_loss: 144.2708\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 138.5831 - val_loss: 153.3872\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 142.1292 - val_loss: 115.7530\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 164.0608 - val_loss: 133.5621\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 170.1428 - val_loss: 114.3588\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 138.8580 - val_loss: 125.1558\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 146.2754 - val_loss: 123.7345\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 145.2362 - val_loss: 109.1529\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.0971 - val_loss: 170.5641\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 154.2482 - val_loss: 107.7483\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 152.9229 - val_loss: 138.7867\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 145.9589 - val_loss: 137.5061\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 143.6305 - val_loss: 194.8138\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 144.3033 - val_loss: 131.9910\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 138.4277 - val_loss: 106.9192\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 142.3336 - val_loss: 112.6956\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 149.3516 - val_loss: 133.1716\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 291.8859 - val_loss: 199.1056\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 206.9739 - val_loss: 422.7750\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 153.6430 - val_loss: 169.4241\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.2594 - val_loss: 137.5758\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 147.4197 - val_loss: 159.0794\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 141.4520 - val_loss: 118.5143\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 142.8213 - val_loss: 126.9378\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 154.7828 - val_loss: 156.1871\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.7887 - val_loss: 138.0080\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.2256 - val_loss: 113.1133\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 178.3648 - val_loss: 122.8129\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 140.4176 - val_loss: 114.8263\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 187.5374 - val_loss: 162.5998\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 151.3328 - val_loss: 112.6305\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 141.3835 - val_loss: 112.2806\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.3700 - val_loss: 127.5337\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 132.4864 - val_loss: 111.1201\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.5431 - val_loss: 110.4786\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 154.8844 - val_loss: 140.3121\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 139.5974 - val_loss: 112.3160\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 134.3805 - val_loss: 119.0514\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 148.2665 - val_loss: 148.2868\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 147.1288 - val_loss: 159.5796\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.1027 - val_loss: 122.9359\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 205.9494 - val_loss: 122.8390\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 133.4870 - val_loss: 121.2869\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 144.6329 - val_loss: 128.8325\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 143.0662 - val_loss: 113.8784\n",
      "Epoch 1320/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 67us/step - loss: 145.3056 - val_loss: 115.7463\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 138.5741 - val_loss: 130.5934\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 135.6685 - val_loss: 163.2054\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 148.4079 - val_loss: 118.0497\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 144.8934 - val_loss: 112.5777\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 137.6433 - val_loss: 116.9657\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 135.9849 - val_loss: 159.8101\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 143.2470 - val_loss: 116.5748\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 209.6933 - val_loss: 161.2321\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 191.8258 - val_loss: 144.2026\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 151.7057 - val_loss: 122.5518\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 153.4549 - val_loss: 128.8942\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.7508 - val_loss: 134.3016\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 249.0060 - val_loss: 133.6024\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 135.7387 - val_loss: 108.2209\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 140.6039 - val_loss: 116.5687\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 140.6213 - val_loss: 153.6728\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 149.3340 - val_loss: 128.5310\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 142.8884 - val_loss: 126.3123\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 138.0348 - val_loss: 120.4280\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 183.2342 - val_loss: 852.9040\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 201.5516 - val_loss: 113.8042\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.2745 - val_loss: 144.7380\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.1630 - val_loss: 160.4748\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.9992 - val_loss: 107.7451\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.9478 - val_loss: 114.5350\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 143.8500 - val_loss: 127.6282\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 137.8299 - val_loss: 117.2481\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 174.6688 - val_loss: 124.0534\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 230.5071 - val_loss: 252.5516\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 155.3288 - val_loss: 117.8573\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 148.4240 - val_loss: 114.0222\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 142.3551 - val_loss: 119.2180\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 138.8431 - val_loss: 135.9047\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 183.1705 - val_loss: 128.6450\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 146.1131 - val_loss: 112.8922\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 139.0923 - val_loss: 111.6305\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 153.4302 - val_loss: 116.7573\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 135.2333 - val_loss: 136.2359\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 136.6380 - val_loss: 111.3234\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 133.5801 - val_loss: 129.6071\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 137.8257 - val_loss: 108.0249\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 160.0069 - val_loss: 106.4768\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 145.6144 - val_loss: 167.9769\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 155.3465 - val_loss: 108.7524\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 142.5666 - val_loss: 115.4942\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 160.2195 - val_loss: 115.3479\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 134.8428 - val_loss: 123.8538\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 136.2768 - val_loss: 136.7416\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 134.1063 - val_loss: 156.0941\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 135.2611 - val_loss: 126.9133\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 182.3967 - val_loss: 118.0146\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 152.2922 - val_loss: 157.9409\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 139.7844 - val_loss: 110.8450\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 133.5301 - val_loss: 206.9033\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 136.9187 - val_loss: 114.8581\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 275.5870 - val_loss: 135.8157\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 150.6850 - val_loss: 120.4641\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 134.5128 - val_loss: 174.5757\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 139.1974 - val_loss: 147.4764\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 160.5242 - val_loss: 145.6753\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 137.5606 - val_loss: 119.2694\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 150.1804 - val_loss: 126.3777\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 150.9537 - val_loss: 106.0969\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 142.0723 - val_loss: 118.9276\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 143.4312 - val_loss: 142.6336\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 141.2569 - val_loss: 108.4993\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 208.9363 - val_loss: 116.1112\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 137.1519 - val_loss: 115.0633\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 166.6487 - val_loss: 130.0615\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 170.5284 - val_loss: 122.0776\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 207.9202 - val_loss: 148.6191\n",
      "Epoch 1392/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 69us/step - loss: 158.8188 - val_loss: 141.6525\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 147.1273 - val_loss: 122.6678\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 157.7263 - val_loss: 118.9756\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 180.8636 - val_loss: 122.6328\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 143.3776 - val_loss: 136.9037\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 135.5402 - val_loss: 111.8758\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.6552 - val_loss: 122.2454\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 137.0243 - val_loss: 112.5357\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 143.0118 - val_loss: 136.6326\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 143.4959 - val_loss: 124.9688\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 137.5536 - val_loss: 187.9574\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 226.3980 - val_loss: 120.8152\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 168.0376 - val_loss: 134.6228\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 169.4965 - val_loss: 117.5036\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.4082 - val_loss: 115.5472\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 185.8220 - val_loss: 127.4374\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 174.1273 - val_loss: 174.1991\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 151.3172 - val_loss: 114.5051\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 137.3984 - val_loss: 129.4066\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 162.8439 - val_loss: 127.0556\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 258.8210 - val_loss: 107.9879\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.5635 - val_loss: 118.5140\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 151.3913 - val_loss: 114.9909\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 135.9730 - val_loss: 127.3086\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 138.0330 - val_loss: 311.7942\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 155.2880 - val_loss: 143.8982\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 144.0656 - val_loss: 136.5764\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 146.5068 - val_loss: 129.1689\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 150.2329 - val_loss: 127.6820\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 148.7450 - val_loss: 113.0885\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.0938 - val_loss: 125.6584\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 143.2003 - val_loss: 111.1010\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 228.5149 - val_loss: 115.4677\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.3575 - val_loss: 115.3081\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 145.6907 - val_loss: 110.9641\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 133.5767 - val_loss: 115.6757\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 141.8423 - val_loss: 148.5998\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 152.9506 - val_loss: 110.0958\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 140.8451 - val_loss: 118.6271\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 170.8470 - val_loss: 132.8604\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 164.6440 - val_loss: 110.5206\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.7856 - val_loss: 127.7597\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 137.2145 - val_loss: 143.3203\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 146.9957 - val_loss: 133.8902\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 137.7174 - val_loss: 149.3710\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 255.8139 - val_loss: 1768.3331\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 201.9693 - val_loss: 116.9586\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 136.7851 - val_loss: 118.4752\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 144.0614 - val_loss: 120.3754\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.8978 - val_loss: 126.7604\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 138.6079 - val_loss: 114.8051\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 132.7671 - val_loss: 113.0205\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 138.2375 - val_loss: 119.8918\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.8962 - val_loss: 108.1198\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.6662 - val_loss: 111.8888\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 134.1813 - val_loss: 108.5014\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 189.4721 - val_loss: 111.3321\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 153.1611 - val_loss: 347.8673\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 189.7753 - val_loss: 109.5542\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 136.8989 - val_loss: 129.3639\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 143.6192 - val_loss: 122.8220\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 138.7300 - val_loss: 158.1517\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.8671 - val_loss: 126.0730\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 132.5641 - val_loss: 119.1114\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 137.3852 - val_loss: 149.0304\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 134.4908 - val_loss: 112.7939\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 376.9981 - val_loss: 139.7169\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 153.5244 - val_loss: 122.2646\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 137.9766 - val_loss: 124.8990\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 139.0853 - val_loss: 106.9725\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 131.6352 - val_loss: 121.6024\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 140.7385 - val_loss: 123.4427\n",
      "Epoch 1464/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.7137 - val_loss: 132.5218\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 153.1307 - val_loss: 169.8122\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.6077 - val_loss: 113.0216\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 142.0175 - val_loss: 221.7429\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 224.2642 - val_loss: 112.1420\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 134.8499 - val_loss: 117.3084\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 132.5812 - val_loss: 133.4402\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 141.3065 - val_loss: 119.0004\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 136.1894 - val_loss: 114.9750\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 147.5650 - val_loss: 115.9948\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 144.8764 - val_loss: 117.0010\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.8753 - val_loss: 182.9537\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 240.1832 - val_loss: 162.4187\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 177.8202 - val_loss: 117.7228\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 140.8564 - val_loss: 108.9251\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 134.6532 - val_loss: 128.3186\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 153.5718 - val_loss: 125.2539\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 159.0451 - val_loss: 123.0593\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 144.2749 - val_loss: 113.2847\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 130.6796 - val_loss: 109.2828\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 141.9922 - val_loss: 108.7015\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.6536 - val_loss: 167.3818\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 158.1813 - val_loss: 166.8057\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 142.3609 - val_loss: 110.0355\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 143.5626 - val_loss: 138.4637\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 140.6700 - val_loss: 109.6045\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 137.2868 - val_loss: 113.8225\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 143.1212 - val_loss: 281.3176\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 186.6916 - val_loss: 107.1774\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 297.1473 - val_loss: 118.8949\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 136.5449 - val_loss: 172.4933\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 139.5217 - val_loss: 113.4388\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.6864 - val_loss: 108.2137\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 140.4586 - val_loss: 147.9221\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 140.2273 - val_loss: 124.1859\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 136.3346 - val_loss: 112.2408\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 145.3258 - val_loss: 130.5826\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 134.2038 - val_loss: 115.4492\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 147.7205 - val_loss: 140.1001\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 130.3311 - val_loss: 109.7991\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 136.3065 - val_loss: 127.8078\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 152.8712 - val_loss: 122.2339\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 157.9382 - val_loss: 168.2341\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 152.6466 - val_loss: 120.0895\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 147.8307 - val_loss: 114.9143\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 142.7091 - val_loss: 125.6488\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.8167 - val_loss: 112.8028\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.4103 - val_loss: 116.9219\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.6282 - val_loss: 142.9247\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 249.4054 - val_loss: 132.4044\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 179.2507 - val_loss: 150.4685\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.9363 - val_loss: 121.7603\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.0018 - val_loss: 106.8752\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.6647 - val_loss: 108.0430\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.6684 - val_loss: 134.2103\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.4460 - val_loss: 124.4760\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.7662 - val_loss: 113.1739\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 138.1446 - val_loss: 112.5450\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8961 - val_loss: 136.4220\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.3804 - val_loss: 196.5100\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7956 - val_loss: 109.9297\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.9135 - val_loss: 119.1133\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1841 - val_loss: 163.6395\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 154.7314 - val_loss: 127.3508\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 144.3423 - val_loss: 122.6418\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 143.0782 - val_loss: 120.9631\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 146.8254 - val_loss: 204.1085\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 142.3114 - val_loss: 115.7602\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 135.2161 - val_loss: 122.8633\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 174.2407 - val_loss: 189.6490\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 216.7190 - val_loss: 125.0266\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 189.9679 - val_loss: 160.4545\n",
      "Epoch 1536/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 61us/step - loss: 149.5641 - val_loss: 115.7817\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.5369 - val_loss: 120.9652\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 137.8818 - val_loss: 115.5845\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 200.5108 - val_loss: 236.5720\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 161.0995 - val_loss: 123.9394\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 135.7314 - val_loss: 132.7713\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 137.1273 - val_loss: 161.1082\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 136.0247 - val_loss: 108.9659\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 165.8565 - val_loss: 111.2308\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 156.9845 - val_loss: 111.7052\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 136.2551 - val_loss: 108.8447\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 136.6770 - val_loss: 110.4363\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 134.2405 - val_loss: 151.7036\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 134.3184 - val_loss: 117.9222\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 192.1462 - val_loss: 109.7833\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 142.6177 - val_loss: 112.8755\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.2343 - val_loss: 129.1143\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.7404 - val_loss: 110.4470\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 134.4270 - val_loss: 108.7249\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 136.9195 - val_loss: 147.8930\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 162.5997 - val_loss: 113.1559\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 135.6745 - val_loss: 155.9414\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 132.9641 - val_loss: 130.4714\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.2498 - val_loss: 111.6759\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 261.8441 - val_loss: 121.9200\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 136.4044 - val_loss: 112.6863\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 137.3703 - val_loss: 121.8351\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 133.5006 - val_loss: 134.2027\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 140.0538 - val_loss: 109.8672\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 135.2663 - val_loss: 131.3679\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 134.5201 - val_loss: 120.8620\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 138.7381 - val_loss: 115.9662\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 138.0887 - val_loss: 116.8057\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 135.0543 - val_loss: 144.9362\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 147.4365 - val_loss: 109.4884\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.5643 - val_loss: 120.3522\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 147.9546 - val_loss: 107.7547\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 133.3354 - val_loss: 115.9603\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.7468 - val_loss: 125.6023\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 197.3835 - val_loss: 173.2755\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 134.5904 - val_loss: 107.7347\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 128.7042 - val_loss: 119.1051\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 136.1325 - val_loss: 159.9111\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 189.9889 - val_loss: 123.8556\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 184.1420 - val_loss: 110.6040\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 161.0242 - val_loss: 107.8625\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 132.6746 - val_loss: 129.6089\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 153.9731 - val_loss: 150.3321\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 150.3063 - val_loss: 130.6020\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 144.8143 - val_loss: 131.3142\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 145.5537 - val_loss: 114.5722\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 137.9145 - val_loss: 132.5581\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 133.1060 - val_loss: 117.9476\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 145.5424 - val_loss: 118.5998\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 240.0792 - val_loss: 116.9416\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 134.5042 - val_loss: 117.7234\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 135.9414 - val_loss: 112.0918\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 201.0965 - val_loss: 123.3077\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 171.3319 - val_loss: 125.9986\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 144.2608 - val_loss: 107.7129\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 133.6627 - val_loss: 109.2886\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 132.9182 - val_loss: 116.7676\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 134.0131 - val_loss: 107.0432\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 145.2703 - val_loss: 133.2299\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 132.5387 - val_loss: 119.3015\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 141.6446 - val_loss: 195.6112\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.1104 - val_loss: 110.3177\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 233.4447 - val_loss: 125.2905\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 166.3012 - val_loss: 149.2199\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 164.9797 - val_loss: 133.2056\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 162.8950 - val_loss: 123.1761\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 172.8708 - val_loss: 122.7597\n",
      "Epoch 1608/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 67us/step - loss: 161.6519 - val_loss: 125.5278\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 158.3216 - val_loss: 119.4118\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 179.1542 - val_loss: 138.1695\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.6361 - val_loss: 137.1947\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.9776 - val_loss: 114.0181\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 132.1272 - val_loss: 173.4043\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 131.8465 - val_loss: 111.2558\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 152.8542 - val_loss: 122.6426\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 133.5549 - val_loss: 123.0269\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 137.9797 - val_loss: 117.9809\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 140.9845 - val_loss: 123.1076\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.8606 - val_loss: 118.2366\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 140.6374 - val_loss: 135.9934\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.3286 - val_loss: 140.6245\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 149.2086 - val_loss: 111.2033\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 155.9582 - val_loss: 118.6736\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 133.4708 - val_loss: 123.7489\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.1634 - val_loss: 111.4981\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 132.2313 - val_loss: 107.2428\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 136.6223 - val_loss: 108.5504\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 235.5430 - val_loss: 116.0627\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.0798 - val_loss: 128.5936\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 138.8119 - val_loss: 120.1018\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 141.7313 - val_loss: 109.2241\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 133.8006 - val_loss: 144.6653\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 133.1043 - val_loss: 164.8970\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 130.9219 - val_loss: 110.7708\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 143.1676 - val_loss: 120.1824\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 140.5219 - val_loss: 127.2278\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.8801 - val_loss: 106.8257\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 145.4031 - val_loss: 112.1096\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 139.5338 - val_loss: 108.7313\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 370.0580 - val_loss: 136.6662\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 136.4934 - val_loss: 129.1851\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 140.2841 - val_loss: 116.1178\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 129.6440 - val_loss: 128.6438\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 135.1247 - val_loss: 109.3121\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.2096 - val_loss: 106.7143\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.7442 - val_loss: 112.9475\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 188.8799 - val_loss: 131.2653\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 158.6324 - val_loss: 176.2949\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 171.1892 - val_loss: 152.0784\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 173.5412 - val_loss: 117.2093\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 143.3593 - val_loss: 112.9729\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.1359 - val_loss: 111.8529\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 128.0323 - val_loss: 129.3461\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 151.2810 - val_loss: 198.2383\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 195.1732 - val_loss: 115.6517\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.4134 - val_loss: 122.0776\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 146.9033 - val_loss: 111.5984\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 140.3187 - val_loss: 124.8129\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 135.6564 - val_loss: 119.7274\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.7205 - val_loss: 108.1258\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 143.1197 - val_loss: 113.3048\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 141.4078 - val_loss: 111.7314\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 136.0296 - val_loss: 134.0604\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.1774 - val_loss: 120.2342\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.5048 - val_loss: 150.8222\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 178.8402 - val_loss: 113.5653\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 203.6908 - val_loss: 249.2608\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 176.0191 - val_loss: 130.1951\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 160.1933 - val_loss: 126.5408\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 153.0799 - val_loss: 184.1104\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 187.5637 - val_loss: 128.2348\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 181.3482 - val_loss: 215.2242\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 162.3713 - val_loss: 128.8325\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.8225 - val_loss: 117.9253\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 147.7982 - val_loss: 113.0829\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.8449 - val_loss: 114.1909\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 135.0820 - val_loss: 131.1870\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 149.4300 - val_loss: 113.2424\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 173.1384 - val_loss: 115.3738\n",
      "Epoch 1680/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 66us/step - loss: 153.0301 - val_loss: 111.8923\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.1414 - val_loss: 171.8308\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.6676 - val_loss: 111.1739\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 136.6280 - val_loss: 116.6138\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 134.2785 - val_loss: 125.0547\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 144.0905 - val_loss: 118.7144\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 135.3424 - val_loss: 211.2758\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 152.6975 - val_loss: 169.2846\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 134.7380 - val_loss: 167.9240\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.2499 - val_loss: 127.2337\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.9213 - val_loss: 134.8160\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.4867 - val_loss: 114.7314\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.2883 - val_loss: 108.8932\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 140.5619 - val_loss: 110.3660\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 138.5463 - val_loss: 122.7832\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 138.6751 - val_loss: 112.0738\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 138.4026 - val_loss: 110.0586\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 170.5464 - val_loss: 125.4137\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 148.7600 - val_loss: 112.0995\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 133.7821 - val_loss: 121.8668\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 136.2839 - val_loss: 120.5782\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 378.8715 - val_loss: 368.9828\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 266.4883 - val_loss: 210.6120\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 189.7014 - val_loss: 125.8959\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 185.1126 - val_loss: 220.7757\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 155.3741 - val_loss: 125.0097\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 164.7227 - val_loss: 126.0930\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 172.7040 - val_loss: 141.1956\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 156.8596 - val_loss: 149.2195\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 141.0831 - val_loss: 163.0795\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 159.5594 - val_loss: 162.0941\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.4855 - val_loss: 118.7885\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 141.3902 - val_loss: 124.6159\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.9489 - val_loss: 121.5755\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 141.1100 - val_loss: 111.9616\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.5713 - val_loss: 122.8746\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.1313 - val_loss: 114.7339\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 158.2932 - val_loss: 123.6312\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 156.3442 - val_loss: 138.3329\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.1846 - val_loss: 159.9067\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.644 - 1s 64us/step - loss: 143.7781 - val_loss: 115.4088\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.1108 - val_loss: 114.1808\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 156.2301 - val_loss: 147.1397\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 139.2060 - val_loss: 126.2590\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 141.9190 - val_loss: 111.1674\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.2057 - val_loss: 109.1974\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 151.4392 - val_loss: 174.2206\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 206.1076 - val_loss: 126.2712\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.5558 - val_loss: 136.0096\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.5838 - val_loss: 117.6839\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 137.6343 - val_loss: 136.4204\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 215.4426 - val_loss: 117.6916\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 144.1345 - val_loss: 136.5739\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 147.6899 - val_loss: 111.4095\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 136.3246 - val_loss: 118.4672\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 143.9887 - val_loss: 117.2711\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 137.3325 - val_loss: 205.7573\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 160.7776 - val_loss: 110.0186\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 140.7976 - val_loss: 116.3393\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 190.0134 - val_loss: 115.7177\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 134.3876 - val_loss: 124.8684\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 136.2440 - val_loss: 116.1138\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.3013 - val_loss: 115.0968\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 132.5407 - val_loss: 122.7851\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 129.8215 - val_loss: 111.0824\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 187.2914 - val_loss: 266.4027\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 135.7006 - val_loss: 109.9572\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.2117 - val_loss: 111.1078\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.7283 - val_loss: 117.1714\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.5760 - val_loss: 112.7679\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 185.6590 - val_loss: 256.3684\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 201.9169 - val_loss: 267.3072\n",
      "Epoch 1752/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.1684 - val_loss: 112.7585\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 165.7161 - val_loss: 116.2082\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 141.8705 - val_loss: 124.5982\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.3335 - val_loss: 135.4535\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.7447 - val_loss: 114.6244\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 138.0888 - val_loss: 137.1395\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 179.4986 - val_loss: 125.1157\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 141.1392 - val_loss: 164.8731\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.7715 - val_loss: 116.9884\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 137.9747 - val_loss: 115.8759\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 150.9540 - val_loss: 172.4583\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.1081 - val_loss: 126.5655\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 177.0340 - val_loss: 122.3400\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 132.1891 - val_loss: 125.3383\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 134.5639 - val_loss: 120.8027\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.7579 - val_loss: 109.7697\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 134.2991 - val_loss: 113.7623\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 174.7356 - val_loss: 130.7284\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 154.0487 - val_loss: 138.9608\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.6624 - val_loss: 118.9860\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 137.3378 - val_loss: 111.7405\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 132.9869 - val_loss: 121.7635\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.5417 - val_loss: 133.8937\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.6246 - val_loss: 235.9248\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.9922 - val_loss: 126.5249\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 247.0913 - val_loss: 142.0719\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 155.8492 - val_loss: 142.2159\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 178.7738 - val_loss: 109.8694\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.9594 - val_loss: 117.0540\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 167.7232 - val_loss: 135.4473\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.9921 - val_loss: 111.9739\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 149.6640 - val_loss: 110.0325\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.2986 - val_loss: 143.0352\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 228.4084 - val_loss: 133.4691\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 136.3387 - val_loss: 111.6584\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.1958 - val_loss: 123.5744\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 151.0580 - val_loss: 135.6935\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 154.4392 - val_loss: 120.3139\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.4518 - val_loss: 123.2049\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 156.7636 - val_loss: 154.8215\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.0771 - val_loss: 129.9077\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.8221 - val_loss: 171.7109\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.7083 - val_loss: 106.4922\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 168.0256 - val_loss: 117.0936\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 170.0862 - val_loss: 113.7733\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 135.4854 - val_loss: 125.0090\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 153.9549 - val_loss: 124.8881\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 130.4122 - val_loss: 118.9377\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 134.1192 - val_loss: 108.5629\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 141.0932 - val_loss: 169.0621\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 136.4742 - val_loss: 112.3164\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 206.1983 - val_loss: 114.9388\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.9915 - val_loss: 110.8240\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 146.0609 - val_loss: 147.2966\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 128.8012 - val_loss: 129.3443\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 131.8941 - val_loss: 114.5955\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 157.1574 - val_loss: 110.1570\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 139.1201 - val_loss: 157.6510\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.2230 - val_loss: 168.9426\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 132.5188 - val_loss: 112.3319\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 128.4105 - val_loss: 112.6595\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.1428 - val_loss: 154.9953\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 134.7093 - val_loss: 118.7166\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.2891 - val_loss: 208.9888\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.3933 - val_loss: 112.1639\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 132.6086 - val_loss: 123.5458\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 140.9069 - val_loss: 120.8434\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 170.2755 - val_loss: 248.9798\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 147.5263 - val_loss: 118.5271\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 133.1797 - val_loss: 145.7138\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.2696 - val_loss: 108.8309\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 149.2866 - val_loss: 124.8935\n",
      "Epoch 1824/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 83us/step - loss: 131.7361 - val_loss: 111.8350\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 133.2120 - val_loss: 123.9812\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 230.2842 - val_loss: 155.5408\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 132.3383 - val_loss: 114.0311\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.4920 - val_loss: 148.2678\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 132.3843 - val_loss: 120.2096\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 149.0591 - val_loss: 108.8112\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 139.5715 - val_loss: 114.0008\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 135.9703 - val_loss: 109.9161\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.0509 - val_loss: 109.5378\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 200.9373 - val_loss: 164.9032\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 131.9967 - val_loss: 110.4286\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 132.7578 - val_loss: 112.8930\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 149.4602 - val_loss: 123.1042\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 128.3306 - val_loss: 113.2385\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 152.2486 - val_loss: 111.2541\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 134.5544 - val_loss: 130.2681\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 129.2736 - val_loss: 110.1017\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 141.9879 - val_loss: 117.6099\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 134.0609 - val_loss: 110.8133\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 136.2501 - val_loss: 112.8521\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.9736 - val_loss: 140.8723\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 136.8070 - val_loss: 112.3233\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 136.0554 - val_loss: 116.5453\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 145.4246 - val_loss: 258.8011\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 157.0328 - val_loss: 115.5187\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 187.9057 - val_loss: 131.2897\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 197.3736 - val_loss: 115.0787\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 155.0585 - val_loss: 128.4475\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 139.0715 - val_loss: 107.5642\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 135.4121 - val_loss: 109.8213\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 136.4555 - val_loss: 110.4712\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 212.5943 - val_loss: 111.8723\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 2s 199us/step - loss: 136.4344 - val_loss: 135.1678\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 132.7389 - val_loss: 145.7868\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 136.6239 - val_loss: 117.8229\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 137.8797 - val_loss: 112.4109\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 131.1179 - val_loss: 115.0962\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 209.0538 - val_loss: 122.5522\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 134.1602 - val_loss: 113.6732\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 133.6282 - val_loss: 117.8288\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 138.4925 - val_loss: 116.1061\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 133.6985 - val_loss: 115.1910\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 243.7147 - val_loss: 112.5356\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 150.1202 - val_loss: 108.6333\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 134.5480 - val_loss: 116.4452\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 135.9707 - val_loss: 120.0309\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 130.1490 - val_loss: 109.1363\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 131.7598 - val_loss: 111.9318\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 130.9816 - val_loss: 114.4155\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 133.7217 - val_loss: 112.9147\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 135.2934 - val_loss: 112.1502\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 139.6671 - val_loss: 119.0810\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 134.5187 - val_loss: 109.6757\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 142.0871 - val_loss: 112.4176\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 141.8664 - val_loss: 190.7159\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 158.9844 - val_loss: 116.1818\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 138.3675 - val_loss: 199.8416\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 225.5257 - val_loss: 217.5303\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 142.9813 - val_loss: 147.8036\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 136.7665 - val_loss: 126.4523\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 138.8857 - val_loss: 113.6165\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 136.0833 - val_loss: 136.7275\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 131.3306 - val_loss: 112.4621\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 133.5830 - val_loss: 123.1417\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 165.5875 - val_loss: 120.3164\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 141.8628 - val_loss: 110.2594\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 133.7997 - val_loss: 128.5574\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 142.9858 - val_loss: 112.4605\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 138.5355 - val_loss: 137.6828\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 134.6909 - val_loss: 123.9918\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 140.2620 - val_loss: 147.7587\n",
      "Epoch 1896/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 97us/step - loss: 132.8130 - val_loss: 119.6130\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 144.3129 - val_loss: 205.3258\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 141.6463 - val_loss: 130.5488\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 158.8256 - val_loss: 173.5767\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 170.1575 - val_loss: 143.7155\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 133.2088 - val_loss: 107.7677\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.1183 - val_loss: 119.6493\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 138.1939 - val_loss: 112.6772\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.5678 - val_loss: 147.4823\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.9215 - val_loss: 183.3775\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.4354 - val_loss: 114.7022\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.0133 - val_loss: 111.3899\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.5591 - val_loss: 110.8518\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4554 - val_loss: 120.9558\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.9437 - val_loss: 151.6805\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.1802 - val_loss: 115.3012\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 131.9992 - val_loss: 149.1726\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 180.3187 - val_loss: 110.9641\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 142.5302 - val_loss: 141.8932\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 151.0882 - val_loss: 141.5175\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 183.7095 - val_loss: 119.1843\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.3696 - val_loss: 107.7990\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.2412 - val_loss: 156.7069\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 136.4096 - val_loss: 120.3088\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.4813 - val_loss: 109.6958\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.2546 - val_loss: 112.6766\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.8200 - val_loss: 115.8910\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 168.7081 - val_loss: 131.7890\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 139.0416 - val_loss: 110.3316\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 134.2253 - val_loss: 117.8031\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 133.5903 - val_loss: 142.2735\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.6679 - val_loss: 109.0413\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 137.6375 - val_loss: 106.3750\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 155.0735 - val_loss: 132.9650\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 169.7854 - val_loss: 167.6780\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.7941 - val_loss: 109.0327\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.4047 - val_loss: 205.0840\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.1919 - val_loss: 111.1853\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 132.3020 - val_loss: 116.6311\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 129.5052 - val_loss: 112.1036\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.6722 - val_loss: 123.9921\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 133.3660 - val_loss: 115.6194\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.2483 - val_loss: 133.8668\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 180.6392 - val_loss: 112.6441\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.2445 - val_loss: 119.2218\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.2640 - val_loss: 123.3671\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.6387 - val_loss: 126.0650\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 141.0501 - val_loss: 134.3631\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.1139 - val_loss: 112.3614\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 146.7269 - val_loss: 111.2153\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 128.0611 - val_loss: 134.0428\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.8380 - val_loss: 139.1559\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 136.0395 - val_loss: 120.3582\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 134.7662 - val_loss: 136.3088\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 138.1630 - val_loss: 209.3497\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 134.8556 - val_loss: 107.2718\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 167.8243 - val_loss: 123.7751\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 133.7385 - val_loss: 115.8852\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.2076 - val_loss: 122.7107\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4842 - val_loss: 118.0981\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 131.4149 - val_loss: 111.8555\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.0922 - val_loss: 133.6415\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 128.6712 - val_loss: 127.2475\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.1953 - val_loss: 111.1750\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.0194 - val_loss: 151.4097\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.6864 - val_loss: 127.0786\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.0048 - val_loss: 122.9371\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 206.8785 - val_loss: 184.9723\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 161.5813 - val_loss: 139.3795\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 127.0024 - val_loss: 127.7265\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.0118 - val_loss: 129.6185\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.0245 - val_loss: 128.9816\n",
      "Epoch 1968/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.7999 - val_loss: 135.5364\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.6648 - val_loss: 133.8801\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9949 - val_loss: 113.6643\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.5666 - val_loss: 146.9296\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4912 - val_loss: 144.1869\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.4684 - val_loss: 110.5441\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.9963 - val_loss: 122.6596\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 221.4277 - val_loss: 122.6439\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 150.1463 - val_loss: 109.9699\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.9014 - val_loss: 111.2493\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 136.1397 - val_loss: 137.8211\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 133.7135 - val_loss: 123.0854\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 127.3144 - val_loss: 118.4315\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.2094 - val_loss: 120.6659\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 137.6459 - val_loss: 163.0498\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 141.5446 - val_loss: 112.0155\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 126.6975 - val_loss: 115.3359\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 133.1846 - val_loss: 114.1164\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 153.8329 - val_loss: 117.9701\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.9216 - val_loss: 112.7854\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 125.5709 - val_loss: 122.2541\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 133.9548 - val_loss: 152.7516\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 133.8738 - val_loss: 113.2035\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 153.9676 - val_loss: 154.9498\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 143.2922 - val_loss: 112.3183\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 131.4635 - val_loss: 128.6415\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.0376 - val_loss: 109.7154\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 129.6576 - val_loss: 116.8020\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 137.0289 - val_loss: 122.6773\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 158.1581 - val_loss: 126.7922\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.1744 - val_loss: 114.7513\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 150.1394 - val_loss: 130.6289\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 141.4747 - val_loss: 110.3465\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 133.6947 - val_loss: 124.6082\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 228.4790 - val_loss: 132.7081\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 157.3147 - val_loss: 113.3201\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 129.9975 - val_loss: 123.7700\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 123.9868 - val_loss: 113.6071\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.7798 - val_loss: 122.2389\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 151.7993 - val_loss: 119.7268\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 129.1066 - val_loss: 113.0169\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 132.6931 - val_loss: 116.7786\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 146.7209 - val_loss: 135.0828\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.4328 - val_loss: 119.5676\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.5288 - val_loss: 114.4629\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 355.1251 - val_loss: 156.1490\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 217.7155 - val_loss: 158.5750\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 194.6065 - val_loss: 145.7579\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 236.1576 - val_loss: 135.7606\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 174.6301 - val_loss: 140.2913\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.8400 - val_loss: 139.7615\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 167.3944 - val_loss: 130.0858\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.8474 - val_loss: 136.6198\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 161.3489 - val_loss: 131.5687\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 149.8058 - val_loss: 129.5445\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 160.2166 - val_loss: 124.6107\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.2315 - val_loss: 132.8968\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 173.9745 - val_loss: 117.7579\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 149.8201 - val_loss: 170.1018\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 162.8665 - val_loss: 135.8359\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 151.2756 - val_loss: 116.3949\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.0752 - val_loss: 201.8808\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 181.2017 - val_loss: 136.6505\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.2327 - val_loss: 120.2793\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.9661 - val_loss: 149.6280\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.6297 - val_loss: 124.3563\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.9731 - val_loss: 132.0924\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 145.6779 - val_loss: 156.1501\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.2911 - val_loss: 184.8257\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0724 - val_loss: 124.5404\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.7632 - val_loss: 126.9767\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7306 - val_loss: 122.8307\n",
      "Epoch 2040/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9468 - val_loss: 114.3619\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.4709 - val_loss: 118.3819\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.4197 - val_loss: 121.0202\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 150.3082 - val_loss: 116.0085\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 137.4065 - val_loss: 114.0651\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.3627 - val_loss: 404.3828\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4672 - val_loss: 159.9252\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.0449 - val_loss: 125.1279\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.0682 - val_loss: 162.2519\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9093 - val_loss: 141.1438\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 173.3133 - val_loss: 114.0662\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6838 - val_loss: 113.4805\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.2396 - val_loss: 164.1997\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 135.5186 - val_loss: 162.3399\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.9608 - val_loss: 115.4032\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 211.008 - 0s 57us/step - loss: 210.0295 - val_loss: 136.9354\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.4222 - val_loss: 112.0067\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0866 - val_loss: 141.0366\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.4853 - val_loss: 115.8470\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.4701 - val_loss: 112.0091\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3906 - val_loss: 124.2094\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 137.5998 - val_loss: 144.0032\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.1103 - val_loss: 121.9462\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.7363 - val_loss: 122.1818\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7866 - val_loss: 121.9033\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 147.1670 - val_loss: 125.2586\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 151.8333 - val_loss: 149.6750\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.1034 - val_loss: 109.9004\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8736 - val_loss: 111.0760\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1907 - val_loss: 122.5569\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6043 - val_loss: 138.8300\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.2459 - val_loss: 135.3138\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6431 - val_loss: 169.5360\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4432 - val_loss: 116.5278\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.4357 - val_loss: 138.7050\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 144.8089 - val_loss: 112.5379\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.8622 - val_loss: 116.3201\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 140.5569 - val_loss: 208.5098\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.2415 - val_loss: 160.9949\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2465 - val_loss: 209.5030\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 172.9106 - val_loss: 170.2327\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3047 - val_loss: 117.6490\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.3923 - val_loss: 113.7660\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.5001 - val_loss: 155.5410\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1729 - val_loss: 116.8716\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.3659 - val_loss: 111.6283\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.9972 - val_loss: 113.4972\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.4877 - val_loss: 177.4196\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.2825 - val_loss: 121.5639\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 240.8853 - val_loss: 142.1900\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.4216 - val_loss: 117.1897\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.9010 - val_loss: 149.4607\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.2522 - val_loss: 148.3655\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 132.0847 - val_loss: 158.1818\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.0587 - val_loss: 123.5213\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 136.1237 - val_loss: 114.2257\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 131.2703 - val_loss: 119.4271\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 135.2279 - val_loss: 156.4840\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 140.8189 - val_loss: 116.3926\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.4532 - val_loss: 119.6019\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 150.9669 - val_loss: 109.9778\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 1s 170us/step - loss: 148.2024 - val_loss: 114.5562\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 150.6555 - val_loss: 121.5721\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 138.3466 - val_loss: 115.7373\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 171.2137 - val_loss: 142.7477\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 139.3953 - val_loss: 155.9296\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 137.4674 - val_loss: 116.2699\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 130.6739 - val_loss: 111.4537\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.1173 - val_loss: 107.2756\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 133.7525 - val_loss: 119.2736\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.1980 - val_loss: 115.9215\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 139.1818 - val_loss: 115.6665\n",
      "Epoch 2112/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 68us/step - loss: 146.3862 - val_loss: 111.3919\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 134.0821 - val_loss: 119.9668\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 130.3864 - val_loss: 118.6274\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 137.2453 - val_loss: 115.7757\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 137.5356 - val_loss: 164.5851\n",
      "Epoch 02116: early stopping\n",
      "Fold score (RMSE): 12.681435585021973\n",
      "Fold #5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 2s 198us/step - loss: 5650.6718 - val_loss: 4265.7725\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 5078.3817 - val_loss: 3679.9384\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 4652.6918 - val_loss: 3998.9476\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 4481.4707 - val_loss: 3869.6357\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 4494.8519 - val_loss: 3641.3714\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 4288.3578 - val_loss: 3624.2741\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 4247.8861 - val_loss: 3767.4104\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 4347.5358 - val_loss: 3443.2747\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 4085.1450 - val_loss: 3596.5023\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 4044.8159 - val_loss: 3323.3343\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 3932.6813 - val_loss: 3165.1490\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 3914.3270 - val_loss: 3077.2136\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 3680.5176 - val_loss: 2882.6544\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 3811.1954 - val_loss: 3376.8697\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 3409.1852 - val_loss: 3006.1174\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 3250.7175 - val_loss: 2530.8429\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 3002.7842 - val_loss: 2296.1526\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 2845.8003 - val_loss: 2197.1375\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 2593.9756 - val_loss: 2007.6575\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 2219.8308 - val_loss: 2933.0197\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1989.3645 - val_loss: 1315.7838\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 1432.1105 - val_loss: 821.6930\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1148.2355 - val_loss: 850.9640\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 1102.3109 - val_loss: 787.5439\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 909.5119 - val_loss: 533.6305\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 818.1394 - val_loss: 502.5154\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 851.4193 - val_loss: 507.4402\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 773.8743 - val_loss: 380.5546\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 644.0425 - val_loss: 501.7548\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 598.9999 - val_loss: 337.5211\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 608.8456 - val_loss: 1174.0766\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 641.7095 - val_loss: 331.6271\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 562.4444 - val_loss: 559.2661\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 525.2653 - val_loss: 503.8784\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 535.2098 - val_loss: 380.5088\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 546.0548 - val_loss: 361.9863\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 636.6293 - val_loss: 305.3436\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 466.4949 - val_loss: 334.7444\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 526.1653 - val_loss: 324.5726\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 569.6330 - val_loss: 439.5210\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 403.5383 - val_loss: 286.6434\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 632.1565 - val_loss: 1046.0325\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 507.6465 - val_loss: 266.5098\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 457.6267 - val_loss: 321.6831\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 446.4850 - val_loss: 448.9738\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 450.7941 - val_loss: 388.7892\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 521.8893 - val_loss: 281.4961\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 442.0087 - val_loss: 250.1342\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 476.4114 - val_loss: 366.2264\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 454.7211 - val_loss: 597.6735\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 551.4571 - val_loss: 389.2746\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 364.4151 - val_loss: 244.2471\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 427.5241 - val_loss: 613.4487\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 386.7913 - val_loss: 240.4643\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 373.4381 - val_loss: 276.8853\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 377.7253 - val_loss: 362.3488\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 434.8782 - val_loss: 252.8971\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 334.8940 - val_loss: 221.7882\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 379.0312 - val_loss: 199.4656\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 378.5354 - val_loss: 266.1991\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 435.4450 - val_loss: 230.0666\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 349.2187 - val_loss: 231.2304\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 354.0606 - val_loss: 221.6676\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 385.3180 - val_loss: 234.9162\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 451.4966 - val_loss: 446.4806\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 441.2523 - val_loss: 205.1967\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 382.1115 - val_loss: 253.3574\n",
      "Epoch 68/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 432.4118 - val_loss: 184.7896\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 358.9020 - val_loss: 279.7651\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 296.5671 - val_loss: 194.3292\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 391.6000 - val_loss: 256.2360\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 306.7823 - val_loss: 437.4559\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 334.3646 - val_loss: 394.2678\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 416.5328 - val_loss: 365.0600\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 322.4622 - val_loss: 221.7837\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 301.1548 - val_loss: 206.1639\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 295.7511 - val_loss: 248.8229\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 295.4123 - val_loss: 277.8897\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 307.4586 - val_loss: 355.5716\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 329.4989 - val_loss: 188.1270\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 390.5377 - val_loss: 304.8342\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 320.9504 - val_loss: 213.4511\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 371.4720 - val_loss: 179.4704\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 311.1726 - val_loss: 252.7036\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 357.9698 - val_loss: 187.6444\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 330.8664 - val_loss: 274.2075\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 345.2042 - val_loss: 212.3423\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 287.1531 - val_loss: 194.5523\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 303.0302 - val_loss: 219.8506\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 402.1266 - val_loss: 338.9336\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 339.3400 - val_loss: 231.7570\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 303.8105 - val_loss: 209.8449\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 248.5413 - val_loss: 319.2988\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 319.6775 - val_loss: 197.2780\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 364.5570 - val_loss: 547.4633\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 300.4998 - val_loss: 186.1367\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 318.8197 - val_loss: 178.9584\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 244.1888 - val_loss: 171.3052\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 304.7873 - val_loss: 179.6814\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 268.089 - 0s 57us/step - loss: 269.0929 - val_loss: 222.9877\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 448.5609 - val_loss: 763.1849\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 329.0950 - val_loss: 180.2266\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 296.7900 - val_loss: 398.9361\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 273.3206 - val_loss: 335.5507\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 261.8725 - val_loss: 186.4428\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 247.2942 - val_loss: 168.5794\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 412.0063 - val_loss: 442.9401\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 276.1276 - val_loss: 201.3512\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 271.1998 - val_loss: 239.8385\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 315.7505 - val_loss: 174.0444\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 267.5114 - val_loss: 158.6458\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 314.6721 - val_loss: 486.1700\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 281.2567 - val_loss: 188.3767\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 260.4902 - val_loss: 255.6405\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 249.2693 - val_loss: 297.6822\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 282.9062 - val_loss: 230.5337\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 332.0238 - val_loss: 157.0417\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 261.2196 - val_loss: 147.2200\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 264.2732 - val_loss: 310.1866\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 317.6281 - val_loss: 168.8033\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 238.4795 - val_loss: 156.2892\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 344.4214 - val_loss: 466.8390\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 280.2341 - val_loss: 174.7458\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 276.9564 - val_loss: 185.2616\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 231.7595 - val_loss: 180.4292\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 270.7450 - val_loss: 157.6813\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 261.4928 - val_loss: 466.0566\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 256.4653 - val_loss: 183.2195\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 226.4852 - val_loss: 260.2310\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 265.2763 - val_loss: 157.7067\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 224.6803 - val_loss: 187.9063\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 318.2499 - val_loss: 409.7781\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 274.3627 - val_loss: 261.8558\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 322.3856 - val_loss: 381.3110\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 258.1494 - val_loss: 168.6872\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 254.1233 - val_loss: 300.2976\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 334.0824 - val_loss: 160.7036\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 252.7220 - val_loss: 169.9346\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 258.7659 - val_loss: 157.2437\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 219.8007 - val_loss: 173.9146\n",
      "Epoch 141/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 258.4768 - val_loss: 143.4194\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 273.0538 - val_loss: 238.4856\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 313.0992 - val_loss: 322.2391\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.5434 - val_loss: 150.8905\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 212.2300 - val_loss: 139.6358\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 239.7732 - val_loss: 148.2952\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 260.6842 - val_loss: 153.5268\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 216.1419 - val_loss: 160.1242\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 243.0714 - val_loss: 594.1435\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 273.1558 - val_loss: 159.6516\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 250.3698 - val_loss: 152.2404\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 204.8468 - val_loss: 160.4575\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 296.5858 - val_loss: 493.2500\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.7172 - val_loss: 149.8533\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 209.0759 - val_loss: 153.8317\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 256.1422 - val_loss: 214.2630\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 247.4357 - val_loss: 140.4438\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 237.7733 - val_loss: 143.7978\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 223.5505 - val_loss: 148.4339\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 288.0437 - val_loss: 444.8707\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 243.8495 - val_loss: 214.4531\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 217.7434 - val_loss: 435.1991\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 273.2638 - val_loss: 140.7677\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 236.3815 - val_loss: 419.1622\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 224.0512 - val_loss: 193.1336\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 260.2786 - val_loss: 190.7435\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 358.9599 - val_loss: 137.2036\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.7673 - val_loss: 137.9104\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 254.3834 - val_loss: 198.7648\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 239.8833 - val_loss: 276.6160\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.0785 - val_loss: 193.5775\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 223.3096 - val_loss: 145.7480\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 207.5554 - val_loss: 392.2960\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 224.5646 - val_loss: 704.9454\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 243.0779 - val_loss: 169.2217\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.1082 - val_loss: 283.0235\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 246.1675 - val_loss: 138.6244\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 312.4224 - val_loss: 145.3974\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 291.7200 - val_loss: 143.7449\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 187.7775 - val_loss: 152.5318\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 266.4423 - val_loss: 201.2656\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 213.4951 - val_loss: 172.7177\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 214.0566 - val_loss: 184.8433\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 215.6382 - val_loss: 221.9845\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 209.3621 - val_loss: 227.6913\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 289.8229 - val_loss: 2043.9967\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 335.6004 - val_loss: 146.7540\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 235.3674 - val_loss: 145.2614\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 257.3982 - val_loss: 174.9582\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 187.7310 - val_loss: 212.1976\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 254.3985 - val_loss: 452.8506\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 263.7064 - val_loss: 235.9526\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 226.5173 - val_loss: 140.6730\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 201.0322 - val_loss: 135.5331\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 221.2418 - val_loss: 135.8681\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 209.7349 - val_loss: 282.9006\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 254.2384 - val_loss: 143.9892\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 226.8124 - val_loss: 164.6535\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.0474 - val_loss: 137.9292\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 213.2945 - val_loss: 133.6475\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 358.8388 - val_loss: 179.1578\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 229.4224 - val_loss: 131.2329\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 229.5255 - val_loss: 183.8508\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.0290 - val_loss: 150.9369\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 242.2286 - val_loss: 136.7508\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.3815 - val_loss: 148.6478\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 246.8586 - val_loss: 600.7340\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 325.8200 - val_loss: 614.4413\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 216.0415 - val_loss: 131.1326\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.6876 - val_loss: 188.8170\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.8958 - val_loss: 144.0824\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 498.1505 - val_loss: 290.2599\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 244.2023 - val_loss: 232.7023\n",
      "Epoch 214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 251.5779 - val_loss: 138.8464\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 222.1050 - val_loss: 273.0538\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 233.0840 - val_loss: 185.9994\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 221.0771 - val_loss: 173.8088\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 184.8786 - val_loss: 155.2396\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 240.3833 - val_loss: 139.3987\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 233.5446 - val_loss: 159.6416\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 225.2488 - val_loss: 255.3189\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 208.8611 - val_loss: 177.6622\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 264.3707 - val_loss: 253.0859\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 249.3861 - val_loss: 433.4047\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 221.8238 - val_loss: 161.5823\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 198.6312 - val_loss: 254.8246\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 218.2040 - val_loss: 167.2486\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.4523 - val_loss: 127.8849\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 253.7140 - val_loss: 141.3175\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 392.7758 - val_loss: 214.0953\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 396.8065 - val_loss: 183.3329\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.6554 - val_loss: 138.4038\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 206.7080 - val_loss: 137.0179\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 358.6373 - val_loss: 194.9201\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 247.6238 - val_loss: 215.9870\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 230.3707 - val_loss: 128.4125\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 215.6807 - val_loss: 764.2718\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 220.5131 - val_loss: 189.9524\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.9050 - val_loss: 172.5334\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 205.4476 - val_loss: 136.9909\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 225.8417 - val_loss: 133.8384\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 308.9107 - val_loss: 132.8257\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.9329 - val_loss: 175.7916\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 214.1551 - val_loss: 303.7009\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 210.4085 - val_loss: 148.0376\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.8114 - val_loss: 130.8409\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 194.4818 - val_loss: 152.4923\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.9532 - val_loss: 129.0549\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.0312 - val_loss: 246.2910\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 197.3553 - val_loss: 127.7778\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 245.4207 - val_loss: 176.5779\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 222.9491 - val_loss: 192.3398\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 219.9861 - val_loss: 141.6723\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 365.8461 - val_loss: 387.0450\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 250.5388 - val_loss: 133.9762\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 240.7814 - val_loss: 149.8321\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 202.0878 - val_loss: 182.4754\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 257.1904 - val_loss: 193.9574\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 228.4311 - val_loss: 247.4276\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 210.0268 - val_loss: 162.1821\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 213.8754 - val_loss: 139.1702\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 177.5376 - val_loss: 131.0939\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 185.8989 - val_loss: 138.6537\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 260.5249 - val_loss: 191.1699\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 199.3973 - val_loss: 148.3391\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 273.7745 - val_loss: 243.0247\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.1396 - val_loss: 176.4068\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 236.1727 - val_loss: 251.8587\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 215.9826 - val_loss: 132.9940\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 205.3048 - val_loss: 144.5158\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 216.5366 - val_loss: 163.1120\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 197.0301 - val_loss: 134.8453\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 218.2638 - val_loss: 190.9580\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.3282 - val_loss: 132.6718\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.2934 - val_loss: 451.4978\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 216.8923 - val_loss: 139.1968\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.6757 - val_loss: 160.4973\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 261.1036 - val_loss: 353.9989\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.3895 - val_loss: 163.7355\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 224.2176 - val_loss: 128.9602\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 209.5081 - val_loss: 149.9603\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 189.7620 - val_loss: 211.6826\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 201.1215 - val_loss: 249.2058\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 254.7093 - val_loss: 308.7440\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.4157 - val_loss: 191.5536\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 254.8507 - val_loss: 182.4793\n",
      "Epoch 287/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 192.0470 - val_loss: 134.6402\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 240.8414 - val_loss: 240.8724\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 256.8682 - val_loss: 126.7339\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.2719 - val_loss: 126.8620\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.1243 - val_loss: 157.3292\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.5667 - val_loss: 240.9520\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 359.4653 - val_loss: 142.1537\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.7735 - val_loss: 129.6836\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 172.5730 - val_loss: 117.8804\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.9767 - val_loss: 124.1247\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 236.5563 - val_loss: 127.7033\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.1030 - val_loss: 236.6843\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 197.4901 - val_loss: 136.1884\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 268.4743 - val_loss: 126.6888\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 212.7685 - val_loss: 145.8702\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 193.5515 - val_loss: 124.7935\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.5167 - val_loss: 122.5841\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.6559 - val_loss: 123.0534\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.4674 - val_loss: 118.4973\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 205.5359 - val_loss: 133.0296\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 271.9226 - val_loss: 178.2780\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 239.1186 - val_loss: 136.9515\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.9887 - val_loss: 122.7306\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 347.1323 - val_loss: 221.1143\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 207.2525 - val_loss: 184.5247\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 173.0137 - val_loss: 119.9380\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 187.0888 - val_loss: 129.2215\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 291.2752 - val_loss: 151.5033\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.5539 - val_loss: 131.1379\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.8309 - val_loss: 127.3984\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.6218 - val_loss: 127.2887\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 198.4083 - val_loss: 178.2097\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 184.6741 - val_loss: 122.4899\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5256 - val_loss: 125.7752\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 173.8021 - val_loss: 136.7677\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.6019 - val_loss: 136.6381\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.8842 - val_loss: 203.5549\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.5986 - val_loss: 149.6519\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 220.4042 - val_loss: 149.5412\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 215.0642 - val_loss: 142.0647\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 203.1300 - val_loss: 377.3644\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 243.8739 - val_loss: 172.5991\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 170.0704 - val_loss: 214.2949\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 243.1501 - val_loss: 378.0268\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 288.3182 - val_loss: 410.3813\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 226.7771 - val_loss: 320.7386\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 199.4278 - val_loss: 139.4672\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 201.7997 - val_loss: 167.4250\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 277.1784 - val_loss: 230.1334\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 213.9856 - val_loss: 149.2379\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.5850 - val_loss: 127.3606\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 186.9945 - val_loss: 273.3134\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 226.3426 - val_loss: 128.6478\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 228.1293 - val_loss: 1740.9000\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 293.5330 - val_loss: 139.6113\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.4189 - val_loss: 130.0670\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.7339 - val_loss: 194.2595\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 200.2656 - val_loss: 192.8487\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 754.2489 - val_loss: 288.3251\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 330.8691 - val_loss: 205.8296\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 265.6533 - val_loss: 160.0091\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 229.1514 - val_loss: 171.9355\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 277.2421 - val_loss: 136.1698\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 212.8726 - val_loss: 139.4903\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.7970 - val_loss: 142.3152\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.1762 - val_loss: 205.5645\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 202.3174 - val_loss: 144.7392\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 173.7108 - val_loss: 126.1050\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 247.2882 - val_loss: 125.8146\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 174.3862 - val_loss: 129.3249\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 274.8332 - val_loss: 151.4418\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 227.4207 - val_loss: 141.3536\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 223.5545 - val_loss: 192.7169\n",
      "Epoch 360/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.2329 - val_loss: 127.5329\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 408.2086 - val_loss: 420.0173\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 351.5581 - val_loss: 162.4602\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 245.4230 - val_loss: 174.0017\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 248.3022 - val_loss: 182.1044\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 296.3904 - val_loss: 421.1460\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 260.4357 - val_loss: 145.8543\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 210.1605 - val_loss: 150.1128\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 189.9905 - val_loss: 141.5580\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 209.4554 - val_loss: 146.2064\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 219.0641 - val_loss: 155.9473\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 211.5847 - val_loss: 340.0346\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 229.0291 - val_loss: 156.2183\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.8421 - val_loss: 146.4274\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.3070 - val_loss: 130.2847\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.2273 - val_loss: 138.1238\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 198.5833 - val_loss: 139.0163\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 205.9092 - val_loss: 188.5012\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.8914 - val_loss: 131.9458\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 266.1158 - val_loss: 176.0101\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 191.2191 - val_loss: 289.3002\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 204.2133 - val_loss: 181.2881\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 190.7561 - val_loss: 130.6528\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 210.3714 - val_loss: 157.9622\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 220.1447 - val_loss: 131.7224\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 185.6774 - val_loss: 168.6019\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.9040 - val_loss: 119.2106\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.4028 - val_loss: 122.3945\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 293.2276 - val_loss: 229.4163\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 288.3306 - val_loss: 374.6489\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 273.2041 - val_loss: 167.0437\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 221.8955 - val_loss: 162.0031\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 242.2909 - val_loss: 245.2679\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 195.6023 - val_loss: 137.0853\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 210.0945 - val_loss: 126.4939\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 200.0614 - val_loss: 138.9975\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 189.8821 - val_loss: 216.8354\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 200.8277 - val_loss: 124.9548\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 228.1210 - val_loss: 205.9798\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 226.8743 - val_loss: 156.6514\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.9028 - val_loss: 175.1401\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 219.5259 - val_loss: 146.1350\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.1044 - val_loss: 151.6937\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.6123 - val_loss: 121.1108\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.0941 - val_loss: 156.5068\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 242.5154 - val_loss: 219.8310\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.0094 - val_loss: 133.7047\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.3679 - val_loss: 198.3210\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 228.9799 - val_loss: 339.0203\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.6584 - val_loss: 204.0102\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.1149 - val_loss: 173.1603\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 274.5427 - val_loss: 144.6055\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.0720 - val_loss: 123.4542\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.8553 - val_loss: 134.2693\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 190.6790 - val_loss: 146.5292\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 195.3718 - val_loss: 139.7495\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 173.6141 - val_loss: 125.8125\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.3709 - val_loss: 132.0140\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 192.2230 - val_loss: 228.8231\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 199.7457 - val_loss: 122.3208\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.1189 - val_loss: 129.8281\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.8852 - val_loss: 145.1054\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 181.7243 - val_loss: 135.4304\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 178.6074 - val_loss: 209.7829\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.6076 - val_loss: 141.5321\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 190.4076 - val_loss: 163.3187\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 211.0221 - val_loss: 122.8321\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.2271 - val_loss: 119.0757\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 178.9267 - val_loss: 145.8277\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.5742 - val_loss: 130.2876\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 183.7694 - val_loss: 319.6218\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 214.6684 - val_loss: 146.9783\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.3419 - val_loss: 135.1593\n",
      "Epoch 433/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.5460 - val_loss: 138.7765\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.4453 - val_loss: 128.0030\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.2176 - val_loss: 127.1849\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.9446 - val_loss: 121.8502\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.0476 - val_loss: 130.1900\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 204.3715 - val_loss: 135.5093\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.3128 - val_loss: 148.1693\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.0558 - val_loss: 126.1270\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.9917 - val_loss: 169.0249\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 170.8289 - val_loss: 157.4814\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 200.3983 - val_loss: 145.7685\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.2585 - val_loss: 166.7032\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 196.8420 - val_loss: 1466.3552\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 209.2620 - val_loss: 127.2651\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.1165 - val_loss: 133.3358\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.1421 - val_loss: 156.8670\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 183.7755 - val_loss: 147.0631\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 195.3129 - val_loss: 187.1604\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 175.4501 - val_loss: 118.2853\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.3091 - val_loss: 216.0793\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 171.3000 - val_loss: 197.5650\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.2231 - val_loss: 124.6194\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.7848 - val_loss: 129.7224\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 186.0629 - val_loss: 141.6898\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.4959 - val_loss: 176.4786\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.4809 - val_loss: 170.8289\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 164.8772 - val_loss: 127.5360\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 194.4058 - val_loss: 168.1268\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 162.7523 - val_loss: 137.6541\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 195.3193 - val_loss: 120.6827\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 158.2020 - val_loss: 132.4481\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 177.9664 - val_loss: 119.5207\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 183.8190 - val_loss: 167.2869\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 164.9893 - val_loss: 132.2772\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.9608 - val_loss: 209.7606\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 212.1591 - val_loss: 121.9813\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.8507 - val_loss: 130.5462\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.5197 - val_loss: 221.3840\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.5644 - val_loss: 124.7295\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 261.8310 - val_loss: 157.9114\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.7604 - val_loss: 119.9756\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.2451 - val_loss: 128.9487\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 170.4267 - val_loss: 130.6182\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.3157 - val_loss: 188.1705\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.4950 - val_loss: 147.0234\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.6331 - val_loss: 195.1414\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.4162 - val_loss: 128.3562\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.0966 - val_loss: 125.0754\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.6451 - val_loss: 126.1758\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.9129 - val_loss: 158.8293\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.8289 - val_loss: 120.6290\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 218.6586 - val_loss: 174.3123\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.2089 - val_loss: 118.4677\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.5437 - val_loss: 154.4256\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.6775 - val_loss: 309.3674\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.6029 - val_loss: 151.4224\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.5367 - val_loss: 175.0729\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 177.9304 - val_loss: 131.1329\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.0707 - val_loss: 144.5067\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 172.7720 - val_loss: 154.1490\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.8426 - val_loss: 150.6780\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.0411 - val_loss: 152.6604\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 162.0537 - val_loss: 127.0023\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 187.5841 - val_loss: 120.9794\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.7224 - val_loss: 145.7808\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.4813 - val_loss: 115.8237\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.1750 - val_loss: 115.3967\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.1371 - val_loss: 142.9351\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.0286 - val_loss: 113.7789\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 200.7857 - val_loss: 2057.8722\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 276.8623 - val_loss: 128.1676\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.8806 - val_loss: 125.1660\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.4663 - val_loss: 136.6502\n",
      "Epoch 506/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.8137 - val_loss: 115.2535\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.2964 - val_loss: 117.9878\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 432.6710 - val_loss: 159.0661\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 251.2052 - val_loss: 193.8284\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 224.2084 - val_loss: 157.5424\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 266.8665 - val_loss: 189.9648\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 259.4826 - val_loss: 300.7510\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.3227 - val_loss: 133.1647\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 200.8334 - val_loss: 233.1073\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 224.6894 - val_loss: 140.2735\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 188.3986 - val_loss: 149.1263\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.7562 - val_loss: 190.9593\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 289.4077 - val_loss: 147.5864\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 229.5336 - val_loss: 130.3095\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 192.8860 - val_loss: 124.9230\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 211.8907 - val_loss: 126.5086\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 260.4069 - val_loss: 161.4774\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 185.5652 - val_loss: 124.8525\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.8095 - val_loss: 122.4775\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 185.1946 - val_loss: 165.6741\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 188.5575 - val_loss: 174.9009\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.0989 - val_loss: 175.3047\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.4109 - val_loss: 130.8811\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.0215 - val_loss: 185.0206\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 200.0876 - val_loss: 146.8765\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 218.8644 - val_loss: 200.0234\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 194.8025 - val_loss: 118.7709\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 220.3718 - val_loss: 211.6423\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 391.7111 - val_loss: 148.5825\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 238.1536 - val_loss: 168.3421\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 224.7180 - val_loss: 147.0609\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 209.6024 - val_loss: 125.7962\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 152.9951 - val_loss: 124.9538\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 163.1364 - val_loss: 118.3544\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 207.8917 - val_loss: 120.0324\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.1326 - val_loss: 133.1637\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 263.0957 - val_loss: 124.4405\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 163.8295 - val_loss: 138.9785\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 181.1289 - val_loss: 147.4407\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 202.7437 - val_loss: 137.4303\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.6294 - val_loss: 152.5422\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 185.5358 - val_loss: 138.6922\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 181.6751 - val_loss: 125.5846\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 200.4674 - val_loss: 207.3774\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.9771 - val_loss: 170.4822\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 336.3794 - val_loss: 195.9427\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.6369 - val_loss: 119.4415\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.2187 - val_loss: 187.5423\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 174.7050 - val_loss: 204.7878\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 173.9404 - val_loss: 125.4295\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 172.8209 - val_loss: 117.8824\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 189.7733 - val_loss: 121.1142\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 159.5281 - val_loss: 119.6070\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.9347 - val_loss: 163.9590\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 267.5225 - val_loss: 207.8625\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 224.2784 - val_loss: 186.7741\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.4236 - val_loss: 131.5259\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.8279 - val_loss: 241.8049\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 169.3918 - val_loss: 123.0484\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.5006 - val_loss: 133.6552\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 370.1964 - val_loss: 145.4278\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 154.0898 - val_loss: 124.7030\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.1789 - val_loss: 119.2979\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.5532 - val_loss: 141.1676\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.9368 - val_loss: 132.6819\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 261.5661 - val_loss: 120.0347\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.4076 - val_loss: 151.6762\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.0472 - val_loss: 124.6838\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.4924 - val_loss: 151.1076\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 204.1470 - val_loss: 128.0512\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 178.9047 - val_loss: 115.4583\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.3596 - val_loss: 133.4546\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.0436 - val_loss: 139.8224\n",
      "Epoch 579/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 195.2616 - val_loss: 117.2441\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 253.4672 - val_loss: 160.9069\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.4230 - val_loss: 207.5382\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 173.8683 - val_loss: 127.6185\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 151.3150 - val_loss: 129.2702\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 170.1405 - val_loss: 117.4287\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 188.4138 - val_loss: 223.9229\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 158.4237 - val_loss: 156.5821\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 160.1988 - val_loss: 115.1483\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 208.8604 - val_loss: 123.6995\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.6828 - val_loss: 123.8340\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.0527 - val_loss: 117.2603\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.4523 - val_loss: 117.4745\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.4301 - val_loss: 118.5635\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.5958 - val_loss: 131.8821\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 157.1344 - val_loss: 117.8914\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 166.4756 - val_loss: 120.0474\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 163.6044 - val_loss: 177.4964\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 160.8834 - val_loss: 156.9498\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 231.5273 - val_loss: 116.9120\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 187.6198 - val_loss: 112.7494\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 257.4619 - val_loss: 194.4887\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 157.2641 - val_loss: 134.3376\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 161.5718 - val_loss: 116.9663\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 167.5741 - val_loss: 136.3110\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 170.0673 - val_loss: 184.6574\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 173.5240 - val_loss: 370.5286\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 169.1653 - val_loss: 119.9071\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 176.4477 - val_loss: 124.3666\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 234.5962 - val_loss: 158.0406\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 154.2858 - val_loss: 118.2008\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 149.5856 - val_loss: 151.0381\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 180.5580 - val_loss: 123.3357\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 151.4809 - val_loss: 126.6575\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 165.9152 - val_loss: 154.8837\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 162.4507 - val_loss: 113.8679\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 181.8459 - val_loss: 211.4739\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 312.7307 - val_loss: 450.3814\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 218.0693 - val_loss: 184.8074\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 166.1247 - val_loss: 125.4312\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.7593 - val_loss: 125.5493\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 225.9199 - val_loss: 121.4176\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 142.9495 - val_loss: 111.0441\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 159.0422 - val_loss: 115.9111\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.9456 - val_loss: 135.0894\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 152.9963 - val_loss: 155.7575\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 188.2125 - val_loss: 250.5230\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 162.1523 - val_loss: 124.4134\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 171.2273 - val_loss: 123.1190\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 188.7199 - val_loss: 123.9118\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 154.1771 - val_loss: 132.3492\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 154.5659 - val_loss: 117.1114\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 160.4850 - val_loss: 358.3172\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 296.5223 - val_loss: 125.9770\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 177.5602 - val_loss: 129.5280\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 202.3829 - val_loss: 116.6053\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 150.0187 - val_loss: 116.1626\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.9131 - val_loss: 169.5989\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 162.6677 - val_loss: 146.1912\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 195.6936 - val_loss: 131.6908\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 175.8401 - val_loss: 125.4954\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 159.0118 - val_loss: 195.0201\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 148.6513 - val_loss: 133.6560\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 176.5043 - val_loss: 155.6196\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 162.9404 - val_loss: 174.1401\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 150.5296 - val_loss: 126.4496\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 149.8437 - val_loss: 114.2611\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 234.5155 - val_loss: 125.7199\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 220.5112 - val_loss: 126.0419\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 255.4437 - val_loss: 134.3570\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 174.6180 - val_loss: 221.5196\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 178.5963 - val_loss: 121.3211\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 190.4960 - val_loss: 165.3123\n",
      "Epoch 652/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 61us/step - loss: 171.4311 - val_loss: 123.5270\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 182.8875 - val_loss: 117.0780\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.0913 - val_loss: 120.2755\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 159.9861 - val_loss: 196.4812\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 177.7059 - val_loss: 147.6600\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 297.8632 - val_loss: 130.2794\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 187.3625 - val_loss: 150.9448\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 163.0436 - val_loss: 126.7026\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 171.9716 - val_loss: 154.2264\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 183.5856 - val_loss: 120.4683\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 178.6536 - val_loss: 133.3838\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 168.4340 - val_loss: 216.0003\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 190.1754 - val_loss: 118.9764\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 180.9504 - val_loss: 164.9277\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 278.3181 - val_loss: 117.3665\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 157.6904 - val_loss: 111.8739\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 202.6302 - val_loss: 143.4926\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 174.4711 - val_loss: 118.2158\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 173.2041 - val_loss: 131.1824\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 161.6680 - val_loss: 128.0662\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 256.2375 - val_loss: 140.2817\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 158.7460 - val_loss: 136.8080\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 172.4750 - val_loss: 150.7543\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 160.6607 - val_loss: 122.0483\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 183.9014 - val_loss: 121.9536\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 156.6536 - val_loss: 113.1544\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 217.4762 - val_loss: 117.7403\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 162.7861 - val_loss: 132.1480\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 175.9638 - val_loss: 113.5304\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 158.7600 - val_loss: 117.1109\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 188.6782 - val_loss: 116.1030\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 180.2460 - val_loss: 360.9462\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 173.9022 - val_loss: 133.6764\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 162.1893 - val_loss: 125.6543\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 157.0043 - val_loss: 119.3081\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 152.4522 - val_loss: 117.3066\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 163.5837 - val_loss: 178.8125\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 214.4703 - val_loss: 348.3023\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 351.0473 - val_loss: 122.3045\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 154.7237 - val_loss: 133.6376\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 159.9516 - val_loss: 118.6285\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 167.5215 - val_loss: 117.4691\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 151.1439 - val_loss: 175.7237\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 175.1055 - val_loss: 191.1665\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 190.3499 - val_loss: 145.5447\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 149.9181 - val_loss: 117.3004\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 171.0113 - val_loss: 276.2704\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 224.4551 - val_loss: 121.6925\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 152.9479 - val_loss: 114.2874\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 210.2375 - val_loss: 168.6515\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 180.4069 - val_loss: 182.1708\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 169.4209 - val_loss: 145.9699\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 184.3826 - val_loss: 172.3794\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 157.8870 - val_loss: 111.8916\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 178.3206 - val_loss: 113.3041\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 148.1242 - val_loss: 116.4821\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 195.8340 - val_loss: 117.0883\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 157.8190 - val_loss: 138.3548\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 148.0538 - val_loss: 151.7010\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 173.9425 - val_loss: 160.6555\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 170.6278 - val_loss: 129.1137\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 156.9738 - val_loss: 118.7594\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 166.5857 - val_loss: 118.2961\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 166.7550 - val_loss: 193.9535\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 179.8624 - val_loss: 116.5109\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 226.2395 - val_loss: 206.0252\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 172.4047 - val_loss: 137.9679\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 177.3140 - val_loss: 120.0233\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 176.5169 - val_loss: 119.6635\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 169.2700 - val_loss: 115.7871\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 412.9742 - val_loss: 142.6883\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 189.3672 - val_loss: 143.2595\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 184.0972 - val_loss: 213.7815\n",
      "Epoch 725/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 64us/step - loss: 164.3093 - val_loss: 134.0278\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 158.3843 - val_loss: 138.4407\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 180.5145 - val_loss: 119.1386\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 173.0266 - val_loss: 174.1938\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 156.3104 - val_loss: 112.3984\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 215.6125 - val_loss: 363.5230\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 296.3843 - val_loss: 186.6515\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 182.3236 - val_loss: 151.5047\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 168.1662 - val_loss: 127.1387\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 173.4907 - val_loss: 200.9785\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 168.0962 - val_loss: 159.9128\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 168.9416 - val_loss: 144.8766\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 220.3826 - val_loss: 125.6878\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 213.7430 - val_loss: 148.5467\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 186.7014 - val_loss: 121.1884\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 167.3361 - val_loss: 118.8878\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 210.1532 - val_loss: 189.9694\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.0087 - val_loss: 162.8571\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 164.2606 - val_loss: 132.1827\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 166.2756 - val_loss: 272.5031\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 157.8571 - val_loss: 132.9615\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 157.8597 - val_loss: 144.7437\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 162.3417 - val_loss: 148.1831\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 169.012 - 1s 63us/step - loss: 169.5029 - val_loss: 125.8945\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 169.5146 - val_loss: 141.7352\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 164.0934 - val_loss: 130.3425\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 225.2175 - val_loss: 122.9216\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.9642 - val_loss: 142.4681\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 156.0120 - val_loss: 113.5589\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 182.5445 - val_loss: 125.9515\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.9048 - val_loss: 133.3574\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 168.1021 - val_loss: 152.1710\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 173.6694 - val_loss: 114.2590\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 186.7454 - val_loss: 118.9608\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 214.9114 - val_loss: 175.2703\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.5475 - val_loss: 115.1956\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 182.7130 - val_loss: 145.1014\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 201.4762 - val_loss: 133.1478\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 188.0750 - val_loss: 143.8920\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 162.9572 - val_loss: 117.1330\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 158.4719 - val_loss: 210.1531\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 165.8268 - val_loss: 123.6140\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 183.7139 - val_loss: 132.9034\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 192.7607 - val_loss: 148.7858\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 168.0640 - val_loss: 134.7966\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 176.0236 - val_loss: 116.8321\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 158.1620 - val_loss: 118.1910\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 227.1603 - val_loss: 189.3630\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 202.1508 - val_loss: 133.1043\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 169.5763 - val_loss: 113.8886\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 158.4277 - val_loss: 119.2383\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 152.2528 - val_loss: 111.3594\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 159.8206 - val_loss: 122.5799\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 227.4765 - val_loss: 124.5420\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 172.5472 - val_loss: 116.2599\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.9771 - val_loss: 114.7690\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 262.4850 - val_loss: 128.7521\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 263.5293 - val_loss: 135.7225\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 150.6103 - val_loss: 113.1936\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.7188 - val_loss: 168.0825\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 139.0195 - val_loss: 146.5842\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 173.3453 - val_loss: 143.3562\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 360.6411 - val_loss: 134.1622\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 200.4424 - val_loss: 144.4428\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 282.7523 - val_loss: 116.5257\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 150.8626 - val_loss: 136.2047\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 145.6711 - val_loss: 111.4735\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 150.8225 - val_loss: 114.2733\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.2760 - val_loss: 116.0128\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 175.0403 - val_loss: 112.3766\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 167.9245 - val_loss: 114.5296\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 160.2620 - val_loss: 121.4253\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.1935 - val_loss: 199.5711\n",
      "Epoch 798/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 68us/step - loss: 175.3683 - val_loss: 111.8996\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.6290 - val_loss: 114.7036\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 153.6315 - val_loss: 115.7591\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 173.2405 - val_loss: 146.5193\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 175.5471 - val_loss: 118.2492\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 145.0499 - val_loss: 117.4785\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 139.8728 - val_loss: 126.5987\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 221.3741 - val_loss: 124.4629\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 159.1120 - val_loss: 171.1606\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 147.0866 - val_loss: 112.2383\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 145.0911 - val_loss: 111.0378\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 162.8037 - val_loss: 134.5478\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 151.5541 - val_loss: 146.0608\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 178.7131 - val_loss: 111.9813\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 174.7289 - val_loss: 130.0076\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 161.8526 - val_loss: 115.8388\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.8960 - val_loss: 122.5533\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.7537 - val_loss: 201.1469\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 161.0985 - val_loss: 114.5516\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 177.5274 - val_loss: 133.3471\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 274.2853 - val_loss: 112.9405\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 160.1396 - val_loss: 146.0872\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 155.8779 - val_loss: 130.6940\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 156.8224 - val_loss: 109.7022\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 166.8259 - val_loss: 134.8895\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 145.6808 - val_loss: 120.7293\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 271.3188 - val_loss: 128.8988\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 183.5696 - val_loss: 122.1134\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 148.8112 - val_loss: 113.7105\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 145.0300 - val_loss: 133.2413\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 143.9933 - val_loss: 110.3890\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 154.2775 - val_loss: 120.1993\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.7042 - val_loss: 193.3567\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 366.3169 - val_loss: 288.5532\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 177.7312 - val_loss: 116.4284\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 193.1236 - val_loss: 164.5248\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 153.3373 - val_loss: 222.5074\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 182.3987 - val_loss: 117.5579\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 213.5991 - val_loss: 136.0781\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 157.0859 - val_loss: 119.9710\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 153.1238 - val_loss: 133.2344\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 152.8586 - val_loss: 184.6098\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 180.2171 - val_loss: 142.5447\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 173.7872 - val_loss: 112.7947\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 178.7868 - val_loss: 110.7095\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 152.9827 - val_loss: 134.7406\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 174.9920 - val_loss: 117.6097\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 169.1875 - val_loss: 114.2481\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 436.2533 - val_loss: 181.0259\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 223.8428 - val_loss: 244.8824\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 254.3314 - val_loss: 198.0841\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 253.4500 - val_loss: 213.4646\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 176.4556 - val_loss: 137.5886\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.6407 - val_loss: 122.2898\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 245.7583 - val_loss: 120.8795\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 204.4043 - val_loss: 144.2109\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 241.8441 - val_loss: 146.5657\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 181.0765 - val_loss: 114.7597\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 172.0153 - val_loss: 150.0078\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 224.1754 - val_loss: 151.3297\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 144.5119 - val_loss: 111.6659\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 139.7241 - val_loss: 117.7561\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 191.4412 - val_loss: 112.3780\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 155.6832 - val_loss: 180.6383\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 178.2764 - val_loss: 133.1907\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 178.2598 - val_loss: 130.2284\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 204.8039 - val_loss: 121.5249\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 151.5012 - val_loss: 121.5395\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 146.1098 - val_loss: 115.3126\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.6523 - val_loss: 171.5920\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 152.5413 - val_loss: 130.7713\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 156.4165 - val_loss: 171.9778\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 168.7822 - val_loss: 117.4483\n",
      "Epoch 871/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 64us/step - loss: 195.4616 - val_loss: 444.9320\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 171.6133 - val_loss: 152.5938\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 147.9086 - val_loss: 124.0002\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 145.9916 - val_loss: 223.6686\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 150.2064 - val_loss: 121.2304\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 156.5282 - val_loss: 109.4114\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.6930 - val_loss: 174.4021\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 262.1786 - val_loss: 152.4220\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 170.0965 - val_loss: 205.8294\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 168.9860 - val_loss: 129.9668\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.2672 - val_loss: 111.9222\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 152.7265 - val_loss: 120.2799\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 165.6468 - val_loss: 110.1458\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 154.5393 - val_loss: 133.1502\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 184.2753 - val_loss: 113.2697\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 258.1525 - val_loss: 297.3812\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 546.8998 - val_loss: 152.9419\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 222.7815 - val_loss: 113.9600\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 156.1632 - val_loss: 120.3598\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 193.5820 - val_loss: 116.3705\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 136.8579 - val_loss: 206.6746\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 133.2261 - val_loss: 125.3239\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.3469 - val_loss: 115.6815\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 164.3593 - val_loss: 596.3595\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 209.5027 - val_loss: 142.1783\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.9059 - val_loss: 118.6332\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 151.0196 - val_loss: 115.6118\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 159.9365 - val_loss: 116.6864\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 142.6226 - val_loss: 115.0682\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 200.2637 - val_loss: 113.6903\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 184.9858 - val_loss: 110.5384\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 161.3558 - val_loss: 236.7759\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 183.1826 - val_loss: 122.7574\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 154.0820 - val_loss: 117.3350\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 177.9600 - val_loss: 114.2172\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 206.9785 - val_loss: 122.5374\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 154.6753 - val_loss: 153.9323\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 151.6903 - val_loss: 143.6932\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 153.8463 - val_loss: 111.7982\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 146.6572 - val_loss: 143.6269\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 149.6711 - val_loss: 160.0414\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.0904 - val_loss: 113.2558\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 146.4288 - val_loss: 114.4694\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 153.9390 - val_loss: 118.5729\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 186.6182 - val_loss: 177.0186\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 315.4373 - val_loss: 130.8675\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.8073 - val_loss: 108.5460\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 137.9372 - val_loss: 110.2956\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 198.6770 - val_loss: 177.6983\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 208.4594 - val_loss: 133.4685\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 212.0243 - val_loss: 153.7199\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.2404 - val_loss: 209.0056\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 161.8711 - val_loss: 108.9544\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.1045 - val_loss: 117.3245\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 148.5618 - val_loss: 142.1692\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.1138 - val_loss: 123.3542\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.7881 - val_loss: 167.3339\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 182.1471 - val_loss: 186.5233\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 260.2095 - val_loss: 113.5642\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 187.2654 - val_loss: 119.3065\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 138.1046 - val_loss: 117.0452\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.2965 - val_loss: 131.7277\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.3023 - val_loss: 114.8138\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 155.7839 - val_loss: 116.3778\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 140.4243 - val_loss: 132.8727\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 155.5284 - val_loss: 120.6947\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 164.3963 - val_loss: 115.4073\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 159.4659 - val_loss: 327.7694\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 173.9291 - val_loss: 110.2211\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 148.4466 - val_loss: 125.5911\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 191.4729 - val_loss: 113.5682\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 145.1504 - val_loss: 146.2402\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 147.9691 - val_loss: 137.7628\n",
      "Epoch 944/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.9984 - val_loss: 145.6645\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 277.1348 - val_loss: 169.3685\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 153.2221 - val_loss: 132.1172\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 328.3250 - val_loss: 406.5215\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 240.8108 - val_loss: 121.3742\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 206.1802 - val_loss: 128.3697\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 136.0983 - val_loss: 114.5237\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 145.7614 - val_loss: 109.0987\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 137.9341 - val_loss: 115.5763\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 189.0504 - val_loss: 175.9533\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 156.9661 - val_loss: 129.0119\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 149.9194 - val_loss: 136.7515\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 148.2357 - val_loss: 111.4403\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 162.2939 - val_loss: 156.7431\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 147.9522 - val_loss: 120.9189\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 180.4394 - val_loss: 154.8168\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 153.0018 - val_loss: 125.2038\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 149.3935 - val_loss: 109.8354\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 187.7400 - val_loss: 120.2452\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 208.8833 - val_loss: 153.1391\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 210.9634 - val_loss: 147.4642\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 586.0342 - val_loss: 372.7529\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 312.2090 - val_loss: 182.3488\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 258.9891 - val_loss: 141.6040\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 220.3485 - val_loss: 184.4749\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 224.5594 - val_loss: 165.8868\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 231.2609 - val_loss: 133.8639\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 203.1331 - val_loss: 166.0493\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 277.1635 - val_loss: 137.7146\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 226.8288 - val_loss: 127.9811\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 222.5326 - val_loss: 140.7079\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 214.3782 - val_loss: 152.5978\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 191.0112 - val_loss: 139.6788\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 178.9385 - val_loss: 127.2009\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 225.6020 - val_loss: 128.4934\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 217.6907 - val_loss: 135.0029\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 212.1699 - val_loss: 148.4512\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 188.5788 - val_loss: 163.3481\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 173.0407 - val_loss: 162.0426\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 212.3170 - val_loss: 162.4540\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 200.4575 - val_loss: 119.6665\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 191.3779 - val_loss: 139.6321\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 235.0732 - val_loss: 154.1390\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 234.5041 - val_loss: 153.6509\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 169.5687 - val_loss: 131.4400\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 191.9844 - val_loss: 152.9276\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 186.9577 - val_loss: 164.3566\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 233.8305 - val_loss: 164.3389\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 234.9410 - val_loss: 134.1905\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 199.9907 - val_loss: 156.8894\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 195.8395 - val_loss: 129.5467\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 199.3826 - val_loss: 137.3286\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 192.8027 - val_loss: 145.4595\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 178.9482 - val_loss: 140.4248\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 287.5157 - val_loss: 718.3985\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 217.4556 - val_loss: 123.6787\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 198.2670 - val_loss: 188.3052\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 229.8053 - val_loss: 119.1242\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 194.2204 - val_loss: 137.3341\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 179.1857 - val_loss: 195.1294\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 175.8322 - val_loss: 140.9481\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 187.9227 - val_loss: 134.9356\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 196.6467 - val_loss: 204.3365\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 263.4296 - val_loss: 123.5119\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 192.9561 - val_loss: 199.1517\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 188.0428 - val_loss: 130.6096\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 180.1028 - val_loss: 146.8954\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 158.1429 - val_loss: 137.3490\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 204.2826 - val_loss: 134.0432\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 179.6383 - val_loss: 243.6681\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 188.6271 - val_loss: 144.4927\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 197.7922 - val_loss: 116.8889\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 209.7509 - val_loss: 201.5525\n",
      "Epoch 1017/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 65us/step - loss: 177.6668 - val_loss: 126.0747\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 188.8717 - val_loss: 121.8826\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 164.7766 - val_loss: 119.2718\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 200.6451 - val_loss: 128.8673\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 197.1788 - val_loss: 123.6678\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 174.0485 - val_loss: 129.0020\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 206.4004 - val_loss: 141.2389\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 190.4196 - val_loss: 120.4391\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 178.4476 - val_loss: 193.3828\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 294.9602 - val_loss: 143.9588\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 194.9794 - val_loss: 118.6149\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 194.1184 - val_loss: 169.2916\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 162.3694 - val_loss: 119.6612\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 213.9908 - val_loss: 187.2243\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 183.0558 - val_loss: 148.3264\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 180.8933 - val_loss: 207.5936\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 191.8752 - val_loss: 124.1572\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 169.7458 - val_loss: 137.9720\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 218.6098 - val_loss: 135.5006\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 165.4952 - val_loss: 126.2451\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 241.2042 - val_loss: 188.3639\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 238.1768 - val_loss: 129.0570\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 192.9666 - val_loss: 143.0186\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 196.2048 - val_loss: 119.4577\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 180.6723 - val_loss: 136.9602\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.1311 - val_loss: 121.5404\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 165.1075 - val_loss: 130.9886\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 191.7491 - val_loss: 138.5136\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 214.8276 - val_loss: 141.4690\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 182.7626 - val_loss: 185.6420\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 172.5961 - val_loss: 236.7829\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 171.7287 - val_loss: 118.2255\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 173.4619 - val_loss: 117.1751\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 254.4083 - val_loss: 124.7405\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 194.0102 - val_loss: 152.1973\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 165.2967 - val_loss: 122.4867\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 183.8259 - val_loss: 228.3143\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 168.1277 - val_loss: 150.0327\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 195.4968 - val_loss: 132.1509\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 216.0025 - val_loss: 128.2990\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 199.8741 - val_loss: 140.0327\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 205.6519 - val_loss: 292.8979\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 241.0263 - val_loss: 133.6201\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 163.8153 - val_loss: 125.7928\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 191.8158 - val_loss: 146.2695\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 213.4508 - val_loss: 118.7937\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 178.0650 - val_loss: 162.0951\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 261.2383 - val_loss: 180.4527\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 170.6825 - val_loss: 179.0561\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 186.4853 - val_loss: 124.3583\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 180.7808 - val_loss: 120.8187\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 205.7004 - val_loss: 125.9746\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 214.1082 - val_loss: 143.7964\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 163.8242 - val_loss: 137.0760\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 199.7359 - val_loss: 130.5144\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 207.8205 - val_loss: 172.6947\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 194.5336 - val_loss: 164.4377\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 206.0859 - val_loss: 205.6732\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 182.5194 - val_loss: 126.0228\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 164.7594 - val_loss: 115.7969\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 203.6749 - val_loss: 293.9219\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 192.8642 - val_loss: 134.2470\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 167.6432 - val_loss: 120.3739\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 214.2582 - val_loss: 152.8400\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 166.0604 - val_loss: 142.5429\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 191.8996 - val_loss: 117.0916\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 171.8772 - val_loss: 133.7264\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 201.7844 - val_loss: 147.8667\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 189.9655 - val_loss: 222.8114\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 228.2815 - val_loss: 138.8751\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 226.7235 - val_loss: 185.7256\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 162.5915 - val_loss: 124.1784\n",
      "Epoch 1089/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 64us/step - loss: 154.7200 - val_loss: 125.5832\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 178.9965 - val_loss: 136.4974\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 180.1556 - val_loss: 122.2699\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 198.1719 - val_loss: 278.7995\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 175.4945 - val_loss: 121.1288\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 182.7269 - val_loss: 146.5644\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 166.0837 - val_loss: 136.3762\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 174.1447 - val_loss: 157.3163\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 192.9329 - val_loss: 130.6544\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 196.9690 - val_loss: 114.8218\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 193.9774 - val_loss: 307.1542\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 184.6171 - val_loss: 113.0906\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 159.5265 - val_loss: 114.9390\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 249.2664 - val_loss: 126.1248\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 162.9774 - val_loss: 112.9426\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 158.8708 - val_loss: 114.1181\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 162.5335 - val_loss: 151.2602\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 194.2713 - val_loss: 355.8901\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 220.0580 - val_loss: 169.0906\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 186.6105 - val_loss: 125.1030\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 182.2298 - val_loss: 160.1386\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 197.5713 - val_loss: 118.6906\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 192.1264 - val_loss: 128.4170\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 173.5949 - val_loss: 177.7499\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 333.9037 - val_loss: 129.1666\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 226.2050 - val_loss: 148.2645\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 165.3913 - val_loss: 116.3765\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 166.2983 - val_loss: 122.0104\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 178.7284 - val_loss: 119.3996\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 168.4515 - val_loss: 190.8752\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 175.5031 - val_loss: 144.6072\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 218.7270 - val_loss: 146.1786\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 210.5015 - val_loss: 125.9080\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 173.2562 - val_loss: 130.2614\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 175.6545 - val_loss: 125.2651\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 168.1011 - val_loss: 120.5734\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 165.3132 - val_loss: 166.5139\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 200.6911 - val_loss: 116.1073\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 215.8629 - val_loss: 142.2113\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 205.3177 - val_loss: 210.0794\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 159.4454 - val_loss: 137.0315\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 171.1845 - val_loss: 127.3282\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 166.1470 - val_loss: 126.8592\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 162.1464 - val_loss: 124.8559\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 170.0933 - val_loss: 125.7873\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 176.7049 - val_loss: 468.7888\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 269.4841 - val_loss: 145.3799\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 177.6931 - val_loss: 133.9499\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 178.7236 - val_loss: 124.3139\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 193.5414 - val_loss: 124.0835\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 146.1930 - val_loss: 125.4542\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 167.9839 - val_loss: 126.7106\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 198.6007 - val_loss: 127.7647\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 186.6277 - val_loss: 175.9239\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 185.9842 - val_loss: 125.0685\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 186.8235 - val_loss: 153.5861\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 211.3781 - val_loss: 139.9451\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 189.1469 - val_loss: 116.4019\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 220.4883 - val_loss: 175.6946\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 184.8582 - val_loss: 127.7644\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 171.2809 - val_loss: 152.1888\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 164.6755 - val_loss: 123.3677\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 189.2883 - val_loss: 137.0721\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 193.8813 - val_loss: 133.4276\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 193.1587 - val_loss: 208.6069\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 181.1649 - val_loss: 152.9461\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 189.7474 - val_loss: 136.7247\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 186.2670 - val_loss: 137.8610\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 202.5294 - val_loss: 129.3705\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 182.5807 - val_loss: 111.1184\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 178.9304 - val_loss: 153.9570\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 172.9197 - val_loss: 138.2134\n",
      "Epoch 1161/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 67us/step - loss: 182.2313 - val_loss: 133.1321\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 217.7312 - val_loss: 113.5854\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 172.3162 - val_loss: 145.9985\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 171.7834 - val_loss: 112.7564\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 180.3148 - val_loss: 120.4244\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 174.4918 - val_loss: 124.3089\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 214.1479 - val_loss: 118.0641\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 184.0321 - val_loss: 117.1226\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.9851 - val_loss: 125.8864\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 196.0353 - val_loss: 125.3027\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 145.8825 - val_loss: 130.3232\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 181.0539 - val_loss: 137.9916\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 177.5613 - val_loss: 128.5244\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 184.3826 - val_loss: 125.6219\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 235.4648 - val_loss: 153.2079\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 180.4687 - val_loss: 117.4116\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.9854 - val_loss: 119.4529\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 167.4853 - val_loss: 118.4873\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 176.6312 - val_loss: 206.9066\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 166.4358 - val_loss: 126.8704\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 179.9245 - val_loss: 129.1718\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 199.8393 - val_loss: 131.4602\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 267.2714 - val_loss: 139.3847\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 154.6942 - val_loss: 113.9230\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 150.1934 - val_loss: 114.4255\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 160.3639 - val_loss: 114.4672\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 191.8931 - val_loss: 241.3328\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 164.1270 - val_loss: 128.8677\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 228.8628 - val_loss: 148.1068\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 174.0467 - val_loss: 180.7233\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 214.4501 - val_loss: 118.3684\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.7610 - val_loss: 114.3914\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 172.6856 - val_loss: 153.9805\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 273.1316 - val_loss: 113.6230\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 272.4392 - val_loss: 120.3004\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 153.4244 - val_loss: 136.6160\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 157.1928 - val_loss: 113.0463\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 164.7588 - val_loss: 128.6591\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 160.7569 - val_loss: 131.2323\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 159.0649 - val_loss: 116.0546\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 149.9510 - val_loss: 123.7178\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 192.6666 - val_loss: 306.8957\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 187.1999 - val_loss: 166.6983\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 161.1474 - val_loss: 224.5837\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 231.6062 - val_loss: 284.6838- ETA: 0s - loss: \n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 192.4381 - val_loss: 123.7453\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 176.4289 - val_loss: 114.6649\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 173.7850 - val_loss: 137.3898\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 173.7046 - val_loss: 140.5848\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 179.9063 - val_loss: 117.1440\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 173.3171 - val_loss: 144.8075\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 192.1096 - val_loss: 116.0983\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 160.4126 - val_loss: 123.3691\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 157.7618 - val_loss: 136.1568\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 173.0003 - val_loss: 112.0510\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 238.2026 - val_loss: 114.2499\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 160.7435 - val_loss: 113.5205\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 144.1357 - val_loss: 135.8459\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 147.5146 - val_loss: 111.1497\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 167.0192 - val_loss: 112.6370\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 167.5056 - val_loss: 162.4520\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 208.2330 - val_loss: 118.2875\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 177.6130 - val_loss: 128.8611\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 199.1312 - val_loss: 126.0629\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 172.9681 - val_loss: 112.9898\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 138.8802 - val_loss: 151.8361\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 156.4273 - val_loss: 130.7203\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 159.6540 - val_loss: 113.6700\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 193.4841 - val_loss: 326.9208\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 192.3628 - val_loss: 219.6272\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 156.1349 - val_loss: 143.8446\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 176.1343 - val_loss: 116.6374\n",
      "Epoch 1233/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/step - loss: 172.9603 - val_loss: 207.6748\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 152.8549 - val_loss: 123.2148\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 171.0111 - val_loss: 121.9135\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 196.1038 - val_loss: 116.5813\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 169.8343 - val_loss: 114.6340\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 187.4436 - val_loss: 125.4130\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 157.5267 - val_loss: 143.3174\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 185.1599 - val_loss: 188.3732\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 175.8398 - val_loss: 116.4628\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 170.3622 - val_loss: 128.6990\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 250.2833 - val_loss: 211.1414\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 166.4206 - val_loss: 116.4290\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 230.7399 - val_loss: 118.0323\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 165.0391 - val_loss: 130.2845\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 237.4591 - val_loss: 133.4259\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 153.8994 - val_loss: 118.9182\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 141.5951 - val_loss: 130.4171\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 150.0888 - val_loss: 113.0492\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 156.0452 - val_loss: 124.2570\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 187.4586 - val_loss: 123.8735\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 156.4569 - val_loss: 122.0585\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 153.7351 - val_loss: 139.2674\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 174.9315 - val_loss: 118.1001\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 184.5101 - val_loss: 113.1779\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 166.5418 - val_loss: 112.4710\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 148.3192 - val_loss: 122.9043\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 218.8108 - val_loss: 143.6801\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 187.3340 - val_loss: 125.1488\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 183.6563 - val_loss: 113.4781\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 209.1905 - val_loss: 124.9794\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 158.7414 - val_loss: 111.3127\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 186.1871 - val_loss: 169.8550\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 146.5696 - val_loss: 117.7205\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 195.3629 - val_loss: 252.9263\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 190.8652 - val_loss: 133.4457\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 164.5777 - val_loss: 116.5198\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 181.4348 - val_loss: 116.2015\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 171.2993 - val_loss: 118.6698\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 160.6548 - val_loss: 124.5586\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 184.1835 - val_loss: 142.9409\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 166.0426 - val_loss: 116.8944\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 185.0163 - val_loss: 138.0878\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 154.1887 - val_loss: 118.4239\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 203.4474 - val_loss: 117.6907\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 169.7848 - val_loss: 169.3071\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 205.6804 - val_loss: 159.7757\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 164.4246 - val_loss: 121.1809\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 155.8134 - val_loss: 159.9996\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 184.9604 - val_loss: 133.6810\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 181.3762 - val_loss: 140.8527\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 212.9560 - val_loss: 134.0053\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 156.7294 - val_loss: 218.3928\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 250.6467 - val_loss: 113.6087\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 174.2796 - val_loss: 115.8416\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 154.1283 - val_loss: 137.5056\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 155.7007 - val_loss: 130.4942\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 161.8194 - val_loss: 151.4224\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 163.9774 - val_loss: 117.5305\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.8524 - val_loss: 144.1592\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 153.8330 - val_loss: 133.7436\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 239.1456 - val_loss: 134.4902\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 242.9506 - val_loss: 158.1199\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 179.8700 - val_loss: 113.1239\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 200.7070 - val_loss: 116.7593\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 162.0209 - val_loss: 161.3652\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 225.5911 - val_loss: 128.1312\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 161.1289 - val_loss: 123.8074\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 159.8985 - val_loss: 161.4164\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.5197 - val_loss: 207.8978\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 176.8314 - val_loss: 113.4210\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 158.9138 - val_loss: 120.1668\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 175.7115 - val_loss: 151.5883\n",
      "Epoch 1305/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 65us/step - loss: 273.9621 - val_loss: 131.4341\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 170.8837 - val_loss: 128.0876\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 165.3596 - val_loss: 122.0951\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 188.4996 - val_loss: 133.3898\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 215.5966 - val_loss: 119.9006\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 186.1854 - val_loss: 120.3545\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 159.8201 - val_loss: 128.5346\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 177.3756 - val_loss: 128.0525\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 180.7178 - val_loss: 117.5827\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 190.0597 - val_loss: 114.4596\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 202.6530 - val_loss: 128.9079\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 175.1323 - val_loss: 111.3913\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 161.2052 - val_loss: 112.2671\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 162.0655 - val_loss: 110.3831\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 184.1733 - val_loss: 171.9425\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 159.9108 - val_loss: 137.8104\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 154.6083 - val_loss: 110.0478\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 347.0603 - val_loss: 276.3227\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 305.5384 - val_loss: 172.5216\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 189.4698 - val_loss: 283.2545\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 216.2456 - val_loss: 152.7224\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 198.2519 - val_loss: 157.5195\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 214.3159 - val_loss: 264.0738\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 190.4217 - val_loss: 133.9438\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 202.3034 - val_loss: 129.7491\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 179.4021 - val_loss: 124.7093\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 170.8457 - val_loss: 127.5063\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 186.1339 - val_loss: 152.1280\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 194.9566 - val_loss: 208.6145\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 210.2328 - val_loss: 118.7568\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 185.9133 - val_loss: 134.9956\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 173.6944 - val_loss: 114.6190\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 159.8709 - val_loss: 135.9456\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 171.0402 - val_loss: 198.1284\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 156.7079 - val_loss: 137.5770\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 167.7900 - val_loss: 136.7953\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.3065 - val_loss: 121.7711\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 185.8976 - val_loss: 120.9890\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 194.0639 - val_loss: 141.5882\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 194.0720 - val_loss: 118.2606\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 157.4617 - val_loss: 121.5735\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.2692 - val_loss: 140.0418\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 187.1004 - val_loss: 150.0568\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.3369 - val_loss: 142.7141\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 196.0643 - val_loss: 134.1576\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.4739 - val_loss: 120.7434\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.2208 - val_loss: 172.9533\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 173.3020 - val_loss: 150.0496\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.8474 - val_loss: 113.0672\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5068 - val_loss: 122.2134\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.8800 - val_loss: 170.4233\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.3966 - val_loss: 143.7713\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 163.9205 - val_loss: 111.7991\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 239.2928 - val_loss: 139.8894\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 185.4679 - val_loss: 122.3123\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.7335 - val_loss: 120.9442\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.7266 - val_loss: 131.4615\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.8117 - val_loss: 123.6696\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.2849 - val_loss: 116.6986\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 219.8207 - val_loss: 160.2198\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 194.6547 - val_loss: 123.4558\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.1734 - val_loss: 125.3713\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.6431 - val_loss: 124.8282\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.7497 - val_loss: 134.8364\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.4013 - val_loss: 128.3991\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 192.4985 - val_loss: 121.5150\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.2631 - val_loss: 162.4106\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 204.2159 - val_loss: 144.9778\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 171.6128 - val_loss: 231.4170\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 178.6869 - val_loss: 117.9288\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 154.7017 - val_loss: 121.7401\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 203.1436 - val_loss: 125.2808\n",
      "Epoch 1377/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.1019 - val_loss: 119.9840\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.6132 - val_loss: 116.8159\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 149.9329 - val_loss: 149.2219\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1816 - val_loss: 245.0058\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.1588 - val_loss: 216.0619\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.8014 - val_loss: 127.9676\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.8294 - val_loss: 172.3021\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.9413 - val_loss: 127.3268\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.2704 - val_loss: 128.9104\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.5720 - val_loss: 175.7591\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 217.3317 - val_loss: 154.4020\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 168.6561 - val_loss: 115.9945\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 180.6760 - val_loss: 112.2691\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.9421 - val_loss: 113.8744\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.8662 - val_loss: 119.8289\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.2797 - val_loss: 185.1519\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.7545 - val_loss: 132.7155\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.3077 - val_loss: 133.1064\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 158.3313 - val_loss: 134.0602\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.0905 - val_loss: 118.2744\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.6204 - val_loss: 172.1055\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.5419 - val_loss: 119.5345\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.0352 - val_loss: 134.5025\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.2274 - val_loss: 160.1139\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 255.3259 - val_loss: 170.3602\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 218.0532 - val_loss: 149.0574\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.9205 - val_loss: 124.0413\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.6094 - val_loss: 198.4887\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 200.0019 - val_loss: 124.4502\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.3795 - val_loss: 148.5280\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 173.1662 - val_loss: 118.9575\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 171.6436 - val_loss: 120.3476\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.2792 - val_loss: 122.8795\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.3141 - val_loss: 131.7683\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.7778 - val_loss: 119.2921\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7050 - val_loss: 132.2628\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2631 - val_loss: 115.0159\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.1455 - val_loss: 117.8337\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 202.1877 - val_loss: 127.2657\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.3280 - val_loss: 109.5828\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 156.8062 - val_loss: 139.8980\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.6375 - val_loss: 141.8503\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.9906 - val_loss: 112.1964\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.8995 - val_loss: 186.9616\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.0859 - val_loss: 162.4490\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.2208 - val_loss: 109.0496\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.9736 - val_loss: 111.5376\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.4628 - val_loss: 116.1909\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.3341 - val_loss: 132.0434\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.3729 - val_loss: 146.2260\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.5185 - val_loss: 120.6522\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.0295 - val_loss: 134.1603\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.0463 - val_loss: 111.3086\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.7010 - val_loss: 117.8702\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.2433 - val_loss: 123.8064\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2715 - val_loss: 132.3261\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.8845 - val_loss: 111.9396\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.9151 - val_loss: 118.4668\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.5673 - val_loss: 188.2839\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.2106 - val_loss: 114.3571\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 161.0200 - val_loss: 155.4499\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 194.2015 - val_loss: 134.9608\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 204.4023 - val_loss: 122.6935\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.3310 - val_loss: 162.3788\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.7774 - val_loss: 116.4368\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.3923 - val_loss: 126.5629\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.0617 - val_loss: 109.6554\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 176.1646 - val_loss: 148.9275\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.2009 - val_loss: 111.5774\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.4792 - val_loss: 163.3796\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3533 - val_loss: 110.4510\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.3053 - val_loss: 119.2015\n",
      "Epoch 1449/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.5994 - val_loss: 190.9244\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.7680 - val_loss: 124.2409\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.4309 - val_loss: 116.4319\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.3731 - val_loss: 121.3575\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.0515 - val_loss: 130.2045\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.6279 - val_loss: 123.4700\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 147.3489 - val_loss: 121.7845\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 167.2821 - val_loss: 113.1735\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 163.3419 - val_loss: 134.2853\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 172.0464 - val_loss: 143.1165\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.8357 - val_loss: 116.6108\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.1251 - val_loss: 167.2902\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.5155 - val_loss: 143.0337\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6192 - val_loss: 184.7645\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.3493 - val_loss: 112.7608\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.0501 - val_loss: 113.9488\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.6092 - val_loss: 207.3142\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.9962 - val_loss: 118.6412\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.8713 - val_loss: 113.5002\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4426 - val_loss: 121.0373\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 274.7670 - val_loss: 130.0312\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.7863 - val_loss: 111.5212\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.7956 - val_loss: 145.5069\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.6882 - val_loss: 118.1740\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.9189 - val_loss: 152.5170\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.8286 - val_loss: 111.4368\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.8455 - val_loss: 164.2739\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.9942 - val_loss: 120.1214\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.9753 - val_loss: 113.9600\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.4693 - val_loss: 141.1566\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.5596 - val_loss: 113.8925\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.5895 - val_loss: 123.4937\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.7159 - val_loss: 112.6846\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.2809 - val_loss: 123.8382\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 208.5954 - val_loss: 130.6028\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.9126 - val_loss: 155.5053\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.6687 - val_loss: 147.9371\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.5307 - val_loss: 109.5745\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.3099 - val_loss: 168.8913\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 152.1649 - val_loss: 108.5901\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 157.5102 - val_loss: 145.7406\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 209.3930 - val_loss: 176.8863\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.1346 - val_loss: 153.9237\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.9988 - val_loss: 226.3282\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.6099 - val_loss: 122.0127\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 165.6273 - val_loss: 134.6664\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 154.2221 - val_loss: 121.4890\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 160.7601 - val_loss: 123.1429\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 151.4265 - val_loss: 125.3976\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 207.1226 - val_loss: 116.7179\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.6720 - val_loss: 121.1797\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.1222 - val_loss: 222.2801\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.1379 - val_loss: 110.0119\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.3384 - val_loss: 851.9545\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.1292 - val_loss: 123.6008\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.9713 - val_loss: 125.3158\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.9608 - val_loss: 121.9535\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 171.3236 - val_loss: 126.6943\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.0403 - val_loss: 145.5662\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.3942 - val_loss: 120.7988\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.3693 - val_loss: 190.3897\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.3013 - val_loss: 113.9522\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 142.6651 - val_loss: 131.7417\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.8972 - val_loss: 119.7528\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.7220 - val_loss: 154.3415\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.2295 - val_loss: 117.1646\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.4875 - val_loss: 113.2491\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.8274 - val_loss: 121.6774\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.8787 - val_loss: 112.7403\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.7783 - val_loss: 214.5396\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.6002 - val_loss: 175.9173\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.0232 - val_loss: 115.0073\n",
      "Epoch 1521/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.3135 - val_loss: 136.3682\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.0632 - val_loss: 154.2127\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 284.2977 - val_loss: 153.2591\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.6898 - val_loss: 115.2333\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.8674 - val_loss: 115.5004\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 213.5272 - val_loss: 153.0340\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 167.2786 - val_loss: 122.5991\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 166.4614 - val_loss: 185.9884\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 161.7960 - val_loss: 123.8191\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.7390 - val_loss: 130.0172\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 194.2608 - val_loss: 139.6584\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 157.5662 - val_loss: 110.3493\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 163.4130 - val_loss: 110.6071\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 138.4295 - val_loss: 128.9685\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.0681 - val_loss: 128.2096\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.7918 - val_loss: 111.9399\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.4549 - val_loss: 107.2922\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.6586 - val_loss: 120.0671\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.3070 - val_loss: 116.5777\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 185.6345 - val_loss: 142.8069\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.8103 - val_loss: 163.5329\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.6598 - val_loss: 120.5571\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.5002 - val_loss: 110.6239\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 159.5559 - val_loss: 178.9945\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 159.5841 - val_loss: 137.0075\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.4057 - val_loss: 114.1818\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 186.7660 - val_loss: 148.0745\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2189 - val_loss: 117.4648\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 155.6698 - val_loss: 117.4992\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.4589 - val_loss: 132.9869\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.3882 - val_loss: 140.9955\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 150.5092 - val_loss: 113.8943\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3457 - val_loss: 149.5246\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.1923 - val_loss: 122.2143\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.3218 - val_loss: 134.3345\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.6670 - val_loss: 119.9887\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 175.0903 - val_loss: 113.2005\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.7279 - val_loss: 235.9960\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 145.7389 - val_loss: 111.2430\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.4026 - val_loss: 125.0115\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7567 - val_loss: 143.7667\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.5900 - val_loss: 112.9741\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.0041 - val_loss: 124.1172\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 186.4890 - val_loss: 195.1779\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.2139 - val_loss: 113.5315\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.7671 - val_loss: 117.8885\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.3711 - val_loss: 123.1542\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.0120 - val_loss: 156.5777\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.3357 - val_loss: 392.5009\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.7913 - val_loss: 110.5691\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.3762 - val_loss: 119.6354\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.4566 - val_loss: 145.0965\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.5984 - val_loss: 135.9348\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.1419 - val_loss: 179.1616\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.0737 - val_loss: 132.6354\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.2711 - val_loss: 121.1867\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.4721 - val_loss: 113.4002\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.6682 - val_loss: 109.6591\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.7384 - val_loss: 213.7847\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.7232 - val_loss: 140.6269\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.3013 - val_loss: 144.1455\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.8235 - val_loss: 131.2409\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.5654 - val_loss: 114.4967\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.6338 - val_loss: 122.8618\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.8541 - val_loss: 143.4070\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.4736 - val_loss: 112.0047\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.6822 - val_loss: 137.8982\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.6097 - val_loss: 134.3546\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 181.0740 - val_loss: 127.9053\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 148.8332 - val_loss: 185.9331\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 159.3307 - val_loss: 115.1850\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 152.6451 - val_loss: 118.6896\n",
      "Epoch 1593/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 57us/step - loss: 220.7422 - val_loss: 126.1673\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.0902 - val_loss: 111.1973\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 164.3245 - val_loss: 133.3721\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.2507 - val_loss: 119.0152\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.3511 - val_loss: 109.1676\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.4005 - val_loss: 117.4207\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5022 - val_loss: 136.6918\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5533 - val_loss: 119.1741\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0328 - val_loss: 119.9309\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.9454 - val_loss: 194.9509\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0706 - val_loss: 140.0172\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 166.7112 - val_loss: 183.9145\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.1643 - val_loss: 128.0839\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 275.5947 - val_loss: 126.6758\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.8466 - val_loss: 133.9823\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6719 - val_loss: 134.1445\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.3524 - val_loss: 113.6343\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 141.6555 - val_loss: 115.6947\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6926 - val_loss: 109.4700\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.1887 - val_loss: 111.5735\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.9801 - val_loss: 113.1011\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.4373 - val_loss: 139.7363\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.1549 - val_loss: 134.0110\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.8006 - val_loss: 120.9584\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.8000 - val_loss: 112.1207\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.1363 - val_loss: 115.8437\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.6729 - val_loss: 118.3515\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 141.0534 - val_loss: 111.1841\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.9687 - val_loss: 140.0676\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.0292 - val_loss: 166.6296\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.9342 - val_loss: 107.9847\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.1377 - val_loss: 114.3023\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.2803 - val_loss: 140.2541\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.3935 - val_loss: 136.1576\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.4215 - val_loss: 127.8455\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6927 - val_loss: 114.0515\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5706 - val_loss: 111.5636\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.8111 - val_loss: 144.4789\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 213.0906 - val_loss: 114.5067\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 167.6842 - val_loss: 115.9949\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.9949 - val_loss: 123.2544\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.2264 - val_loss: 108.0389\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.1199 - val_loss: 119.8813\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.8541 - val_loss: 117.1495\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.2428 - val_loss: 143.8765\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.3977 - val_loss: 147.9678\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4630 - val_loss: 150.4668\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.8001 - val_loss: 119.3911\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 157.8224 - val_loss: 128.8959\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.8200 - val_loss: 120.1716\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.6948 - val_loss: 119.0303\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.9619 - val_loss: 246.9061\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 159.3927 - val_loss: 112.0544\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.5514 - val_loss: 143.1864\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.5528 - val_loss: 116.3037\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.9350 - val_loss: 133.8173\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.4482 - val_loss: 107.6405\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 145.7553 - val_loss: 117.7585\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.9642 - val_loss: 109.1303\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.8430 - val_loss: 203.3501\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.7969 - val_loss: 251.7613\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.3330 - val_loss: 108.4990\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.6415 - val_loss: 150.7429\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.6212 - val_loss: 126.2794\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.7837 - val_loss: 112.7325\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 143.1510 - val_loss: 111.5356\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 159.2917 - val_loss: 118.9409\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 170.8359 - val_loss: 115.8067\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.5375 - val_loss: 111.7773\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.6969 - val_loss: 109.6871\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.2720 - val_loss: 115.9035\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3802 - val_loss: 115.8038\n",
      "Epoch 1665/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.8187 - val_loss: 160.4433\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5218 - val_loss: 155.0381\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6982 - val_loss: 129.3431\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.5498 - val_loss: 124.5875\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.6634 - val_loss: 110.8839\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.2712 - val_loss: 111.7064\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.0065 - val_loss: 109.5519\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3023 - val_loss: 114.5901\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.4854 - val_loss: 130.8335\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.5046 - val_loss: 132.8899\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.8925 - val_loss: 109.9092\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.9178 - val_loss: 108.3327\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.8893 - val_loss: 141.9376\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.3006 - val_loss: 137.1946\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.1268 - val_loss: 121.7294\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.5481 - val_loss: 113.5544\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.4484 - val_loss: 158.9457\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.8686 - val_loss: 114.1363\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.8862 - val_loss: 125.3765\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.4426 - val_loss: 116.1085\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.2466 - val_loss: 115.5854\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 208.1795 - val_loss: 120.2645\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.7727 - val_loss: 155.9791\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.9809 - val_loss: 122.5213\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.7052 - val_loss: 160.8294\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.9566 - val_loss: 377.2011\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 187.5330 - val_loss: 179.5628\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.5574 - val_loss: 110.7512\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3625 - val_loss: 167.5732\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4613 - val_loss: 111.0618\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3211 - val_loss: 150.1748\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.3460 - val_loss: 142.7716\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.2514 - val_loss: 120.9976\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.2293 - val_loss: 117.1571\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.5253 - val_loss: 119.0863\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 176.6404 - val_loss: 117.3777\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.8991 - val_loss: 137.9284\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.5922 - val_loss: 140.7810\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5174 - val_loss: 166.2913\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 231.2309 - val_loss: 126.3695\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 157.5914 - val_loss: 112.0948\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.7711 - val_loss: 255.2101\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.0149 - val_loss: 125.3620\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.7917 - val_loss: 112.8782\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1274 - val_loss: 108.7474\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 170.6535 - val_loss: 163.9787\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 190.0935 - val_loss: 137.9985\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1575 - val_loss: 112.0309\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.9554 - val_loss: 108.5638\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.0441 - val_loss: 113.5699\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 221.5844 - val_loss: 180.9065\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.0193 - val_loss: 175.9528\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.2254 - val_loss: 125.4145\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4629 - val_loss: 107.2290\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.7472 - val_loss: 107.9687\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.2342 - val_loss: 152.4492\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.6079 - val_loss: 147.1772\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.8595 - val_loss: 114.9204\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.2471 - val_loss: 126.3926\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.6656 - val_loss: 133.4436\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 250.0627 - val_loss: 138.8802\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 165.5525 - val_loss: 120.7863\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 163.5934 - val_loss: 122.3314\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 163.7988 - val_loss: 121.2352\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 149.1437 - val_loss: 134.2996\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.6735 - val_loss: 203.7843\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.4759 - val_loss: 238.9982\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.8387 - val_loss: 111.0128\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4369 - val_loss: 114.1740\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 192.8247 - val_loss: 156.4198\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.7417 - val_loss: 110.9888\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.3902 - val_loss: 109.5135\n",
      "Epoch 1737/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/step - loss: 149.7698 - val_loss: 126.3936\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 156.3322 - val_loss: 108.9779\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 153.2928 - val_loss: 108.5571\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 158.7946 - val_loss: 125.1393\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 230.8014 - val_loss: 125.4962\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.2221 - val_loss: 176.8526\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.0076 - val_loss: 164.0120\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.6476 - val_loss: 122.5068\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.6741 - val_loss: 124.0069\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.2796 - val_loss: 127.0475\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.2753 - val_loss: 112.7099\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.8216 - val_loss: 117.1086\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.4258 - val_loss: 130.7639\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.3667 - val_loss: 114.3511\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.6185 - val_loss: 121.6932\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.7329 - val_loss: 115.0055\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.7127 - val_loss: 132.5403\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 158.6708 - val_loss: 119.7419\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.7153 - val_loss: 106.8165\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 156.9173 - val_loss: 139.3391\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.9239 - val_loss: 128.4261\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 147.7028 - val_loss: 140.5602\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.5618 - val_loss: 145.5852\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.4773 - val_loss: 110.2056\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.5685 - val_loss: 120.5481\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.8615 - val_loss: 132.5709\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 200.8889 - val_loss: 111.2924\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.3851 - val_loss: 112.8486\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.4790 - val_loss: 120.9654\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5716 - val_loss: 123.2630\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.9492 - val_loss: 137.6745\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.5046 - val_loss: 149.5729\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1935 - val_loss: 116.5137\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.9460 - val_loss: 115.6998\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.4080 - val_loss: 124.9292\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 150.3825 - val_loss: 136.1264\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.3326 - val_loss: 129.6202\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9077 - val_loss: 129.9319\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.6778 - val_loss: 110.3508\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 183.5283 - val_loss: 113.1415\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.1067 - val_loss: 111.2236\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.8376 - val_loss: 114.6530\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.2401 - val_loss: 149.1318\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.6074 - val_loss: 112.7946\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.1537 - val_loss: 177.7725\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.0775 - val_loss: 135.0801\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.7623 - val_loss: 111.3072\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.0654 - val_loss: 107.8879\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.4520 - val_loss: 131.4102\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.7687 - val_loss: 116.5978\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.2485 - val_loss: 115.0379\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5168 - val_loss: 119.6983\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.6662 - val_loss: 126.3869\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.8075 - val_loss: 150.9741\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.5337 - val_loss: 108.7304\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.3092 - val_loss: 137.0889\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.6729 - val_loss: 141.3008\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 144.1543 - val_loss: 127.6341\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 131.7913 - val_loss: 174.0990\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 204.7365 - val_loss: 119.8017\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 200.7877 - val_loss: 143.1276\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.1007 - val_loss: 117.5905\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3640 - val_loss: 109.6128\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.0033 - val_loss: 106.2815\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.8895 - val_loss: 170.3642\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 139.6965 - val_loss: 107.9879\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.2786 - val_loss: 140.1643\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.5964 - val_loss: 111.8115\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.5735 - val_loss: 109.5806\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.8136 - val_loss: 124.0357\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.0591 - val_loss: 119.8497\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.0161 - val_loss: 123.6426\n",
      "Epoch 1809/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 57us/step - loss: 161.6098 - val_loss: 151.8545\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.0584 - val_loss: 110.1726\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 164.7913 - val_loss: 110.2070\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.8232 - val_loss: 112.1926\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4676 - val_loss: 128.4132\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.3924 - val_loss: 169.8924\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.1464 - val_loss: 180.8794\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.0448 - val_loss: 109.1799\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 132.2997 - val_loss: 110.8156\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9670 - val_loss: 112.7903\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 157.7836 - val_loss: 112.0164\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 162.2034 - val_loss: 239.5814\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.9931 - val_loss: 125.0209\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.3633 - val_loss: 112.3890\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.6433 - val_loss: 112.8765\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 186.3570 - val_loss: 135.3078\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.7151 - val_loss: 113.6612\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.2310 - val_loss: 132.2715\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.1227 - val_loss: 116.5674\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.6913 - val_loss: 111.7748\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.5436 - val_loss: 113.6021\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.2471 - val_loss: 124.0414\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4254 - val_loss: 107.7937\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.4184 - val_loss: 137.1248\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.3955 - val_loss: 125.7066\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.9504 - val_loss: 121.2659\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.9321 - val_loss: 172.4788\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.3439 - val_loss: 108.6301\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.0322 - val_loss: 120.8454\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.1653 - val_loss: 140.1795\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.2174 - val_loss: 121.2612\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.1365 - val_loss: 154.7266\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1288 - val_loss: 107.0398\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5919 - val_loss: 112.8218\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.2156 - val_loss: 126.8546\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9377 - val_loss: 117.2276\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.0329 - val_loss: 116.7049\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.6684 - val_loss: 115.0325\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.3797 - val_loss: 135.1510\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 238.4580 - val_loss: 138.5872\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.4429 - val_loss: 148.6790\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.6019 - val_loss: 113.5683\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 174.6472 - val_loss: 196.9969\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.4033 - val_loss: 129.8185\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.1748 - val_loss: 113.6728\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.6780 - val_loss: 123.3635\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.7139 - val_loss: 115.0510\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.9138 - val_loss: 123.9519\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.3272 - val_loss: 156.0111\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.8898 - val_loss: 127.3991\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1499 - val_loss: 108.1753\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 211.6956 - val_loss: 130.6843\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.5852 - val_loss: 124.4408\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 152.1452 - val_loss: 170.1540\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 150.1550 - val_loss: 107.8163\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 198.7137 - val_loss: 199.1232\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 154.3898 - val_loss: 113.0789\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 218.3767 - val_loss: 154.9088\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 130.6272 - val_loss: 113.9636\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 138.6764 - val_loss: 108.3090\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 134.0676 - val_loss: 139.1304\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 137.7739 - val_loss: 121.1877\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.5556 - val_loss: 130.3176\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.7171 - val_loss: 114.7923\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 188.9139 - val_loss: 113.3712\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 165.6919 - val_loss: 171.7292\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 147.1628 - val_loss: 118.6022\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 168.0424 - val_loss: 111.0164\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.9191 - val_loss: 187.4383\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.6746 - val_loss: 133.5377\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.9258 - val_loss: 111.1892\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.5663 - val_loss: 123.6509\n",
      "Epoch 1881/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.1681 - val_loss: 141.8207\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.2209 - val_loss: 124.1602\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.9632 - val_loss: 128.2421\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 142.2640 - val_loss: 116.7908\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.6313 - val_loss: 109.3518\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.6057 - val_loss: 126.0445\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 155.0915 - val_loss: 147.2932\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 171.8378 - val_loss: 113.6630\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 147.4270 - val_loss: 108.2681\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 143.7316 - val_loss: 115.5221\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 140.8541 - val_loss: 178.6755\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.3573 - val_loss: 194.4255\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.9493 - val_loss: 107.9411\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 157.0911 - val_loss: 139.9562\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 199.5706 - val_loss: 117.3827\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 191.2922 - val_loss: 120.7205\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 158.6254 - val_loss: 110.8119\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 154.7653 - val_loss: 120.8051\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 145.8915 - val_loss: 116.4736\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 151.5055 - val_loss: 109.1911\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 178.9985 - val_loss: 168.8731\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 166.2758 - val_loss: 138.3237\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 163.0996 - val_loss: 124.9824\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 172.1849 - val_loss: 137.9334\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 150.6338 - val_loss: 106.2872\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.5199 - val_loss: 113.0575\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.0314 - val_loss: 140.0484\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 163.9147 - val_loss: 256.1057\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 136.3804 - val_loss: 106.8919\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 153.5506 - val_loss: 111.7724\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 160.3950 - val_loss: 115.3018\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 134.3591 - val_loss: 128.5387\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 133.7363 - val_loss: 113.0468\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 131.4638 - val_loss: 117.1576\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 152.9617 - val_loss: 121.0491\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 159.4674 - val_loss: 109.2182\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 140.9003 - val_loss: 204.7188\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 164.2625 - val_loss: 133.8034\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 185.8725 - val_loss: 116.9162\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 194.6507 - val_loss: 116.1521\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 178.4838 - val_loss: 141.1398\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 149.1578 - val_loss: 112.0700\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 141.6019 - val_loss: 174.1262\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 140.1391 - val_loss: 108.4959\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 150.6002 - val_loss: 106.6627\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 135.2197 - val_loss: 112.3366\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 132.4951 - val_loss: 109.3004\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 150.1816 - val_loss: 108.4284\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 132.3524 - val_loss: 122.9293\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.5808 - val_loss: 116.5559\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 154.1860 - val_loss: 120.9880\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 149.9653 - val_loss: 135.5637\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 165.8571 - val_loss: 113.6376\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 155.9891 - val_loss: 118.0220\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 144.4755 - val_loss: 108.8935\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 155.6555 - val_loss: 108.9742\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 140.2890 - val_loss: 110.8347\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.3678 - val_loss: 129.5001\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 137.4972 - val_loss: 129.3170\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 141.7654 - val_loss: 119.5664\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.2995 - val_loss: 110.7842\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 199.8037 - val_loss: 141.9202\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 159.4196 - val_loss: 112.7440\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 147.3846 - val_loss: 109.3102\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9040 - val_loss: 115.1418\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.1535 - val_loss: 113.9880\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.7104 - val_loss: 112.3064\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 180.1192 - val_loss: 176.2137\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 134.6231 - val_loss: 145.1001\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.2354 - val_loss: 111.2472\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.1814 - val_loss: 112.9142\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.7410 - val_loss: 166.3726\n",
      "Epoch 1953/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.9810 - val_loss: 130.5903\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 146.4287 - val_loss: 111.5961\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.8914 - val_loss: 109.8867\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.1885 - val_loss: 149.4770\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 210.8434 - val_loss: 125.6138\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.0107 - val_loss: 133.0681\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 164.2339 - val_loss: 115.6523\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.9133 - val_loss: 121.9932\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 142.9984 - val_loss: 127.2765\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.7995 - val_loss: 110.2565\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.1640 - val_loss: 126.9052\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.3635 - val_loss: 129.1228\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.9255 - val_loss: 756.0261\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 160.7195 - val_loss: 112.8646\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 133.9003 - val_loss: 106.1146\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 152.9737 - val_loss: 142.4677\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.4087 - val_loss: 178.7741\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 158.4438 - val_loss: 120.8661\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 146.9917 - val_loss: 112.2046\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 155.0435 - val_loss: 121.8339\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 143.5105 - val_loss: 115.0832\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.5711 - val_loss: 127.4850\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 152.2157 - val_loss: 113.4348\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 198.8985 - val_loss: 187.8294\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 141.0188 - val_loss: 112.7675\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 142.6992 - val_loss: 120.6190\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 136.0777 - val_loss: 107.2550\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.4674 - val_loss: 109.0652\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 151.7252 - val_loss: 113.3386\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 150.3090 - val_loss: 106.8020\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 140.4162 - val_loss: 120.9903\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.8957 - val_loss: 145.5342\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 157.7607 - val_loss: 111.6477\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 133.8274 - val_loss: 119.4848\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.2922 - val_loss: 128.9512\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 174.5629 - val_loss: 160.3637\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 162.9805 - val_loss: 121.0166\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.3885 - val_loss: 116.6236\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.9003 - val_loss: 157.5574\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.2234 - val_loss: 107.7516\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 138.3830 - val_loss: 109.0721\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 141.0089 - val_loss: 116.0329\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.7077 - val_loss: 131.6850\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.4337 - val_loss: 123.8530\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 212.1365 - val_loss: 115.6852\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 153.8605 - val_loss: 105.3950\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.0207 - val_loss: 135.7171\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.6352 - val_loss: 147.5213\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.1693 - val_loss: 107.4571\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 138.3182 - val_loss: 147.8677\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 139.3687 - val_loss: 110.3870\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 2s 260us/step - loss: 143.6808 - val_loss: 119.4984\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 152.0143 - val_loss: 129.1769\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 149.3590 - val_loss: 112.0550\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 147.8845 - val_loss: 111.0537\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.7364 - val_loss: 110.4926\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 130.1975 - val_loss: 113.4701\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 151.8933 - val_loss: 151.2845\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.4968 - val_loss: 109.9858\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 129.2507 - val_loss: 135.0748\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 175.0315 - val_loss: 119.6865\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 146.1620 - val_loss: 109.7819\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 133.0644 - val_loss: 107.0544\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 243.0823 - val_loss: 144.5191\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 143.0674 - val_loss: 112.8139\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.3979 - val_loss: 106.1306\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.8766 - val_loss: 160.2417\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8420 - val_loss: 108.6399\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.6384 - val_loss: 145.2962\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 166.8163 - val_loss: 115.4988\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.1890 - val_loss: 125.6012\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.0604 - val_loss: 119.0247\n",
      "Epoch 2025/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.1914 - val_loss: 116.3404\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.7762 - val_loss: 113.2467\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 169.8924 - val_loss: 121.3432\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0889 - val_loss: 119.3822\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 137.4401 - val_loss: 119.8417\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 141.2085 - val_loss: 115.5071\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 158.8633 - val_loss: 118.5639\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 145.3848 - val_loss: 122.4697\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.0862 - val_loss: 182.1355\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 247.2062 - val_loss: 113.5160\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.0714 - val_loss: 141.6714\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.6702 - val_loss: 133.9925\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 142.3445 - val_loss: 146.0919\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 170.8572 - val_loss: 126.6700\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 154.8702 - val_loss: 176.8529\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 199.2403 - val_loss: 164.2613\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 170.8900 - val_loss: 177.6879\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.0619 - val_loss: 111.5512\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.7690 - val_loss: 114.4621\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 131.9469 - val_loss: 134.0293\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.3880 - val_loss: 112.0464\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.5540 - val_loss: 133.0931\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.6011 - val_loss: 123.4294\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 208.0697 - val_loss: 207.7614\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.6961 - val_loss: 113.6459\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.1282 - val_loss: 123.2148\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 151.4566 - val_loss: 109.9456\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 132.2808 - val_loss: 129.8939\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.2309 - val_loss: 114.7403\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.8362 - val_loss: 125.7370\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.7499 - val_loss: 109.2473\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 178.6640 - val_loss: 139.9023\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 160.8494 - val_loss: 114.8006\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 135.4267 - val_loss: 125.5091\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 150.5139 - val_loss: 198.2354\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.1374 - val_loss: 112.6283\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.5681 - val_loss: 114.9112\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.2096 - val_loss: 151.5491\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.1995 - val_loss: 155.0876\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 128.3927 - val_loss: 156.8452\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.6299 - val_loss: 116.0180\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.6063 - val_loss: 114.0754\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.7487 - val_loss: 119.2898\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 201.5684 - val_loss: 127.4386\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.2450 - val_loss: 120.7032\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.6479 - val_loss: 111.1569\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.6239 - val_loss: 116.1464\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.7771 - val_loss: 107.5967\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 163.2087 - val_loss: 125.0449\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.2164 - val_loss: 111.1292\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.2203 - val_loss: 119.9401\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.4440 - val_loss: 119.9912\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 156.2988 - val_loss: 119.9611\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.2311 - val_loss: 154.2895\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 146.8491 - val_loss: 130.3135\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 172.8038 - val_loss: 110.3372\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 193.9412 - val_loss: 140.5785\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 157.5860 - val_loss: 116.6786\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.9432 - val_loss: 107.7950\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7262 - val_loss: 111.3121\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.5860 - val_loss: 111.9911\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.8135 - val_loss: 117.3529\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.5538 - val_loss: 131.2545\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 145.8843 - val_loss: 114.4223\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.1832 - val_loss: 130.4044\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 181.3081 - val_loss: 109.9254\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 169.0602 - val_loss: 110.1548\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.3768 - val_loss: 152.3925\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 136.3357 - val_loss: 110.1212\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 136.3826 - val_loss: 109.7918\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 187.4084 - val_loss: 123.8559\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 142.0011 - val_loss: 107.1425\n",
      "Epoch 2097/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.3065 - val_loss: 143.6757\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 198.1467 - val_loss: 111.0576\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.5525 - val_loss: 117.6388\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8774 - val_loss: 117.4243\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0272 - val_loss: 119.7207\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.1716 - val_loss: 114.9255\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 187.1068 - val_loss: 114.4814\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 137.8638 - val_loss: 115.4325\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0823 - val_loss: 111.3954\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.1051 - val_loss: 119.3600\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.3111 - val_loss: 108.2591\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.9330 - val_loss: 139.0613\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.9773 - val_loss: 175.7804\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 235.4992 - val_loss: 444.9232\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.0311 - val_loss: 123.3147\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.9645 - val_loss: 117.7775\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.9331 - val_loss: 111.1729\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2415 - val_loss: 164.7725\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.0636 - val_loss: 134.5515\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.9122 - val_loss: 118.7853\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.2615 - val_loss: 138.2864\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.6894 - val_loss: 120.5790\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.6574 - val_loss: 139.1755\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.3341 - val_loss: 116.7602\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 169.8157 - val_loss: 193.7352\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.0625 - val_loss: 120.1263\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.8176 - val_loss: 112.9446\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 132.9893 - val_loss: 111.8186\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.5868 - val_loss: 228.5269\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 153.6366 - val_loss: 216.5595\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.8950 - val_loss: 109.8415\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.4988 - val_loss: 142.5517\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.8351 - val_loss: 115.0290\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.4275 - val_loss: 142.0628\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.4527 - val_loss: 121.8773\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8547 - val_loss: 106.6467\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.9466 - val_loss: 124.4830\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.9225 - val_loss: 108.9735\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.4086 - val_loss: 121.8682\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4677 - val_loss: 135.9212\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.2383 - val_loss: 113.5196\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.0275 - val_loss: 118.4041\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.9892 - val_loss: 113.9996\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.6384 - val_loss: 114.2223\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.5456 - val_loss: 139.2664\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.8416 - val_loss: 143.2638\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.8329 - val_loss: 130.6514\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.2800 - val_loss: 114.7103\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.1195 - val_loss: 111.5644\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1654 - val_loss: 140.6304\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 141.5245 - val_loss: 198.8112\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 146.8958 - val_loss: 112.0230\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.1169 - val_loss: 227.9991\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.2081 - val_loss: 113.4859\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.6367 - val_loss: 128.8808\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.5595 - val_loss: 151.0995\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.8406 - val_loss: 121.4407\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 243.7538 - val_loss: 286.6208\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 185.1810 - val_loss: 152.4192\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.0881 - val_loss: 114.4592\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.2091 - val_loss: 139.0885\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6322 - val_loss: 137.6363\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4787 - val_loss: 117.3450\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6803 - val_loss: 112.2159\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 162.9829 - val_loss: 115.4823\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.7854 - val_loss: 122.4962\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9453 - val_loss: 117.5767\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.9922 - val_loss: 236.6128\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.3442 - val_loss: 117.0383\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.9430 - val_loss: 124.1739\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.0458 - val_loss: 114.5908\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5157 - val_loss: 110.0908\n",
      "Epoch 2169/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.0718 - val_loss: 162.0445\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.2068 - val_loss: 146.3134\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 177.2468 - val_loss: 118.8176\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 156.8656 - val_loss: 112.5331\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 142.2142 - val_loss: 132.5452\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.3321 - val_loss: 115.1724\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.3079 - val_loss: 160.3126\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.3611 - val_loss: 111.8413\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.3817 - val_loss: 128.9335\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.2916 - val_loss: 111.8310\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.6296 - val_loss: 108.1777\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.6381 - val_loss: 127.9661\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1646 - val_loss: 118.1318\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.2141 - val_loss: 106.3898\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7994 - val_loss: 112.1611\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.6262 - val_loss: 111.3123\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.3257 - val_loss: 157.5348\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.0484 - val_loss: 108.6503\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.5723 - val_loss: 133.6791\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.2598 - val_loss: 125.0205\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.9182 - val_loss: 121.8869\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8175 - val_loss: 115.7218\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.3274 - val_loss: 129.3091\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.8262 - val_loss: 109.7678\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.4852 - val_loss: 132.4894\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.6561 - val_loss: 111.9181\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.3869 - val_loss: 130.8531\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.5132 - val_loss: 145.9982\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0553 - val_loss: 106.2164\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5057 - val_loss: 107.6333\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.4521 - val_loss: 123.8545\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.2815 - val_loss: 139.1552\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.3647 - val_loss: 161.6901\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.3726 - val_loss: 116.6852\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.7418 - val_loss: 123.6638\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5329 - val_loss: 155.7574\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0985 - val_loss: 122.3293\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.6132 - val_loss: 115.2229\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.8547 - val_loss: 182.7365\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 170.7250 - val_loss: 124.5118\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.0754 - val_loss: 143.7730\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 159.2877 - val_loss: 109.4586\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.0440 - val_loss: 132.6450\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.2547 - val_loss: 132.8893\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.9656 - val_loss: 128.9146\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.2926 - val_loss: 111.3093\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.6763 - val_loss: 105.5806\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.9115 - val_loss: 128.9321\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.8772 - val_loss: 123.1503\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 142.2794 - val_loss: 108.9763\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.6781 - val_loss: 108.2527\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 258.2542 - val_loss: 115.9044\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.8474 - val_loss: 111.0521\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.9824 - val_loss: 112.8229\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.6409 - val_loss: 131.8559\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.9926 - val_loss: 115.8871\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.3711 - val_loss: 107.5912\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.5394 - val_loss: 123.3147\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.8255 - val_loss: 145.7239\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.7835 - val_loss: 109.4873\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.5349 - val_loss: 142.6756\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.8446 - val_loss: 144.1037\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 134.6167 - val_loss: 114.0113\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.9991 - val_loss: 132.3708\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.1294 - val_loss: 135.5599\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.4053 - val_loss: 119.4249\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.1847 - val_loss: 127.7073\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.2961 - val_loss: 114.3550\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.5546 - val_loss: 152.3546\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.5263 - val_loss: 111.7438\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6210 - val_loss: 108.8749\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.4311 - val_loss: 129.3196\n",
      "Epoch 2241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3532 - val_loss: 135.3939\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.9515 - val_loss: 124.0732\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.6564 - val_loss: 111.7154\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.7191 - val_loss: 123.4059\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.6738 - val_loss: 140.3673\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.0330 - val_loss: 157.4969\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 216.3071 - val_loss: 129.0559\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2142 - val_loss: 109.2908\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.1270 - val_loss: 129.3244\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.4074 - val_loss: 112.7202\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3275 - val_loss: 121.9442\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 170.6147 - val_loss: 150.9553\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.6093 - val_loss: 129.7595\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.8003 - val_loss: 112.4756\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.3551 - val_loss: 112.0109\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3231 - val_loss: 111.0413\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.4037 - val_loss: 138.3250\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.5082 - val_loss: 179.3834\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4291 - val_loss: 139.8583\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.5828 - val_loss: 112.2694\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9397 - val_loss: 118.0475\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.4156 - val_loss: 111.1556\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.7485 - val_loss: 183.3298\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 210.6910 - val_loss: 129.4321\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.1445 - val_loss: 122.4189\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.8560 - val_loss: 110.4485\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.4393 - val_loss: 108.9923\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8774 - val_loss: 107.6844\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.0526 - val_loss: 109.9955\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2046 - val_loss: 124.1502\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.8593 - val_loss: 122.8671\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.7929 - val_loss: 115.5362\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.3180 - val_loss: 114.3693\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0428 - val_loss: 122.3942\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.0608 - val_loss: 316.0969\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2815 - val_loss: 108.7980\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 288.8886 - val_loss: 232.6856\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.4744 - val_loss: 124.2228\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.5042 - val_loss: 111.1585\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5389 - val_loss: 120.6883\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.2130 - val_loss: 109.0947\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.2631 - val_loss: 108.2708\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.0120 - val_loss: 139.8288\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.7149 - val_loss: 151.2889\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.0994 - val_loss: 112.4859\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 131.8623 - val_loss: 120.9000\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.4268 - val_loss: 112.9325\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 169.7603 - val_loss: 116.3879\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.1145 - val_loss: 115.0932\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.2305 - val_loss: 115.0189\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6463 - val_loss: 230.9998\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.1469 - val_loss: 186.5440\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.9885 - val_loss: 135.6318\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.0477 - val_loss: 111.1096\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.8543 - val_loss: 122.2528\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.2622 - val_loss: 106.8215\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.0255 - val_loss: 122.5230\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.7385 - val_loss: 123.8320\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.3503 - val_loss: 116.0128\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.0362 - val_loss: 113.4373\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 134.4149 - val_loss: 110.8479\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.2861 - val_loss: 109.6037\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.2124 - val_loss: 149.6626\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.2889 - val_loss: 120.1811\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 176.1639 - val_loss: 166.8184\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.7078 - val_loss: 110.0098\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.1154 - val_loss: 130.4671\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8712 - val_loss: 113.3159\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5299 - val_loss: 161.8851\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.5594 - val_loss: 158.5593\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.6706 - val_loss: 125.0793\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.7802 - val_loss: 113.7528\n",
      "Epoch 2313/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.1309 - val_loss: 120.1414\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.2914 - val_loss: 116.8410\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0657 - val_loss: 110.3365\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.3710 - val_loss: 109.0076\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0314 - val_loss: 140.3446\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.1138 - val_loss: 113.5916\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2442 - val_loss: 158.0779\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.1681 - val_loss: 107.7016\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.2040 - val_loss: 115.0472\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.2779 - val_loss: 115.6286\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.2575 - val_loss: 139.4237\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2171 - val_loss: 123.6609\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.8872 - val_loss: 111.4708\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.1630 - val_loss: 152.2985\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.1004 - val_loss: 110.6228\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.0153 - val_loss: 112.8746\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.2608 - val_loss: 116.9670\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.9645 - val_loss: 120.8058\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 174.1629 - val_loss: 161.8824\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.1397 - val_loss: 109.4775\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.3694 - val_loss: 115.5679\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.2215 - val_loss: 122.5552\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.0756 - val_loss: 119.2953\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.9401 - val_loss: 117.7759\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.8053 - val_loss: 111.8247\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2104 - val_loss: 115.5497\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.1908 - val_loss: 112.7403\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.2849 - val_loss: 118.3471\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 158.0626 - val_loss: 119.9079\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 130.8765 - val_loss: 112.0093\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 140.6150 - val_loss: 109.5788\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 135.4695 - val_loss: 155.2425\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 133.7454 - val_loss: 115.0035\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 133.8514 - val_loss: 109.6963\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 138.1258 - val_loss: 124.6392\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 131.5271 - val_loss: 106.8017\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 155.0824 - val_loss: 150.9039\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 145.2104 - val_loss: 108.0665\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 144.9819 - val_loss: 146.7574\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 171.0823 - val_loss: 127.9913\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 132.8139 - val_loss: 110.7671\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.1664 - val_loss: 108.2765\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 126.5173 - val_loss: 113.5350\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 143.6983 - val_loss: 112.3012\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 146.9446 - val_loss: 138.4704\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 187.0070 - val_loss: 130.3844\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 132.5658 - val_loss: 139.7471\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 132.1772 - val_loss: 122.8335\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.8651 - val_loss: 159.5519\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.4153 - val_loss: 132.9717\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 155.8821 - val_loss: 122.6016\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 147.8117 - val_loss: 124.2555\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.9746 - val_loss: 117.6546\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.5291 - val_loss: 111.7110\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 140.3937 - val_loss: 115.1458\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 137.6039 - val_loss: 145.1229\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 133.6278 - val_loss: 113.5927\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 139.1724 - val_loss: 111.0036\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 137.1215 - val_loss: 152.0179\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 130.8611 - val_loss: 169.9736\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 138.7093 - val_loss: 123.7695\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 176.0279 - val_loss: 125.4563\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 138.6329 - val_loss: 113.0841\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.5224 - val_loss: 107.5073\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 144.8130 - val_loss: 124.4296\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 143.7500 - val_loss: 111.7526\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 141.2848 - val_loss: 141.5260\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 131.1080 - val_loss: 123.7151\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 208.5884 - val_loss: 174.5140\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 142.2737 - val_loss: 122.1664\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.0538 - val_loss: 107.8285\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.8557 - val_loss: 115.3753\n",
      "Epoch 2385/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 74us/step - loss: 130.5757 - val_loss: 119.1150\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 137.1496 - val_loss: 126.1110\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 165.7019 - val_loss: 116.9264\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 136.6517 - val_loss: 116.5974\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 131.2214 - val_loss: 115.7225\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 135.0285 - val_loss: 113.0716\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 130.2809 - val_loss: 113.7007\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.6211 - val_loss: 116.4785\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 127.6518 - val_loss: 108.8425\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 170.5250 - val_loss: 109.4869\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.5625 - val_loss: 118.8288\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 135.1159 - val_loss: 119.0788\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 221.4411 - val_loss: 110.7177\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.9237 - val_loss: 108.5997\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 135.8638 - val_loss: 107.3314\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 131.1865 - val_loss: 123.8004\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 143.8904 - val_loss: 116.6911\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 185.5684 - val_loss: 125.6625\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 168.5816 - val_loss: 113.3736\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 138.6931 - val_loss: 121.7614\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 161.9762 - val_loss: 126.5760\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 135.8834 - val_loss: 119.7249\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 142.1915 - val_loss: 109.4542\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 138.5707 - val_loss: 118.1686\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 135.5143 - val_loss: 112.4336\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 136.1045 - val_loss: 107.8319\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 128.0511 - val_loss: 111.8392\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 138.4989 - val_loss: 108.2229\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 134.0952 - val_loss: 147.3938\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 132.3417 - val_loss: 115.3850\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 138.2937 - val_loss: 138.1632\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 191.9196 - val_loss: 138.8221\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 154.0169 - val_loss: 119.4641\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 126.9550 - val_loss: 122.9352\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 132.3313 - val_loss: 122.7652\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 131.0641 - val_loss: 113.0915\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 150.6535 - val_loss: 109.2025\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 128.9309 - val_loss: 130.4057\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 151.6142 - val_loss: 120.6269\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 129.7736 - val_loss: 114.6981\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 133.9243 - val_loss: 109.9830\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 129.9244 - val_loss: 138.0398\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.5171 - val_loss: 130.1788\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.8820 - val_loss: 113.6688\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.8444 - val_loss: 121.0707\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 158.9755 - val_loss: 125.8055\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 154.1600 - val_loss: 138.9183\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.2102 - val_loss: 120.7995\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.6593 - val_loss: 113.7273\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.2509 - val_loss: 108.2499\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.606 - 1s 76us/step - loss: 131.7627 - val_loss: 107.2225\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 203.9608 - val_loss: 346.4710\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 185.5756 - val_loss: 109.3757\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 125.9080 - val_loss: 109.2690\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 128.8367 - val_loss: 118.4512\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.6474 - val_loss: 115.7240\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 137.1260 - val_loss: 124.9412\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.5602 - val_loss: 136.1751\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 133.9160 - val_loss: 117.0918\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 187.3882 - val_loss: 124.8063\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 156.2640 - val_loss: 120.7806\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.4331 - val_loss: 110.4383\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 140.1257 - val_loss: 121.1720\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 153.8586 - val_loss: 124.3950\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 164.4627 - val_loss: 121.4964\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 140.0558 - val_loss: 163.1892\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 144.6497 - val_loss: 115.5874\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 138.1236 - val_loss: 113.0122\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 132.2663 - val_loss: 140.3021\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 134.8866 - val_loss: 111.1921\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 183.4409 - val_loss: 119.1987\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.1249 - val_loss: 115.9977\n",
      "Epoch 2457/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 70us/step - loss: 144.9250 - val_loss: 107.8275\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 140.3211 - val_loss: 171.1776\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.1036 - val_loss: 118.2836\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.3621 - val_loss: 126.5003\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 139.4265 - val_loss: 120.7420\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 242.5523 - val_loss: 152.7842\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 132.7982 - val_loss: 107.2950\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 128.7281 - val_loss: 143.3720\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.3477 - val_loss: 108.5017\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.0125 - val_loss: 110.0695\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 142.1582 - val_loss: 131.2491\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.9485 - val_loss: 108.6184\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 133.3081 - val_loss: 113.3878\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 131.1407 - val_loss: 122.6976\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.7832 - val_loss: 121.1975\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 131.9887 - val_loss: 110.2398\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 176.7391 - val_loss: 118.8070\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 125.8466 - val_loss: 137.3468\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 134.9796 - val_loss: 111.8200\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 131.6072 - val_loss: 130.3738\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 141.5493 - val_loss: 111.8370\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 141.4310 - val_loss: 108.4034\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 187.1806 - val_loss: 148.5169\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 136.1261 - val_loss: 158.6388\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.8542 - val_loss: 118.9914\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 129.7777 - val_loss: 165.2639\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 131.6847 - val_loss: 134.1654\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.1088 - val_loss: 121.5726\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.6713 - val_loss: 169.9108\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 129.6937 - val_loss: 118.8575\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 177.9918 - val_loss: 392.1733\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 216.8679 - val_loss: 133.8708\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.9489 - val_loss: 112.5283\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 128.1443 - val_loss: 113.6716\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 128.3697 - val_loss: 116.3812\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 130.5013 - val_loss: 112.2833\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 144.3953 - val_loss: 112.2140\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 130.1074 - val_loss: 119.9549\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 143.0374 - val_loss: 116.7574\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 129.4863 - val_loss: 145.0670\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 130.5292 - val_loss: 118.6924\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.6099 - val_loss: 121.7884\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 154.6836 - val_loss: 114.4302\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 185.8962 - val_loss: 120.2759\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 133.1377 - val_loss: 123.2155\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 167.5908 - val_loss: 112.4592\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.7350 - val_loss: 119.4877\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 128.5739 - val_loss: 107.1870\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 126.7010 - val_loss: 124.3745\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 131.5181 - val_loss: 110.8151\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 131.2782 - val_loss: 149.9443\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 140.8693 - val_loss: 119.4413\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 203.1398 - val_loss: 404.7142\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 148.5784 - val_loss: 110.6775\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 127.8534 - val_loss: 109.5423\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 158.0329 - val_loss: 114.3537\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 163.8074 - val_loss: 137.9621\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 138.5018 - val_loss: 114.2659\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 139.8672 - val_loss: 109.9022\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 130.1075 - val_loss: 113.9484\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 136.5177 - val_loss: 117.7811\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 181.8957 - val_loss: 112.4863\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 132.5855 - val_loss: 116.5434\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 135.8039 - val_loss: 116.7548\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 128.2149 - val_loss: 117.1720\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 132.2370 - val_loss: 109.9962\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.4582 - val_loss: 109.2325\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 180.8486 - val_loss: 113.3518\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 141.4699 - val_loss: 121.9931\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.9954 - val_loss: 126.1878\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 128.6746 - val_loss: 152.9913\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 161.3623 - val_loss: 208.3017\n",
      "Epoch 2529/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.6295 - val_loss: 110.2098\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.6791 - val_loss: 124.4738\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.7508 - val_loss: 115.0409\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 134.1514 - val_loss: 117.4953\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.7043 - val_loss: 109.7589\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 130.2140 - val_loss: 119.3291\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 140.9663 - val_loss: 113.9088\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.1661 - val_loss: 120.7750\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.6959 - val_loss: 114.8726\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.2505 - val_loss: 132.6540\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 143.5932 - val_loss: 135.4226\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 145.8533 - val_loss: 117.3034\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.7792 - val_loss: 136.0967\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.0301 - val_loss: 114.9671\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.8696 - val_loss: 128.3025\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.7710 - val_loss: 141.3300\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.8612 - val_loss: 114.0417\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 180.0957 - val_loss: 131.7621\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 137.7733 - val_loss: 127.2489\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 176.0894 - val_loss: 114.2529\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.6126 - val_loss: 111.3071\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 151.2130 - val_loss: 113.8933\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.0654 - val_loss: 121.8763\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 151.1602 - val_loss: 111.3092\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 195.2132 - val_loss: 144.3692\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 140.8361 - val_loss: 118.2034\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 142.9718 - val_loss: 146.7155\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 131.9898 - val_loss: 109.4366\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 126.9286 - val_loss: 111.7361\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 128.5880 - val_loss: 116.4097\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 138.6910 - val_loss: 129.0606\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.4509 - val_loss: 110.7548\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 129.1919 - val_loss: 107.4506\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.2349 - val_loss: 137.8271\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 145.9933 - val_loss: 153.8065\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 160.8459 - val_loss: 158.7454\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 132.4075 - val_loss: 110.3033\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.4769 - val_loss: 111.5648\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.6097 - val_loss: 126.0866\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 173.5017 - val_loss: 140.2117\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 144.4613 - val_loss: 113.0988\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 134.6608 - val_loss: 107.6247\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 144.2912 - val_loss: 111.0946\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 128.8375 - val_loss: 146.9543\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.7283 - val_loss: 109.6831\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.3627 - val_loss: 117.0362\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 148.1155 - val_loss: 109.3415\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 136.2070 - val_loss: 117.4367\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 141.5253 - val_loss: 125.8364\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 146.0294 - val_loss: 128.8791\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 136.3495 - val_loss: 149.9554\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 238.1977 - val_loss: 152.9165\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 134.5731 - val_loss: 114.3910\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.8543 - val_loss: 115.8457\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 155.0812 - val_loss: 114.4844\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.5856 - val_loss: 112.5956\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 161.1179 - val_loss: 133.0415\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 133.8386 - val_loss: 113.9712\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 149.0207 - val_loss: 122.7017\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 174.2532 - val_loss: 128.4217\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 170.2951 - val_loss: 122.1377\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 129.2598 - val_loss: 117.6980\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 126.2782 - val_loss: 127.0905\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 134.7163 - val_loss: 136.5880\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 130.0615 - val_loss: 109.9714\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.9387 - val_loss: 124.9560\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 132.3108 - val_loss: 113.9000\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 130.3056 - val_loss: 118.8645\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 132.6109 - val_loss: 120.3176\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 131.3437 - val_loss: 115.3285\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 134.2519 - val_loss: 129.9109\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 133.9464 - val_loss: 109.9522\n",
      "Epoch 2601/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 66us/step - loss: 159.5202 - val_loss: 148.1512\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 296.1478 - val_loss: 113.6965\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.7378 - val_loss: 119.5626\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 150.3343 - val_loss: 126.6701\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 133.7006 - val_loss: 118.3868\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 143.3195 - val_loss: 113.2016\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.1003 - val_loss: 119.0948\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.3946 - val_loss: 111.1033\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 130.9316 - val_loss: 125.3934\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 130.6551 - val_loss: 112.9356\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 130.7191 - val_loss: 116.9794\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 236.7932 - val_loss: 125.9378\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.2922 - val_loss: 114.3876\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 137.7575 - val_loss: 213.7902\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.3487 - val_loss: 125.6981\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 127.7870 - val_loss: 115.5442\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.6472 - val_loss: 119.4447\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 134.4482 - val_loss: 146.5217\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 136.0825 - val_loss: 126.7133\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 141.8721 - val_loss: 119.4737\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.9718 - val_loss: 111.6709\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 135.4677 - val_loss: 140.0844\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 168.5373 - val_loss: 147.0955\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 131.4630 - val_loss: 136.1443\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.7053 - val_loss: 116.0942\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 139.2606 - val_loss: 143.3767\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.0484 - val_loss: 108.0755\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 136.2829 - val_loss: 107.4625\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.4946 - val_loss: 107.8287\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 142.9660 - val_loss: 115.0510\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.9330 - val_loss: 115.6772\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.8823 - val_loss: 131.4697\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 152.9198 - val_loss: 151.0268\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 155.1468 - val_loss: 156.1250\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 158.5185 - val_loss: 108.1378\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 194.2732 - val_loss: 125.7294\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.0399 - val_loss: 115.3038\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 136.9205 - val_loss: 150.5834\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 145.1974 - val_loss: 117.5303\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 142.6847 - val_loss: 113.2071\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 129.7926 - val_loss: 114.2168\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.0642 - val_loss: 121.0463\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 125.7336 - val_loss: 125.8427\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 136.6477 - val_loss: 126.8686\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.8177 - val_loss: 112.4781\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 137.4701 - val_loss: 110.5539\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 187.4856 - val_loss: 126.0563\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.7647 - val_loss: 110.7318\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 140.0765 - val_loss: 112.2859\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.9268 - val_loss: 111.7782\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 130.6748 - val_loss: 111.3281\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 129.9380 - val_loss: 112.4766\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.4537 - val_loss: 114.2447\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 131.3029 - val_loss: 120.3834\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 174.9823 - val_loss: 111.0393\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.6718 - val_loss: 128.0329\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 130.6002 - val_loss: 119.5147\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 152.4167 - val_loss: 118.5938\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.5389 - val_loss: 109.4124\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 128.8676 - val_loss: 145.9448\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 144.5807 - val_loss: 117.8595\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 159.8151 - val_loss: 112.0593\n",
      "Epoch 2663/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 131.6140 - val_loss: 123.6575\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 134.7201 - val_loss: 113.8820\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 194.6784 - val_loss: 1322.5807\n",
      "Epoch 2666/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 174.9738 - val_loss: 109.6092\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.7971 - val_loss: 135.1546\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 126.5999 - val_loss: 118.4757\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.1872 - val_loss: 117.2469\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 153.7549 - val_loss: 115.8038\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 133.4176 - val_loss: 111.7671\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 124.1673 - val_loss: 125.9352\n",
      "Epoch 2673/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 68us/step - loss: 123.0765 - val_loss: 129.1163\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.6602 - val_loss: 129.8731\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 145.7110 - val_loss: 134.1748\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 185.4004 - val_loss: 117.2153\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 157.5927 - val_loss: 114.4050\n",
      "Epoch 2678/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 128.4895 - val_loss: 107.1656\n",
      "Epoch 2679/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 126.1355 - val_loss: 136.5933\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 137.1412 - val_loss: 114.9390\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 144.4085 - val_loss: 115.9378\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 181.8169 - val_loss: 125.8441\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 155.5216 - val_loss: 112.2763\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 127.5494 - val_loss: 118.1605\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 132.7604 - val_loss: 122.3194\n",
      "Epoch 2686/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 167.6217 - val_loss: 127.9225\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 136.6520 - val_loss: 130.6784\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 136.4804 - val_loss: 125.7357\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 139.3894 - val_loss: 124.7989\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 134.4664 - val_loss: 119.9181\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.0503 - val_loss: 125.8742\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 135.6764 - val_loss: 130.7994\n",
      "Epoch 2693/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 151.1473 - val_loss: 117.1292\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 128.6915 - val_loss: 117.0163\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 130.6271 - val_loss: 117.9386\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.3839 - val_loss: 129.3704\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 152.4919 - val_loss: 232.0791\n",
      "Epoch 2698/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 161.3799 - val_loss: 115.3877\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 134.9132 - val_loss: 114.2208\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.9898 - val_loss: 113.6663\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.3556 - val_loss: 124.4708\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.8544 - val_loss: 146.3868\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.7848 - val_loss: 124.1993\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 145.3029 - val_loss: 119.7138\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 157.5451 - val_loss: 120.4620\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.1064 - val_loss: 111.8481\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 142.0631 - val_loss: 152.3171\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 134.0770 - val_loss: 110.7748\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 130.3789 - val_loss: 111.5577\n",
      "Epoch 2710/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.3262 - val_loss: 117.0955\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 127.6629 - val_loss: 114.4888\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 138.6922 - val_loss: 124.6083\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 174.7947 - val_loss: 119.1993\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 129.1283 - val_loss: 115.0298\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 127.5596 - val_loss: 157.8872\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.6640 - val_loss: 108.8092\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.7070 - val_loss: 108.0900\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 148.9105 - val_loss: 136.9902\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 161.8071 - val_loss: 164.7586\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.6621 - val_loss: 155.8824\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 125.2319 - val_loss: 115.6871\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 144.9935 - val_loss: 119.0173\n",
      "Epoch 2723/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 145.6914 - val_loss: 164.9249\n",
      "Epoch 2724/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 164.7356 - val_loss: 109.3198\n",
      "Epoch 2725/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.3771 - val_loss: 121.6439\n",
      "Epoch 2726/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.1216 - val_loss: 128.7493\n",
      "Epoch 2727/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.2872 - val_loss: 115.1678\n",
      "Epoch 2728/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 154.8645 - val_loss: 114.8953\n",
      "Epoch 2729/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 130.6764 - val_loss: 109.9637\n",
      "Epoch 2730/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.7281 - val_loss: 132.0384\n",
      "Epoch 2731/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.1163 - val_loss: 108.8910\n",
      "Epoch 2732/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.3649 - val_loss: 114.1830\n",
      "Epoch 2733/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.3813 - val_loss: 185.4500\n",
      "Epoch 2734/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 132.1683 - val_loss: 134.8193\n",
      "Epoch 2735/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 129.0594 - val_loss: 110.0656\n",
      "Epoch 2736/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 175.7069 - val_loss: 120.8889\n",
      "Epoch 2737/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.7164 - val_loss: 119.3786\n",
      "Epoch 2738/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 132.6105 - val_loss: 108.8178\n",
      "Epoch 2739/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 159.7424 - val_loss: 127.7507\n",
      "Epoch 2740/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 139.5086 - val_loss: 109.8286\n",
      "Epoch 2741/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 135.1179 - val_loss: 114.9441\n",
      "Epoch 2742/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 129.9032 - val_loss: 111.0056\n",
      "Epoch 2743/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.8779 - val_loss: 113.7037\n",
      "Epoch 2744/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 133.0271 - val_loss: 115.5071\n",
      "Epoch 2745/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 70us/step - loss: 130.7905 - val_loss: 118.0292\n",
      "Epoch 2746/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 126.7334 - val_loss: 119.5953\n",
      "Epoch 2747/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.8221 - val_loss: 128.1364\n",
      "Epoch 2748/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 133.0234 - val_loss: 119.7682\n",
      "Epoch 2749/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.5017 - val_loss: 149.5200\n",
      "Epoch 2750/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 145.7077 - val_loss: 128.1845\n",
      "Epoch 2751/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 135.3547 - val_loss: 115.2390\n",
      "Epoch 2752/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.4807 - val_loss: 124.9136\n",
      "Epoch 2753/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.2455 - val_loss: 140.8732\n",
      "Epoch 2754/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 148.5921 - val_loss: 121.2548\n",
      "Epoch 2755/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 193.0048 - val_loss: 124.3445\n",
      "Epoch 2756/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.9163 - val_loss: 143.9873\n",
      "Epoch 2757/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.8729 - val_loss: 109.6252\n",
      "Epoch 2758/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.7670 - val_loss: 117.0915\n",
      "Epoch 2759/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.6606 - val_loss: 117.5806\n",
      "Epoch 2760/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.4363 - val_loss: 109.1473\n",
      "Epoch 2761/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.7263 - val_loss: 109.3398\n",
      "Epoch 2762/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.0692 - val_loss: 108.2498\n",
      "Epoch 2763/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 132.9056 - val_loss: 130.5923\n",
      "Epoch 2764/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 130.6725 - val_loss: 124.3484\n",
      "Epoch 2765/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.5772 - val_loss: 125.5182\n",
      "Epoch 2766/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.1854 - val_loss: 111.9667\n",
      "Epoch 2767/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 135.3178 - val_loss: 118.4911\n",
      "Epoch 2768/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 128.7202 - val_loss: 113.4397\n",
      "Epoch 2769/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 138.5206 - val_loss: 112.8974\n",
      "Epoch 2770/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 218.6702 - val_loss: 141.7640\n",
      "Epoch 2771/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 147.6295 - val_loss: 108.4932\n",
      "Epoch 2772/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.5494 - val_loss: 139.1187\n",
      "Epoch 2773/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.8043 - val_loss: 109.7321\n",
      "Epoch 2774/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.8475 - val_loss: 108.1910\n",
      "Epoch 2775/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 190.3471 - val_loss: 115.4953\n",
      "Epoch 2776/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.0444 - val_loss: 118.3392\n",
      "Epoch 2777/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 127.2661 - val_loss: 111.6921\n",
      "Epoch 2778/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.8698 - val_loss: 109.0776\n",
      "Epoch 2779/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 137.7145 - val_loss: 144.5360\n",
      "Epoch 2780/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.9517 - val_loss: 109.9471\n",
      "Epoch 2781/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.7183 - val_loss: 114.4243\n",
      "Epoch 2782/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.0435 - val_loss: 108.3769\n",
      "Epoch 2783/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.7168 - val_loss: 118.4104\n",
      "Epoch 2784/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.9802 - val_loss: 119.0551\n",
      "Epoch 2785/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.0017 - val_loss: 165.7560\n",
      "Epoch 2786/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 140.5584 - val_loss: 140.9693\n",
      "Epoch 2787/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 140.9410 - val_loss: 138.8351\n",
      "Epoch 2788/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 131.9573 - val_loss: 114.4167\n",
      "Epoch 2789/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 131.2361 - val_loss: 115.6020\n",
      "Epoch 2790/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 168.6703 - val_loss: 110.0620\n",
      "Epoch 2791/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.6731 - val_loss: 162.9012\n",
      "Epoch 2792/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 135.2795 - val_loss: 109.8288\n",
      "Epoch 2793/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 130.2473 - val_loss: 128.6126\n",
      "Epoch 2794/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.6646 - val_loss: 110.6490\n",
      "Epoch 2795/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 178.0045 - val_loss: 123.5145\n",
      "Epoch 2796/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.1206 - val_loss: 115.3530\n",
      "Epoch 2797/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.0223 - val_loss: 117.5203\n",
      "Epoch 2798/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 141.0582 - val_loss: 115.4184\n",
      "Epoch 2799/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 142.6590 - val_loss: 109.1853\n",
      "Epoch 2800/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.3848 - val_loss: 112.8607\n",
      "Epoch 2801/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 126.5978 - val_loss: 110.1239\n",
      "Epoch 2802/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.0254 - val_loss: 120.6293\n",
      "Epoch 2803/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.8353 - val_loss: 116.6106\n",
      "Epoch 2804/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.2884 - val_loss: 115.0001\n",
      "Epoch 2805/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 153.1315 - val_loss: 147.1727\n",
      "Epoch 2806/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 153.7728 - val_loss: 115.3878\n",
      "Epoch 2807/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 125.4179 - val_loss: 120.0465\n",
      "Epoch 2808/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 168.0885 - val_loss: 141.0610\n",
      "Epoch 2809/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 134.0110 - val_loss: 112.7481\n",
      "Epoch 2810/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.4897 - val_loss: 116.3637\n",
      "Epoch 2811/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 183.1499 - val_loss: 131.3528\n",
      "Epoch 2812/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.2340 - val_loss: 111.6551\n",
      "Epoch 2813/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 140.8317 - val_loss: 118.4056\n",
      "Epoch 2814/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 131.7297 - val_loss: 111.8756\n",
      "Epoch 2815/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 148.1887 - val_loss: 107.9569\n",
      "Epoch 2816/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 134.2774 - val_loss: 115.0249\n",
      "Epoch 2817/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 69us/step - loss: 129.4186 - val_loss: 121.6082\n",
      "Epoch 2818/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 129.4252 - val_loss: 152.4556\n",
      "Epoch 2819/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.3230 - val_loss: 110.0833\n",
      "Epoch 2820/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.8118 - val_loss: 109.0228\n",
      "Epoch 2821/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 132.7737 - val_loss: 112.5044\n",
      "Epoch 2822/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 145.6954 - val_loss: 118.9652\n",
      "Epoch 2823/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 138.7456 - val_loss: 125.6257\n",
      "Epoch 2824/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 135.2529 - val_loss: 112.4896\n",
      "Epoch 2825/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 189.3118 - val_loss: 112.9522\n",
      "Epoch 2826/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 131.3973 - val_loss: 115.3351\n",
      "Epoch 2827/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.4536 - val_loss: 117.6074\n",
      "Epoch 2828/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.9379 - val_loss: 108.9164\n",
      "Epoch 2829/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 160.7750 - val_loss: 111.8062\n",
      "Epoch 2830/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.9933 - val_loss: 163.7647\n",
      "Epoch 2831/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 128.8661 - val_loss: 110.7913\n",
      "Epoch 2832/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 141.6356 - val_loss: 174.9230\n",
      "Epoch 2833/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.1112 - val_loss: 115.5926\n",
      "Epoch 2834/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 223.8959 - val_loss: 123.1119\n",
      "Epoch 2835/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 127.6739 - val_loss: 138.8910\n",
      "Epoch 2836/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 133.1537 - val_loss: 115.0885\n",
      "Epoch 2837/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 126.0600 - val_loss: 111.2948\n",
      "Epoch 2838/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 132.4069 - val_loss: 111.1178\n",
      "Epoch 2839/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 185.2927 - val_loss: 115.2195\n",
      "Epoch 2840/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 348.4493 - val_loss: 228.0865\n",
      "Epoch 2841/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 205.8890 - val_loss: 129.6141\n",
      "Epoch 2842/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 132.4911 - val_loss: 112.4960\n",
      "Epoch 2843/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 132.7545 - val_loss: 111.7707\n",
      "Epoch 2844/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 125.7045 - val_loss: 108.7595\n",
      "Epoch 2845/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.3148 - val_loss: 116.7122\n",
      "Epoch 2846/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 147.3219 - val_loss: 127.7956\n",
      "Epoch 2847/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 144.6883 - val_loss: 123.4374\n",
      "Epoch 2848/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 163.0723 - val_loss: 115.6809\n",
      "Epoch 2849/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 128.1580 - val_loss: 113.4338\n",
      "Epoch 2850/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 220.0219 - val_loss: 183.5838\n",
      "Epoch 2851/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 157.9214 - val_loss: 114.9475\n",
      "Epoch 2852/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 136.5692 - val_loss: 138.6627\n",
      "Epoch 2853/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.5251 - val_loss: 113.0911\n",
      "Epoch 2854/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 127.2658 - val_loss: 108.1958\n",
      "Epoch 2855/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.3846 - val_loss: 122.9833\n",
      "Epoch 2856/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 130.9200 - val_loss: 157.0690\n",
      "Epoch 2857/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 144.0087 - val_loss: 123.1756\n",
      "Epoch 2858/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.9156 - val_loss: 127.3359\n",
      "Epoch 2859/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.2235 - val_loss: 108.7977\n",
      "Epoch 2860/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.4553 - val_loss: 109.7791\n",
      "Epoch 2861/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 131.7030 - val_loss: 130.9494\n",
      "Epoch 2862/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 141.7937 - val_loss: 109.0077\n",
      "Epoch 2863/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 136.2382 - val_loss: 114.3620\n",
      "Epoch 2864/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 124.9867 - val_loss: 115.6777\n",
      "Epoch 2865/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.8923 - val_loss: 138.1267\n",
      "Epoch 2866/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 143.4909 - val_loss: 111.2881\n",
      "Epoch 2867/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 142.3653 - val_loss: 145.6803\n",
      "Epoch 2868/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.8849 - val_loss: 129.4329\n",
      "Epoch 2869/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 136.1847 - val_loss: 114.3033\n",
      "Epoch 2870/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 153.0436 - val_loss: 113.7133\n",
      "Epoch 2871/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.0943 - val_loss: 108.1597\n",
      "Epoch 2872/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 140.7775 - val_loss: 121.2132\n",
      "Epoch 2873/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.2153 - val_loss: 117.8225\n",
      "Epoch 2874/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.2981 - val_loss: 116.4543\n",
      "Epoch 2875/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 133.9543 - val_loss: 125.9721\n",
      "Epoch 2876/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.0377 - val_loss: 117.0170\n",
      "Epoch 2877/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 134.9219 - val_loss: 152.2447\n",
      "Epoch 2878/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 177.4576 - val_loss: 117.3695\n",
      "Epoch 2879/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 126.0679 - val_loss: 130.0422\n",
      "Epoch 2880/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 125.9736 - val_loss: 123.9771\n",
      "Epoch 2881/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 148.5736 - val_loss: 120.2796\n",
      "Epoch 2882/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 144.7779 - val_loss: 110.0467\n",
      "Epoch 2883/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 126.9032 - val_loss: 110.8912\n",
      "Epoch 2884/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 130.4626 - val_loss: 154.9081\n",
      "Epoch 2885/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.5123 - val_loss: 115.8846\n",
      "Epoch 2886/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 124.0218 - val_loss: 126.0169\n",
      "Epoch 2887/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 134.1143 - val_loss: 119.0146\n",
      "Epoch 2888/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 136.1317 - val_loss: 126.0254\n",
      "Epoch 2889/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.4888 - val_loss: 169.1198\n",
      "Epoch 2890/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 128.9042 - val_loss: 125.1492\n",
      "Epoch 2891/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.2655 - val_loss: 114.9866\n",
      "Epoch 2892/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 128.6128 - val_loss: 119.2722\n",
      "Epoch 2893/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.5271 - val_loss: 134.4655\n",
      "Epoch 2894/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 127.5534 - val_loss: 125.0502\n",
      "Epoch 2895/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.9353 - val_loss: 114.7426\n",
      "Epoch 2896/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 140.0132 - val_loss: 110.0732\n",
      "Epoch 2897/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 245.8358 - val_loss: 287.0542\n",
      "Epoch 2898/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 155.8208 - val_loss: 139.9805\n",
      "Epoch 2899/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 125.7418 - val_loss: 107.9607\n",
      "Epoch 2900/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 126.6260 - val_loss: 115.3688\n",
      "Epoch 2901/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 125.2069 - val_loss: 162.4775\n",
      "Epoch 2902/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.6338 - val_loss: 111.0284\n",
      "Epoch 2903/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 140.9472 - val_loss: 121.9948\n",
      "Epoch 2904/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 132.7328 - val_loss: 155.9397\n",
      "Epoch 2905/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 128.3116 - val_loss: 112.7182\n",
      "Epoch 2906/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 128.9116 - val_loss: 130.9526\n",
      "Epoch 2907/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 175.7753 - val_loss: 197.6109\n",
      "Epoch 2908/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 148.3601 - val_loss: 118.5081\n",
      "Epoch 2909/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 142.5583 - val_loss: 110.4725\n",
      "Epoch 2910/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 140.9941 - val_loss: 139.3612\n",
      "Epoch 2911/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 134.5149 - val_loss: 110.8013\n",
      "Epoch 2912/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 126.9080 - val_loss: 123.8705\n",
      "Epoch 2913/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 132.5817 - val_loss: 112.7967\n",
      "Epoch 2914/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 138.1919 - val_loss: 131.9729\n",
      "Epoch 2915/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 137.7168 - val_loss: 115.9412\n",
      "Epoch 2916/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 137.4827 - val_loss: 109.6444\n",
      "Epoch 2917/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 191.2411 - val_loss: 165.7209\n",
      "Epoch 2918/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 133.3686 - val_loss: 122.3248\n",
      "Epoch 2919/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.6631 - val_loss: 112.4322\n",
      "Epoch 2920/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 134.6470 - val_loss: 121.3666\n",
      "Epoch 2921/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 125.4877 - val_loss: 147.6202\n",
      "Epoch 2922/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.7647 - val_loss: 112.4607\n",
      "Epoch 2923/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.3265 - val_loss: 109.0087\n",
      "Epoch 2924/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.1249 - val_loss: 116.5215\n",
      "Epoch 2925/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.4706 - val_loss: 119.3775\n",
      "Epoch 2926/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 130.9955 - val_loss: 124.4776\n",
      "Epoch 2927/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 122.3835 - val_loss: 112.7254\n",
      "Epoch 2928/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 144.4617 - val_loss: 111.7171\n",
      "Epoch 2929/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.9441 - val_loss: 111.5707\n",
      "Epoch 2930/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 137.0424 - val_loss: 111.4365\n",
      "Epoch 2931/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 147.1843 - val_loss: 242.6041\n",
      "Epoch 2932/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 150.8392 - val_loss: 124.1441\n",
      "Epoch 2933/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 128.0434 - val_loss: 110.0671\n",
      "Epoch 2934/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 122.7196 - val_loss: 112.2609\n",
      "Epoch 2935/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 132.0123 - val_loss: 118.4021\n",
      "Epoch 2936/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.6599 - val_loss: 109.9856\n",
      "Epoch 2937/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 127.2787 - val_loss: 140.4019\n",
      "Epoch 2938/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 135.4094 - val_loss: 110.8739\n",
      "Epoch 2939/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 136.4784 - val_loss: 144.5731\n",
      "Epoch 2940/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.9524 - val_loss: 109.5282\n",
      "Epoch 2941/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.3755 - val_loss: 123.5908\n",
      "Epoch 2942/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 126.7414 - val_loss: 109.1349\n",
      "Epoch 2943/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.2569 - val_loss: 121.5034\n",
      "Epoch 2944/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 131.1112 - val_loss: 111.8326\n",
      "Epoch 2945/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 121.8413 - val_loss: 109.8585\n",
      "Epoch 2946/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 137.7078 - val_loss: 111.1060\n",
      "Epoch 2947/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 127.9590 - val_loss: 111.9526\n",
      "Epoch 2948/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 359.8168 - val_loss: 318.2099\n",
      "Epoch 2949/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 330.2635 - val_loss: 118.6174\n",
      "Epoch 2950/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 190.1095 - val_loss: 187.3494\n",
      "Epoch 2951/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 156.8604 - val_loss: 124.5047\n",
      "Epoch 2952/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 130.3272 - val_loss: 110.6919\n",
      "Epoch 2953/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 131.9100 - val_loss: 120.2055\n",
      "Epoch 2954/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.8449 - val_loss: 110.9705\n",
      "Epoch 2955/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 125.3231 - val_loss: 123.8671\n",
      "Epoch 2956/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 152.8138 - val_loss: 135.8956\n",
      "Epoch 2957/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 126.4646 - val_loss: 143.7939\n",
      "Epoch 2958/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 128.2907 - val_loss: 146.5865\n",
      "Epoch 2959/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 127.6506 - val_loss: 114.7008\n",
      "Epoch 2960/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 142.7986 - val_loss: 120.9115\n",
      "Epoch 2961/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 66us/step - loss: 151.1921 - val_loss: 170.2529\n",
      "Epoch 2962/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 156.1178 - val_loss: 112.5910\n",
      "Epoch 2963/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 124.0967 - val_loss: 113.9937\n",
      "Epoch 2964/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 140.4193 - val_loss: 112.5590\n",
      "Epoch 2965/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.5001 - val_loss: 110.7075\n",
      "Epoch 2966/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 125.6562 - val_loss: 141.5107\n",
      "Epoch 2967/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 125.6786 - val_loss: 115.5578\n",
      "Epoch 2968/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 150.6553 - val_loss: 116.3271\n",
      "Epoch 2969/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 144.0355 - val_loss: 116.9473\n",
      "Epoch 2970/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 135.7195 - val_loss: 130.3464\n",
      "Epoch 2971/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 134.1240 - val_loss: 172.8963\n",
      "Epoch 2972/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 175.8163 - val_loss: 155.7106\n",
      "Epoch 2973/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 178.5984 - val_loss: 115.9316\n",
      "Epoch 2974/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 184.5613 - val_loss: 124.8940\n",
      "Epoch 2975/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 132.9645 - val_loss: 120.4651\n",
      "Epoch 2976/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.4149 - val_loss: 114.8972\n",
      "Epoch 2977/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 136.8768 - val_loss: 115.6640\n",
      "Epoch 2978/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 138.9323 - val_loss: 150.1985\n",
      "Epoch 2979/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 130.6413 - val_loss: 110.3124\n",
      "Epoch 2980/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 126.2950 - val_loss: 114.4874\n",
      "Epoch 2981/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 132.7905 - val_loss: 112.8276\n",
      "Epoch 2982/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 148.1922 - val_loss: 117.6801\n",
      "Epoch 2983/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.8372 - val_loss: 142.8903\n",
      "Epoch 2984/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.2501 - val_loss: 162.2977\n",
      "Epoch 2985/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 273.9867 - val_loss: 128.1472\n",
      "Epoch 2986/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 125.1618 - val_loss: 112.8123\n",
      "Epoch 2987/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 187.3688 - val_loss: 123.3072\n",
      "Epoch 2988/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 157.4968 - val_loss: 114.1704\n",
      "Epoch 2989/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 142.3939 - val_loss: 116.0992\n",
      "Epoch 2990/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 122.8628 - val_loss: 120.0136\n",
      "Epoch 2991/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.6677 - val_loss: 115.9048\n",
      "Epoch 2992/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 126.4176 - val_loss: 164.2650\n",
      "Epoch 2993/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 130.8295 - val_loss: 112.0764\n",
      "Epoch 2994/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 122.0389 - val_loss: 129.2375\n",
      "Epoch 2995/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.1573 - val_loss: 125.2707\n",
      "Epoch 2996/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 138.3319 - val_loss: 124.3004\n",
      "Epoch 2997/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.4703 - val_loss: 109.1716\n",
      "Epoch 2998/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.3394 - val_loss: 125.1051\n",
      "Epoch 02998: early stopping\n",
      "Fold score (RMSE): 11.049817085266113\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validate\n",
    "kf = KFold(5)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filename_checkpoint, verbose=0, save_best_only=True)\n",
    "\n",
    "# Turn off KFold\n",
    "#if (0):\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "    \n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dropout(0.01)) # Dropout Layer\n",
    "    model.add(Dense(50, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(25, \n",
    "                    kernel_regularizer=regularizers.l2(0.01), #L2 regularization\n",
    "                    activity_regularizer=regularizers.l1(0.001), #L1 Lasso regularization\n",
    "                    activation='relu')) # Hidden 3 \n",
    "    model.add(Dense(10, activation='relu')) # Hidden 4\n",
    "    model.add(Dense(1)) # Output\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=1000, verbose=1, mode='auto')\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpoint],verbose=1,epochs=10000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's RMSE\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final, out of sample score (RMSE): 11.61795711517334\n"
     ]
    }
   ],
   "source": [
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#pred = model.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "#score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "#print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "#chart_regression(pred.flatten(),y_test)\n",
    "#chart_regression(pred.flatten(),y_test,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(filename_checkpoint)\n",
    "\n",
    "df_test = pd.read_csv(filename_test,na_values=['NA','?'])\n",
    "\n",
    "extract_and_encode_features(df_test)\n",
    "\n",
    "ids_test = df_test['id']\n",
    "df_test.drop('id',1,inplace=True)\n",
    "\n",
    "names_test = df_test['name']\n",
    "df_test.drop('name',1,inplace=True)\n",
    "\n",
    "x_submit = df_test.as_matrix().astype(np.float32)\n",
    "pred_submit = model.predict(x_submit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = [n if n > 0 else n * -1 for n in pred_submit[:,0]]\n",
    "df_submit = pd.DataFrame({'id': ids_test,'cost': cost})\n",
    "df_submit = df_submit[['id', 'cost']]\n",
    "df_submit.to_csv(filename_submit, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
