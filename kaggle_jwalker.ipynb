{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Kaggle Assignment: **\n",
    "\n",
    "**Student Name: Jason Walker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Description\n",
    "This is one of the projects from the course T81-855: Applications of Deep Learning at Washington University in St. Louis. All students must create a Kaggle account and submit a solution. Once you have submitted your solution entry log into Blackboard (at WUSTL) and submit a single file telling me your Kaggle name on the leaderboard (you do not need to register to Kaggle with your real name). This competition will be visible to the public, so there may be non-student submissions as well as student.\n",
    "\n",
    "The data set for this competition consists of a number of input columns that should be used to predict a stores sales. This is a regression problem. The inputs are a mixture of discrete and category values. The data set is from a simulation.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The evaluation pages describes how submissions will be scored and how students should format their submissions. The scores are in RMSE.\n",
    "Submission Format\n",
    "\n",
    "For every store in the dataset, submission files should contain a sales volume.\n",
    "\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "```\n",
    "100000,1.23\n",
    "100001,1.123\n",
    "100002,3.332\n",
    "100003,1.53\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Data Description\n",
    "\n",
    "The data contains data and costs for various office supplies. The data came from a simulation and do not directly correspond to any real-world items. See how well you can predict the cost of an item using the provided data. Feature engineering will likely help you. The *name* column may seem useless at first glance; however, it contains information that you can parse to help your predictions.\n",
    "File descriptions\n",
    "```\n",
    "    id - The identifier/primary key.\n",
    "    name - The name of this item.\n",
    "    manufacturer - The manufacturer.\n",
    "    pack - The number of items in this pack.\n",
    "    weight - The weight of a pack of these items.\n",
    "    height - The height of a pack of these items.\n",
    "    width - The width of a pack of these items.\n",
    "    length - The length of a pack of these items.\n",
    "    cost - The cost for this item pack. This is what you are to predict (the target). \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions\n",
    "\n",
    "You will see these at the top of every module and assignment.  These are simply a set of reusable functions that we will make use of.  Each of them will be explained as the semester progresses.  They are explained in greater detail as the course progresses.  Class 4 contains a complete overview of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "        \n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kaggle Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwalker/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "path = './data'\n",
    "\n",
    "filename_test = os.path.join(path,\"test.csv\")\n",
    "filename_train = os.path.join(path,\"train.csv\")\n",
    "filename_sample = os.path.join(path,\"sample.csv\")\n",
    "filename_submit = os.path.join(path,\"submit.csv\")\n",
    "filename_checkpoint = os.path.join(path,\"checkpoint.hdf5\")\n",
    "\n",
    "df_train = pd.read_csv(filename_train,na_values=['NA','?'])\n",
    "\n",
    "np.random.seed(42) # Uncomment this line to get the same shuffle each time\n",
    "df_train = df_train.reindex(np.random.permutation(df_train.index))\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Encode Features\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def extract_and_encode_features(df):\n",
    "    color_regex='(?P<color>red|blue|green|yellow|orange|pink|black|brown|white)'\n",
    "    df['color'] = df.name.str.extract(color_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    quality_regex='(?P<quality>generic|high\\squality)'\n",
    "    df['quality'] = df.name.str.extract(quality_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    size_regex='(?P<size>tiny|small|medium|large)'\n",
    "    df['size'] = df.name.str.extract(size_regex, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    item_regex='(?P<item>paperclips|paperweights|ink\\spens|pencils|stapler|tablets|thumbtacks|post\\sit\\snotes)'\n",
    "    df['item'] = df.name.str.extract(item_regex, flags=re.IGNORECASE, expand=False)\n",
    "    \n",
    "    for column in ['pack','weight','height','width','length']:\n",
    "        missing_median(df,column)\n",
    "    \n",
    "    #df.insert(1,'surface_area',(df['height']*df['width']*df['length']).astype(int))\n",
    "    \n",
    "    ## encode numeric features\n",
    "    #for column in ['pack','weight','height','width','length','surface_area']:\n",
    "    #    encode_numeric_zscore(df,column)\n",
    "\n",
    "    # encode text/categorical features\n",
    "    for column in ['manufacturer','color','quality','size','item']:\n",
    "        encode_text_dummy(df,column)\n",
    "  \n",
    "extract_and_encode_features(df_train)\n",
    "\n",
    "ids_train = df_train['id']\n",
    "df_train.drop('id',1,inplace=True)\n",
    "\n",
    "names_train = df_train['name']\n",
    "df_train.drop('name',1,inplace=True)\n",
    "\n",
    "x,y = to_xy(df_train,'cost')\n",
    "\n",
    "# Used before KFold\n",
    "#x_train, x_test, y_train, y_test = train_test_split(    \n",
    "#    x, y, test_size=0.25, random_state=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to evaluate the coefficients of a regression\n",
    "%matplotlib inline    \n",
    "from IPython.display import display, HTML    \n",
    "\n",
    "def report_coef(names,coef,intercept):\n",
    "    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n",
    "    r = r.sort_values(by=['coef'])\n",
    "    display(r)\n",
    "    print(\"Intercept: {}\".format(intercept))\n",
    "    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))\n",
    "    \n",
    "# Create linear regression\n",
    "regressor = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# Fit/train linear regression\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "print(names)\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_[0,:],\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Lasso(random_state=0,alpha=0.01)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lasso = Lasso(random_state=42)\n",
    "alphas = np.logspace(-8, 8, 10)\n",
    "\n",
    "scores = list()\n",
    "scores_std = list()\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.alpha = alpha\n",
    "    this_scores = cross_val_score(lasso, x, y, cv=n_folds, n_jobs=1)\n",
    "    scores.append(np.mean(this_scores))\n",
    "    scores_std.append(np.std(this_scores))\n",
    "\n",
    "scores, scores_std = np.array(scores), np.array(scores_std)\n",
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Ridge(alpha=1)\n",
    "\n",
    "# Fit/train Ridge\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_[0,:],\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create linear regression\n",
    "regressor = ElasticNet(alpha=0.01, l1_ratio=0.1)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df_train.columns.values)\n",
    "names.remove(\"cost\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 5184.6087 - val_loss: 4263.2856\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 4795.4176 - val_loss: 3766.8765\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 4533.3148 - val_loss: 3618.5896\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 4330.8708 - val_loss: 3535.3761\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 4197.3030 - val_loss: 3501.0222\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 4167.7544 - val_loss: 3478.9662\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 4200.6497 - val_loss: 3384.7174\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 4018.0491 - val_loss: 3342.5486\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 4046.5790 - val_loss: 3288.3544\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 3806.1785 - val_loss: 3023.8728\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 3777.2678 - val_loss: 3622.6361\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 3417.5771 - val_loss: 2739.0939\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 2929.5884 - val_loss: 3040.2665\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 2627.2613 - val_loss: 2583.2299\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 2167.7411 - val_loss: 1260.5134\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 1764.9363 - val_loss: 1369.6458\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1521.7997 - val_loss: 709.7590\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 1062.6498 - val_loss: 764.1920\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 998.8891 - val_loss: 896.9786\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 1315.0805 - val_loss: 543.1919\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 785.4284 - val_loss: 485.5316\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 666.1441 - val_loss: 475.8127\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 733.4105 - val_loss: 670.3152\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 585.7105 - val_loss: 377.4717\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 608.0615 - val_loss: 407.7909\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 653.8066 - val_loss: 519.0280\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 516.0314 - val_loss: 343.8272\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 556.0579 - val_loss: 350.4101\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 547.0045 - val_loss: 561.7093\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 580.0049 - val_loss: 509.8158\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 514.5540 - val_loss: 306.4794\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 497.7641 - val_loss: 487.6928\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 443.4946 - val_loss: 344.2277\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 543.2976 - val_loss: 378.5461\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 475.3890 - val_loss: 307.7402\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 455.1225 - val_loss: 550.4158\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 520.1543 - val_loss: 337.5352\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 514.6572 - val_loss: 299.3982\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 493.4744 - val_loss: 374.1818\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 410.8934 - val_loss: 276.9631\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 538.9808 - val_loss: 293.1174\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 452.2012 - val_loss: 258.4204\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 456.5876 - val_loss: 340.9131\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 371.7451 - val_loss: 297.0092\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 447.0377 - val_loss: 266.4170\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 431.5800 - val_loss: 414.8432\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 343.1819 - val_loss: 252.6411\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 512.1488 - val_loss: 262.4378\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 544.4211 - val_loss: 316.7904\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 390.1837 - val_loss: 290.8809\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 418.8959 - val_loss: 222.8666\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 379.7339 - val_loss: 397.7457\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 409.5566 - val_loss: 318.3553\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 297.7066 - val_loss: 260.0117\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 336.9531 - val_loss: 225.1942\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 456.4214 - val_loss: 356.2235\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 365.1501 - val_loss: 433.9473\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 404.6337 - val_loss: 389.3617\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 353.1045 - val_loss: 209.4980\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 311.7386 - val_loss: 668.5549\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 507.833 - 0s 51us/step - loss: 505.6739 - val_loss: 354.3337\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 384.6729 - val_loss: 273.3423\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 289.1018 - val_loss: 275.6320\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 312.9427 - val_loss: 382.2106\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 405.7601 - val_loss: 259.8400\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 370.0768 - val_loss: 202.6412\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 322.3565 - val_loss: 343.3990\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 330.4885 - val_loss: 190.4569\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 272.4609 - val_loss: 202.8664\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 571.4520 - val_loss: 208.8547\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 281.6112 - val_loss: 263.6814\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 313.3960 - val_loss: 201.7765\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 319.4472 - val_loss: 436.9334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 317.5942 - val_loss: 315.5768\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 346.5683 - val_loss: 233.6568\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 290.1542 - val_loss: 206.6138\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 361.1052 - val_loss: 418.9859\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 279.6595 - val_loss: 535.5874\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 281.8755 - val_loss: 246.2134\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 296.4417 - val_loss: 491.6167\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 295.6843 - val_loss: 195.3086\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 308.0164 - val_loss: 360.1060\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 249.7150 - val_loss: 210.6006\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.9512 - val_loss: 201.5175\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 251.7887 - val_loss: 207.8490\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 336.0962 - val_loss: 234.8720\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 294.5152 - val_loss: 701.7041\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 294.0070 - val_loss: 232.8802\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 312.3944 - val_loss: 1146.4559\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 256.8390 - val_loss: 191.9383\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.7052 - val_loss: 353.1925\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 435.8105 - val_loss: 346.3856\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 290.3571 - val_loss: 322.2773\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 344.4671 - val_loss: 426.4439\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 293.3999 - val_loss: 229.9823\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 285.5526 - val_loss: 197.7401\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 272.5335 - val_loss: 189.9582\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 289.3832 - val_loss: 465.8965\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 243.6844 - val_loss: 182.3973\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 385.4510 - val_loss: 679.3777\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 445.6837 - val_loss: 598.2280\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 310.2983 - val_loss: 294.8808\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 258.0652 - val_loss: 180.0043\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 274.6129 - val_loss: 186.0389\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 306.6885 - val_loss: 442.5191\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 370.2958 - val_loss: 417.0428\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 238.0194 - val_loss: 202.8766\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 299.9977 - val_loss: 198.5912\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.8140 - val_loss: 176.3660\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.6526 - val_loss: 233.2868\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.5726 - val_loss: 191.3436\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 297.3342 - val_loss: 244.4105\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 344.8143 - val_loss: 185.4368\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.6133 - val_loss: 208.6495\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 212.3377 - val_loss: 201.2589\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 238.6127 - val_loss: 218.5775\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.3609 - val_loss: 191.5289\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 468.2434 - val_loss: 180.4073\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 245.4915 - val_loss: 200.3133\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 233.4538 - val_loss: 225.7942\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 255.6034 - val_loss: 1145.6264\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 395.8321 - val_loss: 181.1367\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 224.3059 - val_loss: 210.9865\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 228.1880 - val_loss: 345.1273\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 284.9228 - val_loss: 189.6796\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 330.9576 - val_loss: 260.1370\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 249.7223 - val_loss: 163.2375\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 195.8682 - val_loss: 259.7183\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 217.1548 - val_loss: 215.0498\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 213.8178 - val_loss: 160.2471\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.6860 - val_loss: 202.8040\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 239.5730 - val_loss: 175.1259\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.5003 - val_loss: 214.1796\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 384.4097 - val_loss: 177.4625\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 250.6570 - val_loss: 219.7303\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 346.1569 - val_loss: 323.3732\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.9779 - val_loss: 175.0571\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 436.3085 - val_loss: 227.2520\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 334.4605 - val_loss: 259.6007\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.5728 - val_loss: 197.7259\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 289.8834 - val_loss: 423.9590\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 265.8899 - val_loss: 531.7053\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 288.4840 - val_loss: 221.5399\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 234.4086 - val_loss: 812.4460\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.0519 - val_loss: 199.9497\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.9942 - val_loss: 170.8052\n",
      "Epoch 147/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.4310 - val_loss: 170.2758\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.3887 - val_loss: 275.6519\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 239.9952 - val_loss: 336.6002\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.9033 - val_loss: 210.4989\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 356.4307 - val_loss: 202.7259\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.4258 - val_loss: 273.0073\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.1685 - val_loss: 216.6297\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.8870 - val_loss: 233.2082\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 337.5540 - val_loss: 255.7913\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 228.7849 - val_loss: 156.8339\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 234.5036 - val_loss: 245.4423\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.4050 - val_loss: 179.3581\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.4202 - val_loss: 172.4855\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 242.4129 - val_loss: 236.8252\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.2721 - val_loss: 175.2195\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.5673 - val_loss: 230.4381\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 271.9361 - val_loss: 352.0004\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.8984 - val_loss: 166.3253\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.9161 - val_loss: 188.2142\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.6502 - val_loss: 179.2355\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 202.2931 - val_loss: 225.4340\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.5058 - val_loss: 188.1199\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 414.0269 - val_loss: 280.6768\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.1698 - val_loss: 160.3667\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.8713 - val_loss: 311.1073\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.2224 - val_loss: 178.8015\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.9237 - val_loss: 438.1444\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.8099 - val_loss: 175.5382\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.1338 - val_loss: 173.8555\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 282.4094 - val_loss: 159.9001\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.3626 - val_loss: 176.3004\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.9268 - val_loss: 183.6987\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.6437 - val_loss: 302.3888\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.8680 - val_loss: 179.9506\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.4712 - val_loss: 177.4970\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.6101 - val_loss: 191.1105\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.7880 - val_loss: 193.2056\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 181.1783 - val_loss: 197.9843\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.6733 - val_loss: 233.2948\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 273.5702 - val_loss: 160.3948\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.3766 - val_loss: 184.4348\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 265.4412 - val_loss: 215.3463\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 203.6464 - val_loss: 156.3493\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 238.6453 - val_loss: 182.4499\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 269.1593 - val_loss: 161.3416\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.4537 - val_loss: 160.5054\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.4906 - val_loss: 166.1362\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 238.4450 - val_loss: 162.5058\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.0798 - val_loss: 149.1870\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 240.4722 - val_loss: 157.0206\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 255.7448 - val_loss: 268.7052\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 260.6884 - val_loss: 227.8099\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 232.1857 - val_loss: 192.4494\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 331.1577 - val_loss: 229.7944\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 212.9536 - val_loss: 261.4523\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 175.6118 - val_loss: 243.0502\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 210.3839 - val_loss: 149.5111\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.4540 - val_loss: 152.3983\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.6514 - val_loss: 173.6679\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.6875 - val_loss: 166.1104\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.7969 - val_loss: 184.7270\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 247.4819 - val_loss: 250.4508\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.7158 - val_loss: 148.4246\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.8361 - val_loss: 169.3128\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.3511 - val_loss: 165.5667\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.0233 - val_loss: 162.2817\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.1514 - val_loss: 148.7931\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.1533 - val_loss: 155.1475\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 261.4786 - val_loss: 828.9328\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.8452 - val_loss: 209.2811\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 362.2551 - val_loss: 395.4834\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 507.2747 - val_loss: 218.8381\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 229.2327 - val_loss: 155.3304\n",
      "Epoch 220/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.3102 - val_loss: 366.6412\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 195.0191 - val_loss: 195.4993\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9925 - val_loss: 171.6863\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 203.4616 - val_loss: 179.3473\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.6172 - val_loss: 151.2030\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.6813 - val_loss: 149.3017\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 199.8051 - val_loss: 183.5751\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 199.0026 - val_loss: 166.6880\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 193.8336 - val_loss: 233.1144\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 366.6360 - val_loss: 156.7599\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 362.2844 - val_loss: 300.4691\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.4021 - val_loss: 231.8116\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 208.2610 - val_loss: 218.7365\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 162.8535 - val_loss: 145.1358\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.5128 - val_loss: 143.3899\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.4902 - val_loss: 224.7800\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2477 - val_loss: 147.7190\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 193.5122 - val_loss: 201.1020\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.4930 - val_loss: 209.9096\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 219.0459 - val_loss: 147.3100\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.2195 - val_loss: 181.4268\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 187.8126 - val_loss: 261.9976\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 545.2396 - val_loss: 231.4006\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 291.4434 - val_loss: 177.5659\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.6016 - val_loss: 201.7062\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.8051 - val_loss: 160.3604\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 184.7795 - val_loss: 236.6628\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.5075 - val_loss: 176.5399\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 248.3267 - val_loss: 145.3858\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.7228 - val_loss: 247.9545\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 183.1768 - val_loss: 152.6575\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 166.3308 - val_loss: 146.4878\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 259.9404 - val_loss: 149.0167\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 174.5927 - val_loss: 159.0356\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.9963 - val_loss: 247.1736\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.3169 - val_loss: 158.0282\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 218.7599 - val_loss: 575.0642\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.0449 - val_loss: 166.2882\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.5655 - val_loss: 154.4951\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.7357 - val_loss: 142.5129\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.7671 - val_loss: 216.7690\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.3587 - val_loss: 159.6672\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 406.2024 - val_loss: 541.9516\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.6626 - val_loss: 168.4245\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.1759 - val_loss: 320.3681\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.5589 - val_loss: 155.1968\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 324.2097 - val_loss: 160.4642\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.4515 - val_loss: 193.0615\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 181.6069 - val_loss: 144.3457\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.5407 - val_loss: 149.5821\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.8399 - val_loss: 139.8441\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 189.0270 - val_loss: 139.5381\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 207.6568 - val_loss: 144.7724\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 231.6817 - val_loss: 415.9948\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 184.5751 - val_loss: 287.2733\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.4474 - val_loss: 148.0976\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.5563 - val_loss: 182.2247\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.1367 - val_loss: 150.6025\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.2815 - val_loss: 181.0627\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.6580 - val_loss: 226.6291\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.3461 - val_loss: 145.4373\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.2593 - val_loss: 177.2596\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 220.9466 - val_loss: 165.0267\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 310.1280 - val_loss: 295.9872\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.5067 - val_loss: 169.8488\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.7284 - val_loss: 205.6832\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 548.3445 - val_loss: 358.7800\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 260.7091 - val_loss: 168.9381\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 289.8032 - val_loss: 169.4653\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 163.5321 - val_loss: 147.7035\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.6567 - val_loss: 149.8817\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3655 - val_loss: 174.3868\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.3920 - val_loss: 146.3215\n",
      "Epoch 293/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 48us/step - loss: 166.3002 - val_loss: 164.3069\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.7628 - val_loss: 161.0776\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 172.7813 - val_loss: 187.2861\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 272.7146 - val_loss: 255.3957\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.0678 - val_loss: 149.0603\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 457.5000 - val_loss: 208.6890\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.6518 - val_loss: 151.6693\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 307.2444 - val_loss: 714.0228\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 278.1326 - val_loss: 159.4155\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8099 - val_loss: 168.0633\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.2743 - val_loss: 151.1006\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.1869 - val_loss: 147.0553\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.3081 - val_loss: 137.3038\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 277.1110 - val_loss: 204.1717\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 220.4622 - val_loss: 191.8898\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 186.6630 - val_loss: 235.6560\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.0095 - val_loss: 421.8290\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 237.7720 - val_loss: 314.9696\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.3400 - val_loss: 146.8892\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.5285 - val_loss: 180.5060\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.6063 - val_loss: 206.7620\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.5612 - val_loss: 194.4359\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.8923 - val_loss: 167.6163\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.9751 - val_loss: 172.3537\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.4033 - val_loss: 177.3595\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 271.3286 - val_loss: 664.9465\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 220.0705 - val_loss: 154.2835\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.3774 - val_loss: 145.8390\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 182.1463 - val_loss: 201.5390\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 208.3308 - val_loss: 435.6309\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 326.2096 - val_loss: 162.8126\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.0223 - val_loss: 153.3778\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 163.4731 - val_loss: 573.1371\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 210.2932 - val_loss: 158.6624\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 151.1364 - val_loss: 160.9385\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.3006 - val_loss: 139.8338\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 159.3494 - val_loss: 174.6435\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.6563 - val_loss: 155.8430\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 197.4716 - val_loss: 147.9108\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.7290 - val_loss: 260.5328\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 198.2680 - val_loss: 163.3506\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.7866 - val_loss: 203.8067\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 288.2611 - val_loss: 142.3314\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2769 - val_loss: 141.1817\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.3511 - val_loss: 288.2752\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 607.0893 - val_loss: 170.2006\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 206.1446 - val_loss: 152.6261\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.7820 - val_loss: 174.8464\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.3962 - val_loss: 301.8114\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 529.7262 - val_loss: 276.1163\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.4382 - val_loss: 153.6080\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 208.4216 - val_loss: 231.8389\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 229.9279 - val_loss: 957.9585\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 202.1531 - val_loss: 201.6907\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 158.9985 - val_loss: 202.0469\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.0399 - val_loss: 150.9632\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.6423 - val_loss: 143.2555\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.4442 - val_loss: 200.9357\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 217.8539 - val_loss: 139.2582\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 223.1555 - val_loss: 295.2650\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 171.437 - 0s 51us/step - loss: 171.7218 - val_loss: 153.4506\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 177.3045 - val_loss: 286.4735\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9467 - val_loss: 143.1282\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 193.8599 - val_loss: 155.6106\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 337.8364 - val_loss: 152.9258\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.6250 - val_loss: 282.6002\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 174.4327 - val_loss: 141.7402\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.4145 - val_loss: 136.1950\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.8352 - val_loss: 205.5093\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 245.1922 - val_loss: 178.1111\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 409.7340 - val_loss: 149.7370\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.4370 - val_loss: 140.5140\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.2121 - val_loss: 155.9571\n",
      "Epoch 366/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.4247 - val_loss: 136.1925\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 166.1036 - val_loss: 158.1663\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 288.5362 - val_loss: 439.7666\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.0576 - val_loss: 174.4367\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.1524 - val_loss: 202.9911\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.0817 - val_loss: 289.6409\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.4756 - val_loss: 274.8789\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.1535 - val_loss: 462.5263\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 333.4641 - val_loss: 157.6320\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.3726 - val_loss: 152.0654\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 226.8558 - val_loss: 151.3614\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.2707 - val_loss: 173.3509\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.4667 - val_loss: 328.5281\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 267.7680 - val_loss: 145.7913\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.0845 - val_loss: 142.5636\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.2477 - val_loss: 158.1547\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.2908 - val_loss: 155.3087\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.9911 - val_loss: 169.9472\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.5377 - val_loss: 249.0181\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 248.3425 - val_loss: 213.9332\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.2554 - val_loss: 161.9213\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2590 - val_loss: 147.1051\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.8386 - val_loss: 264.8944\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.5853 - val_loss: 165.1404\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 332.9533 - val_loss: 210.1794\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 167.1436 - val_loss: 141.0185\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.0036 - val_loss: 196.6918\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1932 - val_loss: 134.3414\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.5421 - val_loss: 142.5150\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.6657 - val_loss: 149.2866\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.4566 - val_loss: 136.5086\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 207.7774 - val_loss: 1601.8878\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 463.8022 - val_loss: 198.4703\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 241.4220 - val_loss: 155.4817\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.0336 - val_loss: 208.6393\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 217.0458 - val_loss: 243.6248\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 240.1904 - val_loss: 178.1523\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.1596 - val_loss: 151.6283\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.4866 - val_loss: 396.1131\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.9467 - val_loss: 257.8129\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 230.8588 - val_loss: 167.0468\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 173.6570 - val_loss: 172.0869\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 237.0115 - val_loss: 243.6099\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2391 - val_loss: 159.6168\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.9113 - val_loss: 154.4247\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.1498 - val_loss: 159.3967\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 208.2778 - val_loss: 142.1887\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 300.5843 - val_loss: 319.9375\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.6046 - val_loss: 196.6016\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 168.5063 - val_loss: 164.4878\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 207.2300 - val_loss: 157.1409\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 183.7158 - val_loss: 361.0747\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 189.3295 - val_loss: 362.3543\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 205.3918 - val_loss: 172.4948\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 189.0454 - val_loss: 146.5038\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.7596 - val_loss: 284.2858\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.4487 - val_loss: 153.3131\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 302.2149 - val_loss: 281.4843\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 298.3445 - val_loss: 163.6086\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.8234 - val_loss: 182.6801\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.1660 - val_loss: 151.7798\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.1562 - val_loss: 153.7474\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.7708 - val_loss: 148.4701\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.4327 - val_loss: 171.8880\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.8528 - val_loss: 160.5069\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.9888 - val_loss: 190.0354- ETA: 0s - loss: 158\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.4017 - val_loss: 145.4390\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.8011 - val_loss: 140.4992\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 194.7410 - val_loss: 156.1480\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.9216 - val_loss: 161.8099\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 173.4994 - val_loss: 270.1150\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 260.7735 - val_loss: 145.4704\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 164.8748 - val_loss: 193.6993\n",
      "Epoch 439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.2512 - val_loss: 165.3573\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.2382 - val_loss: 176.6809\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.6656 - val_loss: 165.3631\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.5398 - val_loss: 232.9565\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.2658 - val_loss: 171.6854\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.0902 - val_loss: 165.8036\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.5496 - val_loss: 170.8577\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.6395 - val_loss: 142.9179\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3047 - val_loss: 161.9440\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 214.0961 - val_loss: 151.3441\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.5105 - val_loss: 159.1155\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.6121 - val_loss: 171.3859\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.7911 - val_loss: 137.8202\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.5815 - val_loss: 148.7834\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.4605 - val_loss: 147.1800\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.4193 - val_loss: 151.4651\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.4316 - val_loss: 147.1641\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.4276 - val_loss: 733.0103\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.7033 - val_loss: 172.8939\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.8190 - val_loss: 213.3124\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.0489 - val_loss: 156.0228\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.4513 - val_loss: 519.2686\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.3191 - val_loss: 191.8393\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.7168 - val_loss: 154.7415\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.2495 - val_loss: 181.7665\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.9390 - val_loss: 169.6083\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.3746 - val_loss: 137.8520\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.4194 - val_loss: 136.4374\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.8153 - val_loss: 190.8495\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.9759 - val_loss: 164.7221\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.1827 - val_loss: 138.5462\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.1506 - val_loss: 235.7877\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.1027 - val_loss: 330.4828\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 206.7838 - val_loss: 260.1902\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.5535 - val_loss: 166.7578\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 203.2727 - val_loss: 340.9030\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.7091 - val_loss: 163.5940\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.9632 - val_loss: 187.2182\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 206.1769 - val_loss: 148.9243\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.5979 - val_loss: 171.9548\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.4623 - val_loss: 150.0005\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 305.4913 - val_loss: 247.2028\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 289.3343 - val_loss: 462.8683\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.4026 - val_loss: 209.4739\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.6078 - val_loss: 148.3235\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 192.7790 - val_loss: 253.0421\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.6678 - val_loss: 162.7537\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.5026 - val_loss: 194.7054\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 167.9224 - val_loss: 137.1645\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.4575 - val_loss: 142.4261\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.6261 - val_loss: 184.2735\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 163.3893 - val_loss: 138.1568\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.2227 - val_loss: 144.6389\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.0566 - val_loss: 157.2708\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.6007 - val_loss: 177.4968\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.2384 - val_loss: 163.8658\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 178.6911 - val_loss: 214.0848\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.6409 - val_loss: 139.7019\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.4011 - val_loss: 135.6433\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.6193 - val_loss: 189.2866\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.2906 - val_loss: 136.2089\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 152.2124 - val_loss: 131.4632\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 168.8157 - val_loss: 147.0388\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 170.0172 - val_loss: 170.9687\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.1401 - val_loss: 139.3500\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 230.0041 - val_loss: 200.2334\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3421 - val_loss: 147.9082\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.7031 - val_loss: 148.8156\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.3169 - val_loss: 441.6407\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 176.2424 - val_loss: 140.5520\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.0468 - val_loss: 139.6390\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.0170 - val_loss: 137.4692\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.9469 - val_loss: 139.2575\n",
      "Epoch 512/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.5419 - val_loss: 133.1420\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0373 - val_loss: 142.1082\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 158.7781 - val_loss: 133.4554\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.5694 - val_loss: 258.5823\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.3051 - val_loss: 220.0420\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.5298 - val_loss: 198.8117\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 260.2394 - val_loss: 163.9368\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.3353 - val_loss: 136.2529\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.5047 - val_loss: 157.5622\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.3964 - val_loss: 174.8925\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.6122 - val_loss: 134.9049\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.1101 - val_loss: 153.2737\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9732 - val_loss: 140.4633\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.8387 - val_loss: 136.9537\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 229.3218 - val_loss: 383.5466\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 292.4538 - val_loss: 166.6270\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.2105 - val_loss: 138.6641\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.2771 - val_loss: 157.9829\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0004 - val_loss: 137.2268\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 166.6523 - val_loss: 140.7730\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 155.2179 - val_loss: 145.6942\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.2786 - val_loss: 609.8350\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.6254 - val_loss: 216.3827\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.5137 - val_loss: 436.5131\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.3316 - val_loss: 160.7763\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.7199 - val_loss: 134.5911\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 188.0907 - val_loss: 228.0080\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 175.5707 - val_loss: 151.6838\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.9189 - val_loss: 146.0139\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.7701 - val_loss: 136.9000\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.2731 - val_loss: 138.5669\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.7192 - val_loss: 168.1642\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 168.9646 - val_loss: 140.7863\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.7990 - val_loss: 172.3197\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4045 - val_loss: 194.7223\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.2708 - val_loss: 145.1053\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.9837 - val_loss: 268.5679\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.0086 - val_loss: 161.2531\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.1089 - val_loss: 157.6176\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0382 - val_loss: 215.6789\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.2325 - val_loss: 134.7547\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.2310 - val_loss: 179.9623\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3956 - val_loss: 140.5545\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.9291 - val_loss: 156.3173\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.5712 - val_loss: 163.9666\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.5508 - val_loss: 130.3565\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6075 - val_loss: 141.0374\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.0784 - val_loss: 179.1895\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.0521 - val_loss: 146.7119\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.0540 - val_loss: 256.7143\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 147.6582 - val_loss: 132.5965\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 148.1414 - val_loss: 152.4637\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 168.4248 - val_loss: 213.0823\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 166.6778 - val_loss: 142.0859\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 237.7753 - val_loss: 443.0486\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 235.8675 - val_loss: 220.8266\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3352 - val_loss: 147.3114\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.6775 - val_loss: 177.2157\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.8332 - val_loss: 167.0474\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.0968 - val_loss: 135.4560\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.4417 - val_loss: 142.0553\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.3287 - val_loss: 219.1700\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 175.0334 - val_loss: 131.0225\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.8333 - val_loss: 165.8913\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 201.2522 - val_loss: 282.6943\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.2783 - val_loss: 134.5058\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2356 - val_loss: 141.8127\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.3407 - val_loss: 151.8150\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.2326 - val_loss: 215.7373\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 217.0790 - val_loss: 144.4581\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 174.4812 - val_loss: 176.9850\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0006 - val_loss: 137.0837\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.9284 - val_loss: 138.1282\n",
      "Epoch 585/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1344 - val_loss: 144.8762\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.9432 - val_loss: 152.0229\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 320.4793 - val_loss: 184.5327\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.2549 - val_loss: 155.3153\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.9308 - val_loss: 198.7527\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.0678 - val_loss: 136.5579\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.6737 - val_loss: 153.4864\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.9592 - val_loss: 131.0538\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.9009 - val_loss: 145.4010\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8917 - val_loss: 389.6315\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 458.8234 - val_loss: 145.5833\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.1851 - val_loss: 139.5575\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.1331 - val_loss: 140.5010\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.8011 - val_loss: 157.3657\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.9673 - val_loss: 140.7388\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2033 - val_loss: 190.7977\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.0047 - val_loss: 164.8576\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.8437 - val_loss: 139.6766\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0724 - val_loss: 140.2122\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.2306 - val_loss: 205.5785\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2455 - val_loss: 143.1579\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.8329 - val_loss: 143.3681\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 205.1624 - val_loss: 135.5156\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.0480 - val_loss: 178.7402\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.5862 - val_loss: 146.7694\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 153.7217 - val_loss: 239.5947\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 163.0951 - val_loss: 156.3444\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 197.7475 - val_loss: 163.0849\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6178 - val_loss: 132.3377\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0031 - val_loss: 157.3909\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.8176 - val_loss: 171.4489\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.7293 - val_loss: 158.5485\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 154.4438 - val_loss: 144.9349\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.8193 - val_loss: 143.8867\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 175.7359 - val_loss: 134.0836\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.8677 - val_loss: 137.2286\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4054 - val_loss: 165.8843\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.9182 - val_loss: 146.7720\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.1550 - val_loss: 197.4020\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.9865 - val_loss: 159.4732\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 212.7101 - val_loss: 301.7781\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3129 - val_loss: 134.6369\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.4189 - val_loss: 165.4543\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5237 - val_loss: 199.2104\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0697 - val_loss: 149.9804\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.8802 - val_loss: 145.1876\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 231.3717 - val_loss: 133.8789\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.7493 - val_loss: 172.2628\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2078 - val_loss: 179.9796\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.9883 - val_loss: 136.6064\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 151.5443 - val_loss: 130.1094\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 152.2269 - val_loss: 160.7234\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 155.3876 - val_loss: 130.3593\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 165.5586 - val_loss: 139.6883\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 199.8541 - val_loss: 136.6233\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.3556 - val_loss: 157.4219\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 177.3180 - val_loss: 147.4878\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.3968 - val_loss: 142.2435\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8793 - val_loss: 135.9789\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8782 - val_loss: 196.4110\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.0658 - val_loss: 166.5627\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.8699 - val_loss: 146.6768\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.6514 - val_loss: 150.6466\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.8707 - val_loss: 144.9878\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5045 - val_loss: 137.0618\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 242.8325 - val_loss: 330.3693\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 234.1217 - val_loss: 153.9955\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7600 - val_loss: 151.3334\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.5342 - val_loss: 131.3323\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1803 - val_loss: 181.4038\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.2173 - val_loss: 135.3975\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 181.7734 - val_loss: 137.4801\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.2002 - val_loss: 199.5183\n",
      "Epoch 658/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0052 - val_loss: 143.3168\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.5018 - val_loss: 203.1275\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2518 - val_loss: 160.2278\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.1754 - val_loss: 133.0179\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.3433 - val_loss: 142.8448\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3257 - val_loss: 154.2744\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 212.8377 - val_loss: 196.1744\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 207.1583 - val_loss: 163.6736\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.4041 - val_loss: 139.2245\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.2137 - val_loss: 148.2693\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.4297 - val_loss: 180.2061\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0943 - val_loss: 135.1858\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5248 - val_loss: 150.9171\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8848 - val_loss: 153.5611\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 141.166 - 0s 51us/step - loss: 141.4733 - val_loss: 229.3625\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 172.3820 - val_loss: 160.2284\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.0436 - val_loss: 139.6332\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.1559 - val_loss: 158.9882\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.7413 - val_loss: 137.1856\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3705 - val_loss: 140.9932\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.1484 - val_loss: 149.9156\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1428 - val_loss: 129.3131\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.6043 - val_loss: 151.8045\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 444.2211 - val_loss: 140.3810\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9108 - val_loss: 150.7577\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9602 - val_loss: 136.4528\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9264 - val_loss: 138.7747\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6779 - val_loss: 162.7006\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.6809 - val_loss: 204.1356\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 201.8737 - val_loss: 180.4503\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.9496 - val_loss: 137.8118\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 142.0762 - val_loss: 183.6538\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.0252 - val_loss: 193.9363\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.8195 - val_loss: 177.3702\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.2040 - val_loss: 136.0237\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3033 - val_loss: 230.1192\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.2855 - val_loss: 199.7768\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.4228 - val_loss: 310.7627\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.8094 - val_loss: 146.5599\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.7053 - val_loss: 163.2730\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.6212 - val_loss: 196.5480\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9674 - val_loss: 135.3472\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.8323 - val_loss: 210.3912\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 156.0306 - val_loss: 235.2673\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3530 - val_loss: 131.6168\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1023 - val_loss: 159.0480\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.6383 - val_loss: 178.4092\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.6495 - val_loss: 169.2777\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.7758 - val_loss: 131.8236\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.6523 - val_loss: 143.5508\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.9361 - val_loss: 147.9348\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 154.5549 - val_loss: 152.5621\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 140.8926 - val_loss: 133.0428\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 154.3039 - val_loss: 154.7278\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2596 - val_loss: 147.8652\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.8366 - val_loss: 198.6460\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.1488 - val_loss: 216.1488\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 203.8676 - val_loss: 172.8225\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.6542 - val_loss: 164.9217\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.7730 - val_loss: 168.0638\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.4688 - val_loss: 132.4185\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 247.0266 - val_loss: 386.2369\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 401.8217 - val_loss: 408.5346\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.1784 - val_loss: 142.0890\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5408 - val_loss: 142.5654\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.3055 - val_loss: 140.1875\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.3963 - val_loss: 139.7832\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.1237 - val_loss: 157.0707\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.2911 - val_loss: 153.6745\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.0851 - val_loss: 150.5229\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.3043 - val_loss: 144.1049\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.0924 - val_loss: 162.9195\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.2584 - val_loss: 142.6417\n",
      "Epoch 731/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.2277 - val_loss: 340.9338\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.1820 - val_loss: 172.4345\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.4970 - val_loss: 207.6744\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 161.2333 - val_loss: 333.3008\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.3666 - val_loss: 144.3340\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.9967 - val_loss: 155.9645\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.9985 - val_loss: 286.9463\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1921 - val_loss: 144.0896\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3390 - val_loss: 227.9310\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.1201 - val_loss: 151.0483\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.9147 - val_loss: 154.4416\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 139.8978 - val_loss: 148.1460\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0114 - val_loss: 159.4824\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.4155 - val_loss: 217.0155\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.1941 - val_loss: 145.3681\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8674 - val_loss: 223.1746\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.6998 - val_loss: 134.7141\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.2256 - val_loss: 133.6253\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0732 - val_loss: 135.8875\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.8311 - val_loss: 137.6498\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.5364 - val_loss: 138.4837\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7964 - val_loss: 138.8116\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 147.0401 - val_loss: 166.1735\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 250.5993 - val_loss: 140.4244\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.3229 - val_loss: 139.8462\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2754 - val_loss: 249.9055\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.3109 - val_loss: 134.7908\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2006 - val_loss: 164.9380\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9951 - val_loss: 133.0291\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.7136 - val_loss: 161.8808\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 153.3950 - val_loss: 152.3363\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 146.3376 - val_loss: 146.3192\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3563 - val_loss: 146.7465\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.4069 - val_loss: 153.7600\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.4163 - val_loss: 145.4965\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6786 - val_loss: 136.1040\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2328 - val_loss: 130.2172\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.5474 - val_loss: 160.0759\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.4102 - val_loss: 133.8004\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.6612 - val_loss: 279.9934\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 217.2128 - val_loss: 184.1957\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4328 - val_loss: 235.9299\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.5044 - val_loss: 150.0816\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9233 - val_loss: 136.9998\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.1078 - val_loss: 198.7694\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4452 - val_loss: 132.6694\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.3036 - val_loss: 136.2829\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.5207 - val_loss: 157.0717\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.7620 - val_loss: 194.2487\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.3236 - val_loss: 155.6725\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.9127 - val_loss: 161.9604\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.2529 - val_loss: 226.0043\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 160.3290 - val_loss: 133.8439\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.8725 - val_loss: 143.7530\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 269.2182 - val_loss: 157.4844\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6052 - val_loss: 128.8235\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.5585 - val_loss: 156.3976\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.3863 - val_loss: 261.0824\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.7889 - val_loss: 192.2494\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1783 - val_loss: 139.3805\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.7770 - val_loss: 149.3052\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2603 - val_loss: 185.8006\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 365.6533 - val_loss: 193.2121\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.2841 - val_loss: 160.6186\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.5143 - val_loss: 155.8533\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 202.6158 - val_loss: 163.4012\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.6547 - val_loss: 143.4340\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.2840 - val_loss: 174.7735\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0750 - val_loss: 152.5073\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.4706 - val_loss: 215.7720\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.5687 - val_loss: 139.2083\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.2472 - val_loss: 131.6052\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6357 - val_loss: 153.4326\n",
      "Epoch 804/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.4900 - val_loss: 142.4383\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.1839 - val_loss: 165.3578\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 279.2076 - val_loss: 140.2993\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8441 - val_loss: 156.3011\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.4467 - val_loss: 157.9897\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.1493 - val_loss: 163.3148\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.3187 - val_loss: 206.0522\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.7020 - val_loss: 138.7939\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3971 - val_loss: 361.0978\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.5416 - val_loss: 160.1933\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.8897 - val_loss: 140.8418\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.8707 - val_loss: 172.2761\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.1889 - val_loss: 152.2426\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2366 - val_loss: 186.9605\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.1568 - val_loss: 157.8467\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.0117 - val_loss: 958.4234\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.4275 - val_loss: 156.0242\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.5369 - val_loss: 350.1265\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6064 - val_loss: 144.0202\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.6791 - val_loss: 147.0865\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.2001 - val_loss: 161.2745\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.2180 - val_loss: 164.8895\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2497 - val_loss: 141.9544\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7693 - val_loss: 141.4287\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.8059 - val_loss: 189.8512\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 342.0697 - val_loss: 333.3681\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 232.7550 - val_loss: 233.5924\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.0656 - val_loss: 228.0849\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 191.9858 - val_loss: 146.5546\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.8802 - val_loss: 147.8454\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.4132 - val_loss: 142.6881\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.8618 - val_loss: 143.6672\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.9652 - val_loss: 185.3001\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.3755 - val_loss: 140.8194\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.7776 - val_loss: 149.7084\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.0446 - val_loss: 166.1425\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.3919 - val_loss: 138.2856\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.8934 - val_loss: 160.8551\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6897 - val_loss: 157.6585\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0448 - val_loss: 144.9088\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 160.0141 - val_loss: 214.3174\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.2234 - val_loss: 160.5339\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.5156 - val_loss: 150.3431\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.7283 - val_loss: 150.6375\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.1797 - val_loss: 137.5134\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.4204 - val_loss: 172.6428\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.4435 - val_loss: 150.0979\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 144.1866 - val_loss: 206.9638\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.3292 - val_loss: 194.1243\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.8523 - val_loss: 134.7962\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 162.4395 - val_loss: 203.0134\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8180 - val_loss: 179.3408\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8069 - val_loss: 164.5981\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 160.7967 - val_loss: 182.2617\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.8699 - val_loss: 170.1789\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 182.1588 - val_loss: 140.7785\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 158.8243 - val_loss: 274.9298\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.7227 - val_loss: 134.5846\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.0601 - val_loss: 152.5792\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3639 - val_loss: 143.9358\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.8707 - val_loss: 243.7792\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 149.8838 - val_loss: 133.8943\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1566 - val_loss: 142.9713\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.1493 - val_loss: 153.0236\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9782 - val_loss: 153.1801\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 203.6936 - val_loss: 154.3248\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.0365 - val_loss: 171.8054\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4153 - val_loss: 137.7499\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7122 - val_loss: 128.0830\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9587 - val_loss: 137.4396\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8049 - val_loss: 134.5909\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.6660 - val_loss: 141.9017\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 145.9556 - val_loss: 143.1342\n",
      "Epoch 877/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0021 - val_loss: 173.2872\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7112 - val_loss: 164.6549\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.3694 - val_loss: 132.2207\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.2865 - val_loss: 141.3683\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.1814 - val_loss: 133.3545\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.6611 - val_loss: 136.4911\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.2984 - val_loss: 142.6730\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.3076 - val_loss: 143.2591\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5652 - val_loss: 156.1456\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9272 - val_loss: 141.1413\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8748 - val_loss: 133.4943\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4008 - val_loss: 140.3185\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.7457 - val_loss: 143.1445\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.1076 - val_loss: 147.0772\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.2242 - val_loss: 187.6608\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0751 - val_loss: 197.9792\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.8884 - val_loss: 133.8466\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1070 - val_loss: 187.2038\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 135.9159 - val_loss: 236.8569\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1458 - val_loss: 138.3038\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.3202 - val_loss: 171.2256\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.6849 - val_loss: 156.9237\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.8654 - val_loss: 224.8384\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.4223 - val_loss: 132.6660\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 137.6662 - val_loss: 130.8711\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.9381 - val_loss: 162.1975\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.5435 - val_loss: 374.6841\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.7079 - val_loss: 158.9723\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.6432 - val_loss: 168.7359\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 136.4774 - val_loss: 180.4655\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.8725 - val_loss: 140.1841\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.1090 - val_loss: 164.4846\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7103 - val_loss: 224.0960\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2965 - val_loss: 157.8387\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.0551 - val_loss: 132.5949\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8778 - val_loss: 201.8054\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.9725 - val_loss: 154.1716\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.4488 - val_loss: 175.2096\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.6906 - val_loss: 145.4884\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 148.6335 - val_loss: 141.8788\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.4851 - val_loss: 145.8161\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 281.9632 - val_loss: 363.4896\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.1667 - val_loss: 143.5875\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5513 - val_loss: 238.8648\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.5088 - val_loss: 143.6755\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.3106 - val_loss: 128.1312\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.2361 - val_loss: 166.4616\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.5379 - val_loss: 172.2176\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.6896 - val_loss: 242.3784\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 138.0813 - val_loss: 158.8916\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.9755 - val_loss: 167.9078\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.8149 - val_loss: 151.9819\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.3468 - val_loss: 131.2162\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 160.4868 - val_loss: 171.6059\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 165.0009 - val_loss: 409.9800\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 171.9066 - val_loss: 164.4890\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 138.1398 - val_loss: 129.9992\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 135.9103 - val_loss: 145.9592\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.9746 - val_loss: 134.1443\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8537 - val_loss: 137.6254\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.1823 - val_loss: 158.9278\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9941 - val_loss: 146.2786\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.9174 - val_loss: 148.4650\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5933 - val_loss: 149.4006\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.3994 - val_loss: 138.9727\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.0262 - val_loss: 139.5046\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 277.0469 - val_loss: 145.1641\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.7571 - val_loss: 134.0177\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.3298 - val_loss: 159.0235\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.0124 - val_loss: 141.0258\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 137.042 - 0s 51us/step - loss: 138.1000 - val_loss: 129.9528\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 197.3618 - val_loss: 145.9694\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4093 - val_loss: 130.5876\n",
      "Epoch 950/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1794 - val_loss: 247.5931\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8019 - val_loss: 153.8150\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.9622 - val_loss: 132.5726\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.7696 - val_loss: 143.9562\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.9228 - val_loss: 145.1926\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1628 - val_loss: 287.0600\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6127 - val_loss: 179.8116\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4789 - val_loss: 148.7702\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.6596 - val_loss: 178.6898\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 135.2925 - val_loss: 140.8962\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6258 - val_loss: 131.0462\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.9759 - val_loss: 151.3306\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.8668 - val_loss: 155.5505\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7864 - val_loss: 278.1253\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.9549 - val_loss: 136.2338\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.6129 - val_loss: 137.4687\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.6915 - val_loss: 393.2015\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.8866 - val_loss: 156.8965\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.8017 - val_loss: 130.3611\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0317 - val_loss: 149.3402\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1271 - val_loss: 152.1219\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5810 - val_loss: 127.4894\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5413 - val_loss: 179.3598\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2031 - val_loss: 132.9730\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.2059 - val_loss: 154.2532\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4797 - val_loss: 131.6559\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.4629 - val_loss: 136.5542\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6677 - val_loss: 153.4630\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.1589 - val_loss: 141.2304\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4058 - val_loss: 130.4623\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.5496 - val_loss: 202.9205\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 202.4027 - val_loss: 135.7438\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.9463 - val_loss: 159.5729\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.3613 - val_loss: 140.3487\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4936 - val_loss: 147.8779\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 127.9082 - val_loss: 138.9232\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0475 - val_loss: 210.6126\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.5033 - val_loss: 153.8831\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6763 - val_loss: 131.7154\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4891 - val_loss: 131.6094\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1278 - val_loss: 148.8955\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.0898 - val_loss: 142.2509\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.3286 - val_loss: 134.2197\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5847 - val_loss: 202.1727\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.5138 - val_loss: 188.2952\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.7706 - val_loss: 133.6852\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5303 - val_loss: 141.8139\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.6741 - val_loss: 137.7367\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0166 - val_loss: 143.6725\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.5601 - val_loss: 144.3184\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.7393 - val_loss: 178.8373\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2848 - val_loss: 183.0967\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.2580 - val_loss: 152.0108\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.4785 - val_loss: 142.8965\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3930 - val_loss: 136.1298\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 176.0604 - val_loss: 135.2338\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 214.6776 - val_loss: 146.3530\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.9333 - val_loss: 159.8576\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2178 - val_loss: 129.8916\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 272.8540 - val_loss: 229.5145\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.0706 - val_loss: 143.6815\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.2985 - val_loss: 179.0345\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.5448 - val_loss: 138.2254\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.9497 - val_loss: 150.7096\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2205 - val_loss: 139.3567\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7388 - val_loss: 137.9225\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4500 - val_loss: 174.3271\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.5164 - val_loss: 160.8897\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.3135 - val_loss: 137.4190\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6277 - val_loss: 139.4453\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 158.0983 - val_loss: 156.0637\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6079 - val_loss: 147.6510\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5567 - val_loss: 133.0844\n",
      "Epoch 1023/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0300 - val_loss: 163.1349\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0793 - val_loss: 130.1998\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8042 - val_loss: 162.0248\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.1372 - val_loss: 141.2969\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 339.4643 - val_loss: 312.4219\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 311.7793 - val_loss: 231.0333\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 232.3844 - val_loss: 168.7501\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 190.9317 - val_loss: 224.7898\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.6394 - val_loss: 176.8689\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.6633 - val_loss: 149.8756\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.0442 - val_loss: 156.4497\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.4932 - val_loss: 160.9876\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.7678 - val_loss: 155.9396\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 238.5179 - val_loss: 161.2190\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 189.9132 - val_loss: 182.8803\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.2884 - val_loss: 176.1981\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.7588 - val_loss: 148.5412\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.7755 - val_loss: 150.4543\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.2531 - val_loss: 205.4880\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.9369 - val_loss: 135.6107\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.5001 - val_loss: 140.1167\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7987 - val_loss: 196.9992\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.4199 - val_loss: 163.1088\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6665 - val_loss: 200.4075\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 233.4877 - val_loss: 161.8909\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6304 - val_loss: 141.6387\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 145.8401 - val_loss: 134.6032\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8626 - val_loss: 161.1331\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.1446 - val_loss: 300.8820\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.3676 - val_loss: 236.7210\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.8413 - val_loss: 140.6432\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.3273 - val_loss: 137.6253\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0543 - val_loss: 151.7816\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.4734 - val_loss: 290.5692\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 205.1372 - val_loss: 156.7346\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6545 - val_loss: 210.0813\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.4454 - val_loss: 134.1868\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7506 - val_loss: 161.0405\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.9920 - val_loss: 155.4547\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2385 - val_loss: 157.5416\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.5004 - val_loss: 162.8382\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1850 - val_loss: 141.4382\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.9791 - val_loss: 145.2274\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.2329 - val_loss: 166.7910\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.7169 - val_loss: 184.9745\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.3965 - val_loss: 138.7761\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.8625 - val_loss: 132.3308\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.0497 - val_loss: 137.5575\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.5807 - val_loss: 142.6131\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.3716 - val_loss: 197.5147\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7723 - val_loss: 138.1125\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 152.4059 - val_loss: 136.3742\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7949 - val_loss: 141.0933\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.3882 - val_loss: 133.0606\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4296 - val_loss: 151.0604\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.9538 - val_loss: 372.4454\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 159.8801 - val_loss: 196.3126\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 207.6584 - val_loss: 245.7016\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 138.9486 - val_loss: 162.1852\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.9987 - val_loss: 135.6993\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.2848 - val_loss: 234.3489\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5939 - val_loss: 202.7494\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.1694 - val_loss: 145.3161\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.6588 - val_loss: 136.2299\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.5369 - val_loss: 154.5830\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.0398 - val_loss: 184.5783\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.1478 - val_loss: 240.5657\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2549 - val_loss: 136.9463\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 141.2421 - val_loss: 139.2682\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.4902 - val_loss: 137.8533\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.8287 - val_loss: 150.5544\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.3422 - val_loss: 143.1650\n",
      "Epoch 1095/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7870 - val_loss: 152.4191\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 139.1380 - val_loss: 151.8471\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.6139 - val_loss: 207.8286\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.2117 - val_loss: 146.1994\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3195 - val_loss: 135.4402\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5121 - val_loss: 131.0186\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 147.5014 - val_loss: 231.7029\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.8885 - val_loss: 154.7964\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7759 - val_loss: 138.7522\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.5529 - val_loss: 148.2990\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6652 - val_loss: 299.4209\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.4752 - val_loss: 182.4122\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.2753 - val_loss: 132.1542\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5810 - val_loss: 230.4354\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.4069 - val_loss: 134.2024\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.0475 - val_loss: 162.1471\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5454 - val_loss: 132.3452\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5018 - val_loss: 146.0915\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.3051 - val_loss: 141.1502\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.7515 - val_loss: 188.2549\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.3000 - val_loss: 176.7289\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1258 - val_loss: 141.6416\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0117 - val_loss: 188.1043\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.7967 - val_loss: 169.2222\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.3901 - val_loss: 144.2423\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4961 - val_loss: 311.8851\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.9222 - val_loss: 141.5104\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.0272 - val_loss: 158.8463\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1489 - val_loss: 141.6320\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4531 - val_loss: 140.2703\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.7610 - val_loss: 196.6142\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9071 - val_loss: 130.6448\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.2213 - val_loss: 177.1953\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.2122 - val_loss: 231.0730\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.8661 - val_loss: 161.8767\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.8218 - val_loss: 131.4659\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8678 - val_loss: 168.9869\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.3754 - val_loss: 137.3088\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.4723 - val_loss: 131.2728\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 140.9688 - val_loss: 149.5851\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8980 - val_loss: 153.2985\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4953 - val_loss: 139.6122\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4101 - val_loss: 171.7849\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2396 - val_loss: 233.7812\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.5810 - val_loss: 413.8902\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.5800 - val_loss: 177.7662\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.4131 - val_loss: 149.7626\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.1860 - val_loss: 146.7742\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.4397 - val_loss: 145.1663\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.0390 - val_loss: 154.3499\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.6401 - val_loss: 131.5003\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6825 - val_loss: 132.8073\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0023 - val_loss: 135.4511\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.5463 - val_loss: 151.6906\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4492 - val_loss: 134.6998\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5469 - val_loss: 133.3820\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 130.6681 - val_loss: 148.1188\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 146.3901 - val_loss: 136.2187\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 150.7607 - val_loss: 153.9351\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.4944 - val_loss: 212.0883\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 149.6877 - val_loss: 137.8268\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.6790 - val_loss: 167.2197\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0596 - val_loss: 168.0430\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.0974 - val_loss: 153.4832\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.5672 - val_loss: 303.2717\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 199.5217 - val_loss: 175.8858\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 147.8199 - val_loss: 171.0270\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 151.1664 - val_loss: 200.6194\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8694 - val_loss: 140.6361\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9003 - val_loss: 137.5524\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9178 - val_loss: 160.4866\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6086 - val_loss: 134.2139\n",
      "Epoch 1167/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6152 - val_loss: 146.5965\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.9734 - val_loss: 141.4885\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0376 - val_loss: 187.5780\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.2336 - val_loss: 167.7367\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.0529 - val_loss: 145.9640\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.0396 - val_loss: 130.3307\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.7650 - val_loss: 223.9847\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.2193 - val_loss: 139.9502\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7611 - val_loss: 298.0497\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.0291 - val_loss: 130.1760\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9054 - val_loss: 153.8338\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0005 - val_loss: 143.3380\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.8119 - val_loss: 144.7458\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1157 - val_loss: 160.3019\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8509 - val_loss: 127.9442\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.7717 - val_loss: 136.9383\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3690 - val_loss: 126.8040\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.7630 - val_loss: 173.2088\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.0958 - val_loss: 147.2163\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.0429 - val_loss: 157.3379\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.0494 - val_loss: 510.5098\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.1577 - val_loss: 199.0632\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6320 - val_loss: 131.8743\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8968 - val_loss: 134.6362\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6812 - val_loss: 137.0909\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2780 - val_loss: 150.5238\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2567 - val_loss: 148.1869\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0183 - val_loss: 200.9380\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7003 - val_loss: 130.4119\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.8632 - val_loss: 129.6841\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6972 - val_loss: 135.2118\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0698 - val_loss: 129.2735\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.8398 - val_loss: 174.9679\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0909 - val_loss: 133.1786\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7937 - val_loss: 131.1421\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8585 - val_loss: 133.5836\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7245 - val_loss: 152.9376\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0383 - val_loss: 136.5166\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.1948 - val_loss: 199.5067\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 270.6997 - val_loss: 152.6123\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 126.0580 - val_loss: 140.6407\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2837 - val_loss: 135.5422\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3490 - val_loss: 129.3332 ETA: 0s - loss: 126.\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.3261 - val_loss: 138.2362\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3486 - val_loss: 179.0362\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7001 - val_loss: 129.4593\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.1000 - val_loss: 129.8175\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7527 - val_loss: 132.5444\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7878 - val_loss: 193.6937\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.9904 - val_loss: 131.5489\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1419 - val_loss: 146.9658\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7198 - val_loss: 191.9282\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.9085 - val_loss: 144.7282\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3678 - val_loss: 141.3514\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2479 - val_loss: 135.1082\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.5561 - val_loss: 148.0085\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 128.2642 - val_loss: 140.5304\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 133.7443 - val_loss: 135.7722\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.9257 - val_loss: 130.3936\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 140.3544 - val_loss: 196.2245\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 220.1925 - val_loss: 484.1581\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9851 - val_loss: 140.6816\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0207 - val_loss: 133.6730\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5417 - val_loss: 133.6884\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0273 - val_loss: 148.9117\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6130 - val_loss: 147.9369\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5877 - val_loss: 185.8327\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7967 - val_loss: 272.6359\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7226 - val_loss: 132.3862\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6116 - val_loss: 169.7744\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.9107 - val_loss: 135.7092\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3647 - val_loss: 129.7856\n",
      "Epoch 1239/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.6003 - val_loss: 131.5296\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9628 - val_loss: 176.5008\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7540 - val_loss: 133.7160\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4317 - val_loss: 142.0678\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.5308 - val_loss: 129.3874\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0083 - val_loss: 134.0272\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8135 - val_loss: 206.0784\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5166 - val_loss: 139.7046\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.4610 - val_loss: 135.1190\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9067 - val_loss: 159.8829\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5708 - val_loss: 130.5642\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.2002 - val_loss: 142.1995\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.2722 - val_loss: 138.1159\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.0576 - val_loss: 131.8622\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5956 - val_loss: 141.7287\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7830 - val_loss: 132.0590\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1142 - val_loss: 133.9877\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0486 - val_loss: 141.5213\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9765 - val_loss: 145.9875\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.9345 - val_loss: 147.6540\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2259 - val_loss: 168.0317\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.3212 - val_loss: 135.5510\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9520 - val_loss: 141.3942\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5006 - val_loss: 140.1728\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3349 - val_loss: 141.7436\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4734 - val_loss: 143.0084\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.2239 - val_loss: 179.3304\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3948 - val_loss: 132.4140\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.9650 - val_loss: 128.8724\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5703 - val_loss: 218.4514\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3283 - val_loss: 137.4054\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.0317 - val_loss: 136.3951\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9058 - val_loss: 135.3612\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.5626 - val_loss: 140.6462\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9596 - val_loss: 131.0241\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.4168 - val_loss: 161.7541\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.8541 - val_loss: 831.7642\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.1533 - val_loss: 135.4425\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6232 - val_loss: 169.0310\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.4287 - val_loss: 132.8718\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.5256 - val_loss: 137.3271\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.3398 - val_loss: 138.2907\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.5281 - val_loss: 135.3266\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4168 - val_loss: 129.8027\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5874 - val_loss: 130.4641\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9610 - val_loss: 136.8800\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.8781 - val_loss: 132.1173\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.1832 - val_loss: 2321.4864\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 462.3003 - val_loss: 187.6578\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.0514 - val_loss: 200.6272\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.7285 - val_loss: 174.6218\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.2155 - val_loss: 149.2030\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.2911 - val_loss: 172.6778\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.7974 - val_loss: 179.2924\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.1419 - val_loss: 257.0702\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7515 - val_loss: 157.6554\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 155.1387 - val_loss: 137.0202\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 157.6278 - val_loss: 164.7358\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 186.4962 - val_loss: 172.4013\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 147.5530 - val_loss: 211.6351\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6917 - val_loss: 179.3046\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.1485 - val_loss: 229.9651\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.9416 - val_loss: 176.2210\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.3799 - val_loss: 143.0886\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.5050 - val_loss: 145.1106\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.8243 - val_loss: 150.5773\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8200 - val_loss: 131.9518\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.8051 - val_loss: 158.2900\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.4723 - val_loss: 135.5872\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7046 - val_loss: 132.8616\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4247 - val_loss: 134.8621\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.9151 - val_loss: 180.4669\n",
      "Epoch 1311/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4187 - val_loss: 145.4459\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7516 - val_loss: 213.2055\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.6353 - val_loss: 144.6397\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8828 - val_loss: 146.6456\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.3589 - val_loss: 175.6942\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.7537 - val_loss: 137.5810\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6105 - val_loss: 138.5625\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2644 - val_loss: 143.2280\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.9899 - val_loss: 213.2326\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.9825 - val_loss: 199.3771\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0582 - val_loss: 142.6191\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5387 - val_loss: 158.0707\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.8207 - val_loss: 192.7539\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.7033 - val_loss: 174.0292\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0923 - val_loss: 143.9275\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.5036 - val_loss: 165.7413\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9099 - val_loss: 133.6200\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0913 - val_loss: 139.4179\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2985 - val_loss: 133.1316\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4185 - val_loss: 189.2126\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3871 - val_loss: 133.4932\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.9678 - val_loss: 160.2373\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5228 - val_loss: 153.1096\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8040 - val_loss: 140.4997\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2394 - val_loss: 134.4930\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 140.568 - 0s 50us/step - loss: 140.0507 - val_loss: 134.3402\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8273 - val_loss: 133.9081\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.4485 - val_loss: 153.4463\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9019 - val_loss: 148.5705\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.1196 - val_loss: 171.8448\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.1189 - val_loss: 131.1993\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0258 - val_loss: 161.1959\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5558 - val_loss: 154.9227\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 147.4996 - val_loss: 135.6871\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.5863 - val_loss: 145.7676\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.2130 - val_loss: 156.6146\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.9651 - val_loss: 134.2888\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6915 - val_loss: 133.9589\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2692 - val_loss: 142.5623\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6003 - val_loss: 240.6232\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.5460 - val_loss: 133.0332\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9164 - val_loss: 157.9513\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.8826 - val_loss: 159.3515\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1195 - val_loss: 171.5939\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3567 - val_loss: 131.5093\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8662 - val_loss: 138.5756\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9867 - val_loss: 164.7845\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9153 - val_loss: 260.9771\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.8437 - val_loss: 139.9264\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.4592 - val_loss: 151.1999\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4998 - val_loss: 134.2218\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.0898 - val_loss: 132.4293\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.7036 - val_loss: 130.1257\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.1367 - val_loss: 133.2804\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9481 - val_loss: 224.0361\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 171.8535 - val_loss: 137.3860\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 146.3263 - val_loss: 199.2363\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 136.7547 - val_loss: 137.3526\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.5911 - val_loss: 190.2062\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.0570 - val_loss: 132.9825\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7566 - val_loss: 141.3077\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8382 - val_loss: 175.7164\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0301 - val_loss: 136.9868- ETA: 0s - loss: 18\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.5974 - val_loss: 180.6516\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9218 - val_loss: 135.8976\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2104 - val_loss: 151.2115\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.6517 - val_loss: 133.0209\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5973 - val_loss: 131.1048\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.1310 - val_loss: 138.9952\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.2969 - val_loss: 133.5804\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9233 - val_loss: 161.6009\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.8558 - val_loss: 136.6242\n",
      "Epoch 1383/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2721 - val_loss: 231.7965\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4899 - val_loss: 154.0032\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8574 - val_loss: 155.9933\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.3137 - val_loss: 158.0382\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8798 - val_loss: 140.7930\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0662 - val_loss: 152.6769\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.1298 - val_loss: 160.9023\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.5998 - val_loss: 132.9395\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.8801 - val_loss: 759.1501\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.5273 - val_loss: 131.4132\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5743 - val_loss: 174.6165\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1938 - val_loss: 134.5885\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5494 - val_loss: 138.4142\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0336 - val_loss: 151.6664\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.6451 - val_loss: 133.1270\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.3598 - val_loss: 291.6156\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6385 - val_loss: 287.1898\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.6442 - val_loss: 138.0105\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7889 - val_loss: 161.9387\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2160 - val_loss: 186.2752\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.2843 - val_loss: 137.7650\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.2435 - val_loss: 134.6858\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 132.152 - 0s 51us/step - loss: 132.1581 - val_loss: 131.1767\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3477 - val_loss: 132.4122\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3571 - val_loss: 130.8099\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 139.042 - 0s 50us/step - loss: 138.8786 - val_loss: 131.9955\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7514 - val_loss: 138.9439\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2071 - val_loss: 142.0822\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.1254 - val_loss: 160.3204\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.6089 - val_loss: 157.8222\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0050 - val_loss: 138.0825\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.1929 - val_loss: 156.6071\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0086 - val_loss: 139.3275\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9730 - val_loss: 164.3071\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2260 - val_loss: 140.5911\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1466 - val_loss: 171.8701\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.9669 - val_loss: 151.9222\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7951 - val_loss: 142.6440\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6136 - val_loss: 134.5711\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.0675 - val_loss: 135.8359\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7815 - val_loss: 130.9647\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3129 - val_loss: 134.0265\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5857 - val_loss: 137.4651\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.0870 - val_loss: 186.5608\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2270 - val_loss: 148.8861\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5712 - val_loss: 156.5431\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.9477 - val_loss: 326.3086\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.4863 - val_loss: 161.7508\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9704 - val_loss: 191.6740\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8022 - val_loss: 131.2209\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8532 - val_loss: 134.3175\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5453 - val_loss: 136.4153\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1685 - val_loss: 138.0603\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.8264 - val_loss: 203.7920\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4987 - val_loss: 134.7375\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6252 - val_loss: 133.6745\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 195.2290 - val_loss: 225.9328\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.8508 - val_loss: 180.2249\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.0683 - val_loss: 159.6283\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1875 - val_loss: 198.9503\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.3141 - val_loss: 180.7031\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6900 - val_loss: 138.5651\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7273 - val_loss: 200.8999\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.9694 - val_loss: 161.1268\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.9129 - val_loss: 205.6592\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3817 - val_loss: 156.7058\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3046 - val_loss: 139.9649\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.4591 - val_loss: 147.6309\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6679 - val_loss: 130.0654\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.6795 - val_loss: 150.2882\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.2279 - val_loss: 142.1851\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.6053 - val_loss: 138.5992\n",
      "Epoch 1455/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.5070 - val_loss: 136.9102\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6889 - val_loss: 154.0013\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3975 - val_loss: 132.6358\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.2876 - val_loss: 183.2084\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9845 - val_loss: 146.3117\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.3882 - val_loss: 153.8628\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.4802 - val_loss: 186.0160\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.6510 - val_loss: 142.5243\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1206 - val_loss: 166.7085\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5174 - val_loss: 143.8091\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4560 - val_loss: 134.4200\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6835 - val_loss: 141.6986\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.0909 - val_loss: 139.3749\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.4295 - val_loss: 180.2595\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9145 - val_loss: 130.2822\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.6938 - val_loss: 200.6121\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.4423 - val_loss: 177.4529\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.5277 - val_loss: 167.5209\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9029 - val_loss: 149.6857\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7738 - val_loss: 128.2468\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5258 - val_loss: 142.3879\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 132.650 - 0s 51us/step - loss: 132.6776 - val_loss: 137.5372\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.5734 - val_loss: 137.4821\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3807 - val_loss: 131.8299\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.4719 - val_loss: 151.9240\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3519 - val_loss: 133.5197\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1855 - val_loss: 153.7561\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9881 - val_loss: 159.3369\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.5377 - val_loss: 129.9093\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.5265 - val_loss: 161.0634\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0257 - val_loss: 134.4612\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8820 - val_loss: 145.1159\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 202.0997 - val_loss: 135.7785\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6112 - val_loss: 134.7519\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.8542 - val_loss: 478.1737\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.1322 - val_loss: 136.2705\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8365 - val_loss: 136.0942\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1986 - val_loss: 141.4283\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3102 - val_loss: 135.4879\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8331 - val_loss: 134.3157\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 123.732 - 0s 51us/step - loss: 122.9038 - val_loss: 129.2104\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.4163 - val_loss: 134.3493\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3323 - val_loss: 135.1186\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.4051 - val_loss: 139.1361\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.2203 - val_loss: 191.6050\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2667 - val_loss: 135.7071\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0709 - val_loss: 139.5480\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3061 - val_loss: 167.5544\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2403 - val_loss: 128.8661\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.6264 - val_loss: 148.8676\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2131 - val_loss: 135.2868\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.7952 - val_loss: 152.7107\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.1104 - val_loss: 141.8574\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4445 - val_loss: 186.8071\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.6892 - val_loss: 134.3672\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.5599 - val_loss: 132.3609\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3166 - val_loss: 127.1899\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 122.7220 - val_loss: 162.2449\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 131.7122 - val_loss: 156.6299\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.4138 - val_loss: 132.0808\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.8583 - val_loss: 140.3088\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.8847 - val_loss: 200.9614\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4549 - val_loss: 228.4107\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.2624 - val_loss: 137.8819\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2259 - val_loss: 135.2674\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4470 - val_loss: 274.4605\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.3536 - val_loss: 132.8684\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.7142 - val_loss: 158.8903\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8691 - val_loss: 135.7208\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9647 - val_loss: 136.2844\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.2170 - val_loss: 156.7106\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 123.987 - 0s 51us/step - loss: 127.1795 - val_loss: 181.9665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.7183 - val_loss: 134.3281\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7749 - val_loss: 136.0180\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0483 - val_loss: 154.9893\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1280 - val_loss: 140.8676\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.4524 - val_loss: 137.3647\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.354 - 0s 50us/step - loss: 126.8289 - val_loss: 159.2601\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8489 - val_loss: 141.0327\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1505 - val_loss: 146.1027\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.2677 - val_loss: 134.3103\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5058 - val_loss: 154.9193\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3907 - val_loss: 213.4932\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3603 - val_loss: 137.1030\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.0599 - val_loss: 136.9805\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 138.2497 - val_loss: 145.2361\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.5528 - val_loss: 180.1993\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9576 - val_loss: 158.9810\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1373 - val_loss: 181.4076\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0978 - val_loss: 175.1974\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6290 - val_loss: 157.8948\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0778 - val_loss: 147.2857\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.4063 - val_loss: 396.1497\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5770 - val_loss: 139.6651\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0705 - val_loss: 176.2425\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7667 - val_loss: 136.6009\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6274 - val_loss: 154.0364\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8715 - val_loss: 161.6620\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.4982 - val_loss: 150.0881\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9732 - val_loss: 133.9964\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.5862 - val_loss: 136.0400\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7678 - val_loss: 157.4777\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.3411 - val_loss: 138.4699\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2633 - val_loss: 136.1823\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0378 - val_loss: 918.0431\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 197.1710 - val_loss: 142.9803\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6022 - val_loss: 146.8944\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7665 - val_loss: 137.7125\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0466 - val_loss: 167.0465\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4552 - val_loss: 136.7934\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3210 - val_loss: 139.4319\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5872 - val_loss: 139.4234\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.9039 - val_loss: 149.1090\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3639 - val_loss: 138.2181\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3170 - val_loss: 189.8508\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9254 - val_loss: 255.4175\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8636 - val_loss: 132.8918\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.2165 - val_loss: 129.5940\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.1414 - val_loss: 137.5084\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6116 - val_loss: 134.9337\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4351 - val_loss: 136.2854\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9279 - val_loss: 142.4372\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.4113 - val_loss: 149.9426\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3743 - val_loss: 140.8398\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0618 - val_loss: 131.1390\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.4950 - val_loss: 138.1052\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.3304 - val_loss: 176.0332\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.5081 - val_loss: 143.6484\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0954 - val_loss: 179.9959\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.9372 - val_loss: 227.1492\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.7666 - val_loss: 148.6566\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 133.4484 - val_loss: 134.7287\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 153.2415 - val_loss: 159.3947\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 126.6844 - val_loss: 188.8733\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.3326 - val_loss: 142.0436\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.6987 - val_loss: 155.1599\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.3124 - val_loss: 179.9909\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5450 - val_loss: 189.2170\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.0634 - val_loss: 143.3565\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2677 - val_loss: 130.0898\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7465 - val_loss: 161.7782\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.8571 - val_loss: 189.9475\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0116 - val_loss: 140.5084\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.6511 - val_loss: 173.6398\n",
      "Epoch 1599/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.9468 - val_loss: 203.4132\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1447 - val_loss: 204.6755\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.5651 - val_loss: 149.9047\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.6294 - val_loss: 140.6955\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1022 - val_loss: 137.6583\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.3849 - val_loss: 198.6427\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0414 - val_loss: 138.6788\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.3416 - val_loss: 180.3994\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8019 - val_loss: 130.5331\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0277 - val_loss: 131.7559\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5319 - val_loss: 184.7845\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.4253 - val_loss: 187.5881\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.0818 - val_loss: 176.0004\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.2867 - val_loss: 147.6401\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.1289 - val_loss: 160.7361\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7199 - val_loss: 190.0013\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0566 - val_loss: 143.8314\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.9662 - val_loss: 175.1083\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.1598 - val_loss: 193.7934\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5738 - val_loss: 142.0836\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4116 - val_loss: 143.2876\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 159.758 - 0s 51us/step - loss: 158.7693 - val_loss: 137.7094\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6733 - val_loss: 155.8538\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0303 - val_loss: 431.8321\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8217 - val_loss: 142.3646\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4642 - val_loss: 139.0088\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.4704 - val_loss: 206.8661\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5657 - val_loss: 173.3486\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.2902 - val_loss: 136.9801\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7995 - val_loss: 162.9420\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3207 - val_loss: 140.2007\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.8148 - val_loss: 157.5268\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.8848 - val_loss: 134.0843\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8532 - val_loss: 144.3707\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.6020 - val_loss: 144.0213\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.2710 - val_loss: 147.6090\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7550 - val_loss: 178.5748\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.9889 - val_loss: 135.0055\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7934 - val_loss: 170.9327\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.7340 - val_loss: 145.8191\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7615 - val_loss: 135.4426\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 145.0377 - val_loss: 208.8211\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.6367 - val_loss: 168.9134\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5110 - val_loss: 186.1540\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9916 - val_loss: 152.0779\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.9562 - val_loss: 194.2193\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.0156 - val_loss: 138.6231\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.8542 - val_loss: 139.9540\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 262.0625 - val_loss: 172.6671\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9059 - val_loss: 132.1836\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.3062 - val_loss: 144.0923\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0641 - val_loss: 150.7480\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3146 - val_loss: 166.6846\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6084 - val_loss: 153.7471\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2605 - val_loss: 166.8634\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3889 - val_loss: 144.3646\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.0864 - val_loss: 137.4208\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.4794 - val_loss: 147.6551\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.9539 - val_loss: 139.0491\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 130.6049 - val_loss: 128.1735\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 128.2822 - val_loss: 256.1286\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.8586 - val_loss: 142.2474\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 222.4212 - val_loss: 147.7577\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5291 - val_loss: 138.6213\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4838 - val_loss: 143.4501\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1805 - val_loss: 162.1057\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3643 - val_loss: 129.4532\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7774 - val_loss: 150.1949\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2727 - val_loss: 133.9598\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.9189 - val_loss: 158.7613\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8728 - val_loss: 129.3818\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.0452 - val_loss: 175.9810\n",
      "Epoch 1671/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.2674 - val_loss: 132.2158\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.4323 - val_loss: 138.6108\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 132.2310 - val_loss: 144.6875\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.2761 - val_loss: 231.8095\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 391.1402 - val_loss: 152.0779\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8829 - val_loss: 139.3422\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.0494 - val_loss: 162.5317\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4315 - val_loss: 132.8386\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0629 - val_loss: 145.4910\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.2518 - val_loss: 151.0608\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5044 - val_loss: 132.7749\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2425 - val_loss: 174.4855\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.1612 - val_loss: 129.1938\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8750 - val_loss: 219.2775\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.5293 - val_loss: 151.5027\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8869 - val_loss: 138.9764\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 362.6766 - val_loss: 166.3095\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4714 - val_loss: 148.8292\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5661 - val_loss: 175.7798\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 155.9009 - val_loss: 178.1652\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.2062 - val_loss: 282.1603\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.4572 - val_loss: 164.8915\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9891 - val_loss: 140.7583\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.0967 - val_loss: 213.6425\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.3570 - val_loss: 323.5868\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7490 - val_loss: 141.2349\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1775 - val_loss: 172.5020\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.4573 - val_loss: 450.1931\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6269 - val_loss: 216.7069\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1622 - val_loss: 150.7879\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.1438 - val_loss: 142.3198\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6592 - val_loss: 178.3505\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1578 - val_loss: 167.3169\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4991 - val_loss: 175.2929\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.6380 - val_loss: 156.7930\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2961 - val_loss: 175.5185\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.4545 - val_loss: 158.4183\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.7635 - val_loss: 168.4205\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0727 - val_loss: 143.3185\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.3679 - val_loss: 157.4701\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.8574 - val_loss: 142.7791\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2423 - val_loss: 168.1112\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3193 - val_loss: 136.8799\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.2332 - val_loss: 160.2388\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8493 - val_loss: 149.0318\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0415 - val_loss: 150.8981\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.8092 - val_loss: 163.0827\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.0355 - val_loss: 189.6866\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7756 - val_loss: 174.1654\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.4639 - val_loss: 138.8363\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.4740 - val_loss: 225.7769\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5879 - val_loss: 163.8534\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.8779 - val_loss: 151.8907\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.7510 - val_loss: 149.0991\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 142.223 - 0s 51us/step - loss: 141.8760 - val_loss: 142.9149\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2357 - val_loss: 145.1332\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.8481 - val_loss: 146.0297\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6067 - val_loss: 221.4745\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6669 - val_loss: 144.7781\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0059 - val_loss: 143.1883\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.3060 - val_loss: 136.6228\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 127.8898 - val_loss: 137.4095\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 156.4452 - val_loss: 174.2979\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 132.601 - 1s 63us/step - loss: 132.4421 - val_loss: 144.3555\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.3922 - val_loss: 165.6655\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.9636 - val_loss: 160.0032\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.0678 - val_loss: 145.5291\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.2842 - val_loss: 193.7852\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.5858 - val_loss: 174.2668\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.4180 - val_loss: 165.6199\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8127 - val_loss: 139.1364\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1500 - val_loss: 160.0321\n",
      "Epoch 1743/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.5365 - val_loss: 297.6408\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8407 - val_loss: 142.9809\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.0901 - val_loss: 155.6620\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7888 - val_loss: 219.9989\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.0881 - val_loss: 261.5411\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2545 - val_loss: 176.2280\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.2638 - val_loss: 151.2097\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.8834 - val_loss: 156.0971\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2181 - val_loss: 147.0219\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.7677 - val_loss: 325.8330\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.890 - 0s 50us/step - loss: 143.8745 - val_loss: 145.7456\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3980 - val_loss: 155.3136\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.5544 - val_loss: 162.4826\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4046 - val_loss: 252.6528\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.0753 - val_loss: 137.8267\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.9463 - val_loss: 135.2322\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.3035 - val_loss: 134.2352\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.6583 - val_loss: 134.0737\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9559 - val_loss: 139.6157\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.1945 - val_loss: 156.3292\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.6324 - val_loss: 135.8544\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1879 - val_loss: 281.6798\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.4674 - val_loss: 228.6479\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.5636 - val_loss: 130.5929\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.1125 - val_loss: 175.6275\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4117 - val_loss: 139.9118\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7891 - val_loss: 258.3519\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5786 - val_loss: 169.3097\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.7094 - val_loss: 173.5814\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.2343 - val_loss: 157.6936\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8294 - val_loss: 150.5414\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0580 - val_loss: 136.9059\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0921 - val_loss: 219.0828\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.9039 - val_loss: 135.0845\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8433 - val_loss: 270.4252\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7731 - val_loss: 219.9952\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7579 - val_loss: 171.6597\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8154 - val_loss: 146.1887\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1580 - val_loss: 180.4718\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5174 - val_loss: 140.0940\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.2185 - val_loss: 214.4809\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8695 - val_loss: 156.1620\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8887 - val_loss: 136.8544\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3297 - val_loss: 145.0354\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4539 - val_loss: 143.6750\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0237 - val_loss: 135.8423\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.9879 - val_loss: 151.8838\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.9827 - val_loss: 143.7531\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.0632 - val_loss: 134.6818\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7297 - val_loss: 153.3598\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.4657 - val_loss: 133.9954\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7742 - val_loss: 146.7988\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1159 - val_loss: 159.4197\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6711 - val_loss: 259.9095\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.8974 - val_loss: 180.2303\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.7927 - val_loss: 143.5305\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7222 - val_loss: 191.0931\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.3671 - val_loss: 207.1836\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7706 - val_loss: 130.9769\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7510 - val_loss: 144.4885\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1255 - val_loss: 133.7470\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 129.1289 - val_loss: 136.8283\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 143.3901 - val_loss: 219.1670\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.1285 - val_loss: 132.2710\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 130.8570 - val_loss: 186.7279\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8962 - val_loss: 174.4153\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.3720 - val_loss: 151.2832\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1185 - val_loss: 150.6978\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.995 - 0s 51us/step - loss: 128.3978 - val_loss: 134.9636\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.6503 - val_loss: 140.6528\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.9442 - val_loss: 211.2252\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9445 - val_loss: 146.3118\n",
      "Epoch 1815/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2163 - val_loss: 137.1737\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.3172 - val_loss: 198.3501\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3947 - val_loss: 136.5084\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2566 - val_loss: 139.5265\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.1091 - val_loss: 190.3664\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.2055 - val_loss: 150.1204\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.5868 - val_loss: 174.7597\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6068 - val_loss: 266.4546\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2096 - val_loss: 167.5736\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.3807 - val_loss: 147.7846\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.5283 - val_loss: 140.5768\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9931 - val_loss: 140.7844\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3862 - val_loss: 144.0568\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.8804 - val_loss: 161.5867\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.0514 - val_loss: 202.3330\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3976 - val_loss: 144.6272\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3527 - val_loss: 141.5967\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2326 - val_loss: 134.1573\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0080 - val_loss: 152.2162\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5585 - val_loss: 196.2859\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8100 - val_loss: 139.1884\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.4674 - val_loss: 139.0299\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0550 - val_loss: 135.4049\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8004 - val_loss: 186.6715\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4797 - val_loss: 279.6899\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.7133 - val_loss: 148.6181\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7297 - val_loss: 161.5853\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7939 - val_loss: 154.6019\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6924 - val_loss: 144.9567\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4678 - val_loss: 148.8091\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5665 - val_loss: 135.1421\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.2856 - val_loss: 133.1595\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6615 - val_loss: 146.8785\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3651 - val_loss: 137.6648\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9581 - val_loss: 153.2321\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9542 - val_loss: 135.8179\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.7108 - val_loss: 129.8311\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.3663 - val_loss: 143.1278\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 140.1660 - val_loss: 154.3788\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5096 - val_loss: 151.3942\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5556 - val_loss: 162.6528\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.8771 - val_loss: 160.9079\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7590 - val_loss: 250.3707\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.1233 - val_loss: 227.0372\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.2869 - val_loss: 201.4094\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.3552 - val_loss: 140.5189\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.1304 - val_loss: 141.3974\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5510 - val_loss: 160.6020\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0107 - val_loss: 179.1384\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.0197 - val_loss: 165.2957\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3880 - val_loss: 167.8398\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.6409 - val_loss: 196.2233\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0251 - val_loss: 136.8456\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 138.3575 - val_loss: 141.1921\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.1547 - val_loss: 177.2058\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5121 - val_loss: 161.3000\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.0253 - val_loss: 134.2831\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4756 - val_loss: 134.9248\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0950 - val_loss: 140.5678\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8622 - val_loss: 141.8047\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.2870 - val_loss: 134.9719\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1370 - val_loss: 129.4853\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 143.0267 - val_loss: 169.8180\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.0608 - val_loss: 135.4518\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.8882 - val_loss: 130.1369\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 140.4183 - val_loss: 138.5501\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.8781 - val_loss: 203.2871\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.4822 - val_loss: 147.1146\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9805 - val_loss: 138.3124\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.6406 - val_loss: 164.5193\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5850 - val_loss: 135.9730\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8724 - val_loss: 142.6207\n",
      "Epoch 1887/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0745 - val_loss: 130.4857\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0880 - val_loss: 135.8555\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.3885 - val_loss: 137.4787\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9153 - val_loss: 146.8208\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0230 - val_loss: 139.3256\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 244.2228 - val_loss: 174.8773\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0194 - val_loss: 136.6245\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.9620 - val_loss: 148.0732\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4537 - val_loss: 132.9774\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.9312 - val_loss: 239.1422\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 121.696 - 0s 51us/step - loss: 121.1717 - val_loss: 179.9467\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2050 - val_loss: 136.1082\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8855 - val_loss: 174.4328\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.0371 - val_loss: 167.7509\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.9274 - val_loss: 164.5118\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2254 - val_loss: 170.9313\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.3845 - val_loss: 143.9364\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 146.5109 - val_loss: 308.2594\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.6054 - val_loss: 190.8429\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3504 - val_loss: 153.3558\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.7480 - val_loss: 136.4245\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5652 - val_loss: 190.4797\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5727 - val_loss: 136.1568\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9205 - val_loss: 139.1793\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3204 - val_loss: 133.7412\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9622 - val_loss: 159.9539\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.4597 - val_loss: 142.9479\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1203 - val_loss: 148.9733\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6940 - val_loss: 162.6720\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.1855 - val_loss: 132.4222\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0627 - val_loss: 200.6914\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.8354 - val_loss: 202.5505\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9637 - val_loss: 132.0052\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.7519 - val_loss: 146.6336\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7630 - val_loss: 138.7971\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.0541 - val_loss: 146.1475\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6972 - val_loss: 134.0547\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0920 - val_loss: 159.6904\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0341 - val_loss: 140.8691\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.2169 - val_loss: 150.3706\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6389 - val_loss: 132.3533\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5028 - val_loss: 233.6900\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0649 - val_loss: 132.1717\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.2305 - val_loss: 129.4413\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7202 - val_loss: 155.1587\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6396 - val_loss: 133.6087\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.1122 - val_loss: 138.3203\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2371 - val_loss: 134.8564\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5219 - val_loss: 136.7379\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5751 - val_loss: 189.8731\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4741 - val_loss: 136.9963\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.4592 - val_loss: 162.7446\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9602 - val_loss: 167.7226\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0149 - val_loss: 158.3995\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.8813 - val_loss: 189.6339\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7591 - val_loss: 134.8937\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8107 - val_loss: 149.4917\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7834 - val_loss: 149.3345\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5337 - val_loss: 141.4781\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.8475 - val_loss: 139.6447\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8101 - val_loss: 146.4153\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.9162 - val_loss: 167.0798\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1671 - val_loss: 139.9831\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.6731 - val_loss: 171.4516\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7506 - val_loss: 131.3594\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4510 - val_loss: 158.4229\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 127.1811 - val_loss: 134.8833\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.1589 - val_loss: 152.6139\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5750 - val_loss: 179.3784\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.998 - 0s 50us/step - loss: 132.3321 - val_loss: 204.2176\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 278.5747 - val_loss: 149.4139\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 134.683 - 0s 51us/step - loss: 134.4709 - val_loss: 134.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0819 - val_loss: 133.1702\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 114.9810 - val_loss: 131.2697\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 120.7737 - val_loss: 140.9378\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 121.8092 - val_loss: 130.1346\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.5860 - val_loss: 130.0460\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5438 - val_loss: 152.3231\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.2142 - val_loss: 135.6211\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4527 - val_loss: 134.8220\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5555 - val_loss: 131.1633\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.3265 - val_loss: 144.0811\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4344 - val_loss: 144.2805\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.4524 - val_loss: 147.9198\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3418 - val_loss: 141.8553\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.6759 - val_loss: 146.3574\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.9659 - val_loss: 142.4496\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8541 - val_loss: 136.3492\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.0672 - val_loss: 134.1547\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4602 - val_loss: 151.4690\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.4659 - val_loss: 134.5411\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4138 - val_loss: 189.8314\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.8262 - val_loss: 236.1114\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8066 - val_loss: 137.2791\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3498 - val_loss: 148.8538\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.9707 - val_loss: 206.1495\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1612 - val_loss: 147.6777\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0399 - val_loss: 141.7853\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2032 - val_loss: 139.3018\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6521 - val_loss: 137.6554\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.5458 - val_loss: 171.3234\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.2214 - val_loss: 135.6619\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.6905 - val_loss: 160.0639\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7361 - val_loss: 149.1369\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9924 - val_loss: 132.6544\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1356 - val_loss: 162.1058\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 194.9133 - val_loss: 238.9402\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3149 - val_loss: 177.3695\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5232 - val_loss: 142.0181\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9012 - val_loss: 258.0404\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.8648 - val_loss: 137.9928\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5145 - val_loss: 133.7967\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.8030 - val_loss: 140.4532\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7885 - val_loss: 154.3442\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1090 - val_loss: 141.5217\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2403 - val_loss: 132.2315\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1669 - val_loss: 142.9821\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5084 - val_loss: 145.4535\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7648 - val_loss: 151.1224\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2470 - val_loss: 139.8025\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.4079 - val_loss: 199.2220\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6919 - val_loss: 142.1533\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.9460 - val_loss: 164.7944\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.0044 - val_loss: 162.0951\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5474 - val_loss: 134.1189\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.9503 - val_loss: 142.9758\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3259 - val_loss: 139.7311\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.9898 - val_loss: 169.0016\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.2248 - val_loss: 185.5929\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7646 - val_loss: 152.7440\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0832 - val_loss: 137.0475TA: 0s - loss: 112\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6622 - val_loss: 137.6144\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5783 - val_loss: 146.7845\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3376 - val_loss: 145.4167\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.9462 - val_loss: 145.0979\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4659 - val_loss: 206.8937\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 127.9445 - val_loss: 148.2722\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 233.7701 - val_loss: 139.4141\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 119.1978 - val_loss: 138.0081\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.8629 - val_loss: 136.7905\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.1594 - val_loss: 135.3522\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.4061 - val_loss: 138.0975\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.3879 - val_loss: 169.8765\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8998 - val_loss: 130.5856\n",
      "Epoch 2031/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9581 - val_loss: 136.3948\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.5328 - val_loss: 148.3099\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.4376 - val_loss: 156.1255\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.7038 - val_loss: 137.8990\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.0065 - val_loss: 133.7356\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.7749 - val_loss: 133.5197\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.9516 - val_loss: 200.7001\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1919 - val_loss: 130.4979\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.6059 - val_loss: 178.7022\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.8642 - val_loss: 134.8620\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1690 - val_loss: 223.2066\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.5448 - val_loss: 135.7881\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6172 - val_loss: 143.3067\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.3747 - val_loss: 168.6546\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7229 - val_loss: 137.0417\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1096 - val_loss: 127.3438\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3617 - val_loss: 179.4463\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.1821 - val_loss: 148.3364\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6893 - val_loss: 144.0317\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.2978 - val_loss: 141.8518\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.8674 - val_loss: 139.3090\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.5713 - val_loss: 154.3638\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.7609 - val_loss: 130.4802\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7196 - val_loss: 159.5990\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.9250 - val_loss: 183.1211\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9121 - val_loss: 135.2008\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.6801 - val_loss: 135.7468\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5273 - val_loss: 130.5461\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.3877 - val_loss: 142.3720\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3313 - val_loss: 140.9518\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0917 - val_loss: 149.4226\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.7962 - val_loss: 144.8552\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0944 - val_loss: 129.1274\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.5317 - val_loss: 135.6002\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.2886 - val_loss: 155.3856\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1364 - val_loss: 171.1791\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 131.8975 - val_loss: 149.6235\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1837 - val_loss: 149.5530\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7257 - val_loss: 141.1733\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9929 - val_loss: 131.0137\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2321 - val_loss: 142.8102\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.2361 - val_loss: 134.1443\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3985 - val_loss: 144.6216\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.6351 - val_loss: 210.5527\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7453 - val_loss: 197.6016\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.4621 - val_loss: 132.0550\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.1352 - val_loss: 146.2097\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6632 - val_loss: 134.1286\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.5476 - val_loss: 138.4391\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5036 - val_loss: 140.6017\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.5474 - val_loss: 225.5126\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7605 - val_loss: 209.2445\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.9223 - val_loss: 190.6061\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1275 - val_loss: 146.4805\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4107 - val_loss: 317.7263\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6643 - val_loss: 138.3684\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.9125 - val_loss: 133.1941\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.6041 - val_loss: 148.5075\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.2079 - val_loss: 175.6855\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7239 - val_loss: 172.2759\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.7828 - val_loss: 131.8060\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0277 - val_loss: 136.9623\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8779 - val_loss: 131.4628\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.2260 - val_loss: 199.2998\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.0904 - val_loss: 130.0160\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.7550 - val_loss: 223.0727\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 135.9691 - val_loss: 134.9913\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.1695 - val_loss: 143.0457\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.9861 - val_loss: 144.2326\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2049 - val_loss: 139.8342\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.5351 - val_loss: 131.9916\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8894 - val_loss: 144.1767\n",
      "Epoch 2103/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.3542 - val_loss: 166.7683\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.2058 - val_loss: 141.0931\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4611 - val_loss: 129.5643\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.3513 - val_loss: 136.2574\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.4806 - val_loss: 184.5668\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9398 - val_loss: 130.6903\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.9774 - val_loss: 141.9650\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3679 - val_loss: 158.6454\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.2059 - val_loss: 162.6223\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.3854 - val_loss: 140.4693\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.3797 - val_loss: 145.9996\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.1898 - val_loss: 138.5477\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.7305 - val_loss: 152.9967\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7783 - val_loss: 143.1267\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6427 - val_loss: 153.3559\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6372 - val_loss: 131.2513\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7616 - val_loss: 183.5229\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5837 - val_loss: 174.1453\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3478 - val_loss: 144.8876\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5297 - val_loss: 164.0682\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.7319 - val_loss: 138.2023\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7164 - val_loss: 138.4361\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0271 - val_loss: 134.6205\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0843 - val_loss: 163.9788\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.9139 - val_loss: 157.2373\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.4472 - val_loss: 164.5010\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8702 - val_loss: 131.7868\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1970 - val_loss: 137.0493\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.5238 - val_loss: 140.5513\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2660 - val_loss: 155.0160\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6111 - val_loss: 140.1451\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8403 - val_loss: 132.2230\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0124 - val_loss: 141.9055\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0825 - val_loss: 156.7782\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.8848 - val_loss: 147.7235\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.0181 - val_loss: 135.6464\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.0055 - val_loss: 175.6299\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 235.3087 - val_loss: 153.1252\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2972 - val_loss: 131.2297\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1392 - val_loss: 137.9975\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.2388 - val_loss: 134.1195\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.1619 - val_loss: 133.5961\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.2720 - val_loss: 170.3504\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.2725 - val_loss: 134.5095\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.3508 - val_loss: 139.9371\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6390 - val_loss: 173.3905\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.3325 - val_loss: 134.0010\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2499 - val_loss: 138.1555\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.6160 - val_loss: 184.4566\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.4449 - val_loss: 212.6604\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6455 - val_loss: 146.6096\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8986 - val_loss: 153.1352\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.0066 - val_loss: 184.5034\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5580 - val_loss: 165.8568\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.4046 - val_loss: 152.4141\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9623 - val_loss: 247.6242\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3785 - val_loss: 164.2884\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.0541 - val_loss: 142.2435\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.5576 - val_loss: 129.3277\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3552 - val_loss: 136.8247\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.5637 - val_loss: 141.1301\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.4213 - val_loss: 144.7836\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.8530 - val_loss: 143.4178\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6497 - val_loss: 168.3757\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.6602 - val_loss: 140.4033\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4709 - val_loss: 249.8060\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 128.2991 - val_loss: 172.6226\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.7694 - val_loss: 190.5677\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 119.0154 - val_loss: 152.4230\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.4756 - val_loss: 130.6818\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8713 - val_loss: 183.9594\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8229 - val_loss: 144.1251ETA: 0s - loss: 11\n",
      "Epoch 2175/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0651 - val_loss: 178.3346\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6648 - val_loss: 187.0638\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6899 - val_loss: 172.0011\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.7733 - val_loss: 137.4871\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.1238 - val_loss: 142.5912\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1796 - val_loss: 130.3368\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7381 - val_loss: 152.5183\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.0309 - val_loss: 156.7126\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4260 - val_loss: 178.9637\n",
      "Epoch 02183: early stopping\n",
      "Fold score (RMSE): 13.351117134094238\n",
      "Fold #2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 4871.1075 - val_loss: 4879.3216\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4466.1275 - val_loss: 4626.6440\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4166.4021 - val_loss: 4537.5364\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4043.2461 - val_loss: 4302.1919\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3920.3382 - val_loss: 4169.9848\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3791.7176 - val_loss: 4556.8795\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3750.3752 - val_loss: 4163.8727\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3652.3660 - val_loss: 4158.4416\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3437.7061 - val_loss: 3522.5838\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 3271.4941 - val_loss: 4891.1849\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3378.2890 - val_loss: 3052.2052\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3138.0979 - val_loss: 3258.6033\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 2738.3942 - val_loss: 2273.2253\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 2262.7094 - val_loss: 1939.8906\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 2393.5179 - val_loss: 2149.4672\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1943.7128 - val_loss: 1787.7820\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1521.3218 - val_loss: 1436.7757\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1074.8992 - val_loss: 887.5979\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1156.1710 - val_loss: 1565.1337\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1070.9465 - val_loss: 503.5126\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 868.3877 - val_loss: 508.2202\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 725.0469 - val_loss: 570.6136\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 739.9207 - val_loss: 485.4588\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 623.2916 - val_loss: 397.6610\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 596.1733 - val_loss: 551.6739\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 713.5455 - val_loss: 384.1273\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 518.9948 - val_loss: 362.8915\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 542.1394 - val_loss: 351.1310\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 547.4926 - val_loss: 566.1623\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 528.1471 - val_loss: 765.0096\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 690.8656 - val_loss: 455.7972\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 668.8071 - val_loss: 845.2880\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 505.4198 - val_loss: 329.6746\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 546.9494 - val_loss: 609.2151\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 545.2769 - val_loss: 289.2516\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 455.4731 - val_loss: 376.1532\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 534.0894 - val_loss: 524.8699\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 460.9006 - val_loss: 283.4761\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 479.8888 - val_loss: 286.0722\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 399.2245 - val_loss: 342.6841\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 469.9123 - val_loss: 307.5072\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 381.4386 - val_loss: 336.3353\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 447.2411 - val_loss: 502.5761\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 437.0314 - val_loss: 800.0430\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 395.6440 - val_loss: 256.1284\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 411.3239 - val_loss: 418.6623\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 359.8516 - val_loss: 257.5505\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 375.8394 - val_loss: 378.0120\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 337.8247 - val_loss: 319.3051\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 560.7390 - val_loss: 316.9309\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 417.9010 - val_loss: 281.6713\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 371.5265 - val_loss: 356.7425\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 379.9765 - val_loss: 1212.0492\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 396.6265 - val_loss: 279.6400\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 352.9542 - val_loss: 265.4318\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 328.4425 - val_loss: 232.0867\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 356.1367 - val_loss: 418.8702\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 323.7869 - val_loss: 445.3969\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 321.2943 - val_loss: 221.5196\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 485.5268 - val_loss: 438.9246\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 311.2725 - val_loss: 243.9307\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 401.9279 - val_loss: 247.6775\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 367.0767 - val_loss: 222.9120\n",
      "Epoch 64/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 340.4349 - val_loss: 336.8147\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 288.8939 - val_loss: 535.5369\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 409.0603 - val_loss: 260.8138\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 292.2141 - val_loss: 262.5049\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 327.3969 - val_loss: 396.7557\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 278.2972 - val_loss: 276.8203\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 315.4361 - val_loss: 229.1026\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 286.0007 - val_loss: 224.7847\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 286.5522 - val_loss: 528.4958\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 308.7719 - val_loss: 351.2320\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 356.5174 - val_loss: 312.9162\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 358.1937 - val_loss: 336.5895\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 379.6452 - val_loss: 408.4893\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 338.7050 - val_loss: 245.9977\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 265.284 - 0s 51us/step - loss: 265.4374 - val_loss: 658.4759\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 306.5737 - val_loss: 331.4444\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 293.7479 - val_loss: 221.2812\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.5715 - val_loss: 268.9204\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.5512 - val_loss: 214.6456\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 384.5109 - val_loss: 308.3702\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 275.1048 - val_loss: 215.7854\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 444.0477 - val_loss: 199.8337\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.2243 - val_loss: 328.0959\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 288.2567 - val_loss: 228.9375\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.4877 - val_loss: 194.3539\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 314.9457 - val_loss: 336.5266\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 298.1937 - val_loss: 262.9445\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 243.9209 - val_loss: 196.9115\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 273.9714 - val_loss: 271.6376\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.6606 - val_loss: 221.1173\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 324.1648 - val_loss: 895.9573\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 279.0068 - val_loss: 222.4474\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 272.9417 - val_loss: 1784.8712\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 421.2279 - val_loss: 281.4462\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.7884 - val_loss: 233.7357\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 344.5268 - val_loss: 225.9528\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 362.7208 - val_loss: 210.7514\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.8357 - val_loss: 224.3168\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 291.7508 - val_loss: 268.6872\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.3118 - val_loss: 178.5108\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 242.7969 - val_loss: 192.7218\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 291.0977 - val_loss: 247.3219\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.8517 - val_loss: 195.9892\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 261.6222 - val_loss: 197.1113\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 381.3493 - val_loss: 431.4422\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.2162 - val_loss: 187.7508\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 368.1237 - val_loss: 175.5349\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 269.9465 - val_loss: 444.6205\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.4413 - val_loss: 317.3104\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 263.7646 - val_loss: 272.8847\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 255.2657 - val_loss: 213.1464\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.7075 - val_loss: 234.2902\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 277.5178 - val_loss: 243.6977\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 345.4128 - val_loss: 195.3460\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 261.3600 - val_loss: 169.4337\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 325.0467 - val_loss: 420.9891\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 281.8320 - val_loss: 242.0299\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 308.6182 - val_loss: 918.6107\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 245.3307 - val_loss: 165.1581\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 240.8385 - val_loss: 159.4084\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 391.0698 - val_loss: 238.6292\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 307.3842 - val_loss: 419.2519\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 257.3494 - val_loss: 194.5407\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 240.4105 - val_loss: 220.9699\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 346.6076 - val_loss: 231.3620\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 205.0329 - val_loss: 253.7175\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.2504 - val_loss: 214.9504\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.1910 - val_loss: 171.4007\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.6717 - val_loss: 198.1079\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 260.0204 - val_loss: 516.5030\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 370.1471 - val_loss: 209.1634\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.0825 - val_loss: 179.5506\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 233.6358 - val_loss: 169.1487\n",
      "Epoch 137/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 267.2128 - val_loss: 235.5446\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.1790 - val_loss: 196.2343\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.7051 - val_loss: 183.5647\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.7441 - val_loss: 161.8047\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 203.151 - 0s 50us/step - loss: 202.8834 - val_loss: 179.8847\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 285.5705 - val_loss: 203.4984\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.9966 - val_loss: 203.3650\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.3090 - val_loss: 254.5081\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.2251 - val_loss: 627.3980\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 225.0827 - val_loss: 708.8168\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 263.0259 - val_loss: 188.2713\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.5920 - val_loss: 255.2862\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 287.2162 - val_loss: 275.5648\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.0877 - val_loss: 161.8012\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 349.2646 - val_loss: 207.4381\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.3544 - val_loss: 228.6930\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.4041 - val_loss: 179.6595\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.9279 - val_loss: 163.8019\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.8272 - val_loss: 203.6498\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.1117 - val_loss: 578.0417\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.9283 - val_loss: 205.9883\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 272.0233 - val_loss: 189.9193\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.6249 - val_loss: 178.4018\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 292.7143 - val_loss: 187.9426\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.5950 - val_loss: 266.9290\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 200.496 - 0s 50us/step - loss: 198.4503 - val_loss: 153.7981\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.4495 - val_loss: 231.6161\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.3028 - val_loss: 251.9488\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.2229 - val_loss: 438.5675\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 214.5982 - val_loss: 289.7149\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.7952 - val_loss: 538.3416\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.1570 - val_loss: 327.4663\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.0193 - val_loss: 203.0827\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.2096 - val_loss: 248.0065\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.4607 - val_loss: 176.0325\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.8088 - val_loss: 150.5327\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9421 - val_loss: 189.0016\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.1990 - val_loss: 261.3120\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.0212 - val_loss: 204.0257\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 390.6110 - val_loss: 413.3886\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.3880 - val_loss: 207.4762\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.3577 - val_loss: 190.1988\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 217.4085 - val_loss: 323.6493\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.5883 - val_loss: 148.2349\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.8178 - val_loss: 549.8998\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 377.2638 - val_loss: 754.2226\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 372.3260 - val_loss: 251.1363\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.4074 - val_loss: 174.3472\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.5323 - val_loss: 192.9989\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 254.3151 - val_loss: 372.8144\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 279.9280 - val_loss: 158.8161\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 210.1823 - val_loss: 380.9680\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 365.4692 - val_loss: 394.4204\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 274.6378 - val_loss: 163.9064\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.2810 - val_loss: 155.6999\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.1791 - val_loss: 204.6033\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.6481 - val_loss: 145.0691\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.2954 - val_loss: 170.5319\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 343.3651 - val_loss: 559.8572\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.8566 - val_loss: 205.3842\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.1253 - val_loss: 286.5933\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 239.5560 - val_loss: 155.8733\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 207.4177 - val_loss: 217.1244\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 238.3733 - val_loss: 284.6462\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 304.2680 - val_loss: 326.4208\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.7271 - val_loss: 177.2342\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.0627 - val_loss: 152.7012\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.8802 - val_loss: 185.9367\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.7191 - val_loss: 168.3410\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.0033 - val_loss: 185.7767\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 229.0700 - val_loss: 164.5447\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.0808 - val_loss: 261.3012\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.1661 - val_loss: 174.4784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.5283 - val_loss: 170.8156\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.2717 - val_loss: 154.2409\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.1099 - val_loss: 153.2683\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1129 - val_loss: 170.3895\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.6580 - val_loss: 202.0578\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.0828 - val_loss: 144.6553\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.4348 - val_loss: 179.8127\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.9901 - val_loss: 153.4531\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.8916 - val_loss: 178.1740\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 586.1470 - val_loss: 357.9801\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.8822 - val_loss: 200.0027\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.8127 - val_loss: 251.6485\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.3415 - val_loss: 644.4397\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.9131 - val_loss: 195.7569\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.1229 - val_loss: 287.5068\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 250.7175 - val_loss: 335.0506\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3239 - val_loss: 155.0500\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6344 - val_loss: 162.3677\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.8077 - val_loss: 148.0946\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.6951 - val_loss: 161.5730\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.2751 - val_loss: 314.4729\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 283.9665 - val_loss: 224.3660\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.6435 - val_loss: 186.8082\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.7657 - val_loss: 398.4566\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.5357 - val_loss: 296.6565\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 289.3646 - val_loss: 1618.6777\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.1512 - val_loss: 152.4389\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.9890 - val_loss: 158.4696\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2399 - val_loss: 250.0160\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3803 - val_loss: 278.2792\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.8343 - val_loss: 159.7928\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.1128 - val_loss: 147.2094\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 870.8097 - val_loss: 685.8039\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 533.9843 - val_loss: 448.9857\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 452.2045 - val_loss: 234.3059\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 341.6364 - val_loss: 318.4932\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 360.1004 - val_loss: 441.5280\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 256.145 - 0s 50us/step - loss: 257.9963 - val_loss: 289.4182\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.5825 - val_loss: 181.2926\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 264.8471 - val_loss: 378.5175\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 293.9929 - val_loss: 210.4960\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 246.7744 - val_loss: 179.1645\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.4976 - val_loss: 315.1060\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 297.8048 - val_loss: 347.5978\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 244.4882 - val_loss: 209.3366\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 203.0749 - val_loss: 160.3511\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.9087 - val_loss: 363.9688\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 256.3435 - val_loss: 365.7859\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.9350 - val_loss: 195.3308\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.3695 - val_loss: 260.8928\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 223.5640 - val_loss: 207.5304\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.5040 - val_loss: 272.5435\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.3905 - val_loss: 440.6443\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.8936 - val_loss: 198.5361\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.1707 - val_loss: 158.2923\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 254.7054 - val_loss: 154.5430\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 229.0659 - val_loss: 275.8395\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 220.2537 - val_loss: 241.6328\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.1069 - val_loss: 184.0029\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.8060 - val_loss: 267.1576\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 205.2063 - val_loss: 339.2479\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 239.9028 - val_loss: 331.2344\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 201.1455 - val_loss: 176.2490\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.9104 - val_loss: 153.5167\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.9721 - val_loss: 283.8922\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 298.7942 - val_loss: 165.4208\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.0554 - val_loss: 197.6808\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.5909 - val_loss: 184.6000\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.2890 - val_loss: 197.7212\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 197.5340 - val_loss: 194.8624\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.8194 - val_loss: 185.1045\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.7750 - val_loss: 286.8726\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.2088 - val_loss: 169.8657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.1371 - val_loss: 166.8441\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.7413 - val_loss: 152.1916\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.0732 - val_loss: 228.4295\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.5780 - val_loss: 152.3547\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 242.2205 - val_loss: 241.4919\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3908 - val_loss: 264.6319\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.0432 - val_loss: 179.7310\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.1415 - val_loss: 159.2902\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.3860 - val_loss: 187.1797\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.4505 - val_loss: 259.6824\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 206.6013 - val_loss: 160.8911\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.5852 - val_loss: 193.1053\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 252.4718 - val_loss: 215.0338\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.8470 - val_loss: 156.7883\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.8728 - val_loss: 196.1378\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 202.3710 - val_loss: 361.0593\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.4381 - val_loss: 147.0074\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.1664 - val_loss: 281.5434\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.4042 - val_loss: 376.1059\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 392.0953 - val_loss: 151.2642\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.7486 - val_loss: 183.0415\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.7124 - val_loss: 424.0059\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.6940 - val_loss: 159.3968\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.0177 - val_loss: 189.9318\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3393 - val_loss: 181.2501\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.5262 - val_loss: 239.4932\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.8167 - val_loss: 196.4827\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.9834 - val_loss: 159.2591\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.6602 - val_loss: 335.2387\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.8309 - val_loss: 172.0163\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 410.6279 - val_loss: 236.8324\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.9753 - val_loss: 143.7822\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.5404 - val_loss: 163.0092\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.1938 - val_loss: 156.8161\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4746 - val_loss: 141.6674\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.4860 - val_loss: 175.8916\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.7798 - val_loss: 156.9994\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 188.4096 - val_loss: 178.0619\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.3669 - val_loss: 156.3093\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.5442 - val_loss: 165.1591\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.4709 - val_loss: 149.3130\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.6021 - val_loss: 164.6207\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.1801 - val_loss: 143.8336\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.8954 - val_loss: 194.0799\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.0254 - val_loss: 177.8452\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.8006 - val_loss: 150.4806\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.6565 - val_loss: 139.5686\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.7511 - val_loss: 435.5691\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.9952 - val_loss: 142.0937\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.6868 - val_loss: 161.0012\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.5475 - val_loss: 255.9031\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 881.1860 - val_loss: 295.7176\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.1422 - val_loss: 300.6811\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.7813 - val_loss: 165.3141\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 247.1231 - val_loss: 186.5638\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3538 - val_loss: 166.0763\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.2878 - val_loss: 152.4470\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.3210 - val_loss: 151.6445\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2419 - val_loss: 149.6568\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 250.1591 - val_loss: 172.7924\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 172.6018 - val_loss: 152.4277\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 163.6599 - val_loss: 150.6126\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 169.9713 - val_loss: 148.8652\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.0999 - val_loss: 227.2219\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.2862 - val_loss: 180.9369\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.0564 - val_loss: 171.4419\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.7721 - val_loss: 563.4173\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.6549 - val_loss: 168.1325\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 254.0756 - val_loss: 208.6329\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.0211 - val_loss: 185.9574\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.4008 - val_loss: 288.5919\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.3880 - val_loss: 149.3925\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.5308 - val_loss: 338.7758\n",
      "Epoch 356/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9642 - val_loss: 171.0046\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3866 - val_loss: 141.1088\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 246.0883 - val_loss: 165.1080\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.4822 - val_loss: 143.9043\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 472.5741 - val_loss: 182.6176\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 243.8952 - val_loss: 626.8034\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 263.5391 - val_loss: 405.0977\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.8110 - val_loss: 155.7517\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1592 - val_loss: 155.5014\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.0063 - val_loss: 143.0050\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9715 - val_loss: 237.4515\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.4927 - val_loss: 154.8507\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.5381 - val_loss: 138.6018\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.4856 - val_loss: 152.2093\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 295.9808 - val_loss: 233.4168\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 235.4056 - val_loss: 198.2510\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.2570 - val_loss: 195.8296\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.7119 - val_loss: 226.4619\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.3520 - val_loss: 199.9396\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.1358 - val_loss: 204.2143\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.1731 - val_loss: 166.0537\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.9317 - val_loss: 176.0462\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.1975 - val_loss: 404.4843\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.8537 - val_loss: 197.5896\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.1745 - val_loss: 189.5001\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.1455 - val_loss: 263.4754\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8726 - val_loss: 195.8709\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 199.2321 - val_loss: 160.9147\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7239 - val_loss: 168.4972\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1144 - val_loss: 289.0207\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.6445 - val_loss: 148.0743\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.5640 - val_loss: 154.8900\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.0625 - val_loss: 175.1293\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.0557 - val_loss: 147.8784\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 422.1121 - val_loss: 192.1140\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.9943 - val_loss: 141.3821\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5516 - val_loss: 145.6280\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1072 - val_loss: 175.4435\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9672 - val_loss: 141.7266\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 255.4252 - val_loss: 191.2972\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.4325 - val_loss: 153.6571\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.9470 - val_loss: 176.6615\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2421 - val_loss: 174.3449\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.0307 - val_loss: 199.8665\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 207.3792 - val_loss: 458.7353\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.0692 - val_loss: 144.0442\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.9190 - val_loss: 214.1098\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.3513 - val_loss: 209.0684\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7646 - val_loss: 158.9962\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.4682 - val_loss: 143.6227\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2832 - val_loss: 153.2443\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5102 - val_loss: 164.6091\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.0361 - val_loss: 265.3621\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5413 - val_loss: 179.3423\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 344.8162 - val_loss: 161.7583\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.5302 - val_loss: 152.0528\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.7377 - val_loss: 171.7646\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.3047 - val_loss: 178.0159\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 198.1368 - val_loss: 209.8727\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 185.7022 - val_loss: 142.2058\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 179.9495 - val_loss: 171.8566\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.0714 - val_loss: 166.1676\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.1705 - val_loss: 147.6829\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.4252 - val_loss: 182.6395\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.8969 - val_loss: 163.1026\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 236.7006 - val_loss: 304.3382\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.6278 - val_loss: 231.7518\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2919 - val_loss: 150.2782\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4264 - val_loss: 226.5913\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4935 - val_loss: 308.8871\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.7574 - val_loss: 1245.5208\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.1924 - val_loss: 226.9725\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5392 - val_loss: 147.2583\n",
      "Epoch 429/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.1969 - val_loss: 163.8019\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.7275 - val_loss: 164.4586\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3927 - val_loss: 170.9290ETA: 0s - loss: 12\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0327 - val_loss: 151.9150\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.0702 - val_loss: 203.3915\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.3121 - val_loss: 144.9793\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 462.4748 - val_loss: 295.3710\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 289.7428 - val_loss: 283.9373\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.1236 - val_loss: 157.7732\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.0828 - val_loss: 161.2097\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.1202 - val_loss: 159.3988\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.0446 - val_loss: 146.4685\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5878 - val_loss: 152.6555\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 192.8390 - val_loss: 178.6534\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.9169 - val_loss: 173.6556\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.5955 - val_loss: 176.2065\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.8303 - val_loss: 340.4864\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.7427 - val_loss: 154.0348\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2977 - val_loss: 149.2714\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 151.2789 - val_loss: 159.0607\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.0659 - val_loss: 182.1331\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.8943 - val_loss: 174.1071\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2813 - val_loss: 163.8216\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.6577 - val_loss: 449.2806\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.7905 - val_loss: 143.4734\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5117 - val_loss: 157.7783\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5391 - val_loss: 142.1440\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2013 - val_loss: 153.1349\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.6816 - val_loss: 195.3561\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.3595 - val_loss: 146.7303\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.9737 - val_loss: 260.0763\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.0358 - val_loss: 149.1923\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.3858 - val_loss: 164.1036\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.1777 - val_loss: 153.1356\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 265.2483 - val_loss: 291.9943\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 182.2496 - val_loss: 142.5754\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.8209 - val_loss: 163.4971\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.7820 - val_loss: 154.9139\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4632 - val_loss: 171.3127\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.6783 - val_loss: 186.8413\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.8298 - val_loss: 151.8559\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.5614 - val_loss: 188.5950\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.3588 - val_loss: 211.0492\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 144.4968 - val_loss: 227.8897\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9170 - val_loss: 147.4219\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.6353 - val_loss: 186.2804\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3991 - val_loss: 198.5166\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 346.3671 - val_loss: 195.8752\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.2945 - val_loss: 144.8469\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4774 - val_loss: 160.5384\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6848 - val_loss: 250.2704\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.3509 - val_loss: 210.7808\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.9534 - val_loss: 223.4956\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.3242 - val_loss: 180.9680\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.0387 - val_loss: 268.4406\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8747 - val_loss: 155.2723\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.4472 - val_loss: 181.1043\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.2685 - val_loss: 142.7514\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1846 - val_loss: 140.7632\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5703 - val_loss: 144.3355\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 442.8233 - val_loss: 241.4728\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.6734 - val_loss: 154.1635\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.5917 - val_loss: 227.1029\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0788 - val_loss: 154.0982\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3072 - val_loss: 143.1694\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.4075 - val_loss: 159.7587\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.0319 - val_loss: 147.5423\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 149.4791 - val_loss: 137.9178\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 167.7177 - val_loss: 209.5713\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 173.8988 - val_loss: 153.0395\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.3735 - val_loss: 194.9960\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1291 - val_loss: 153.1483\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.0048 - val_loss: 159.7436\n",
      "Epoch 502/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.7556 - val_loss: 191.4673\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 295.4530 - val_loss: 144.1580\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 187.6290 - val_loss: 166.2835\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.7870 - val_loss: 156.6090\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 254.7455 - val_loss: 190.0173\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7716 - val_loss: 152.1248\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.0389 - val_loss: 170.4402\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.9577 - val_loss: 143.5764\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6191 - val_loss: 137.4159\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 160.5027 - val_loss: 200.2776\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 152.5377 - val_loss: 154.2720\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 157.9437 - val_loss: 137.3181\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 355.1503 - val_loss: 167.8271\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 158.7532 - val_loss: 150.2812\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 158.4322 - val_loss: 433.4359\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 172.4849 - val_loss: 161.6837\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.1126 - val_loss: 159.0269\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 170.4736 - val_loss: 147.4880\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 225.7243 - val_loss: 164.6707\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 219.6764 - val_loss: 155.8784\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 200.0536 - val_loss: 146.0133\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 358.7047 - val_loss: 380.5476\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.8796 - val_loss: 170.3792\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.7997 - val_loss: 157.1047\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 154.1146 - val_loss: 167.2551\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 143.7990 - val_loss: 165.8412\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 151.4701 - val_loss: 167.4020\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 155.6611 - val_loss: 141.8197\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 161.0563 - val_loss: 139.2872\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.4164 - val_loss: 137.2917\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.4220 - val_loss: 176.0791\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 257.3402 - val_loss: 181.7126\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 166.0832 - val_loss: 155.0389\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 158.1860 - val_loss: 180.1499\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 182.6408 - val_loss: 198.1074\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 174.9848 - val_loss: 166.0019\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 161.9570 - val_loss: 180.6405\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 155.1384 - val_loss: 143.3256\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 171.9994 - val_loss: 207.0473\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.0728 - val_loss: 151.5098\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 351.7482 - val_loss: 191.0262\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 279.4768 - val_loss: 228.5391\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 147.3331 - val_loss: 150.3282\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.8670 - val_loss: 214.7457\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.4734 - val_loss: 141.4237\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 126.5421 - val_loss: 150.5280\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.4972 - val_loss: 145.0295\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 138.9559 - val_loss: 139.4958\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 148.8512 - val_loss: 184.3410\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 136.0227 - val_loss: 257.2959\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 152.4247 - val_loss: 151.5385\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 160.0193 - val_loss: 196.3210\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 259.3612 - val_loss: 169.7111\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 155.4465 - val_loss: 170.6580\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 179.7550 - val_loss: 137.8641\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 159.7776 - val_loss: 151.1020\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 165.6300 - val_loss: 207.7104\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 146.1804 - val_loss: 205.7393\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 142.4728 - val_loss: 195.1133\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 202.0234 - val_loss: 146.3745\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.9797 - val_loss: 209.7067\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8602 - val_loss: 226.0349\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 270.0229 - val_loss: 185.3023\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.7080 - val_loss: 214.6287\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0439 - val_loss: 175.9859\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6061 - val_loss: 181.4359\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.1520 - val_loss: 278.4844\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.8573 - val_loss: 138.1158\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.1638 - val_loss: 163.2257\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0074 - val_loss: 146.9967\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0372 - val_loss: 145.7108\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0651 - val_loss: 148.7978\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.2436 - val_loss: 138.1918\n",
      "Epoch 575/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.2597 - val_loss: 169.3680\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9339 - val_loss: 151.0494\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.8957 - val_loss: 161.3479\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 258.9369 - val_loss: 146.9761\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2134 - val_loss: 155.7124\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7742 - val_loss: 149.4698\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5876 - val_loss: 139.1020\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.5446 - val_loss: 159.1343\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 228.9767 - val_loss: 256.1531\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.6663 - val_loss: 156.7395\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.6711 - val_loss: 189.0632\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.5634 - val_loss: 294.0274\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2354 - val_loss: 139.4941\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1603 - val_loss: 352.8084\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4711 - val_loss: 146.1014\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.5284 - val_loss: 194.8763\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.2108 - val_loss: 144.7693\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.6944 - val_loss: 201.7645\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6873 - val_loss: 148.1003\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7694 - val_loss: 133.9067\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.8537 - val_loss: 166.8954\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4776 - val_loss: 171.1794\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2258 - val_loss: 188.3132\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8563 - val_loss: 320.6592\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 242.3133 - val_loss: 158.4464\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.5099 - val_loss: 186.7134\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 235.5113 - val_loss: 149.5012\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6818 - val_loss: 154.0860\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.9786 - val_loss: 175.0805\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 150.7825 - val_loss: 158.3036\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.3614 - val_loss: 163.9315\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5076 - val_loss: 218.0948\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4418 - val_loss: 269.9843\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1938 - val_loss: 161.1374\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.4165 - val_loss: 163.4738\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0142 - val_loss: 137.7058\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6497 - val_loss: 163.0017\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.1212 - val_loss: 162.2190\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.9673 - val_loss: 312.6047\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 299.6797 - val_loss: 172.4541\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.7216 - val_loss: 138.0170\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 129.6000 - val_loss: 164.3616\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 141.0549 - val_loss: 138.8209\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 347.1204 - val_loss: 146.3696\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 133.6680 - val_loss: 143.0294\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 235.9149 - val_loss: 144.2763\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.0506 - val_loss: 158.5162\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.8245 - val_loss: 195.3602\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2626 - val_loss: 133.5013\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4624 - val_loss: 144.3384\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0176 - val_loss: 167.8174\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.4591 - val_loss: 161.5856\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.8869 - val_loss: 143.9721\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.4681 - val_loss: 148.0335\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8864 - val_loss: 138.8583\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0298 - val_loss: 262.2004\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 239.1105 - val_loss: 472.0820\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 181.5857 - val_loss: 160.3154\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7296 - val_loss: 144.0115\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9741 - val_loss: 136.2310\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3142 - val_loss: 169.1203\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0175 - val_loss: 137.1500\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.1244 - val_loss: 158.7232\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 136.9286 - val_loss: 168.7074\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.8288 - val_loss: 146.3804\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0746 - val_loss: 139.0565\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.7811 - val_loss: 145.0442\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3495 - val_loss: 178.9934\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.5764 - val_loss: 146.9088\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3172 - val_loss: 141.8777\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.7374 - val_loss: 171.5011\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9228 - val_loss: 204.5537\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6251 - val_loss: 138.9335\n",
      "Epoch 648/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9612 - val_loss: 195.3148\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4530 - val_loss: 149.6028\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 474.9894 - val_loss: 677.9653\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 300.2292 - val_loss: 147.4633\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.0618 - val_loss: 142.1905\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2978 - val_loss: 144.4166\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5508 - val_loss: 157.3556\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.1176 - val_loss: 181.9717\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.8060 - val_loss: 137.7965\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7629 - val_loss: 261.1134\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.7422 - val_loss: 144.4954\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.9947 - val_loss: 160.6196\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7154 - val_loss: 155.6321\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2182 - val_loss: 219.1770\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5922 - val_loss: 183.6139\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0668 - val_loss: 147.2922\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.0217 - val_loss: 176.4672\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4588 - val_loss: 334.5035\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1252 - val_loss: 141.0680\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0670 - val_loss: 151.5022\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 589.3545 - val_loss: 317.7647\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 290.0059 - val_loss: 170.6735\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.3773 - val_loss: 158.4347\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9581 - val_loss: 173.4579\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.4292 - val_loss: 154.0963\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9611 - val_loss: 159.0222\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.0349 - val_loss: 171.6980\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.0512 - val_loss: 154.6492\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.6910 - val_loss: 140.6560\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.3287 - val_loss: 145.5469\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.9590 - val_loss: 174.1575\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.5460 - val_loss: 153.2157\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0398 - val_loss: 140.9023\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.2819 - val_loss: 152.4596\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 238.1123 - val_loss: 207.4704\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.0344 - val_loss: 138.6907\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1636 - val_loss: 192.1000\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9325 - val_loss: 143.1930\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.5247 - val_loss: 144.3399\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 135.7342 - val_loss: 170.7045\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 179.923 - 1s 77us/step - loss: 175.4660 - val_loss: 180.7213\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 144.6499 - val_loss: 133.0702\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 172.5095 - val_loss: 152.9652\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0233 - val_loss: 146.7410\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.2713 - val_loss: 209.7510\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.3138 - val_loss: 892.5350\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.2271 - val_loss: 146.6841\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7574 - val_loss: 167.9956\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.7473 - val_loss: 179.7770\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8443 - val_loss: 162.4613\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1605 - val_loss: 225.8616\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.0359 - val_loss: 150.4766\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4920 - val_loss: 140.3090\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0775 - val_loss: 149.1248\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0504 - val_loss: 150.2294\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.0515 - val_loss: 211.0254\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3959 - val_loss: 162.8875\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3798 - val_loss: 149.2622\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.8850 - val_loss: 133.4649\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1701 - val_loss: 182.6754\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 363.8128 - val_loss: 148.8159\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.4825 - val_loss: 145.0917\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0384 - val_loss: 148.0028\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5603 - val_loss: 141.9265\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8413 - val_loss: 192.9435\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0272 - val_loss: 186.2335\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.7786 - val_loss: 149.6110\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.7927 - val_loss: 295.8037\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9050 - val_loss: 136.5360\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5398 - val_loss: 143.2777\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2570 - val_loss: 136.5012\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5663 - val_loss: 142.0312\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 289.3095 - val_loss: 188.3072\n",
      "Epoch 721/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.4934 - val_loss: 137.7918\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3498 - val_loss: 138.5713\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5141 - val_loss: 144.0457\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.5498 - val_loss: 140.1339\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8807 - val_loss: 148.7007\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.6162 - val_loss: 140.8399\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9032 - val_loss: 178.3348\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5510 - val_loss: 160.4717\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.2618 - val_loss: 553.8921\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 303.8112 - val_loss: 175.1250\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 250.8360 - val_loss: 179.6657\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.9998 - val_loss: 152.0007\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.0347 - val_loss: 143.4121\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4370 - val_loss: 145.1501\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.3088 - val_loss: 242.8443\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 150.1029 - val_loss: 141.1339\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 349.7084 - val_loss: 171.2460\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.3647 - val_loss: 265.9653\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.3180 - val_loss: 150.1637\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.9995 - val_loss: 193.8207\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 169.786 - 0s 50us/step - loss: 170.0795 - val_loss: 232.1067\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2860 - val_loss: 177.6929\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.2269 - val_loss: 170.5215\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.6129 - val_loss: 296.8539\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0631 - val_loss: 169.5564\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 170.6541 - val_loss: 154.6569\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.6187 - val_loss: 157.1093\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.9873 - val_loss: 208.1908\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 181.9954 - val_loss: 195.5108\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.8619 - val_loss: 176.2530\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.3107 - val_loss: 141.2592\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6161 - val_loss: 142.3708\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.3210 - val_loss: 176.0230\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.8982 - val_loss: 161.2483\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.1540 - val_loss: 170.3550\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7268 - val_loss: 147.8257\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5689 - val_loss: 181.5498\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 169.9717 - val_loss: 181.8824\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 209.6229 - val_loss: 702.7992\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 256.0653 - val_loss: 182.0276\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.5931 - val_loss: 173.5235\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.0055 - val_loss: 189.3460\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.8950 - val_loss: 154.1276\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0652 - val_loss: 142.8631\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5348 - val_loss: 152.5482\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4771 - val_loss: 157.5704\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.2459 - val_loss: 141.0289\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6231 - val_loss: 146.0421\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.8741 - val_loss: 178.6362\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.8234 - val_loss: 566.5322\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.8164 - val_loss: 141.4642\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5685 - val_loss: 140.2961\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.3179 - val_loss: 247.9750\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4532 - val_loss: 235.9400\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7171 - val_loss: 148.2220\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.1457 - val_loss: 169.7511\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.3486 - val_loss: 140.0471\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 135.041 - 0s 50us/step - loss: 136.9184 - val_loss: 145.9847\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1400 - val_loss: 160.7818\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.4032 - val_loss: 219.4810\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.2747 - val_loss: 167.0470\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4102 - val_loss: 153.6437\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3240 - val_loss: 236.9363\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1257 - val_loss: 138.7285\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.4386 - val_loss: 155.4304\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2117 - val_loss: 172.9925\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1915 - val_loss: 142.7781\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.9655 - val_loss: 342.5938\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.8548 - val_loss: 174.7574\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.2506 - val_loss: 145.4535\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3389 - val_loss: 163.8246\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4292 - val_loss: 205.9845\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3968 - val_loss: 167.1366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8942 - val_loss: 180.2612\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6632 - val_loss: 146.6529\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.6588 - val_loss: 163.2229\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.9282 - val_loss: 161.0611\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.6400 - val_loss: 178.7788\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.4993 - val_loss: 185.8666\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.9545 - val_loss: 147.9055\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.4864 - val_loss: 142.6676\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4384 - val_loss: 139.3822\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.6778 - val_loss: 140.7776\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6606 - val_loss: 148.6445\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7814 - val_loss: 168.6595\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.1351 - val_loss: 145.8173\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1146 - val_loss: 151.6636\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.1103 - val_loss: 135.2974\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9521 - val_loss: 193.2285\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.9158 - val_loss: 160.3778\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1605 - val_loss: 157.2850\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0979 - val_loss: 298.6643\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.4091 - val_loss: 172.0632\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.9340 - val_loss: 175.6509\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6015 - val_loss: 173.3610\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4796 - val_loss: 170.1312\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 300.4722 - val_loss: 249.8860\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9709 - val_loss: 140.4688\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2778 - val_loss: 140.7322\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5466 - val_loss: 163.0851\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3638 - val_loss: 141.8122\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3821 - val_loss: 146.0009\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3791 - val_loss: 134.3825\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9921 - val_loss: 156.8700\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 137.965 - 0s 50us/step - loss: 139.9526 - val_loss: 398.1369\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.2837 - val_loss: 155.8737\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8253 - val_loss: 160.5772\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 143.095 - 0s 51us/step - loss: 143.8621 - val_loss: 180.3882\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3573 - val_loss: 182.9478\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.9792 - val_loss: 201.4879\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.7506 - val_loss: 170.2523\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 148.4679 - val_loss: 143.3999\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 198.2739 - val_loss: 2134.0185\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.0616 - val_loss: 145.2768\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.0987 - val_loss: 253.4903\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.4514 - val_loss: 146.5673\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5044 - val_loss: 135.9685\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5088 - val_loss: 141.5305\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5555 - val_loss: 182.5416\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.6860 - val_loss: 141.8138\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.6414 - val_loss: 157.4579\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4023 - val_loss: 208.1469\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.4808 - val_loss: 177.0851\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9926 - val_loss: 199.1778\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 159.364 - 0s 50us/step - loss: 158.4350 - val_loss: 141.9965\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.5358 - val_loss: 155.7966\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.5561 - val_loss: 201.7229\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4803 - val_loss: 157.2130\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1687 - val_loss: 159.1656\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 209.743 - 0s 51us/step - loss: 207.6665 - val_loss: 178.6459\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9190 - val_loss: 190.1838\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8930 - val_loss: 158.9087\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.1455 - val_loss: 226.0346\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.5438 - val_loss: 141.4118\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.2071 - val_loss: 283.9576\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9845 - val_loss: 151.0576\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6360 - val_loss: 198.8345\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4743 - val_loss: 184.1593\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.5863 - val_loss: 167.2456\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0488 - val_loss: 142.6293\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5559 - val_loss: 166.2102\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.5909 - val_loss: 156.3118\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.9457 - val_loss: 178.0179\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.5233 - val_loss: 177.3773\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.1003 - val_loss: 191.9601\n",
      "Epoch 866/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2318 - val_loss: 138.7748\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1292 - val_loss: 147.7552\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.0087 - val_loss: 240.9314\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1935 - val_loss: 141.7576\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.4355 - val_loss: 158.0623\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.1306 - val_loss: 143.7946\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0793 - val_loss: 143.9664\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3861 - val_loss: 154.8621\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8117 - val_loss: 141.4308\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.0827 - val_loss: 244.7777\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.3833 - val_loss: 154.3080\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6357 - val_loss: 164.4820\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4356 - val_loss: 165.2026\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2373 - val_loss: 136.5967\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8184 - val_loss: 153.8258\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0692 - val_loss: 138.1617\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2092 - val_loss: 139.1738\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2516 - val_loss: 198.7760\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2398 - val_loss: 182.6986\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.3315 - val_loss: 163.0094\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.5858 - val_loss: 231.1152\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.0034 - val_loss: 390.6926\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.3557 - val_loss: 178.0661\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.8370 - val_loss: 134.3587\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1040 - val_loss: 144.7295\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.4256 - val_loss: 150.3436\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3619 - val_loss: 132.7180\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.2718 - val_loss: 147.3360\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2322 - val_loss: 141.5293\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4460 - val_loss: 164.5412\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.4028 - val_loss: 401.3079\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.6512 - val_loss: 151.4486\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.3197 - val_loss: 257.8307\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6579 - val_loss: 144.6752\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5111 - val_loss: 133.4134\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.5285 - val_loss: 149.9584\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.5786 - val_loss: 138.6134\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 139.3565 - val_loss: 203.0612\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.0896 - val_loss: 141.5942\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.4426 - val_loss: 139.1112\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7457 - val_loss: 142.3156\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.8512 - val_loss: 139.8674\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.2863 - val_loss: 311.7698\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2186 - val_loss: 178.2430\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.9705 - val_loss: 165.5023\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.6571 - val_loss: 175.2713\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.8942 - val_loss: 362.7631\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 424.0528 - val_loss: 146.2547\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8979 - val_loss: 149.5932\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9392 - val_loss: 139.5130\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4359 - val_loss: 143.2207\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1232 - val_loss: 168.7005\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.5681 - val_loss: 167.2165\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3196 - val_loss: 133.1257\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2780 - val_loss: 131.2327\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8878 - val_loss: 141.7775\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.3180 - val_loss: 141.5990\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.8332 - val_loss: 141.0290\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3452 - val_loss: 140.1982\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.3331 - val_loss: 150.4700\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5003 - val_loss: 140.5119\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 529.1271 - val_loss: 510.8104\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 323.1547 - val_loss: 320.5111\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.5086 - val_loss: 197.8718\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.4668 - val_loss: 161.6867\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.6041 - val_loss: 159.1860\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.2390 - val_loss: 145.4487\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8974 - val_loss: 168.2824\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5155 - val_loss: 155.2236\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.9566 - val_loss: 136.9619\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.1988 - val_loss: 148.0015\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.2541 - val_loss: 150.3288\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.4914 - val_loss: 163.6768\n",
      "Epoch 939/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1503 - val_loss: 137.6030\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.3245 - val_loss: 250.9205\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.2557 - val_loss: 180.9868\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3076 - val_loss: 151.5752\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1730 - val_loss: 151.4672\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8202 - val_loss: 152.9691\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 170.7826 - val_loss: 246.0141\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.1625 - val_loss: 156.5631\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.5029 - val_loss: 152.9759\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.8141 - val_loss: 200.6870\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8265 - val_loss: 169.2029\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5354 - val_loss: 141.7674\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6071 - val_loss: 149.4268\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5422 - val_loss: 179.3511\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.3583 - val_loss: 173.8635\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.3076 - val_loss: 144.4220\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.0837 - val_loss: 139.4420\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4670 - val_loss: 150.2305\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3400 - val_loss: 161.1041\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6691 - val_loss: 147.9855\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3894 - val_loss: 149.3178\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.9756 - val_loss: 143.5351\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2078 - val_loss: 175.6922\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 136.589 - 0s 51us/step - loss: 137.3661 - val_loss: 157.1889\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1798 - val_loss: 154.7747\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9763 - val_loss: 178.5839\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8744 - val_loss: 139.0063\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 130.197 - 0s 50us/step - loss: 130.1562 - val_loss: 178.6069\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.0552 - val_loss: 163.1686\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5568 - val_loss: 143.4317\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0445 - val_loss: 228.3825\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3939 - val_loss: 154.8107\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.3469 - val_loss: 254.9516\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3434 - val_loss: 189.0354\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2795 - val_loss: 141.2920\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.1586 - val_loss: 138.6543\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 168.6103 - val_loss: 201.6967\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 198.0559 - val_loss: 179.6751\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.9990 - val_loss: 150.9386\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 168.6988 - val_loss: 223.5654\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8156 - val_loss: 146.9672\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.5421 - val_loss: 173.6250\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3239 - val_loss: 190.5123\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9967 - val_loss: 144.7282\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.9568 - val_loss: 138.5016\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1716 - val_loss: 153.2672\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6645 - val_loss: 182.7396\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2711 - val_loss: 143.8771\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8287 - val_loss: 160.2371\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2593 - val_loss: 142.8147\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6063 - val_loss: 164.9219\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9372 - val_loss: 139.8522\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4728 - val_loss: 146.0189\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.2006 - val_loss: 139.2154\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.4598 - val_loss: 155.7777\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0246 - val_loss: 212.6866\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.1058 - val_loss: 197.1122\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7884 - val_loss: 146.7361\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 135.758 - 0s 51us/step - loss: 135.7272 - val_loss: 147.3009\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6885 - val_loss: 258.1115\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.5055 - val_loss: 153.9539\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0638 - val_loss: 142.8670\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9778 - val_loss: 172.0740\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1128 - val_loss: 156.3090\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5710 - val_loss: 143.3610\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6840 - val_loss: 410.6775\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.5397 - val_loss: 144.3987\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9591 - val_loss: 197.5602\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.6585 - val_loss: 151.6118\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9193 - val_loss: 153.9468\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.6790 - val_loss: 149.7087\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.3576 - val_loss: 141.7672\n",
      "Epoch 1011/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7314 - val_loss: 141.2135\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9213 - val_loss: 153.5926\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.2243 - val_loss: 162.9722\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6351 - val_loss: 150.7785\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 132.5395 - val_loss: 155.1321\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.2224 - val_loss: 139.8134\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.4397 - val_loss: 178.6464\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.1215 - val_loss: 141.0066\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8079 - val_loss: 140.1934\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.3894 - val_loss: 640.5820\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.3635 - val_loss: 162.3107\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9588 - val_loss: 138.8215\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5256 - val_loss: 144.3082\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.3614 - val_loss: 134.4393\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3651 - val_loss: 154.1993\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1717 - val_loss: 281.1063\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.1612 - val_loss: 159.9453\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5309 - val_loss: 137.7009\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9621 - val_loss: 174.0491\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.5791 - val_loss: 163.5917\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.6975 - val_loss: 142.7637\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0153 - val_loss: 155.0671\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5617 - val_loss: 203.2932\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7519 - val_loss: 150.5262\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.6722 - val_loss: 165.1682\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6784 - val_loss: 165.1923\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2235 - val_loss: 151.1764\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7436 - val_loss: 177.5418\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7253 - val_loss: 172.8085\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.6212 - val_loss: 143.1212\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6612 - val_loss: 147.8070\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1994 - val_loss: 209.1725\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6698 - val_loss: 132.0010\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.2131 - val_loss: 148.5194\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.9019 - val_loss: 154.2363\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 143.5292 - val_loss: 163.3916\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.0775 - val_loss: 225.3729\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 168.8655 - val_loss: 152.9475\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7987 - val_loss: 149.3235\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5982 - val_loss: 140.7766\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 268.0595 - val_loss: 153.9851\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0217 - val_loss: 138.2263\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 180.9048 - val_loss: 158.6979\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0937 - val_loss: 158.1407\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.6475 - val_loss: 142.8431\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0160 - val_loss: 138.5945\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7312 - val_loss: 203.3822\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9133 - val_loss: 138.2763\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1503 - val_loss: 136.9806\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.5321 - val_loss: 169.7911\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2236 - val_loss: 153.2212\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.4051 - val_loss: 134.8856\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7272 - val_loss: 134.0864\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3796 - val_loss: 135.1642\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.3772 - val_loss: 155.5656\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.6438 - val_loss: 149.6350\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 175.7256 - val_loss: 146.7092\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2410 - val_loss: 141.0974\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5383 - val_loss: 169.9707\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2108 - val_loss: 155.8826\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2839 - val_loss: 196.0181\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.2251 - val_loss: 169.5103\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3454 - val_loss: 134.5230\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.5326 - val_loss: 193.4600\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3268 - val_loss: 142.3817\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9762 - val_loss: 160.1915\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9237 - val_loss: 144.5441\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1419 - val_loss: 354.6378\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1964 - val_loss: 247.6534\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1570 - val_loss: 233.6829\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.4882 - val_loss: 189.6882\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.2404 - val_loss: 145.5003\n",
      "Epoch 1083/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.9205 - val_loss: 144.3412\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.8732 - val_loss: 132.0217\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5024 - val_loss: 207.4220\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4256 - val_loss: 141.7416\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2741 - val_loss: 152.1990\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6937 - val_loss: 162.4106\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0620 - val_loss: 252.8383\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.6081 - val_loss: 143.0729\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9797 - val_loss: 133.7385\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 450.1941 - val_loss: 333.2633\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 286.2003 - val_loss: 350.1028\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 229.9748 - val_loss: 207.7974\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.4595 - val_loss: 179.0093\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.8858 - val_loss: 368.9155\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 177.917 - 0s 50us/step - loss: 180.3789 - val_loss: 364.1441\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4057 - val_loss: 192.4900\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.8737 - val_loss: 185.0139\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.1690 - val_loss: 159.5555\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5459 - val_loss: 159.8117\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 189.1836 - val_loss: 175.2322\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0280 - val_loss: 169.6345\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.7793 - val_loss: 273.6717\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2040 - val_loss: 170.3500\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.3385 - val_loss: 391.4058\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.6125 - val_loss: 187.7519\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3631 - val_loss: 160.4665\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.7795 - val_loss: 152.5713\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.5960 - val_loss: 173.3296\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2992 - val_loss: 159.5805\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.1109 - val_loss: 162.5404\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1909 - val_loss: 164.8888\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.8452 - val_loss: 192.0542\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.4248 - val_loss: 154.2580\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.1809 - val_loss: 153.4806\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 146.9289 - val_loss: 151.8101\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.0747 - val_loss: 192.6842\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 188.1991 - val_loss: 158.5943\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 141.9669 - val_loss: 178.0860\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3927 - val_loss: 148.1304\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.8258 - val_loss: 158.8206\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7427 - val_loss: 150.2411\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.3453 - val_loss: 142.8960\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5264 - val_loss: 174.8200\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 229.8234 - val_loss: 207.1506\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.4380 - val_loss: 161.0977\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6076 - val_loss: 179.8925\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3123 - val_loss: 194.3723\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4993 - val_loss: 225.4345\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2792 - val_loss: 217.0239\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8196 - val_loss: 150.7147\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4764 - val_loss: 146.1255\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7740 - val_loss: 163.7958\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1520 - val_loss: 140.4516\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7395 - val_loss: 173.8723\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7028 - val_loss: 181.6065\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7900 - val_loss: 150.4239\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3038 - val_loss: 163.3288\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.4244 - val_loss: 221.6094\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2278 - val_loss: 148.2115\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.6831 - val_loss: 191.7169\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6727 - val_loss: 188.0574\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6120 - val_loss: 143.6402\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1865 - val_loss: 188.3186\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.9502 - val_loss: 142.3648\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0781 - val_loss: 139.9923\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 152.5682 - val_loss: 258.7092\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7536 - val_loss: 193.1937\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.7317 - val_loss: 139.7509\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0070 - val_loss: 228.8556\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.9733 - val_loss: 225.0002\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 327.0519 - val_loss: 160.9525\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.0978 - val_loss: 146.8071\n",
      "Epoch 1155/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.9178 - val_loss: 165.0428\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.0508 - val_loss: 261.3776\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2609 - val_loss: 170.3973\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2339 - val_loss: 292.3374\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.4049 - val_loss: 148.1598\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.4076 - val_loss: 166.3121\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.9747 - val_loss: 194.9719\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.0193 - val_loss: 149.7737\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.8735 - val_loss: 145.8374\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9256 - val_loss: 402.6333\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3632 - val_loss: 204.3997\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8709 - val_loss: 193.3000\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5839 - val_loss: 141.5232\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.5300 - val_loss: 201.6618\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6293 - val_loss: 160.7364\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.4196 - val_loss: 174.6270\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9235 - val_loss: 143.7399\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.9397 - val_loss: 157.4245\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.2240 - val_loss: 144.2881\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2271 - val_loss: 138.6815\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8545 - val_loss: 174.9695\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8599 - val_loss: 155.9840\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1239 - val_loss: 138.0658\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.6827 - val_loss: 213.2342\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.0069 - val_loss: 193.3531\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7662 - val_loss: 139.7619\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5435 - val_loss: 191.3217\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0173 - val_loss: 158.3919\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.9603 - val_loss: 200.0949\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8253 - val_loss: 154.4150\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.8548 - val_loss: 151.9338\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.3058 - val_loss: 203.6912\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.1193 - val_loss: 142.4818\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 131.3216 - val_loss: 189.4764\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 139.0390 - val_loss: 147.8129\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 175.6863 - val_loss: 148.3451\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 157.0678 - val_loss: 139.2830\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.7804 - val_loss: 142.1297\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 137.0492 - val_loss: 149.9618\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.2988 - val_loss: 139.5370\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 146.7716 - val_loss: 142.9408\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 192.9907 - val_loss: 626.4716\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 176.9372 - val_loss: 144.7289\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 148.4521 - val_loss: 139.1193\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.5366 - val_loss: 162.6182\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 127.8805 - val_loss: 205.5198\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 142.5256 - val_loss: 159.3460\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.6382 - val_loss: 146.5140\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 166.5637 - val_loss: 223.5818\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.4805 - val_loss: 137.3729\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.1922 - val_loss: 219.8070\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.1627 - val_loss: 187.0959\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.3564 - val_loss: 197.4848\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 145.2146 - val_loss: 142.7414\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 140.2020 - val_loss: 157.1066\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 274.3849 - val_loss: 157.6216\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 131.7819 - val_loss: 147.3455\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 146.4504 - val_loss: 166.8186\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.3231 - val_loss: 140.9372\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.8630 - val_loss: 154.7834\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.2068 - val_loss: 152.9848\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 124.9920 - val_loss: 140.3217\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.4453 - val_loss: 159.2114\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 140.0113 - val_loss: 210.6710\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.8327 - val_loss: 174.4624\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 134.4406 - val_loss: 150.8939\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9513 - val_loss: 313.2458\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.3833 - val_loss: 135.0579\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.7159 - val_loss: 132.9098\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 132.7093 - val_loss: 146.5111\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 142.7260 - val_loss: 141.1408\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.4444 - val_loss: 177.9206\n",
      "Epoch 1227/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.9379 - val_loss: 182.5646\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 125.4115 - val_loss: 163.9097\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.6226 - val_loss: 300.3518\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 146.8937 - val_loss: 154.8997\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 129.2052 - val_loss: 253.7639\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 148.6797 - val_loss: 154.3780\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.4049 - val_loss: 200.4027\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 227.1990 - val_loss: 141.5249\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 160.2369 - val_loss: 148.0968\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7731 - val_loss: 157.0849\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4089 - val_loss: 169.6027\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.9393 - val_loss: 169.6408\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4480 - val_loss: 168.4305\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2688 - val_loss: 133.9555\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6608 - val_loss: 257.2823\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.5650 - val_loss: 135.5571\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.1940 - val_loss: 161.1204\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.5204 - val_loss: 170.2677\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.1811 - val_loss: 133.8473\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1307 - val_loss: 145.1847\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2447 - val_loss: 134.3551\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.5899 - val_loss: 349.0266\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.3490 - val_loss: 179.8658\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 136.9609 - val_loss: 177.7107\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 163.8281 - val_loss: 149.4686\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5450 - val_loss: 178.9435\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8654 - val_loss: 137.5724\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.3354 - val_loss: 138.3032\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5122 - val_loss: 175.9705\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.2507 - val_loss: 136.3791\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.3326 - val_loss: 139.5583\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 196.6817 - val_loss: 288.0398\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1304 - val_loss: 139.9350\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8785 - val_loss: 135.7973\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.2114 - val_loss: 159.0998\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5022 - val_loss: 165.1960\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.4126 - val_loss: 160.8728\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0185 - val_loss: 158.9694\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1380 - val_loss: 135.4152\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7424 - val_loss: 160.2096\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4217 - val_loss: 168.4042\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.6607 - val_loss: 152.2422\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4838 - val_loss: 131.6597\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.4472 - val_loss: 150.1372\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.7410 - val_loss: 170.2417\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.7347 - val_loss: 204.5749\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3215 - val_loss: 152.5721\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1306 - val_loss: 155.8757\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0001 - val_loss: 151.0320\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.7798 - val_loss: 141.0674\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7306 - val_loss: 219.0852\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8130 - val_loss: 155.3190\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9077 - val_loss: 162.0185\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2593 - val_loss: 187.7261\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.9042 - val_loss: 145.6934\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.6661 - val_loss: 151.3698\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2626 - val_loss: 199.9335\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2236 - val_loss: 134.8069\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0822 - val_loss: 161.2477\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2530 - val_loss: 137.9743\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8195 - val_loss: 152.5726\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.0879 - val_loss: 184.7017\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3876 - val_loss: 153.8956\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2960 - val_loss: 309.1796\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.3615 - val_loss: 140.9272\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5971 - val_loss: 196.3125\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7762 - val_loss: 147.2598\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3776 - val_loss: 140.2346\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0854 - val_loss: 135.1738\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5799 - val_loss: 135.2185\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0475 - val_loss: 135.9511\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0330 - val_loss: 240.8681\n",
      "Epoch 1299/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3905 - val_loss: 138.8719\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4415 - val_loss: 182.8819\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9726 - val_loss: 178.0719\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9986 - val_loss: 134.2597\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.0554 - val_loss: 137.2414\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 138.879 - 0s 51us/step - loss: 138.4691 - val_loss: 189.4508\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.1296 - val_loss: 195.0202\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.9245 - val_loss: 161.8416\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3168 - val_loss: 163.4724\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.5327 - val_loss: 131.0866\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 183.4804 - val_loss: 160.1452\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9591 - val_loss: 151.5458\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1929 - val_loss: 142.1090\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5322 - val_loss: 136.3596\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4502 - val_loss: 186.2359\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4504 - val_loss: 154.0404\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8652 - val_loss: 207.9422\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0743 - val_loss: 202.3189\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1314 - val_loss: 147.9157\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5668 - val_loss: 145.4410\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4003 - val_loss: 133.1395\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 128.9535 - val_loss: 143.2175\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.1577 - val_loss: 172.6533\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.0911 - val_loss: 136.4761\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 167.8501 - val_loss: 149.5548\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.1763 - val_loss: 139.0985\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2118 - val_loss: 139.2921\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0021 - val_loss: 203.1074\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.2040 - val_loss: 167.7815\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1536 - val_loss: 137.3644\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.3393 - val_loss: 151.1533\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 190.2466 - val_loss: 136.5829\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9558 - val_loss: 151.3478\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.1643 - val_loss: 140.2194\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.1692 - val_loss: 140.1847\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0143 - val_loss: 166.2233\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.6011 - val_loss: 191.1265\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3235 - val_loss: 145.3747\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2834 - val_loss: 151.9087\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6412 - val_loss: 216.9035\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5753 - val_loss: 180.5908\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5026 - val_loss: 153.9091\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3429 - val_loss: 154.9083\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.0373 - val_loss: 233.7482\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6532 - val_loss: 133.8653\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5644 - val_loss: 177.0150\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8763 - val_loss: 154.9650\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7023 - val_loss: 137.0443\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.4651 - val_loss: 159.3244\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1520 - val_loss: 159.3049\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.3564 - val_loss: 157.1477\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8020 - val_loss: 149.0249\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3303 - val_loss: 151.3232\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5087 - val_loss: 141.3841\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0982 - val_loss: 161.3434\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.5649 - val_loss: 191.3798\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9866 - val_loss: 165.1481\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0495 - val_loss: 140.5457\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2605 - val_loss: 133.1141\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.8459 - val_loss: 171.0438\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9307 - val_loss: 144.4313\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0917 - val_loss: 158.5531\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3433 - val_loss: 155.7221\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3812 - val_loss: 135.3076\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1020 - val_loss: 142.2576\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4625 - val_loss: 188.8915\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.8324 - val_loss: 239.6705\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.0631 - val_loss: 146.3439\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7112 - val_loss: 161.0380\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7137 - val_loss: 145.0309\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5921 - val_loss: 141.9256\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6817 - val_loss: 144.0592\n",
      "Epoch 1371/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.9945 - val_loss: 153.8142\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6313 - val_loss: 172.7186\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2414 - val_loss: 137.3283\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5383 - val_loss: 160.7557\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.8746 - val_loss: 175.0034\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.4636 - val_loss: 171.1125\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0594 - val_loss: 148.8913\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.7928 - val_loss: 202.6344\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4104 - val_loss: 143.9517\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.4022 - val_loss: 171.2278\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.5377 - val_loss: 135.3604\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.0171 - val_loss: 137.7724\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7535 - val_loss: 145.5960\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.9625 - val_loss: 145.3174\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.9387 - val_loss: 171.3548\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1911 - val_loss: 173.8279\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8993 - val_loss: 149.4641\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8398 - val_loss: 134.7762\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9068 - val_loss: 252.1259\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7032 - val_loss: 166.8089\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.4412 - val_loss: 247.0665\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.7395 - val_loss: 135.2654\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.0202 - val_loss: 185.3706\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.2175 - val_loss: 134.5650\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.4890 - val_loss: 147.5015\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1830 - val_loss: 145.3819\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7541 - val_loss: 152.7269\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0699 - val_loss: 215.6137\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6637 - val_loss: 226.9996\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 294.0967 - val_loss: 193.7987\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4803 - val_loss: 139.5730\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3584 - val_loss: 148.9083\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8823 - val_loss: 147.8096\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7258 - val_loss: 166.4212\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0141 - val_loss: 159.1811\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.7473 - val_loss: 204.5411\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7849 - val_loss: 134.7836\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3116 - val_loss: 143.8051\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0714 - val_loss: 154.2277\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3728 - val_loss: 149.7217\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1546 - val_loss: 156.6376\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2488 - val_loss: 154.5875\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.7498 - val_loss: 160.0183\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2141 - val_loss: 164.3696\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1586 - val_loss: 151.8582\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.3485 - val_loss: 144.5625\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.8090 - val_loss: 174.0422\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4301 - val_loss: 164.1982\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3108 - val_loss: 197.8958\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.4146 - val_loss: 143.6940\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4539 - val_loss: 171.1847\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2843 - val_loss: 150.8855\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4379 - val_loss: 190.7672\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2463 - val_loss: 149.7005\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4724 - val_loss: 160.7491\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.7448 - val_loss: 144.0093\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.2681 - val_loss: 183.1836\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5949 - val_loss: 140.2091\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.5161 - val_loss: 367.8575\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.8025 - val_loss: 137.5637\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4099 - val_loss: 141.4320\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5900 - val_loss: 147.1608\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5159 - val_loss: 135.7130\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8480 - val_loss: 162.9489\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7531 - val_loss: 147.8749\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0771 - val_loss: 216.6479\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7372 - val_loss: 272.9843\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5137 - val_loss: 169.5064\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3398 - val_loss: 166.8820\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1692 - val_loss: 138.5500\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 126.186 - 0s 51us/step - loss: 126.7237 - val_loss: 137.6185\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2861 - val_loss: 168.3071\n",
      "Epoch 1443/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3063 - val_loss: 159.4675\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2105 - val_loss: 146.5019\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5340 - val_loss: 181.9158\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8105 - val_loss: 142.9794\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5940 - val_loss: 140.3722\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3029 - val_loss: 142.0344\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.1626 - val_loss: 138.5469\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.1088 - val_loss: 141.9852\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 118.9441 - val_loss: 134.6750\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.4647 - val_loss: 134.3616\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5096 - val_loss: 137.3211\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9878 - val_loss: 138.3889\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6341 - val_loss: 174.5107\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.2659 - val_loss: 142.0186\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7492 - val_loss: 156.9965\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4807 - val_loss: 140.4223\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.898 - 0s 50us/step - loss: 131.9642 - val_loss: 159.2721\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6525 - val_loss: 136.3147\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.5347 - val_loss: 141.2395\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 129.550 - 0s 51us/step - loss: 129.4338 - val_loss: 166.7246\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.0444 - val_loss: 221.2647\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 126.6359 - val_loss: 161.2414\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 135.5940 - val_loss: 138.0158\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 130.9747 - val_loss: 159.0901\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.8505 - val_loss: 140.8490\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5814 - val_loss: 154.4210\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5792 - val_loss: 150.7833\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7940 - val_loss: 183.6676\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.1002 - val_loss: 159.4093\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5856 - val_loss: 217.8142\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4946 - val_loss: 140.9086\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8730 - val_loss: 141.9903\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1087 - val_loss: 160.3341\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9231 - val_loss: 136.4050\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2249 - val_loss: 146.2879\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6051 - val_loss: 144.2105\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3984 - val_loss: 181.9997\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8844 - val_loss: 137.5693\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0198 - val_loss: 177.1668\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6654 - val_loss: 131.8980\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0531 - val_loss: 141.3451\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.6019 - val_loss: 170.9721\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9794 - val_loss: 168.9919\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.0529 - val_loss: 133.3267\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 126.6574 - val_loss: 136.9356\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2452 - val_loss: 164.9931\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0019 - val_loss: 195.8260\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8280 - val_loss: 337.8886\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4389 - val_loss: 163.8106\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4438 - val_loss: 194.3093\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2593 - val_loss: 139.6015\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0041 - val_loss: 149.8495\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.2184 - val_loss: 169.3443\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0251 - val_loss: 216.4216\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.0819 - val_loss: 132.9981\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.8344 - val_loss: 143.5511\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.1159 - val_loss: 175.2495\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3086 - val_loss: 212.3429\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4489 - val_loss: 157.6561\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7314 - val_loss: 146.9485\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.5500 - val_loss: 142.8027\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.9787 - val_loss: 148.9247\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6354 - val_loss: 141.0888\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6663 - val_loss: 150.5552\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4662 - val_loss: 176.1403\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1596 - val_loss: 277.4122\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.0480 - val_loss: 182.0828\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4679 - val_loss: 144.5192\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.5354 - val_loss: 208.3634\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.7995 - val_loss: 186.3113\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4426 - val_loss: 134.7325\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.0230 - val_loss: 152.1268\n",
      "Epoch 1515/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9980 - val_loss: 133.8844\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3388 - val_loss: 141.6699\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6919 - val_loss: 142.1357\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8026 - val_loss: 139.2586\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7834 - val_loss: 138.5259\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1437 - val_loss: 140.9677\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.1082 - val_loss: 142.0268\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.6250 - val_loss: 157.0778\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.0009 - val_loss: 146.8918\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7398 - val_loss: 162.2107\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1772 - val_loss: 135.1112\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5949 - val_loss: 145.0891\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5914 - val_loss: 135.1379\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7971 - val_loss: 249.2617\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 137.862 - 0s 50us/step - loss: 137.1099 - val_loss: 138.7271\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5308 - val_loss: 149.8946\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.5715 - val_loss: 139.9373\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6204 - val_loss: 171.5493\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6276 - val_loss: 137.0217\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0682 - val_loss: 185.4446\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 184.9062 - val_loss: 223.9290\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 168.9757 - val_loss: 151.5307\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 137.1047 - val_loss: 184.0487\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.0345 - val_loss: 143.6799\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.1955 - val_loss: 146.0859\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4816 - val_loss: 164.9006\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7735 - val_loss: 159.3285\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.1899 - val_loss: 138.6506\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0447 - val_loss: 150.8185\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.0774 - val_loss: 133.4793\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.4028 - val_loss: 133.7421\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.7925 - val_loss: 143.0846\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.4950 - val_loss: 138.8251\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3866 - val_loss: 136.8661\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4769 - val_loss: 138.7510\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8319 - val_loss: 144.8882\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2143 - val_loss: 177.3956\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4067 - val_loss: 140.7968\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6904 - val_loss: 240.4402\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4279 - val_loss: 154.6203\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4834 - val_loss: 261.9508\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.7242 - val_loss: 163.9501\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4979 - val_loss: 141.8478\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6461 - val_loss: 134.0638\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4107 - val_loss: 140.4319\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5725 - val_loss: 144.5112\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4770 - val_loss: 143.0463\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4353 - val_loss: 133.1257\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.1869 - val_loss: 297.1422\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.5790 - val_loss: 174.8175\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5990 - val_loss: 169.4560\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.3198 - val_loss: 138.7779\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.2053 - val_loss: 141.5915\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6054 - val_loss: 169.4452\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.1157 - val_loss: 156.6293\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3400 - val_loss: 132.2542\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1578 - val_loss: 167.1956\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4280 - val_loss: 136.0735\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0214 - val_loss: 157.9423\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3478 - val_loss: 134.9263\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 177.9106 - val_loss: 1179.1808\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7962 - val_loss: 160.2419\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2195 - val_loss: 177.1523\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6894 - val_loss: 162.8964\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.2197 - val_loss: 155.7651\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.4665 - val_loss: 164.3457\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0343 - val_loss: 139.0899\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.9596 - val_loss: 172.7487\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4605 - val_loss: 137.4351\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7672 - val_loss: 143.8218\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 244.6618 - val_loss: 137.6622\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.7514 - val_loss: 147.4616\n",
      "Epoch 1587/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2874 - val_loss: 133.3956\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4870 - val_loss: 153.3234\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.0121 - val_loss: 151.7065\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2537 - val_loss: 141.7947\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9442 - val_loss: 316.5829\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2256 - val_loss: 137.1238\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.3571 - val_loss: 187.9715\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8598 - val_loss: 135.8255\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.2175 - val_loss: 159.2935\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 119.9633 - val_loss: 138.0341\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5712 - val_loss: 138.8306\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7383 - val_loss: 168.7869\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7440 - val_loss: 171.4421\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3180 - val_loss: 189.0433\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2649 - val_loss: 138.6909\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.4310 - val_loss: 145.8487\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3082 - val_loss: 148.9366\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5755 - val_loss: 149.3779\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8740 - val_loss: 138.3777\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2716 - val_loss: 173.6548\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.4981 - val_loss: 153.2402\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 122.8700 - val_loss: 148.8883\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 142.3181 - val_loss: 152.3379\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.1269 - val_loss: 145.8778\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4460 - val_loss: 239.7053\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2123 - val_loss: 140.8972\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8289 - val_loss: 264.2916\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.0806 - val_loss: 145.1792\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1909 - val_loss: 134.2262\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7815 - val_loss: 135.7126\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.1359 - val_loss: 221.6094\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7301 - val_loss: 147.6465\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1328 - val_loss: 158.6914\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.7231 - val_loss: 282.6413\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2032 - val_loss: 168.9306\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8746 - val_loss: 139.0398\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2023 - val_loss: 149.0654\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.8139 - val_loss: 133.3885\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.3287 - val_loss: 137.9952\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.9966 - val_loss: 136.3135\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0088 - val_loss: 153.7428\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.4253 - val_loss: 161.7238\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8707 - val_loss: 138.6555\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3852 - val_loss: 145.2701\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3851 - val_loss: 170.9174\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7287 - val_loss: 135.1149\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.7985 - val_loss: 238.8046\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 150.7597 - val_loss: 149.6490\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8922 - val_loss: 161.4363\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.2058 - val_loss: 141.3216\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0845 - val_loss: 137.5649\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7275 - val_loss: 143.4841\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2895 - val_loss: 134.5560\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3989 - val_loss: 168.2414\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.6988 - val_loss: 149.9541\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.5306 - val_loss: 227.0108\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9377 - val_loss: 136.7727\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2206 - val_loss: 136.0031\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5113 - val_loss: 140.9234\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8968 - val_loss: 150.2659\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1323 - val_loss: 139.9609\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2453 - val_loss: 147.2115\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.8102 - val_loss: 144.2891\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.6897 - val_loss: 140.6021\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.8935 - val_loss: 134.9466\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2433 - val_loss: 298.1331\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1412 - val_loss: 158.5257\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.2427 - val_loss: 149.1740\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0421 - val_loss: 170.4211\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5806 - val_loss: 139.8627\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2269 - val_loss: 138.4354\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7675 - val_loss: 168.3397\n",
      "Epoch 1659/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6928 - val_loss: 213.7917\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0926 - val_loss: 268.3683\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3494 - val_loss: 151.8422\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6990 - val_loss: 135.8667\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.6280 - val_loss: 173.2517\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.1443 - val_loss: 159.5772\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.7846 - val_loss: 136.5641\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5976 - val_loss: 170.6263\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7872 - val_loss: 155.3170\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.2299 - val_loss: 160.0146\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5933 - val_loss: 157.2393\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.1608 - val_loss: 144.8404\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9034 - val_loss: 140.9615\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5253 - val_loss: 140.7919\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.0114 - val_loss: 137.2591\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.5292 - val_loss: 166.7580\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9317 - val_loss: 140.4447\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5146 - val_loss: 135.5849\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7173 - val_loss: 160.1141\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 126.4162 - val_loss: 225.1345\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 119.9935 - val_loss: 143.9508\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 122.2550 - val_loss: 136.4855\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.1552 - val_loss: 193.3454\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.5057 - val_loss: 145.9033\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9079 - val_loss: 140.3449\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2579 - val_loss: 133.8920\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7818 - val_loss: 1012.1800\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9727 - val_loss: 173.3439\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1633 - val_loss: 147.3512\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.6610 - val_loss: 141.9701\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0469 - val_loss: 137.2515\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.2776 - val_loss: 176.9005\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.1507 - val_loss: 193.5027\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.4703 - val_loss: 131.8135\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.8292 - val_loss: 130.7583\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.2064 - val_loss: 206.3553\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.8430 - val_loss: 155.5019\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9645 - val_loss: 141.6194\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6610 - val_loss: 175.9972\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.9958 - val_loss: 148.6450\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5072 - val_loss: 142.6832\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0200 - val_loss: 223.0165\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7996 - val_loss: 136.0859\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4331 - val_loss: 141.4125\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.0303 - val_loss: 138.3833\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9453 - val_loss: 151.6667\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5138 - val_loss: 140.6461\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2102 - val_loss: 171.2192\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7553 - val_loss: 193.3125\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.0265 - val_loss: 136.5649\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.9314 - val_loss: 167.7136\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.4870 - val_loss: 144.6274\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.6363 - val_loss: 169.6649\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.7768 - val_loss: 226.9091\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8914 - val_loss: 137.6339\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2853 - val_loss: 140.9415\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.6789 - val_loss: 131.7860\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5852 - val_loss: 137.1330\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1873 - val_loss: 166.7341\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.3771 - val_loss: 133.5195\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.0772 - val_loss: 145.8018\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7042 - val_loss: 223.1126\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4296 - val_loss: 183.6558\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3454 - val_loss: 166.2238\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3429 - val_loss: 145.9858\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0615 - val_loss: 144.8991\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.4095 - val_loss: 148.1992\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3748 - val_loss: 135.5773\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2551 - val_loss: 154.8151\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6410 - val_loss: 133.0307\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.0581 - val_loss: 162.0077\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9500 - val_loss: 158.4438\n",
      "Epoch 1731/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3212 - val_loss: 144.0263\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0129 - val_loss: 211.3985\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.6570 - val_loss: 151.7409\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5883 - val_loss: 135.6414\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8396 - val_loss: 182.4475\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.9258 - val_loss: 148.8790\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6946 - val_loss: 142.9901\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5670 - val_loss: 137.6314\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 117.4501 - val_loss: 132.1334\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 150.9596 - val_loss: 140.5173\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 197.0129 - val_loss: 138.5662\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.8263 - val_loss: 151.1229\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.5364 - val_loss: 172.3829\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.3782 - val_loss: 136.2639\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6319 - val_loss: 174.9353\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.6462 - val_loss: 132.1590\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.8773 - val_loss: 168.0972\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.3607 - val_loss: 154.1489\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.6658 - val_loss: 134.8801\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 118.6319 - val_loss: 138.5094\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 194.0082 - val_loss: 143.6564\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 119.5950 - val_loss: 137.6693\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.5948 - val_loss: 153.5865\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9328 - val_loss: 137.7271\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.2599 - val_loss: 144.7884\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.8355 - val_loss: 144.3140\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5498 - val_loss: 136.6876\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.8083 - val_loss: 142.0174\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.2371 - val_loss: 177.5288\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3844 - val_loss: 155.3955\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1246 - val_loss: 142.2983\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2248 - val_loss: 144.3080\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1579 - val_loss: 137.8075\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.0681 - val_loss: 137.4242\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 158.143 - 0s 50us/step - loss: 157.9984 - val_loss: 163.0788\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4305 - val_loss: 141.8902\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.3479 - val_loss: 159.3829\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3869 - val_loss: 148.9067\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.5013 - val_loss: 135.8097\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1185 - val_loss: 136.6845\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4089 - val_loss: 142.7866\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.2232 - val_loss: 154.2463\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1830 - val_loss: 153.5204\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4095 - val_loss: 167.0080\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.1736 - val_loss: 347.4349\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5205 - val_loss: 162.6824\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.9381 - val_loss: 144.3975\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5394 - val_loss: 235.6242\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.8589 - val_loss: 142.4805\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.7734 - val_loss: 140.0298\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3073 - val_loss: 139.9727\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.9094 - val_loss: 148.1149\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.2030 - val_loss: 137.2669\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 125.987 - 0s 50us/step - loss: 125.2930 - val_loss: 136.8501\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1324 - val_loss: 149.7924\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7967 - val_loss: 162.2844\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9265 - val_loss: 181.9914\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9650 - val_loss: 153.5916\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.9461 - val_loss: 144.8900\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.9129 - val_loss: 562.0803\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7422 - val_loss: 140.6292\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0270 - val_loss: 187.7229\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.2466 - val_loss: 169.7632\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 120.104 - 0s 51us/step - loss: 119.2629 - val_loss: 197.1803\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.4752 - val_loss: 227.2905\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.9817 - val_loss: 187.2669\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4619 - val_loss: 136.8887\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 120.755 - 0s 51us/step - loss: 120.9043 - val_loss: 157.9371\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1476 - val_loss: 168.7040\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7465 - val_loss: 153.3091\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.5057 - val_loss: 147.3703\n",
      "Epoch 1802/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.4131 - val_loss: 156.4005\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8524 - val_loss: 134.5850\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8986 - val_loss: 137.4020\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7519 - val_loss: 184.0175\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.3996 - val_loss: 149.1957\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.2182 - val_loss: 146.3881\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4421 - val_loss: 174.2088\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6309 - val_loss: 134.0425\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.1818 - val_loss: 145.1951\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.8864 - val_loss: 141.0835\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7849 - val_loss: 137.1874\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.3814 - val_loss: 134.4047\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7592 - val_loss: 152.1181\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.1089 - val_loss: 157.4224\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.2832 - val_loss: 165.3040\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.9017 - val_loss: 141.5073\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.0571 - val_loss: 133.5407\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.2029 - val_loss: 153.3484\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9176 - val_loss: 135.3011\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7694 - val_loss: 141.1350\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.2289 - val_loss: 212.9801\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 120.4293 - val_loss: 155.0832\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 126.0947 - val_loss: 133.9496\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 122.3555 - val_loss: 174.0245\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 125.2768 - val_loss: 134.5097\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7790 - val_loss: 226.8471\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 288.0155 - val_loss: 189.6747\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.0311 - val_loss: 175.3427\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.1573 - val_loss: 171.3852\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1808 - val_loss: 155.5050\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.1830 - val_loss: 143.7297\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3842 - val_loss: 131.4513\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7218 - val_loss: 135.3928\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.6850 - val_loss: 134.1265\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1126 - val_loss: 211.7775\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1820 - val_loss: 189.7888\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.9567 - val_loss: 149.2166\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1272 - val_loss: 139.0711\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.5079 - val_loss: 139.0052\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8860 - val_loss: 146.4304\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.5220 - val_loss: 202.4901\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7117 - val_loss: 131.9222\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.5176 - val_loss: 140.2443\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8526 - val_loss: 134.5746\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.1848 - val_loss: 157.9360\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.3526 - val_loss: 143.7531\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 201.1079 - val_loss: 280.9349\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3100 - val_loss: 245.2767\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.5795 - val_loss: 187.0552\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.2524 - val_loss: 142.0674\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5125 - val_loss: 167.2549\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.6886 - val_loss: 145.6544\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7618 - val_loss: 191.1468\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.9622 - val_loss: 150.5935\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8919 - val_loss: 141.2747\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7947 - val_loss: 143.7811\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6380 - val_loss: 198.8622\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.7427 - val_loss: 186.3565\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8681 - val_loss: 133.2141\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3276 - val_loss: 145.0710\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5046 - val_loss: 137.9970\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.5243 - val_loss: 150.2665\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0691 - val_loss: 151.0420\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.5904 - val_loss: 139.1280\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3473 - val_loss: 161.1982\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0035 - val_loss: 150.7124\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4015 - val_loss: 135.2949\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2751 - val_loss: 154.9725\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5953 - val_loss: 135.3769\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5863 - val_loss: 140.5170\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.0389 - val_loss: 138.6803\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0071 - val_loss: 152.1664\n",
      "Epoch 1874/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.9949 - val_loss: 134.0348\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7530 - val_loss: 141.5152\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.2226 - val_loss: 141.8179\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0420 - val_loss: 141.8737\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7902 - val_loss: 139.2904\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5423 - val_loss: 140.6713\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.9634 - val_loss: 148.2893\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.3373 - val_loss: 159.1014\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4137 - val_loss: 143.7729\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.2388 - val_loss: 149.5400\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.6104 - val_loss: 1247.5045\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.1852 - val_loss: 139.8405\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.8491 - val_loss: 135.2724\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.7422 - val_loss: 141.5919\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.8299 - val_loss: 142.9576\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0258 - val_loss: 134.9616\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.6782 - val_loss: 145.2620\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.6263 - val_loss: 149.5665\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.2817 - val_loss: 144.5001\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.0747 - val_loss: 186.3085\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.0684 - val_loss: 160.3565\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0981 - val_loss: 138.5467\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.9975 - val_loss: 133.0824\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.9496 - val_loss: 141.0855\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6529 - val_loss: 174.3374\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2544 - val_loss: 137.6479\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5686 - val_loss: 160.2763\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2236 - val_loss: 203.1851\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2145 - val_loss: 169.8359\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5022 - val_loss: 139.6923\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9085 - val_loss: 140.3676\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.1217 - val_loss: 131.3264\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.4406 - val_loss: 142.8818\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 142.4747 - val_loss: 234.7352\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 206.9714 - val_loss: 141.0894\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 116.4712 - val_loss: 134.1137\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.6180 - val_loss: 135.8646\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0575 - val_loss: 144.8387\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7099 - val_loss: 145.2458\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 169.8976 - val_loss: 181.5793\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.7112 - val_loss: 206.8779\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9478 - val_loss: 139.1005\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4274 - val_loss: 153.3457\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.3744 - val_loss: 133.6278\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.0284 - val_loss: 171.9572\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.7876 - val_loss: 209.6301\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5310 - val_loss: 132.7084\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.6134 - val_loss: 177.6729\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.5150 - val_loss: 142.0968\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.7609 - val_loss: 178.0321\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0560 - val_loss: 132.8349\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9934 - val_loss: 136.0797\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.1457 - val_loss: 136.9337\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5657 - val_loss: 182.7484\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.5701 - val_loss: 138.0600\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4514 - val_loss: 146.0518\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2178 - val_loss: 165.5140\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1155 - val_loss: 242.1873\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 248.1908 - val_loss: 136.8535\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.9097 - val_loss: 133.2612\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0216 - val_loss: 140.1242\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.8771 - val_loss: 146.7462\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 128.3284 - val_loss: 222.3562\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.6145 - val_loss: 176.8312\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.9597 - val_loss: 137.6939\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.9605 - val_loss: 134.6567\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1532 - val_loss: 133.9502\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3902 - val_loss: 142.6070\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5271 - val_loss: 171.1711A: 0s - loss: 9\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.9696 - val_loss: 148.3670\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5075 - val_loss: 151.1459\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 123.5291 - val_loss: 172.3477\n",
      "Epoch 1946/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7563 - val_loss: 178.1473\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4458 - val_loss: 160.2230\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.1262 - val_loss: 142.1973\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1741 - val_loss: 133.6353\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.0401 - val_loss: 165.8575\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.6022 - val_loss: 156.7740\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7518 - val_loss: 152.2215\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7903 - val_loss: 139.4056\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.4318 - val_loss: 143.3453\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4131 - val_loss: 152.3760\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.4063 - val_loss: 166.3866\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.9421 - val_loss: 135.8027\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3582 - val_loss: 149.2712\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8642 - val_loss: 140.8483\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.1791 - val_loss: 189.0178\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9113 - val_loss: 143.4310\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6635 - val_loss: 139.7492\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.3545 - val_loss: 174.5283\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5706 - val_loss: 170.1257\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.7386 - val_loss: 184.9450\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.0857 - val_loss: 195.4629\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.0347 - val_loss: 154.6420\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3235 - val_loss: 140.4632\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 126.6602 - val_loss: 136.9593\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 131.5147 - val_loss: 133.6045\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 120.1139 - val_loss: 190.9116\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6280 - val_loss: 137.0496\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7283 - val_loss: 165.9035\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.7416 - val_loss: 141.0968\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7657 - val_loss: 144.6831\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.6329 - val_loss: 140.6691\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.7692 - val_loss: 183.3691\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8453 - val_loss: 136.6647\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2614 - val_loss: 144.6374\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6132 - val_loss: 255.5726\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 387.9797 - val_loss: 244.2164\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.9384 - val_loss: 177.1412\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.3899 - val_loss: 166.3813\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1882 - val_loss: 155.3788\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4512 - val_loss: 147.7211\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6280 - val_loss: 152.6945\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1993 - val_loss: 139.0118\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.7465 - val_loss: 136.6955\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 156.7679 - val_loss: 146.6831\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1814 - val_loss: 161.7403\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.2136 - val_loss: 140.5100\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.8324 - val_loss: 142.2625\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3593 - val_loss: 142.8960\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.0160 - val_loss: 134.3810\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3147 - val_loss: 158.4350\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.1346 - val_loss: 157.5220\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5413 - val_loss: 138.4818\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.9069 - val_loss: 153.2906\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.5197 - val_loss: 139.3123\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1696 - val_loss: 160.8010\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.9299 - val_loss: 158.6922\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.7936 - val_loss: 144.0204\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3231 - val_loss: 144.1430\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8230 - val_loss: 193.7805\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9501 - val_loss: 152.4276\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.1873 - val_loss: 159.6147\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1036 - val_loss: 167.8538\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.1512 - val_loss: 218.9856\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.8657 - val_loss: 139.4730\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6086 - val_loss: 137.2813\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.5393 - val_loss: 135.9116\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.5223 - val_loss: 149.0650\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1325 - val_loss: 145.4567\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7868 - val_loss: 152.2887\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 130.8391ETA: 0s - loss: 1 - 0s 51us/step - loss: 131.0792 - val_loss: 135.1304\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1839 - val_loss: 164.9391\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.7596 - val_loss: 220.1571\n",
      "Epoch 2018/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.5206 - val_loss: 141.0042\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6315 - val_loss: 302.5127\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.0328 - val_loss: 146.9234\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.6746 - val_loss: 160.0569\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3203 - val_loss: 156.1675\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7722 - val_loss: 139.2571\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7522 - val_loss: 171.5049\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.7316 - val_loss: 161.5845\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0177 - val_loss: 138.5516\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2700 - val_loss: 141.7855\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.1118 - val_loss: 151.0650\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.3067 - val_loss: 232.3177\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8791 - val_loss: 152.2582\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9755 - val_loss: 154.9353\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3394 - val_loss: 138.0415\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.5617 - val_loss: 142.4780\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.0492 - val_loss: 141.8192\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 121.6813 - val_loss: 155.9733\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4874 - val_loss: 133.6663\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9056 - val_loss: 166.9887\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5526 - val_loss: 167.0960\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.7250 - val_loss: 148.8689\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6436 - val_loss: 182.0917\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 129.1482 - val_loss: 140.0004\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 120.4618 - val_loss: 131.1528\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 129.5584 - val_loss: 170.8064\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 126.3604 - val_loss: 139.1352\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.3652 - val_loss: 144.1594\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2381 - val_loss: 141.4547\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.7927 - val_loss: 167.1848\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.3825 - val_loss: 153.7087\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 203.2437 - val_loss: 141.0517\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.7401 - val_loss: 168.8983\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6621 - val_loss: 131.2718\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.8589 - val_loss: 139.2424\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.8781 - val_loss: 172.7639\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0204 - val_loss: 156.0369\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.5922 - val_loss: 162.0515\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6085 - val_loss: 148.6180\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3924 - val_loss: 148.4540\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.6434 - val_loss: 132.7665\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3251 - val_loss: 142.5737\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5765 - val_loss: 149.4344\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1682 - val_loss: 150.5682\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.8178 - val_loss: 133.9229\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.9165 - val_loss: 154.0136\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1607 - val_loss: 211.3199\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.4826 - val_loss: 130.6962\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6358 - val_loss: 144.0265\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3109 - val_loss: 304.5997\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.8970 - val_loss: 161.3035\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.2470 - val_loss: 147.2590\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1895 - val_loss: 146.6527\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 311.5978 - val_loss: 269.2329\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.0036 - val_loss: 140.7140\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.2301 - val_loss: 149.9868\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.5806 - val_loss: 139.9044\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0676 - val_loss: 138.8656\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.0475 - val_loss: 132.7948\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.9058 - val_loss: 144.7079\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.6803 - val_loss: 139.2779\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.3318 - val_loss: 136.1270\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.4243 - val_loss: 149.2786\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.0798 - val_loss: 183.1637\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.6962 - val_loss: 177.1855\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8932 - val_loss: 138.6099\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3136 - val_loss: 131.6247\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.8366 - val_loss: 141.4460\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5463 - val_loss: 176.2820\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6753 - val_loss: 135.8239\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4492 - val_loss: 160.2647\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5347 - val_loss: 138.6423\n",
      "Epoch 2090/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.1487 - val_loss: 148.1087\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3371 - val_loss: 149.8780\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.7325 - val_loss: 254.0309\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 169.2175 - val_loss: 138.9267\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.7969 - val_loss: 145.3445\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.2367 - val_loss: 155.5696\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2446 - val_loss: 184.2177\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0744 - val_loss: 155.3981\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.3361 - val_loss: 142.8890\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6941 - val_loss: 156.7560\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2736 - val_loss: 192.4663\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0477 - val_loss: 178.4154\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1572 - val_loss: 152.3808\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4985 - val_loss: 142.0874\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.7695 - val_loss: 146.9168\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.2474 - val_loss: 132.1188\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.2068 - val_loss: 172.3633\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.3023 - val_loss: 137.0875\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.2408 - val_loss: 517.5869\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.5220 - val_loss: 164.8212\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.4298 - val_loss: 139.1395\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.6980 - val_loss: 131.5875\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 114.9364 - val_loss: 133.4128\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 120.1134 - val_loss: 139.6171\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 116.7162 - val_loss: 133.8642\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 120.7311 - val_loss: 131.4986\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.9088 - val_loss: 134.0822\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.2478 - val_loss: 142.2794\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.7035 - val_loss: 139.0949\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.1433 - val_loss: 141.8970\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.7716 - val_loss: 137.7657\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.7758 - val_loss: 180.5522\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 116.2832 - val_loss: 133.4464\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.4770 - val_loss: 142.4143\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2786 - val_loss: 145.5444\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5932 - val_loss: 143.3366\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8767 - val_loss: 153.3567\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.6378 - val_loss: 134.8321\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.4003 - val_loss: 150.0121\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.7190 - val_loss: 134.4121\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.1098 - val_loss: 228.5859\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 205.2407 - val_loss: 140.4624\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.9627 - val_loss: 148.4404\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.8379 - val_loss: 154.9594\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.6177 - val_loss: 132.5751\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7984 - val_loss: 204.1616\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9913 - val_loss: 135.1554\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1986 - val_loss: 135.6095\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2736 - val_loss: 146.8313\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5173 - val_loss: 134.9482\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0087 - val_loss: 176.8652\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7856 - val_loss: 140.5905\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.2793 - val_loss: 136.6981\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.2150 - val_loss: 157.4197\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5931 - val_loss: 137.3513\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.3418 - val_loss: 131.1270\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1393 - val_loss: 147.6728\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.7493 - val_loss: 198.0436\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.9785 - val_loss: 151.9485\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5696 - val_loss: 193.6251\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.5951 - val_loss: 184.7515\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.5302 - val_loss: 164.3682\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2138 - val_loss: 176.8487\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9912 - val_loss: 135.8172\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1176 - val_loss: 158.1509\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1213 - val_loss: 141.1280\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.4020 - val_loss: 142.6112\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.4741 - val_loss: 137.8159\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6348 - val_loss: 137.8894\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.7162 - val_loss: 162.3327\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5587 - val_loss: 159.8443\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.5119 - val_loss: 241.2408\n",
      "Epoch 2162/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5322 - val_loss: 134.0265\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.2747 - val_loss: 140.0583\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1562 - val_loss: 136.1532\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4627 - val_loss: 138.9130\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9032 - val_loss: 166.7293\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8543 - val_loss: 158.9361\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0176 - val_loss: 165.1151\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.3752 - val_loss: 132.6447\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.0055 - val_loss: 137.4774\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.1306 - val_loss: 174.0148\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7627 - val_loss: 130.7953\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0832 - val_loss: 145.0427\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.2614 - val_loss: 134.7673\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.5882 - val_loss: 138.1082\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.5880 - val_loss: 136.8667\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.0615 - val_loss: 133.6408\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.5223 - val_loss: 146.1459\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.0603 - val_loss: 156.9624\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0161 - val_loss: 137.5867\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.2280 - val_loss: 151.8975\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6170 - val_loss: 157.5114- ETA: 0s - loss: 10\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2724 - val_loss: 137.6964\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.3114 - val_loss: 136.5915\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 123.3969 - val_loss: 160.3157\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 127.6149 - val_loss: 145.2851\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 118.4753 - val_loss: 148.3394\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4309 - val_loss: 143.3440\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.4207 - val_loss: 153.7039\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 311.8857 - val_loss: 194.6447\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.7231 - val_loss: 160.7537\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0361 - val_loss: 136.1394\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.8136 - val_loss: 145.3272\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.1198 - val_loss: 150.1358\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.1599 - val_loss: 139.7253\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.4548 - val_loss: 146.0004\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.2567 - val_loss: 132.2989\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 117.4140 - val_loss: 137.0536\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.4176 - val_loss: 140.3637\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5882 - val_loss: 142.4806\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9944 - val_loss: 150.8204\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.4382 - val_loss: 132.2186\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.1243 - val_loss: 177.4922\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.1923 - val_loss: 135.9669\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.6848 - val_loss: 198.8623\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.3761 - val_loss: 235.3206\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.4024 - val_loss: 155.4582\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6757 - val_loss: 149.7867\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6193 - val_loss: 156.2216\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.8391 - val_loss: 135.5870\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.0545 - val_loss: 137.7697\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.6176 - val_loss: 158.4820\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.2225 - val_loss: 241.6453\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.7923 - val_loss: 156.5976\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.4718 - val_loss: 170.4879\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.5327 - val_loss: 227.4303\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.5536 - val_loss: 139.7535\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8653 - val_loss: 137.4732\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.5124 - val_loss: 143.0671\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1740 - val_loss: 145.3043\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3345 - val_loss: 163.3112\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.5921 - val_loss: 133.1694\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 116.211 - 0s 51us/step - loss: 116.9739 - val_loss: 191.9097\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.6547 - val_loss: 143.6553\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7101 - val_loss: 132.8434\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.1546 - val_loss: 166.9895\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.6762 - val_loss: 132.9961\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 241.9974 - val_loss: 157.4591\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.3380 - val_loss: 143.6065\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6236 - val_loss: 215.6767\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.7675 - val_loss: 134.9888\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.4835 - val_loss: 143.6995\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.0724 - val_loss: 153.5383\n",
      "Epoch 2234/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7236 - val_loss: 144.3654\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2107 - val_loss: 161.7413\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.2840 - val_loss: 162.0077\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5563 - val_loss: 141.7293\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5546 - val_loss: 146.1376\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1100 - val_loss: 152.5407\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.7233 - val_loss: 131.6929\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.5940 - val_loss: 160.2436\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.8226 - val_loss: 146.3090\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2626 - val_loss: 185.3099\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6029 - val_loss: 136.6959\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.0923 - val_loss: 160.8715\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.7276 - val_loss: 135.1473\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1604 - val_loss: 132.4550\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.7910 - val_loss: 171.8856\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.6987 - val_loss: 162.1594\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9414 - val_loss: 131.7056\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3283 - val_loss: 161.2778\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.7043 - val_loss: 155.0203\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5527 - val_loss: 139.8777\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 121.3068 - val_loss: 134.9905\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.9955 - val_loss: 162.7139\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.3990 - val_loss: 145.7594\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.0400 - val_loss: 179.2872\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 114.6072 - val_loss: 137.0705\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 119.5368 - val_loss: 145.6244\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 121.6495 - val_loss: 145.6902\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.1466 - val_loss: 146.1339\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1096 - val_loss: 148.2452\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.1221 - val_loss: 134.2155\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0464 - val_loss: 145.0099\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.1573 - val_loss: 145.5967\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.8101 - val_loss: 150.9293\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7106 - val_loss: 136.8950\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.0706 - val_loss: 167.1189\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.8651 - val_loss: 144.5075\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.8588 - val_loss: 146.2114\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.3985 - val_loss: 169.2336\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.0352 - val_loss: 143.3861\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1212 - val_loss: 139.3980\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.5718 - val_loss: 133.1368\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4203 - val_loss: 169.0041\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.1516 - val_loss: 161.0827\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.6380 - val_loss: 140.6640\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.8743 - val_loss: 183.4241\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6430 - val_loss: 154.6698\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.8591 - val_loss: 170.1904\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.8160 - val_loss: 134.6614\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.2105 - val_loss: 151.9635\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.7372 - val_loss: 221.6198\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.0731 - val_loss: 139.3268\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.6627 - val_loss: 165.1993\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7128 - val_loss: 169.3377\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8830 - val_loss: 134.1840\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.7703 - val_loss: 153.0749\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.9911 - val_loss: 163.2321\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.2620 - val_loss: 143.6171\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8453 - val_loss: 133.3939\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.3575 - val_loss: 160.2176\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.2877 - val_loss: 143.4174\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.9317 - val_loss: 143.3629\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5249 - val_loss: 142.5380\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1310 - val_loss: 182.6880\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2125 - val_loss: 135.8247\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 124.6081 - val_loss: 142.5989\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.7843 - val_loss: 222.1455\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.2070 - val_loss: 138.3814\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9405 - val_loss: 167.5031\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.5395 - val_loss: 160.7777\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7340 - val_loss: 134.0627\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7355 - val_loss: 148.8375\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4320 - val_loss: 133.0481\n",
      "Epoch 2306/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7056 - val_loss: 150.1800\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.1864 - val_loss: 142.7237\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7449 - val_loss: 166.2782\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.847 - 0s 51us/step - loss: 128.0525 - val_loss: 137.3695\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3773 - val_loss: 165.8933\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.0134 - val_loss: 205.2192\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4946 - val_loss: 139.4480\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8199 - val_loss: 148.1511\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2354 - val_loss: 138.2418\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0105 - val_loss: 145.7127\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.7078 - val_loss: 148.7020\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.9680 - val_loss: 150.8657\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.7658 - val_loss: 135.7937\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.3172 - val_loss: 137.4662\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.6062 - val_loss: 166.4453\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.6923 - val_loss: 151.6572\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.7369 - val_loss: 135.3214\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.8089 - val_loss: 151.9572\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.0910 - val_loss: 144.6937\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.0865 - val_loss: 150.8945\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.7315 - val_loss: 159.7048\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.6910 - val_loss: 136.1746\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1231 - val_loss: 144.4566\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.6516 - val_loss: 143.4911\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.6042 - val_loss: 140.4173\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.2391 - val_loss: 161.5645\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 121.5139 - val_loss: 133.9310\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.0186 - val_loss: 188.6220\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 117.1870 - val_loss: 134.6370\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.1306 - val_loss: 171.6804\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.4916 - val_loss: 139.2824\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.9756 - val_loss: 153.5607\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.8092 - val_loss: 138.1210\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5930 - val_loss: 167.7215\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2085 - val_loss: 137.2425\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.0400 - val_loss: 139.3280\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5718 - val_loss: 147.0465\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.8137 - val_loss: 141.0710\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 119.0790 - val_loss: 230.5926\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.1300 - val_loss: 136.9175\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5531 - val_loss: 174.9141\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1315 - val_loss: 139.8533\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.8320 - val_loss: 149.9878\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7132 - val_loss: 146.0806\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.2404 - val_loss: 139.3562\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.9676 - val_loss: 139.5664\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3447 - val_loss: 133.2466\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.9020 - val_loss: 136.5420\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6022 - val_loss: 134.1116\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.0017 - val_loss: 136.1000\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8616 - val_loss: 165.8502\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.1927 - val_loss: 135.5520\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.6991 - val_loss: 136.1942\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6266 - val_loss: 136.3053\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.8328 - val_loss: 136.9102\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5422 - val_loss: 140.9230\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7457 - val_loss: 156.8732\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.3863 - val_loss: 145.2856\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.8741 - val_loss: 133.9000\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5479 - val_loss: 161.5309\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4734 - val_loss: 141.7188\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.9484 - val_loss: 135.1288\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6529 - val_loss: 147.9440\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.0510 - val_loss: 153.0415\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.5836 - val_loss: 150.0753\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1888 - val_loss: 561.2327\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5002 - val_loss: 143.1198\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.6080 - val_loss: 315.7234\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.5916 - val_loss: 176.5811\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.8409 - val_loss: 145.9870\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.3178 - val_loss: 145.2602\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.0049 - val_loss: 136.1838\n",
      "Epoch 2378/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.7821 - val_loss: 138.1326\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 117.127 - 0s 51us/step - loss: 117.2967 - val_loss: 193.2379\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.8486 - val_loss: 146.9868\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8212 - val_loss: 150.2908\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.8053 - val_loss: 164.7307\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.6428 - val_loss: 155.3078\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 282.6472 - val_loss: 142.0631\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9185 - val_loss: 170.3421\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.7437 - val_loss: 139.1703\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.1683 - val_loss: 147.8062\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.7653 - val_loss: 136.8441\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.0096 - val_loss: 154.3407\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.6303 - val_loss: 135.5227\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.9664 - val_loss: 143.9697\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.1073 - val_loss: 148.4245\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.2359 - val_loss: 143.6171\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6600 - val_loss: 143.3054\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 143.7065 - val_loss: 141.3963\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.8270 - val_loss: 159.3304\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 113.4235 - val_loss: 165.9749\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 113.7929 - val_loss: 140.2321\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.2673 - val_loss: 173.4681\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3877 - val_loss: 154.4838\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3779 - val_loss: 135.3171\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.1090 - val_loss: 221.4370\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.2666 - val_loss: 139.5692\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 115.6129 - val_loss: 163.0495\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.0488 - val_loss: 141.3429\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 143.1602 - val_loss: 178.0707\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 139.5201 - val_loss: 155.5462\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.1656 - val_loss: 143.8249\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.7369 - val_loss: 161.5716\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.4721 - val_loss: 139.1650\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.1722 - val_loss: 152.4357\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7024 - val_loss: 134.8143\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.6105 - val_loss: 205.6576\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.8794 - val_loss: 146.4133\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6482 - val_loss: 161.3382\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.2480 - val_loss: 133.5838\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3696 - val_loss: 253.4431\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.8927 - val_loss: 136.2025\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9580 - val_loss: 149.6958\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.0152 - val_loss: 134.1390\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.4476 - val_loss: 152.8987\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.5890 - val_loss: 143.8894\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8937 - val_loss: 139.4548\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3837 - val_loss: 158.0367\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.4371 - val_loss: 139.6096\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6033 - val_loss: 143.0812\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 266.9108 - val_loss: 138.0777\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.6906 - val_loss: 140.6567\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.6439 - val_loss: 140.1678\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.9577 - val_loss: 136.0177\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.9710 - val_loss: 135.7059\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.9987 - val_loss: 140.9913\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.3688 - val_loss: 161.5152\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.6900 - val_loss: 163.9747\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.6707 - val_loss: 137.3762\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.1178 - val_loss: 155.1284\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.2420 - val_loss: 140.9574\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9255 - val_loss: 179.0920\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5865 - val_loss: 168.8221\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.5616 - val_loss: 152.6971\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7354 - val_loss: 140.7187\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.2122 - val_loss: 134.1174\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.3754 - val_loss: 150.4771\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3466 - val_loss: 140.1080\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.3462 - val_loss: 138.3465\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.6329 - val_loss: 138.4514\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0227 - val_loss: 131.9020\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9018 - val_loss: 148.7268\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9767 - val_loss: 135.0937\n",
      "Epoch 2450/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.3250 - val_loss: 188.9956\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.3721 - val_loss: 134.5473\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.0991 - val_loss: 136.0017\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.6733 - val_loss: 133.6651\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.2974 - val_loss: 160.5596\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.7542 - val_loss: 149.9762\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8620 - val_loss: 140.5617\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3359 - val_loss: 140.0467\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.7186 - val_loss: 133.8868\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.3291 - val_loss: 166.4691\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4243 - val_loss: 165.8088\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8511 - val_loss: 199.8584\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2841 - val_loss: 161.7059\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.5670 - val_loss: 141.8036\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.0960 - val_loss: 133.8326\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.9676 - val_loss: 132.3613\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.9410 - val_loss: 139.5854\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.2910 - val_loss: 138.9036\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8574 - val_loss: 173.4939\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.8505 - val_loss: 136.0836\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.0596 - val_loss: 157.4893\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.7247 - val_loss: 155.6041\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.9018 - val_loss: 150.0875\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4518 - val_loss: 154.4672\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.4645 - val_loss: 163.0609\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6062 - val_loss: 153.8644\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.1379 - val_loss: 169.3187\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.6767 - val_loss: 132.5569\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 114.5906 - val_loss: 144.5281\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 116.6809 - val_loss: 129.4968\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 120.5218 - val_loss: 156.5184\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0361 - val_loss: 206.0526\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.2000 - val_loss: 148.7468\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.1320 - val_loss: 148.3387\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3809 - val_loss: 165.7012\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3984 - val_loss: 158.9664\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9010 - val_loss: 144.6900\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.4623 - val_loss: 137.8905\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.1531 - val_loss: 133.5837\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5988 - val_loss: 158.8715\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3112 - val_loss: 132.6898\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.7806 - val_loss: 148.6910\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0914 - val_loss: 142.3596\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.5650 - val_loss: 139.0802\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.5877 - val_loss: 138.9656\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.6142 - val_loss: 145.6253\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.8098 - val_loss: 147.0650\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1060 - val_loss: 201.7333\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.9746 - val_loss: 145.4822\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4119 - val_loss: 155.8309\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.9928 - val_loss: 143.5354\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.6085 - val_loss: 142.1183\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.3193 - val_loss: 147.7386\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.3227 - val_loss: 135.2539\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.6297 - val_loss: 156.8070\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.3436 - val_loss: 140.5957\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9884 - val_loss: 139.8323\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.9205 - val_loss: 158.9250\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3514 - val_loss: 136.8696\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.2476 - val_loss: 133.8135\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.8419 - val_loss: 145.9522\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.4134 - val_loss: 137.8745\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.6713 - val_loss: 146.5483\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 116.726 - 0s 50us/step - loss: 116.6633 - val_loss: 139.1694\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6505 - val_loss: 158.0746\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 204.2977 - val_loss: 200.8058\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.1985 - val_loss: 154.6375\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5603 - val_loss: 153.8417\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.5258 - val_loss: 176.6828\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.0803 - val_loss: 145.6721\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8048 - val_loss: 147.1369\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.3606 - val_loss: 154.9418\n",
      "Epoch 2522/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.6597 - val_loss: 132.9295\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9095 - val_loss: 168.7127\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.2676 - val_loss: 151.6473\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.1080 - val_loss: 140.9646\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5404 - val_loss: 156.8784\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3945 - val_loss: 142.6520\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6831 - val_loss: 218.9047\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0889 - val_loss: 147.7537\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.6589 - val_loss: 148.0822\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.5405 - val_loss: 151.7507\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.0090 - val_loss: 135.5527\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.9234 - val_loss: 142.4275\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.6159 - val_loss: 132.7447\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7022 - val_loss: 131.4107\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.2047 - val_loss: 142.8049\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.5178 - val_loss: 136.6842\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.3858 - val_loss: 139.8428\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6026 - val_loss: 156.1076\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.4168 - val_loss: 138.4184\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.5052 - val_loss: 148.0664\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.1665 - val_loss: 136.9786\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.0304 - val_loss: 136.2150\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.0436 - val_loss: 151.5992\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8525 - val_loss: 156.7214\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.5195 - val_loss: 141.1061\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.8216 - val_loss: 227.8417\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.6036 - val_loss: 154.6614\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.0589 - val_loss: 135.9236\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8954 - val_loss: 139.2865\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 114.2914 - val_loss: 135.0240\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 114.1370 - val_loss: 154.8245\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 116.3727 - val_loss: 135.2675\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.4667 - val_loss: 142.1190\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.3714 - val_loss: 142.5544\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.9641 - val_loss: 143.5768\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9669 - val_loss: 146.9944\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8370 - val_loss: 164.5645\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7916 - val_loss: 139.2460\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0902 - val_loss: 134.6537\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5459 - val_loss: 150.6891\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.2444 - val_loss: 165.7511\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.0966 - val_loss: 185.3153\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8075 - val_loss: 131.6844\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.4630 - val_loss: 137.9763\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1465 - val_loss: 152.8629\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.9460 - val_loss: 144.7028\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.3379 - val_loss: 138.5331\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.5829 - val_loss: 141.1247\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.8158 - val_loss: 143.8958\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.2274 - val_loss: 147.2605\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3073 - val_loss: 143.5051\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.9498 - val_loss: 151.9728\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.7447 - val_loss: 171.5398\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5057 - val_loss: 141.3337\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.2846 - val_loss: 143.3965\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8457 - val_loss: 151.3813\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.5709 - val_loss: 171.2742\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.1848 - val_loss: 148.7877\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.2360 - val_loss: 139.9525\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7533 - val_loss: 137.5143\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3442 - val_loss: 185.0956\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.4565 - val_loss: 140.0171\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1481 - val_loss: 143.5806\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.9579 - val_loss: 144.4418\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.4011 - val_loss: 157.8267\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.8305 - val_loss: 179.9642\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9375 - val_loss: 195.9914\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9232 - val_loss: 132.9291\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.2428 - val_loss: 152.2022\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.8588 - val_loss: 156.0177\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.1956 - val_loss: 133.7176\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.7957 - val_loss: 166.7096\n",
      "Epoch 2594/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2544 - val_loss: 138.0043\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5769 - val_loss: 178.9480\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.7332 - val_loss: 136.9577\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8317 - val_loss: 182.7109\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4527 - val_loss: 144.0123\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.7796 - val_loss: 148.6234\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 129.7123 - val_loss: 185.1058\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 123.7742 - val_loss: 143.7593\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4650 - val_loss: 153.5697\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.2968 - val_loss: 178.2666\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.6727 - val_loss: 147.8987\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.0918 - val_loss: 185.7377\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.1107 - val_loss: 149.4579\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 152.576 - 0s 51us/step - loss: 152.8167 - val_loss: 190.8971\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.1844 - val_loss: 178.2971\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.4676 - val_loss: 162.8101\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0623 - val_loss: 137.6214\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5125 - val_loss: 148.1618\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.8552 - val_loss: 137.7391\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0129 - val_loss: 133.7809\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.1714 - val_loss: 153.2548\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8012 - val_loss: 139.3513\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.5742 - val_loss: 140.4800\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.7202 - val_loss: 140.0523\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.6756 - val_loss: 151.3109\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0601 - val_loss: 168.6441\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3123 - val_loss: 143.3817\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.4838 - val_loss: 148.2321\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.0743 - val_loss: 137.8593\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.1057 - val_loss: 159.1042\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.5254 - val_loss: 151.1173\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.5797 - val_loss: 152.5208\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8624 - val_loss: 136.4395\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.7890 - val_loss: 181.7395\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2295 - val_loss: 134.5496\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.2221 - val_loss: 161.9145\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.9095 - val_loss: 145.7905\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.7192 - val_loss: 138.1551\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.3699 - val_loss: 144.3669\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.3077 - val_loss: 140.8239\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.8003 - val_loss: 271.8954\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 193.6030 - val_loss: 144.8224\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 143.1254 - val_loss: 144.4462\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 142.1279 - val_loss: 146.7405\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.2225 - val_loss: 138.7034\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 117.5497 - val_loss: 153.3338\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.7853 - val_loss: 135.7651\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.1626 - val_loss: 133.0037\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.8555 - val_loss: 133.5765\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.9351 - val_loss: 139.7331\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 111.8283 - val_loss: 134.4692\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.4175 - val_loss: 180.2285\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.9632 - val_loss: 155.7971\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2456 - val_loss: 139.1634\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.8382 - val_loss: 139.7317\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6564 - val_loss: 148.4909\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.6430 - val_loss: 147.7601\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0940 - val_loss: 165.6083\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.2628 - val_loss: 140.3357\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7700 - val_loss: 143.2315\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.5583 - val_loss: 159.7288\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.0167 - val_loss: 179.6477\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.1982 - val_loss: 142.3436\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.9755 - val_loss: 143.8031\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.4610 - val_loss: 138.0191\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.5397 - val_loss: 136.6353\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.1186 - val_loss: 148.6921\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.2060 - val_loss: 134.3686\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.8642 - val_loss: 136.4228\n",
      "Epoch 2663/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.7535 - val_loss: 136.1689\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.8839 - val_loss: 152.5431\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.9259 - val_loss: 150.4900\n",
      "Epoch 2666/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.1852 - val_loss: 137.8133\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.6071 - val_loss: 138.8771\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.5859 - val_loss: 144.6956\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.9601 - val_loss: 134.5743\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.5142 - val_loss: 139.0225\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.7138 - val_loss: 140.2393\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.9042 - val_loss: 183.7558\n",
      "Epoch 2673/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.0106 - val_loss: 136.8271\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7840 - val_loss: 137.3554\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3011 - val_loss: 147.1887\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 114.7047 - val_loss: 133.6628\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 140.6876 - val_loss: 142.6637\n",
      "Epoch 2678/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.6504 - val_loss: 139.5031\n",
      "Epoch 2679/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.9156 - val_loss: 151.8921\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.3609 - val_loss: 164.1459\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 115.4084 - val_loss: 154.8965\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.0601 - val_loss: 149.2370\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.4823 - val_loss: 145.8231\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.1454 - val_loss: 151.8757\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.4126 - val_loss: 148.7684\n",
      "Epoch 2686/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.6041 - val_loss: 182.5153\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.9232 - val_loss: 140.0146\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.5014 - val_loss: 429.5285\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 203.0492 - val_loss: 147.7761\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.0686 - val_loss: 140.0699\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8127 - val_loss: 142.6218\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.0214 - val_loss: 153.9847\n",
      "Epoch 2693/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.7725 - val_loss: 158.8708\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 124.6660 - val_loss: 141.5162\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7480 - val_loss: 146.6997\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.1375 - val_loss: 135.4411\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 111.3128 - val_loss: 135.9984\n",
      "Epoch 2698/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 124.5376 - val_loss: 143.1497\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 119.2442 - val_loss: 142.6727\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4019 - val_loss: 153.4824\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7647 - val_loss: 156.8489\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.7232 - val_loss: 161.3252\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.1736 - val_loss: 151.8213\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1593 - val_loss: 146.8062\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7993 - val_loss: 136.9516\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4317 - val_loss: 173.0064\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.7413 - val_loss: 160.3118\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2687 - val_loss: 177.6749\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7489 - val_loss: 163.5060\n",
      "Epoch 2710/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.2709 - val_loss: 137.8321\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.5227 - val_loss: 158.8012\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.9372 - val_loss: 136.3628\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.2195 - val_loss: 227.2097\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.1843 - val_loss: 143.0686\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.9284 - val_loss: 152.7947\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8251 - val_loss: 153.6735\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.8087 - val_loss: 141.2305\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.9935 - val_loss: 141.0183\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.4133 - val_loss: 162.5197\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.8075 - val_loss: 181.3817\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2941 - val_loss: 134.9497\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.9871 - val_loss: 161.2951\n",
      "Epoch 2723/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.4800 - val_loss: 168.1486\n",
      "Epoch 2724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.2691 - val_loss: 140.2808\n",
      "Epoch 2725/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.2266 - val_loss: 151.0728\n",
      "Epoch 2726/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.0098 - val_loss: 135.2275\n",
      "Epoch 2727/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3848 - val_loss: 136.3359\n",
      "Epoch 2728/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.7626 - val_loss: 147.5717\n",
      "Epoch 2729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9101 - val_loss: 235.7549\n",
      "Epoch 2730/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.1685 - val_loss: 140.0475\n",
      "Epoch 2731/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.0761 - val_loss: 134.4068\n",
      "Epoch 2732/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.2515 - val_loss: 160.2301\n",
      "Epoch 2733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.4013 - val_loss: 141.5291\n",
      "Epoch 2734/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.6963 - val_loss: 143.5146\n",
      "Epoch 2735/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.9824 - val_loss: 269.0438\n",
      "Epoch 2736/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.4156 - val_loss: 138.7266\n",
      "Epoch 2737/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.5663 - val_loss: 155.0199\n",
      "Epoch 2738/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.4889 - val_loss: 137.3935\n",
      "Epoch 2739/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.1758 - val_loss: 137.6961\n",
      "Epoch 2740/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.4202 - val_loss: 179.6942\n",
      "Epoch 2741/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.8562 - val_loss: 164.5579\n",
      "Epoch 2742/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.1377 - val_loss: 150.6761\n",
      "Epoch 2743/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.4098 - val_loss: 186.2748\n",
      "Epoch 2744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0356 - val_loss: 149.4143\n",
      "Epoch 2745/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.2246 - val_loss: 159.8868\n",
      "Epoch 2746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2409 - val_loss: 149.0319\n",
      "Epoch 2747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4422 - val_loss: 179.2588\n",
      "Epoch 2748/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9822 - val_loss: 146.7791\n",
      "Epoch 2749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7648 - val_loss: 147.5549\n",
      "Epoch 2750/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.3777 - val_loss: 138.9013\n",
      "Epoch 2751/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3271 - val_loss: 132.8669\n",
      "Epoch 2752/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.5234 - val_loss: 160.5254\n",
      "Epoch 2753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.7047 - val_loss: 140.2826\n",
      "Epoch 2754/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.1973 - val_loss: 152.1416\n",
      "Epoch 2755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6682 - val_loss: 142.5624\n",
      "Epoch 2756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.8745 - val_loss: 141.3922\n",
      "Epoch 2757/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0113 - val_loss: 137.5930\n",
      "Epoch 2758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4888 - val_loss: 191.3625\n",
      "Epoch 2759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.6029 - val_loss: 134.4032\n",
      "Epoch 2760/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.1101 - val_loss: 134.9102\n",
      "Epoch 2761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.5892 - val_loss: 147.9232\n",
      "Epoch 2762/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 119.067 - 0s 51us/step - loss: 118.7375 - val_loss: 159.3740\n",
      "Epoch 2763/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.2667 - val_loss: 139.8947\n",
      "Epoch 2764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.9528 - val_loss: 146.7909\n",
      "Epoch 2765/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.4629 - val_loss: 134.2578\n",
      "Epoch 2766/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1157 - val_loss: 211.1724\n",
      "Epoch 2767/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.9974 - val_loss: 138.7154\n",
      "Epoch 2768/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3621 - val_loss: 140.7127\n",
      "Epoch 2769/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.3760 - val_loss: 143.3146\n",
      "Epoch 2770/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 115.0838 - val_loss: 158.7476\n",
      "Epoch 2771/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 118.5375 - val_loss: 151.5411\n",
      "Epoch 2772/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 119.1995 - val_loss: 158.8906\n",
      "Epoch 2773/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.5365 - val_loss: 133.3751\n",
      "Epoch 2774/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.4069 - val_loss: 214.6345\n",
      "Epoch 2775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 250.6079 - val_loss: 140.9637\n",
      "Epoch 2776/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1463 - val_loss: 148.8959\n",
      "Epoch 2777/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6503 - val_loss: 140.6056\n",
      "Epoch 2778/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2226 - val_loss: 139.6105\n",
      "Epoch 2779/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7652 - val_loss: 167.5211\n",
      "Epoch 2780/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.6271 - val_loss: 131.4212\n",
      "Epoch 2781/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.1100 - val_loss: 149.4342\n",
      "Epoch 2782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.4047 - val_loss: 143.3881\n",
      "Epoch 2783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.4511 - val_loss: 148.6641\n",
      "Epoch 2784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.7280 - val_loss: 133.2185\n",
      "Epoch 2785/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.8157 - val_loss: 136.3067\n",
      "Epoch 2786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.0767 - val_loss: 133.7026\n",
      "Epoch 2787/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.4647 - val_loss: 145.7890\n",
      "Epoch 2788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8358 - val_loss: 137.2551- ETA: 0s - loss: 13\n",
      "Epoch 2789/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.4229 - val_loss: 146.6927\n",
      "Epoch 2790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0213 - val_loss: 176.7676\n",
      "Epoch 2791/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.7328 - val_loss: 162.1563\n",
      "Epoch 2792/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.7163 - val_loss: 142.0410\n",
      "Epoch 2793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5761 - val_loss: 150.0931\n",
      "Epoch 2794/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.7896 - val_loss: 155.7493\n",
      "Epoch 2795/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.0417 - val_loss: 135.4503\n",
      "Epoch 2796/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.6434 - val_loss: 146.2242\n",
      "Epoch 2797/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 119.8338 - val_loss: 143.0360\n",
      "Epoch 2798/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2141 - val_loss: 162.0971\n",
      "Epoch 2799/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.8856 - val_loss: 148.1190\n",
      "Epoch 2800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9014 - val_loss: 147.9923\n",
      "Epoch 2801/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.2112 - val_loss: 180.4686\n",
      "Epoch 2802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8049 - val_loss: 148.9093\n",
      "Epoch 2803/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 228.7274 - val_loss: 182.7542\n",
      "Epoch 2804/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4530 - val_loss: 146.8276\n",
      "Epoch 2805/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6945 - val_loss: 215.6836\n",
      "Epoch 2806/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.4792 - val_loss: 203.9111\n",
      "Epoch 2807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9467 - val_loss: 137.6101\n",
      "Epoch 2808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.5542 - val_loss: 147.7475\n",
      "Epoch 2809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.4110 - val_loss: 175.5160\n",
      "Epoch 2810/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.9756 - val_loss: 140.9085\n",
      "Epoch 2811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.7470 - val_loss: 144.1520\n",
      "Epoch 2812/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.7977 - val_loss: 160.9397\n",
      "Epoch 2813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.2925 - val_loss: 143.9921\n",
      "Epoch 2814/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3164 - val_loss: 169.4017\n",
      "Epoch 2815/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.2262 - val_loss: 140.9126\n",
      "Epoch 2816/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.8805 - val_loss: 177.9634\n",
      "Epoch 2817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1688 - val_loss: 135.8646\n",
      "Epoch 2818/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.7635 - val_loss: 134.3854\n",
      "Epoch 2819/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3884 - val_loss: 145.5653\n",
      "Epoch 2820/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.5054 - val_loss: 156.7044\n",
      "Epoch 2821/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.0542 - val_loss: 157.2736\n",
      "Epoch 2822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.5732 - val_loss: 156.4408\n",
      "Epoch 2823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.5209 - val_loss: 144.2962\n",
      "Epoch 2824/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2413 - val_loss: 142.7782\n",
      "Epoch 2825/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.7236 - val_loss: 145.4449\n",
      "Epoch 2826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7162 - val_loss: 136.0238\n",
      "Epoch 2827/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.6163 - val_loss: 140.8730\n",
      "Epoch 2828/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.2585 - val_loss: 136.8179\n",
      "Epoch 2829/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2339 - val_loss: 142.0245\n",
      "Epoch 2830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5962 - val_loss: 134.7962\n",
      "Epoch 2831/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.4161 - val_loss: 140.6204\n",
      "Epoch 2832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9221 - val_loss: 165.8407\n",
      "Epoch 2833/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.6706 - val_loss: 159.0419\n",
      "Epoch 2834/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 113.9132 - val_loss: 135.9920\n",
      "Epoch 2835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5954 - val_loss: 137.6497\n",
      "Epoch 2836/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0249 - val_loss: 147.6402\n",
      "Epoch 2837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.8354 - val_loss: 140.1167\n",
      "Epoch 2838/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 114.694 - 0s 50us/step - loss: 116.5606 - val_loss: 160.5799\n",
      "Epoch 2839/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.5400 - val_loss: 133.3344\n",
      "Epoch 2840/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.8698 - val_loss: 141.8807\n",
      "Epoch 2841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3507 - val_loss: 140.7861\n",
      "Epoch 2842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4389 - val_loss: 166.2340\n",
      "Epoch 2843/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 124.0240 - val_loss: 191.0218\n",
      "Epoch 2844/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.2147 - val_loss: 136.5998\n",
      "Epoch 2845/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 114.5088 - val_loss: 157.9570\n",
      "Epoch 2846/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.1768 - val_loss: 145.0401\n",
      "Epoch 2847/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9603 - val_loss: 197.4332\n",
      "Epoch 2848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.0862 - val_loss: 203.6484\n",
      "Epoch 2849/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.2457 - val_loss: 150.6357\n",
      "Epoch 2850/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.0845 - val_loss: 142.4170\n",
      "Epoch 2851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.3327 - val_loss: 132.7333\n",
      "Epoch 2852/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.4157 - val_loss: 142.8510\n",
      "Epoch 2853/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.4710 - val_loss: 140.4271\n",
      "Epoch 2854/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.4040 - val_loss: 146.8228\n",
      "Epoch 2855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.2980 - val_loss: 142.9742\n",
      "Epoch 2856/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.1325 - val_loss: 132.5044\n",
      "Epoch 2857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.9670 - val_loss: 172.1606\n",
      "Epoch 2858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4622 - val_loss: 149.9145\n",
      "Epoch 2859/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.7313 - val_loss: 158.6358\n",
      "Epoch 2860/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2122 - val_loss: 144.5596\n",
      "Epoch 2861/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4144 - val_loss: 140.5466\n",
      "Epoch 2862/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.3445 - val_loss: 151.5069\n",
      "Epoch 2863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.8030 - val_loss: 148.3745\n",
      "Epoch 2864/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.7619 - val_loss: 177.5324\n",
      "Epoch 2865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.8372 - val_loss: 149.7642\n",
      "Epoch 2866/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0080 - val_loss: 155.6963\n",
      "Epoch 2867/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.0884 - val_loss: 143.0949\n",
      "Epoch 2868/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.2314 - val_loss: 137.5655\n",
      "Epoch 2869/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.8006 - val_loss: 179.6597\n",
      "Epoch 2870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4512 - val_loss: 151.9503\n",
      "Epoch 2871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.8167 - val_loss: 152.3133\n",
      "Epoch 2872/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.8377 - val_loss: 162.1808\n",
      "Epoch 2873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4361 - val_loss: 173.0621\n",
      "Epoch 2874/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.5866 - val_loss: 157.5667\n",
      "Epoch 2875/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5205 - val_loss: 167.8468\n",
      "Epoch 2876/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.5728 - val_loss: 152.1890\n",
      "Epoch 2877/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.0300 - val_loss: 162.8200\n",
      "Epoch 2878/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.5224 - val_loss: 134.2028\n",
      "Epoch 2879/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8226 - val_loss: 157.7007\n",
      "Epoch 2880/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.1540 - val_loss: 143.7815\n",
      "Epoch 2881/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.1858 - val_loss: 133.4217\n",
      "Epoch 2882/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.1192 - val_loss: 184.4231\n",
      "Epoch 2883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6848 - val_loss: 145.3658\n",
      "Epoch 2884/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.3503 - val_loss: 178.1027\n",
      "Epoch 2885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3025 - val_loss: 132.4291\n",
      "Epoch 2886/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7828 - val_loss: 141.1128\n",
      "Epoch 2887/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.4777 - val_loss: 144.7602\n",
      "Epoch 2888/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.1678 - val_loss: 139.1807\n",
      "Epoch 2889/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.8048 - val_loss: 140.9551\n",
      "Epoch 2890/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.8895 - val_loss: 159.1437\n",
      "Epoch 2891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.8476 - val_loss: 143.0450\n",
      "Epoch 2892/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.6334 - val_loss: 147.9281\n",
      "Epoch 2893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.7634 - val_loss: 154.1462- ETA: 0s - loss: 116\n",
      "Epoch 2894/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.9587 - val_loss: 161.8561ETA: 0s - loss: 129\n",
      "Epoch 2895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7227 - val_loss: 171.3258\n",
      "Epoch 2896/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.5427 - val_loss: 161.2738\n",
      "Epoch 2897/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.3619 - val_loss: 166.5681\n",
      "Epoch 2898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.0735 - val_loss: 137.1685\n",
      "Epoch 2899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.3114 - val_loss: 159.1333\n",
      "Epoch 2900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.2970 - val_loss: 142.1740\n",
      "Epoch 2901/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.5812 - val_loss: 136.4895\n",
      "Epoch 2902/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 120.3985 - val_loss: 138.7270\n",
      "Epoch 2903/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.7576 - val_loss: 143.4696\n",
      "Epoch 2904/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.5588 - val_loss: 179.1683\n",
      "Epoch 2905/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.7214 - val_loss: 276.5027\n",
      "Epoch 2906/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.3506 - val_loss: 149.0907\n",
      "Epoch 2907/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.8576 - val_loss: 157.3834\n",
      "Epoch 2908/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.1786 - val_loss: 159.6600\n",
      "Epoch 2909/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.3651 - val_loss: 153.1432\n",
      "Epoch 2910/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.5447 - val_loss: 173.8625\n",
      "Epoch 2911/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.0443 - val_loss: 156.6822\n",
      "Epoch 2912/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.0746 - val_loss: 137.5328\n",
      "Epoch 2913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.8638 - val_loss: 157.2549\n",
      "Epoch 2914/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3964 - val_loss: 155.9017\n",
      "Epoch 2915/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.3711 - val_loss: 139.5489\n",
      "Epoch 2916/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 105.0918 - val_loss: 140.3265\n",
      "Epoch 2917/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 109.1223 - val_loss: 131.4580\n",
      "Epoch 2918/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 109.2514 - val_loss: 133.1762\n",
      "Epoch 2919/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 112.2355 - val_loss: 133.9573\n",
      "Epoch 2920/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.6063 - val_loss: 156.2489\n",
      "Epoch 2921/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.8959 - val_loss: 194.5184\n",
      "Epoch 2922/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.4691 - val_loss: 139.0595\n",
      "Epoch 2923/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.0341 - val_loss: 145.5049\n",
      "Epoch 2924/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.6268 - val_loss: 139.0728\n",
      "Epoch 2925/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.7224 - val_loss: 145.7691\n",
      "Epoch 2926/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.7150 - val_loss: 147.6662\n",
      "Epoch 2927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.0813 - val_loss: 135.3516\n",
      "Epoch 2928/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.5209 - val_loss: 137.1177\n",
      "Epoch 2929/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.9120 - val_loss: 135.3140\n",
      "Epoch 2930/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.1365 - val_loss: 150.1356\n",
      "Epoch 2931/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.7741 - val_loss: 133.7574\n",
      "Epoch 2932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.8853 - val_loss: 167.1180\n",
      "Epoch 2933/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.9249 - val_loss: 136.6450\n",
      "Epoch 2934/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.4468 - val_loss: 168.8365\n",
      "Epoch 2935/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6581 - val_loss: 149.1231\n",
      "Epoch 2936/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 109.8078 - val_loss: 141.1496\n",
      "Epoch 2937/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.6041 - val_loss: 135.9277\n",
      "Epoch 2938/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.3358 - val_loss: 140.8644\n",
      "Epoch 2939/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.5049 - val_loss: 139.7326\n",
      "Epoch 2940/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.7099 - val_loss: 150.5815\n",
      "Epoch 2941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.1777 - val_loss: 161.8312\n",
      "Epoch 2942/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9177 - val_loss: 138.5607\n",
      "Epoch 2943/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.7407 - val_loss: 150.5630\n",
      "Epoch 2944/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.6057 - val_loss: 134.6696\n",
      "Epoch 2945/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.5429 - val_loss: 208.0478\n",
      "Epoch 2946/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.8022 - val_loss: 158.1099\n",
      "Epoch 2947/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.5878 - val_loss: 195.6498\n",
      "Epoch 2948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.8674 - val_loss: 165.0243\n",
      "Epoch 2949/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.9316 - val_loss: 146.6847\n",
      "Epoch 2950/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.7680 - val_loss: 142.0295\n",
      "Epoch 2951/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6466 - val_loss: 268.7255\n",
      "Epoch 2952/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6467 - val_loss: 135.6236\n",
      "Epoch 2953/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.5171 - val_loss: 161.6302\n",
      "Epoch 2954/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9140 - val_loss: 132.7247\n",
      "Epoch 2955/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.4723 - val_loss: 166.6840\n",
      "Epoch 2956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.5972 - val_loss: 131.0522\n",
      "Epoch 2957/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.4788 - val_loss: 143.1828\n",
      "Epoch 2958/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.6627 - val_loss: 160.0063\n",
      "Epoch 2959/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.0144 - val_loss: 154.3486\n",
      "Epoch 2960/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.1684 - val_loss: 133.8056\n",
      "Epoch 2961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1008 - val_loss: 146.6312\n",
      "Epoch 2962/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.6435 - val_loss: 152.9104\n",
      "Epoch 2963/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.8027 - val_loss: 141.6435\n",
      "Epoch 2964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.7121 - val_loss: 160.1788\n",
      "Epoch 2965/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0549 - val_loss: 150.1225\n",
      "Epoch 2966/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 119.7447 - val_loss: 153.7050\n",
      "Epoch 2967/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.6592 - val_loss: 138.3075\n",
      "Epoch 2968/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3892 - val_loss: 136.4215\n",
      "Epoch 2969/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 168.4438 - val_loss: 227.2493\n",
      "Epoch 2970/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 126.6919 - val_loss: 180.6075\n",
      "Epoch 2971/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.8478 - val_loss: 186.7232\n",
      "Epoch 2972/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6588 - val_loss: 142.1647\n",
      "Epoch 2973/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.1187 - val_loss: 154.9854\n",
      "Epoch 2974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1480 - val_loss: 143.1848\n",
      "Epoch 2975/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.1843 - val_loss: 183.0981\n",
      "Epoch 2976/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.2255 - val_loss: 146.1652\n",
      "Epoch 2977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.1098 - val_loss: 160.5142\n",
      "Epoch 2978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0902 - val_loss: 184.7930\n",
      "Epoch 2979/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.0817 - val_loss: 139.0665\n",
      "Epoch 2980/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.5693 - val_loss: 153.3936\n",
      "Epoch 2981/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.1008 - val_loss: 133.4158- ETA: 0s - loss: 140\n",
      "Epoch 2982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.9111 - val_loss: 175.9893\n",
      "Epoch 2983/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.7272 - val_loss: 146.0840\n",
      "Epoch 2984/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.4715 - val_loss: 143.8423\n",
      "Epoch 2985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.1735 - val_loss: 148.0336\n",
      "Epoch 2986/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.4578 - val_loss: 162.6957\n",
      "Epoch 2987/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.9312 - val_loss: 143.8205\n",
      "Epoch 2988/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.0894 - val_loss: 136.5835\n",
      "Epoch 2989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.6342 - val_loss: 129.4597\n",
      "Epoch 2990/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 118.7137 - val_loss: 143.6469\n",
      "Epoch 2991/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 114.3226 - val_loss: 136.3040\n",
      "Epoch 2992/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 117.9840 - val_loss: 138.3670\n",
      "Epoch 2993/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.1859 - val_loss: 138.0078\n",
      "Epoch 2994/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.4809 - val_loss: 137.8369\n",
      "Epoch 2995/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.2738 - val_loss: 141.3951\n",
      "Epoch 2996/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 115.4235 - val_loss: 133.7989\n",
      "Epoch 2997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.1858 - val_loss: 153.0719\n",
      "Epoch 2998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.5510 - val_loss: 158.5772\n",
      "Epoch 2999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7353 - val_loss: 140.3953\n",
      "Epoch 3000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.7347 - val_loss: 145.5471\n",
      "Epoch 3001/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.4591 - val_loss: 151.5909\n",
      "Epoch 3002/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.0846 - val_loss: 135.1659\n",
      "Epoch 3003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.8313 - val_loss: 184.7477\n",
      "Epoch 3004/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.8188 - val_loss: 135.3729\n",
      "Epoch 3005/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.3735 - val_loss: 146.1454\n",
      "Epoch 3006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.0829 - val_loss: 142.7355\n",
      "Epoch 3007/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 109.8696 - val_loss: 197.6595\n",
      "Epoch 3008/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.5236 - val_loss: 164.8679\n",
      "Epoch 3009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.4231 - val_loss: 147.6701\n",
      "Epoch 3010/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.5772 - val_loss: 139.3317\n",
      "Epoch 3011/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.2977 - val_loss: 137.6287\n",
      "Epoch 3012/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 113.571 - 0s 51us/step - loss: 113.4754 - val_loss: 129.4104\n",
      "Epoch 3013/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.4019 - val_loss: 150.3536\n",
      "Epoch 3014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0687 - val_loss: 154.5859\n",
      "Epoch 3015/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.6796 - val_loss: 154.7292\n",
      "Epoch 3016/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3814 - val_loss: 144.8879\n",
      "Epoch 3017/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.6001 - val_loss: 140.4878\n",
      "Epoch 3018/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.4858 - val_loss: 145.9915\n",
      "Epoch 3019/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.1267 - val_loss: 155.3554\n",
      "Epoch 3020/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 124.121 - 0s 51us/step - loss: 123.7249 - val_loss: 152.8465\n",
      "Epoch 3021/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.8137 - val_loss: 158.7538\n",
      "Epoch 3022/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.3920 - val_loss: 195.9520\n",
      "Epoch 3023/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3284 - val_loss: 143.9860\n",
      "Epoch 3024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.0198 - val_loss: 179.3796\n",
      "Epoch 3025/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9441 - val_loss: 133.0375\n",
      "Epoch 3026/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.0977 - val_loss: 138.2452\n",
      "Epoch 3027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4593 - val_loss: 164.3908\n",
      "Epoch 3028/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.3745 - val_loss: 152.5058\n",
      "Epoch 3029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.0446 - val_loss: 140.9085\n",
      "Epoch 3030/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.4183 - val_loss: 176.0396\n",
      "Epoch 3031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5320 - val_loss: 142.0583\n",
      "Epoch 3032/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.4974 - val_loss: 137.0801\n",
      "Epoch 3033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.3174 - val_loss: 136.9059\n",
      "Epoch 3034/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.5103 - val_loss: 154.4790\n",
      "Epoch 3035/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5375 - val_loss: 138.4784\n",
      "Epoch 3036/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.5224 - val_loss: 136.8183\n",
      "Epoch 3037/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.0809 - val_loss: 161.0975\n",
      "Epoch 3038/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.2393 - val_loss: 171.4858\n",
      "Epoch 3039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.5484 - val_loss: 186.4649\n",
      "Epoch 3040/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.5466 - val_loss: 160.2606\n",
      "Epoch 3041/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.0192 - val_loss: 149.4880\n",
      "Epoch 3042/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.1466 - val_loss: 219.8382\n",
      "Epoch 3043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.4923 - val_loss: 148.6456\n",
      "Epoch 3044/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.1062 - val_loss: 170.7798\n",
      "Epoch 3045/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.5682 - val_loss: 146.9320\n",
      "Epoch 3046/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.5805 - val_loss: 144.5997\n",
      "Epoch 3047/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1273 - val_loss: 149.5384\n",
      "Epoch 3048/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.8244 - val_loss: 142.5341\n",
      "Epoch 3049/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.6928 - val_loss: 152.2870\n",
      "Epoch 3050/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.5401 - val_loss: 187.7361\n",
      "Epoch 3051/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 121.6596 - val_loss: 137.7195\n",
      "Epoch 3052/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.7484 - val_loss: 138.6939\n",
      "Epoch 3053/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.1304 - val_loss: 139.7797\n",
      "Epoch 3054/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0071 - val_loss: 175.2252\n",
      "Epoch 3055/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.5850 - val_loss: 140.5035\n",
      "Epoch 3056/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.6188 - val_loss: 181.8999\n",
      "Epoch 3057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.6499 - val_loss: 144.1950\n",
      "Epoch 3058/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.3803 - val_loss: 136.2994\n",
      "Epoch 3059/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.2037 - val_loss: 190.5341\n",
      "Epoch 3060/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.3954 - val_loss: 133.1889\n",
      "Epoch 3061/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.7740 - val_loss: 137.2525\n",
      "Epoch 3062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1203 - val_loss: 139.2300\n",
      "Epoch 3063/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 106.5512 - val_loss: 131.8893\n",
      "Epoch 3064/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 109.8586 - val_loss: 136.7813\n",
      "Epoch 3065/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 120.3524 - val_loss: 156.6113\n",
      "Epoch 3066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.8521 - val_loss: 134.3874\n",
      "Epoch 3067/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.1727 - val_loss: 136.1278\n",
      "Epoch 3068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.2275 - val_loss: 137.6680\n",
      "Epoch 3069/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.0036 - val_loss: 146.9790\n",
      "Epoch 3070/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.7567 - val_loss: 146.7792\n",
      "Epoch 3071/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.6141 - val_loss: 135.8360\n",
      "Epoch 3072/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.5588 - val_loss: 135.9768\n",
      "Epoch 3073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8994 - val_loss: 142.7695\n",
      "Epoch 3074/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.7214 - val_loss: 143.3457\n",
      "Epoch 3075/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.0288 - val_loss: 139.1083\n",
      "Epoch 3076/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.5377 - val_loss: 147.2718\n",
      "Epoch 3077/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4435 - val_loss: 136.0798\n",
      "Epoch 3078/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.8509 - val_loss: 172.3405\n",
      "Epoch 3079/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8307 - val_loss: 140.2940\n",
      "Epoch 3080/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 111.5212 - val_loss: 172.3381\n",
      "Epoch 3081/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.1530 - val_loss: 148.4748\n",
      "Epoch 3082/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.0874 - val_loss: 190.6085\n",
      "Epoch 3083/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7924 - val_loss: 138.1611\n",
      "Epoch 3084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.2433 - val_loss: 136.0275\n",
      "Epoch 3085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1814 - val_loss: 140.1853\n",
      "Epoch 3086/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.7484 - val_loss: 144.6811\n",
      "Epoch 3087/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.3382 - val_loss: 133.0421\n",
      "Epoch 3088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.7355 - val_loss: 137.5682\n",
      "Epoch 3089/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.6024 - val_loss: 255.1976\n",
      "Epoch 3090/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 114.3666 - val_loss: 151.7347\n",
      "Epoch 3091/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.2703 - val_loss: 143.0654\n",
      "Epoch 3092/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.1196 - val_loss: 139.6821\n",
      "Epoch 3093/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.5102 - val_loss: 133.2978\n",
      "Epoch 3094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.0204 - val_loss: 149.0178\n",
      "Epoch 3095/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.7958 - val_loss: 148.8289\n",
      "Epoch 3096/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.6807 - val_loss: 152.5169\n",
      "Epoch 3097/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.6693 - val_loss: 147.6878- ETA: 0s - loss: 107\n",
      "Epoch 3098/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.9622 - val_loss: 162.0353\n",
      "Epoch 3099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6168 - val_loss: 134.7343\n",
      "Epoch 3100/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.2406 - val_loss: 202.3087\n",
      "Epoch 3101/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.7480 - val_loss: 148.8669\n",
      "Epoch 3102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6535 - val_loss: 143.1305\n",
      "Epoch 3103/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.4032 - val_loss: 178.1250\n",
      "Epoch 3104/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.1205 - val_loss: 145.7668\n",
      "Epoch 3105/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.1426 - val_loss: 148.9415\n",
      "Epoch 3106/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 158.3330 - val_loss: 171.8341\n",
      "Epoch 3107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2251 - val_loss: 145.7811\n",
      "Epoch 3108/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.5211 - val_loss: 210.2650\n",
      "Epoch 3109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.3451 - val_loss: 150.3411\n",
      "Epoch 3110/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.4451 - val_loss: 153.4546\n",
      "Epoch 3111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.3093 - val_loss: 176.0480\n",
      "Epoch 3112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.7829 - val_loss: 142.4980\n",
      "Epoch 3113/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.1341 - val_loss: 152.4950\n",
      "Epoch 3114/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.4441 - val_loss: 143.5393\n",
      "Epoch 3115/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.3155 - val_loss: 142.8437\n",
      "Epoch 3116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.9996 - val_loss: 138.5207\n",
      "Epoch 3117/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.0282 - val_loss: 149.4717\n",
      "Epoch 3118/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.4745 - val_loss: 184.5078\n",
      "Epoch 3119/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.7657 - val_loss: 138.1000\n",
      "Epoch 3120/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.6831 - val_loss: 134.8395\n",
      "Epoch 3121/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.1839 - val_loss: 133.3546\n",
      "Epoch 3122/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.5293 - val_loss: 138.5959\n",
      "Epoch 3123/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.2301 - val_loss: 138.1362\n",
      "Epoch 3124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.8771 - val_loss: 153.2662\n",
      "Epoch 3125/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.4779 - val_loss: 165.4825\n",
      "Epoch 3126/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.1541 - val_loss: 202.1713\n",
      "Epoch 3127/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.8075 - val_loss: 157.1195\n",
      "Epoch 3128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.0921 - val_loss: 147.1598\n",
      "Epoch 3129/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.4669 - val_loss: 144.9343\n",
      "Epoch 3130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8036 - val_loss: 165.4275\n",
      "Epoch 3131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.0708 - val_loss: 189.1952\n",
      "Epoch 3132/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.8749 - val_loss: 162.7430\n",
      "Epoch 3133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.8996 - val_loss: 143.4216\n",
      "Epoch 3134/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.6213 - val_loss: 163.3307\n",
      "Epoch 3135/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.3793 - val_loss: 201.0064\n",
      "Epoch 3136/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 107.2873 - val_loss: 140.8920\n",
      "Epoch 3137/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 113.9987 - val_loss: 152.2325\n",
      "Epoch 3138/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 112.0268 - val_loss: 144.4847\n",
      "Epoch 3139/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.5380 - val_loss: 146.2187\n",
      "Epoch 3140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6144 - val_loss: 152.6197\n",
      "Epoch 3141/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.6311 - val_loss: 147.4989\n",
      "Epoch 3142/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 134.9281 - val_loss: 136.2504\n",
      "Epoch 3143/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 122.0741 - val_loss: 141.7080\n",
      "Epoch 3144/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 113.2069 - val_loss: 156.2919\n",
      "Epoch 3145/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 108.9161 - val_loss: 139.0063\n",
      "Epoch 3146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.9688 - val_loss: 168.9622\n",
      "Epoch 3147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2235 - val_loss: 166.6637\n",
      "Epoch 3148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8147 - val_loss: 156.6082\n",
      "Epoch 3149/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8936 - val_loss: 187.2697\n",
      "Epoch 3150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4807 - val_loss: 138.3343\n",
      "Epoch 3151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8954 - val_loss: 147.3399\n",
      "Epoch 3152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0430 - val_loss: 139.6240\n",
      "Epoch 3153/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.4152 - val_loss: 145.5850\n",
      "Epoch 3154/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.6404 - val_loss: 140.3804\n",
      "Epoch 3155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7758 - val_loss: 151.9062\n",
      "Epoch 3156/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8888 - val_loss: 140.8782\n",
      "Epoch 3157/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.3152 - val_loss: 160.9146\n",
      "Epoch 3158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.0024 - val_loss: 138.8559\n",
      "Epoch 3159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.4863 - val_loss: 148.3246\n",
      "Epoch 3160/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.6721 - val_loss: 134.6451\n",
      "Epoch 3161/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.0944 - val_loss: 169.4176\n",
      "Epoch 3162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.9236 - val_loss: 144.2283\n",
      "Epoch 3163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.9440 - val_loss: 141.7323\n",
      "Epoch 3164/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 240.4542 - val_loss: 172.0600\n",
      "Epoch 3165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5235 - val_loss: 140.0112\n",
      "Epoch 3166/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.5178 - val_loss: 136.3494\n",
      "Epoch 3167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.0573 - val_loss: 153.9243\n",
      "Epoch 3168/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7382 - val_loss: 151.3051\n",
      "Epoch 3169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.0918 - val_loss: 134.1034\n",
      "Epoch 3170/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.4511 - val_loss: 143.4807\n",
      "Epoch 3171/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.7073 - val_loss: 133.0068\n",
      "Epoch 3172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0561 - val_loss: 140.6007\n",
      "Epoch 3173/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 104.8974 - val_loss: 149.8054\n",
      "Epoch 3174/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.5857 - val_loss: 150.2459\n",
      "Epoch 3175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.8448 - val_loss: 184.7894\n",
      "Epoch 3176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.0689 - val_loss: 134.4306\n",
      "Epoch 3177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.1835 - val_loss: 149.7435\n",
      "Epoch 3178/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.7892 - val_loss: 138.9686\n",
      "Epoch 3179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.4290 - val_loss: 167.4971\n",
      "Epoch 3180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.8488 - val_loss: 140.8010\n",
      "Epoch 3181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.4780 - val_loss: 151.1177\n",
      "Epoch 3182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.2867 - val_loss: 161.6793\n",
      "Epoch 3183/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.4111 - val_loss: 137.6558\n",
      "Epoch 3184/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.2400 - val_loss: 197.7715\n",
      "Epoch 3185/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.6015 - val_loss: 162.1146\n",
      "Epoch 3186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.4766 - val_loss: 151.1937\n",
      "Epoch 3187/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.5567 - val_loss: 178.4766\n",
      "Epoch 3188/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.7247 - val_loss: 174.0227\n",
      "Epoch 3189/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4955 - val_loss: 183.9356\n",
      "Epoch 3190/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.3462 - val_loss: 139.2103\n",
      "Epoch 3191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.2180 - val_loss: 130.5970\n",
      "Epoch 3192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0881 - val_loss: 153.5340\n",
      "Epoch 3193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.3590 - val_loss: 139.7907\n",
      "Epoch 3194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.2161 - val_loss: 135.5241\n",
      "Epoch 3195/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.4444 - val_loss: 175.9527\n",
      "Epoch 3196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.6299 - val_loss: 144.1923\n",
      "Epoch 3197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7026 - val_loss: 159.9873\n",
      "Epoch 3198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.7322 - val_loss: 146.2887\n",
      "Epoch 3199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.9795 - val_loss: 147.7810\n",
      "Epoch 3200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.8918 - val_loss: 226.4405\n",
      "Epoch 3201/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.4831 - val_loss: 150.6884\n",
      "Epoch 3202/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0698 - val_loss: 163.6956\n",
      "Epoch 3203/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.4311 - val_loss: 136.9568\n",
      "Epoch 3204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.6888 - val_loss: 133.9969\n",
      "Epoch 3205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.4045 - val_loss: 139.2190\n",
      "Epoch 3206/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.2945 - val_loss: 146.3230\n",
      "Epoch 3207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2729 - val_loss: 153.1564\n",
      "Epoch 3208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.7432 - val_loss: 136.2881\n",
      "Epoch 3209/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 126.3157 - val_loss: 149.4068\n",
      "Epoch 3210/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 119.960 - 1s 77us/step - loss: 120.3074 - val_loss: 161.0641\n",
      "Epoch 3211/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 115.9078 - val_loss: 135.9477\n",
      "Epoch 3212/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 117.832 - 0s 51us/step - loss: 117.3285 - val_loss: 145.5150\n",
      "Epoch 3213/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.2897 - val_loss: 139.4191\n",
      "Epoch 3214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.6969 - val_loss: 156.0197\n",
      "Epoch 3215/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.3985 - val_loss: 135.7917\n",
      "Epoch 3216/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.0865 - val_loss: 142.6821\n",
      "Epoch 3217/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.9434 - val_loss: 144.2206\n",
      "Epoch 3218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.1857 - val_loss: 142.8864\n",
      "Epoch 3219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.0776 - val_loss: 134.7663\n",
      "Epoch 3220/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.7083 - val_loss: 143.2515\n",
      "Epoch 3221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.2593 - val_loss: 155.2129\n",
      "Epoch 3222/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.9226 - val_loss: 148.1011\n",
      "Epoch 3223/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.6068 - val_loss: 153.5313\n",
      "Epoch 3224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 103.3118 - val_loss: 153.0340\n",
      "Epoch 3225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.5900 - val_loss: 144.7604\n",
      "Epoch 3226/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.6845 - val_loss: 132.0324\n",
      "Epoch 3227/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.0434 - val_loss: 248.3340\n",
      "Epoch 3228/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 114.5388 - val_loss: 144.4986\n",
      "Epoch 3229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.3014 - val_loss: 139.7552\n",
      "Epoch 3230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.4750 - val_loss: 143.9074\n",
      "Epoch 3231/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 106.3152 - val_loss: 138.4943\n",
      "Epoch 3232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.2104 - val_loss: 172.8847\n",
      "Epoch 3233/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.0903 - val_loss: 192.5694\n",
      "Epoch 3234/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.9471 - val_loss: 138.2596\n",
      "Epoch 3235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.2239 - val_loss: 151.8341\n",
      "Epoch 3236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.2476 - val_loss: 135.2886\n",
      "Epoch 3237/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7984 - val_loss: 174.1281\n",
      "Epoch 3238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.3513 - val_loss: 143.4064\n",
      "Epoch 3239/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.6634 - val_loss: 134.5801\n",
      "Epoch 3240/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 198.4757 - val_loss: 148.4998\n",
      "Epoch 3241/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.4031 - val_loss: 151.6162\n",
      "Epoch 3242/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.4912 - val_loss: 133.6903\n",
      "Epoch 3243/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.6989 - val_loss: 147.3693\n",
      "Epoch 3244/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.7408 - val_loss: 163.9832\n",
      "Epoch 3245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.8174 - val_loss: 183.0301\n",
      "Epoch 3246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.4641 - val_loss: 137.5898\n",
      "Epoch 3247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.8877 - val_loss: 140.4654\n",
      "Epoch 3248/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.3718 - val_loss: 146.9952\n",
      "Epoch 3249/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.6954 - val_loss: 160.5169\n",
      "Epoch 3250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.5522 - val_loss: 140.1917\n",
      "Epoch 3251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.2618 - val_loss: 143.7102\n",
      "Epoch 3252/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0626 - val_loss: 146.8414\n",
      "Epoch 3253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.5002 - val_loss: 134.4647\n",
      "Epoch 3254/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.3464 - val_loss: 140.9973\n",
      "Epoch 3255/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1049 - val_loss: 177.1842\n",
      "Epoch 3256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6465 - val_loss: 136.3303\n",
      "Epoch 3257/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.6284 - val_loss: 141.9624\n",
      "Epoch 3258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.4766 - val_loss: 147.0202\n",
      "Epoch 3259/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.2976 - val_loss: 134.6021\n",
      "Epoch 3260/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.7553 - val_loss: 198.2493\n",
      "Epoch 3261/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.3981 - val_loss: 132.9013\n",
      "Epoch 3262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.7871 - val_loss: 134.3864\n",
      "Epoch 3263/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 108.4171 - val_loss: 139.5261\n",
      "Epoch 3264/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.3216 - val_loss: 154.5091\n",
      "Epoch 3265/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.0229 - val_loss: 162.6745\n",
      "Epoch 3266/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3697 - val_loss: 166.9639\n",
      "Epoch 3267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.1983 - val_loss: 181.3557\n",
      "Epoch 3268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.6618 - val_loss: 143.7083\n",
      "Epoch 3269/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.7435 - val_loss: 153.6433\n",
      "Epoch 3270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.3235 - val_loss: 135.1236\n",
      "Epoch 3271/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.7563 - val_loss: 165.3882\n",
      "Epoch 3272/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.4133 - val_loss: 161.3870\n",
      "Epoch 3273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.7912 - val_loss: 132.8415\n",
      "Epoch 3274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.4656 - val_loss: 142.1863\n",
      "Epoch 3275/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.7122 - val_loss: 161.0983\n",
      "Epoch 3276/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.2212 - val_loss: 143.7578\n",
      "Epoch 3277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7156 - val_loss: 173.4280\n",
      "Epoch 3278/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.5137 - val_loss: 134.0730\n",
      "Epoch 3279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.6090 - val_loss: 139.4336\n",
      "Epoch 3280/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.3551 - val_loss: 138.6623\n",
      "Epoch 3281/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 112.6856 - val_loss: 156.4291\n",
      "Epoch 3282/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 109.9985 - val_loss: 137.6999\n",
      "Epoch 3283/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 112.4782 - val_loss: 158.3452\n",
      "Epoch 3284/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 109.3105 - val_loss: 133.7599\n",
      "Epoch 3285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.1402 - val_loss: 136.9612\n",
      "Epoch 3286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.6510 - val_loss: 144.5907\n",
      "Epoch 3287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.5551 - val_loss: 158.7091\n",
      "Epoch 3288/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.2761 - val_loss: 137.4668\n",
      "Epoch 3289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7229 - val_loss: 147.7355\n",
      "Epoch 3290/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.2455 - val_loss: 161.3568\n",
      "Epoch 3291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.1027 - val_loss: 159.5560\n",
      "Epoch 3292/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.2508 - val_loss: 139.0225\n",
      "Epoch 3293/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.8720 - val_loss: 147.2165\n",
      "Epoch 3294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.8495 - val_loss: 138.4710\n",
      "Epoch 3295/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.8696 - val_loss: 145.8715\n",
      "Epoch 3296/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.7908 - val_loss: 147.5221\n",
      "Epoch 3297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2285 - val_loss: 141.1365\n",
      "Epoch 3298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.6803 - val_loss: 132.8088\n",
      "Epoch 3299/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.6183 - val_loss: 140.8484\n",
      "Epoch 3300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.4310 - val_loss: 224.5024\n",
      "Epoch 3301/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.3361 - val_loss: 168.2283\n",
      "Epoch 3302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.2855 - val_loss: 136.9217\n",
      "Epoch 3303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.2377 - val_loss: 195.1228\n",
      "Epoch 3304/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 157.403 - 0s 51us/step - loss: 156.6800 - val_loss: 143.9713\n",
      "Epoch 3305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2061 - val_loss: 167.1381\n",
      "Epoch 3306/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.3599 - val_loss: 150.8545\n",
      "Epoch 3307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1704 - val_loss: 142.3037\n",
      "Epoch 3308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.5099 - val_loss: 141.8128\n",
      "Epoch 3309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.0668 - val_loss: 133.1574\n",
      "Epoch 3310/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.3503 - val_loss: 137.6481\n",
      "Epoch 3311/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.3610 - val_loss: 167.2414\n",
      "Epoch 3312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.8267 - val_loss: 144.2166\n",
      "Epoch 3313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 102.9742 - val_loss: 137.9189\n",
      "Epoch 3314/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.4304 - val_loss: 150.7122\n",
      "Epoch 3315/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.3892 - val_loss: 174.3190\n",
      "Epoch 3316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9610 - val_loss: 140.5319\n",
      "Epoch 3317/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.3145 - val_loss: 365.5144\n",
      "Epoch 3318/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0006 - val_loss: 136.6328\n",
      "Epoch 3319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5397 - val_loss: 135.2630\n",
      "Epoch 3320/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.7242 - val_loss: 133.8317\n",
      "Epoch 3321/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8497 - val_loss: 144.5426\n",
      "Epoch 3322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.0905 - val_loss: 152.0461\n",
      "Epoch 3323/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.1061 - val_loss: 177.9116\n",
      "Epoch 3324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2201 - val_loss: 137.4875\n",
      "Epoch 3325/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.2054 - val_loss: 180.2787\n",
      "Epoch 3326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.1572 - val_loss: 132.8350\n",
      "Epoch 3327/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.8070 - val_loss: 146.6410A: 0s - loss: 1\n",
      "Epoch 3328/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.7908 - val_loss: 137.2035\n",
      "Epoch 3329/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 106.6029 - val_loss: 156.7349\n",
      "Epoch 3330/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.4895 - val_loss: 135.2621\n",
      "Epoch 3331/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.1157 - val_loss: 137.8685\n",
      "Epoch 3332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9357 - val_loss: 140.6681\n",
      "Epoch 3333/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.9471 - val_loss: 137.7543\n",
      "Epoch 3334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.8058 - val_loss: 151.2081\n",
      "Epoch 3335/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9756 - val_loss: 172.9938\n",
      "Epoch 3336/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.4909 - val_loss: 135.4450\n",
      "Epoch 3337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.8085 - val_loss: 162.6788\n",
      "Epoch 3338/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.4527 - val_loss: 148.4450\n",
      "Epoch 3339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.7674 - val_loss: 139.6900\n",
      "Epoch 3340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.5865 - val_loss: 187.6484\n",
      "Epoch 3341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.3642 - val_loss: 140.2817\n",
      "Epoch 3342/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 107.5066 - val_loss: 138.0187\n",
      "Epoch 3343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.5556 - val_loss: 161.6998\n",
      "Epoch 3344/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.2578 - val_loss: 143.1295\n",
      "Epoch 3345/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.8394 - val_loss: 171.2173\n",
      "Epoch 3346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.5191 - val_loss: 179.2539\n",
      "Epoch 3347/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.5112 - val_loss: 176.4933\n",
      "Epoch 3348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.1483 - val_loss: 147.0369\n",
      "Epoch 3349/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.3445 - val_loss: 135.4747\n",
      "Epoch 3350/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.4332 - val_loss: 134.6040\n",
      "Epoch 3351/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.1318 - val_loss: 143.9791\n",
      "Epoch 3352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 102.2760 - val_loss: 141.7857\n",
      "Epoch 3353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.4944 - val_loss: 134.5924\n",
      "Epoch 3354/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 108.6125 - val_loss: 229.7434\n",
      "Epoch 3355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.3181 - val_loss: 155.9508\n",
      "Epoch 3356/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.1523 - val_loss: 135.7201\n",
      "Epoch 3357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.0661 - val_loss: 155.1126\n",
      "Epoch 3358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.4352 - val_loss: 134.1228\n",
      "Epoch 3359/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 104.7118 - val_loss: 138.9888\n",
      "Epoch 3360/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.2420 - val_loss: 149.4711\n",
      "Epoch 3361/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.9377 - val_loss: 146.8173\n",
      "Epoch 3362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.7762 - val_loss: 133.2630\n",
      "Epoch 3363/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 105.0375 - val_loss: 145.0549\n",
      "Epoch 3364/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 104.3175 - val_loss: 163.0173\n",
      "Epoch 3365/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 109.9231 - val_loss: 139.9105\n",
      "Epoch 3366/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.7230 - val_loss: 228.9762\n",
      "Epoch 3367/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.0586 - val_loss: 147.9475\n",
      "Epoch 3368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.6039 - val_loss: 132.4657\n",
      "Epoch 3369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.3812 - val_loss: 140.4713\n",
      "Epoch 3370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.1317 - val_loss: 139.6023\n",
      "Epoch 3371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1227 - val_loss: 149.4026\n",
      "Epoch 3372/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.6204 - val_loss: 144.8434\n",
      "Epoch 3373/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 113.6810 - val_loss: 137.6326\n",
      "Epoch 3374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.3187 - val_loss: 180.9681\n",
      "Epoch 3375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.1077 - val_loss: 153.2387\n",
      "Epoch 3376/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.2416 - val_loss: 146.2238\n",
      "Epoch 3377/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.9171 - val_loss: 141.3899\n",
      "Epoch 3378/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.7929 - val_loss: 198.0582\n",
      "Epoch 3379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.6330 - val_loss: 132.4384\n",
      "Epoch 3380/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.6864 - val_loss: 188.8862\n",
      "Epoch 3381/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 106.6089 - val_loss: 145.3698\n",
      "Epoch 3382/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.0114 - val_loss: 244.6825\n",
      "Epoch 3383/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.1903 - val_loss: 163.6355\n",
      "Epoch 3384/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.4519 - val_loss: 144.0758\n",
      "Epoch 3385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.0243 - val_loss: 155.5161\n",
      "Epoch 3386/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3692 - val_loss: 164.5395\n",
      "Epoch 3387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.7655 - val_loss: 153.7326\n",
      "Epoch 3388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.0259 - val_loss: 219.5686\n",
      "Epoch 3389/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.2395 - val_loss: 141.9388\n",
      "Epoch 3390/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.7961 - val_loss: 142.5701\n",
      "Epoch 3391/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.1085 - val_loss: 138.1832\n",
      "Epoch 3392/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.0732 - val_loss: 159.7316\n",
      "Epoch 3393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.7811 - val_loss: 201.2782\n",
      "Epoch 3394/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.5416 - val_loss: 137.5209\n",
      "Epoch 3395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2904 - val_loss: 151.5962\n",
      "Epoch 3396/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.7683 - val_loss: 151.2764\n",
      "Epoch 3397/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.4343 - val_loss: 184.1697\n",
      "Epoch 3398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.2789 - val_loss: 161.5482\n",
      "Epoch 3399/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.0245 - val_loss: 163.7940\n",
      "Epoch 3400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.6694 - val_loss: 136.8165\n",
      "Epoch 3401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6485 - val_loss: 152.5948\n",
      "Epoch 3402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.2516 - val_loss: 205.4346\n",
      "Epoch 3403/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.6437 - val_loss: 129.8362\n",
      "Epoch 3404/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5678 - val_loss: 146.3804\n",
      "Epoch 3405/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.4115 - val_loss: 140.5305\n",
      "Epoch 3406/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.4875 - val_loss: 153.7015\n",
      "Epoch 3407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.6790 - val_loss: 169.2834\n",
      "Epoch 3408/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.9304 - val_loss: 161.3877\n",
      "Epoch 3409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 101.1973 - val_loss: 152.5800\n",
      "Epoch 3410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.2648 - val_loss: 137.5074\n",
      "Epoch 3411/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.3770 - val_loss: 136.7142\n",
      "Epoch 3412/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 101.7976 - val_loss: 158.5619\n",
      "Epoch 3413/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 105.5123 - val_loss: 138.6062\n",
      "Epoch 3414/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.2787 - val_loss: 153.4078\n",
      "Epoch 3415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5899 - val_loss: 134.4465\n",
      "Epoch 3416/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.0951 - val_loss: 132.1436\n",
      "Epoch 3417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.4461 - val_loss: 139.9370\n",
      "Epoch 3418/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8056 - val_loss: 165.3707\n",
      "Epoch 3419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.9048 - val_loss: 158.9642\n",
      "Epoch 3420/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.5877 - val_loss: 286.2531\n",
      "Epoch 3421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6182 - val_loss: 142.8046\n",
      "Epoch 3422/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 104.8756 - val_loss: 159.5220\n",
      "Epoch 3423/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4443 - val_loss: 143.4060\n",
      "Epoch 3424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 102.9174 - val_loss: 142.1815\n",
      "Epoch 3425/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 106.6685 - val_loss: 156.3471\n",
      "Epoch 3426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.9962 - val_loss: 139.4359\n",
      "Epoch 3427/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 106.0564 - val_loss: 139.4829\n",
      "Epoch 3428/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 101.7944 - val_loss: 140.0971\n",
      "Epoch 3429/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 113.1835 - val_loss: 132.6610\n",
      "Epoch 3430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.7626 - val_loss: 146.9511\n",
      "Epoch 3431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.8687 - val_loss: 187.5711\n",
      "Epoch 3432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.6558 - val_loss: 205.0014\n",
      "Epoch 3433/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3786 - val_loss: 151.4445\n",
      "Epoch 3434/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.0016 - val_loss: 151.0160\n",
      "Epoch 3435/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.8214 - val_loss: 157.1245\n",
      "Epoch 3436/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.7354 - val_loss: 170.2738\n",
      "Epoch 3437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5263 - val_loss: 131.9107\n",
      "Epoch 3438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 352.4848 - val_loss: 139.4059\n",
      "Epoch 3439/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1683 - val_loss: 174.2303\n",
      "Epoch 3440/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 108.5821 - val_loss: 134.2534\n",
      "Epoch 3441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.7925 - val_loss: 139.0432\n",
      "Epoch 3442/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 100.9577 - val_loss: 144.1003\n",
      "Epoch 3443/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.9904 - val_loss: 134.3116\n",
      "Epoch 3444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.9369 - val_loss: 142.8418\n",
      "Epoch 3445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.2291 - val_loss: 147.2170\n",
      "Epoch 3446/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 101.9087 - val_loss: 161.4170\n",
      "Epoch 3447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.0817 - val_loss: 133.6679\n",
      "Epoch 3448/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 102.1918 - val_loss: 181.1453\n",
      "Epoch 3449/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.7027 - val_loss: 137.3027\n",
      "Epoch 3450/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.7394 - val_loss: 222.5693\n",
      "Epoch 3451/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.3784 - val_loss: 153.3433\n",
      "Epoch 3452/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.1028 - val_loss: 167.1097\n",
      "Epoch 3453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 97.5797 - val_loss: 141.3578\n",
      "Epoch 3454/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.3194 - val_loss: 146.3959\n",
      "Epoch 3455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.5027 - val_loss: 146.6191\n",
      "Epoch 3456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.6610 - val_loss: 199.8772\n",
      "Epoch 3457/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.4677 - val_loss: 131.9325\n",
      "Epoch 3458/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.6598 - val_loss: 162.2092\n",
      "Epoch 3459/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.5323 - val_loss: 159.0827\n",
      "Epoch 3460/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.0548 - val_loss: 158.5694\n",
      "Epoch 3461/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.2644 - val_loss: 147.4843\n",
      "Epoch 3462/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.3143 - val_loss: 134.5973\n",
      "Epoch 3463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.4448 - val_loss: 134.5410\n",
      "Epoch 3464/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.3929 - val_loss: 143.1476\n",
      "Epoch 3465/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.9651 - val_loss: 149.5441\n",
      "Epoch 3466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.7325 - val_loss: 145.6467\n",
      "Epoch 3467/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.4654 - val_loss: 142.2201\n",
      "Epoch 3468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.4571 - val_loss: 158.9790\n",
      "Epoch 3469/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.5447 - val_loss: 150.1184\n",
      "Epoch 3470/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.3776 - val_loss: 132.0784\n",
      "Epoch 3471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.7039 - val_loss: 159.4103\n",
      "Epoch 3472/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.4452 - val_loss: 141.4629\n",
      "Epoch 3473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.6223 - val_loss: 133.4663\n",
      "Epoch 3474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.7582 - val_loss: 133.8309\n",
      "Epoch 3475/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.3821 - val_loss: 144.5925\n",
      "Epoch 3476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.9335 - val_loss: 141.1448\n",
      "Epoch 3477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.7241 - val_loss: 151.8120\n",
      "Epoch 3478/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.9059 - val_loss: 167.1483\n",
      "Epoch 3479/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.0077 - val_loss: 139.4404\n",
      "Epoch 3480/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.0403 - val_loss: 146.7117\n",
      "Epoch 3481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.8010 - val_loss: 147.1827\n",
      "Epoch 3482/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.7480 - val_loss: 136.4563\n",
      "Epoch 3483/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.5701 - val_loss: 163.6521\n",
      "Epoch 3484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.8575 - val_loss: 160.6738\n",
      "Epoch 3485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6208 - val_loss: 144.6619\n",
      "Epoch 3486/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.6671 - val_loss: 152.9494\n",
      "Epoch 3487/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 105.3443 - val_loss: 143.4472\n",
      "Epoch 3488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.0464 - val_loss: 138.1294\n",
      "Epoch 3489/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.8993 - val_loss: 165.7075\n",
      "Epoch 3490/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.3748 - val_loss: 153.0639\n",
      "Epoch 3491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.3935 - val_loss: 141.9864\n",
      "Epoch 3492/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 106.4318 - val_loss: 152.7837\n",
      "Epoch 3493/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.6249 - val_loss: 143.8962\n",
      "Epoch 3494/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.0867 - val_loss: 153.1151\n",
      "Epoch 3495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.2534 - val_loss: 147.6562\n",
      "Epoch 3496/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.8232 - val_loss: 203.2361\n",
      "Epoch 3497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.1276 - val_loss: 158.1574\n",
      "Epoch 3498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.0474 - val_loss: 162.7670\n",
      "Epoch 3499/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 122.6136 - val_loss: 213.3716\n",
      "Epoch 3500/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 111.5854 - val_loss: 146.2736\n",
      "Epoch 3501/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 112.0325 - val_loss: 138.7761\n",
      "Epoch 3502/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 143.4986 - val_loss: 165.8107\n",
      "Epoch 3503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.9723 - val_loss: 135.0632\n",
      "Epoch 3504/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.2761 - val_loss: 144.8571\n",
      "Epoch 3505/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 105.4251 - val_loss: 138.2696\n",
      "Epoch 3506/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5469 - val_loss: 237.9274\n",
      "Epoch 3507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.8500 - val_loss: 163.8510\n",
      "Epoch 3508/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.9514 - val_loss: 140.6972\n",
      "Epoch 3509/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.9998 - val_loss: 154.4318\n",
      "Epoch 3510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.7590 - val_loss: 253.2146\n",
      "Epoch 3511/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.6660 - val_loss: 151.3109\n",
      "Epoch 3512/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 105.9053 - val_loss: 147.2582\n",
      "Epoch 3513/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.9675 - val_loss: 167.3708\n",
      "Epoch 3514/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.0773 - val_loss: 178.8679\n",
      "Epoch 3515/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.3618 - val_loss: 151.9663\n",
      "Epoch 3516/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.3003 - val_loss: 137.2040\n",
      "Epoch 3517/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.1399 - val_loss: 145.6814\n",
      "Epoch 3518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.8910 - val_loss: 139.0933\n",
      "Epoch 3519/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 110.8844 - val_loss: 152.2827\n",
      "Epoch 3520/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.3191 - val_loss: 191.2938\n",
      "Epoch 3521/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.8491 - val_loss: 137.2449\n",
      "Epoch 3522/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.6083 - val_loss: 154.5707\n",
      "Epoch 3523/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.4610 - val_loss: 147.2612\n",
      "Epoch 3524/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.6662 - val_loss: 147.2596\n",
      "Epoch 3525/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.0306 - val_loss: 220.4423\n",
      "Epoch 3526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4902 - val_loss: 167.5519\n",
      "Epoch 3527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.4002 - val_loss: 135.2306\n",
      "Epoch 3528/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.4103 - val_loss: 138.7033\n",
      "Epoch 3529/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.3316 - val_loss: 137.1679\n",
      "Epoch 3530/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.9374 - val_loss: 153.6630\n",
      "Epoch 3531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 103.4545 - val_loss: 164.5951\n",
      "Epoch 3532/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.4378 - val_loss: 141.6719\n",
      "Epoch 3533/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3890 - val_loss: 140.0857\n",
      "Epoch 3534/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.1033 - val_loss: 138.9100\n",
      "Epoch 3535/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.4981 - val_loss: 151.9072\n",
      "Epoch 3536/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 102.8600 - val_loss: 150.1964\n",
      "Epoch 3537/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.4018 - val_loss: 160.8643\n",
      "Epoch 3538/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 110.8692 - val_loss: 161.7882\n",
      "Epoch 3539/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 106.6242 - val_loss: 140.5444\n",
      "Epoch 3540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 105.0220 - val_loss: 154.3340\n",
      "Epoch 3541/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.8158 - val_loss: 193.5871\n",
      "Epoch 3542/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.0825 - val_loss: 154.3844\n",
      "Epoch 3543/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.4960 - val_loss: 145.2771\n",
      "Epoch 3544/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.1042 - val_loss: 132.8077\n",
      "Epoch 3545/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 109.0521 - val_loss: 268.7052\n",
      "Epoch 3546/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.7810 - val_loss: 135.4383\n",
      "Epoch 3547/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.2077 - val_loss: 243.2493\n",
      "Epoch 3548/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.3910 - val_loss: 148.2433\n",
      "Epoch 3549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.7507 - val_loss: 134.3400\n",
      "Epoch 3550/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 103.7487 - val_loss: 150.5997\n",
      "Epoch 3551/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.6025 - val_loss: 167.4592\n",
      "Epoch 3552/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.5899 - val_loss: 153.4638\n",
      "Epoch 3553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.3859 - val_loss: 134.7016\n",
      "Epoch 3554/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 109.5681 - val_loss: 167.0233\n",
      "Epoch 3555/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 109.0707 - val_loss: 146.3686\n",
      "Epoch 3556/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 102.8559 - val_loss: 139.5316\n",
      "Epoch 3557/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.8073 - val_loss: 152.9050\n",
      "Epoch 3558/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.1491 - val_loss: 206.4069\n",
      "Epoch 3559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3205 - val_loss: 197.2517\n",
      "Epoch 3560/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 108.7386 - val_loss: 133.7463\n",
      "Epoch 3561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.1312 - val_loss: 165.5653\n",
      "Epoch 3562/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.8551 - val_loss: 129.7243\n",
      "Epoch 3563/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.5715 - val_loss: 144.2284\n",
      "Epoch 3564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.2395 - val_loss: 159.2373\n",
      "Epoch 3565/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 107.9390 - val_loss: 168.5916\n",
      "Epoch 3566/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.6935 - val_loss: 143.1829\n",
      "Epoch 3567/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 107.9421 - val_loss: 138.7474\n",
      "Epoch 3568/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.0225 - val_loss: 144.1178\n",
      "Epoch 3569/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.2118 - val_loss: 164.1136\n",
      "Epoch 3570/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 111.9525 - val_loss: 145.8283\n",
      "Epoch 3571/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 111.1345 - val_loss: 140.7809\n",
      "Epoch 3572/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 109.0892 - val_loss: 133.5702\n",
      "Epoch 3573/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 114.3862 - val_loss: 144.1309\n",
      "Epoch 3574/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 106.8185 - val_loss: 132.5269\n",
      "Epoch 3575/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 106.5032 - val_loss: 131.3581\n",
      "Epoch 3576/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 106.9734 - val_loss: 139.5472\n",
      "Epoch 3577/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.7297 - val_loss: 139.0735\n",
      "Epoch 3578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9527 - val_loss: 139.6207\n",
      "Epoch 3579/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.7219 - val_loss: 141.6953\n",
      "Epoch 3580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 104.0575 - val_loss: 142.9623\n",
      "Epoch 3581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.2278 - val_loss: 145.3853\n",
      "Epoch 3582/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.2853 - val_loss: 135.6499\n",
      "Epoch 3583/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 105.3370 - val_loss: 138.5952\n",
      "Epoch 3584/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.3766 - val_loss: 142.1565\n",
      "Epoch 3585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.0518 - val_loss: 175.4321\n",
      "Epoch 3586/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.6330 - val_loss: 138.6036\n",
      "Epoch 3587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6896 - val_loss: 153.5292\n",
      "Epoch 3588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.1091 - val_loss: 148.1094\n",
      "Epoch 3589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8255 - val_loss: 147.7355\n",
      "Epoch 3590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5995 - val_loss: 137.2694\n",
      "Epoch 3591/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8090 - val_loss: 312.4079\n",
      "Epoch 3592/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6591 - val_loss: 137.8615\n",
      "Epoch 3593/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.7649 - val_loss: 181.3722\n",
      "Epoch 3594/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.9903 - val_loss: 144.6527\n",
      "Epoch 3595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.1024 - val_loss: 146.6394\n",
      "Epoch 3596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.9582 - val_loss: 138.8290\n",
      "Epoch 3597/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.3335 - val_loss: 190.5814\n",
      "Epoch 3598/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.6284 - val_loss: 147.1553\n",
      "Epoch 3599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.9615 - val_loss: 140.1429\n",
      "Epoch 3600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3787 - val_loss: 158.3840\n",
      "Epoch 3601/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.4535 - val_loss: 131.7440\n",
      "Epoch 3602/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.6152 - val_loss: 134.7361\n",
      "Epoch 3603/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.0921 - val_loss: 138.9207\n",
      "Epoch 3604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.1145 - val_loss: 150.4487\n",
      "Epoch 3605/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 106.5429 - val_loss: 143.5453\n",
      "Epoch 3606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.2553 - val_loss: 144.6783\n",
      "Epoch 3607/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.7823 - val_loss: 134.7253\n",
      "Epoch 3608/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 108.6412 - val_loss: 145.6389\n",
      "Epoch 3609/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 106.7642 - val_loss: 139.8888\n",
      "Epoch 3610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.9526 - val_loss: 139.2549\n",
      "Epoch 3611/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9805 - val_loss: 137.5264\n",
      "Epoch 3612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.2261 - val_loss: 142.0357\n",
      "Epoch 3613/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3549 - val_loss: 196.4554\n",
      "Epoch 3614/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.9049 - val_loss: 139.0802\n",
      "Epoch 3615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 102.8196 - val_loss: 170.0167\n",
      "Epoch 3616/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.6538 - val_loss: 147.4301\n",
      "Epoch 3617/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4069 - val_loss: 147.3931\n",
      "Epoch 3618/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.4240 - val_loss: 188.8440\n",
      "Epoch 3619/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3934 - val_loss: 153.0044\n",
      "Epoch 3620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9753 - val_loss: 153.5471\n",
      "Epoch 3621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.1414 - val_loss: 187.5839\n",
      "Epoch 3622/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.2289 - val_loss: 156.2839\n",
      "Epoch 3623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.4176 - val_loss: 138.7550\n",
      "Epoch 3624/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 113.3276 - val_loss: 142.9776\n",
      "Epoch 3625/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 112.6836 - val_loss: 135.6218\n",
      "Epoch 3626/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.7983 - val_loss: 231.4763\n",
      "Epoch 3627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.7613 - val_loss: 146.6192\n",
      "Epoch 3628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.0888 - val_loss: 139.0916\n",
      "Epoch 3629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.7769 - val_loss: 136.6783\n",
      "Epoch 3630/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.6468 - val_loss: 168.5582\n",
      "Epoch 3631/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.3177 - val_loss: 159.4900\n",
      "Epoch 3632/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.6709 - val_loss: 211.5467\n",
      "Epoch 3633/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7267 - val_loss: 865.9413\n",
      "Epoch 3634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.9031 - val_loss: 139.8854\n",
      "Epoch 3635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.3779 - val_loss: 134.6468\n",
      "Epoch 3636/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 99.1559 - val_loss: 161.4340\n",
      "Epoch 3637/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 102.6681 - val_loss: 141.9680\n",
      "Epoch 3638/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 102.5834 - val_loss: 143.2153\n",
      "Epoch 3639/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.6358 - val_loss: 139.5870\n",
      "Epoch 3640/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 104.2301 - val_loss: 142.1363\n",
      "Epoch 3641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.2628 - val_loss: 151.4150\n",
      "Epoch 3642/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 111.1009 - val_loss: 133.2803\n",
      "Epoch 3643/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 111.8448 - val_loss: 155.6194\n",
      "Epoch 3644/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 115.8267 - val_loss: 149.5061\n",
      "Epoch 3645/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 110.7219 - val_loss: 157.4208\n",
      "Epoch 3646/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.5577 - val_loss: 156.4730\n",
      "Epoch 3647/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 115.848 - 0s 51us/step - loss: 116.2134 - val_loss: 145.2196\n",
      "Epoch 3648/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.7124 - val_loss: 144.7206\n",
      "Epoch 3649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.8702 - val_loss: 139.7145\n",
      "Epoch 3650/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8146 - val_loss: 240.1229\n",
      "Epoch 3651/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 106.7032 - val_loss: 139.2794\n",
      "Epoch 3652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.5702 - val_loss: 153.9601\n",
      "Epoch 3653/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.2506 - val_loss: 160.6890\n",
      "Epoch 3654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.7922 - val_loss: 151.7880\n",
      "Epoch 3655/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.8070 - val_loss: 161.2024\n",
      "Epoch 3656/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.1404 - val_loss: 133.0452\n",
      "Epoch 3657/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.9362 - val_loss: 169.4569\n",
      "Epoch 3658/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.2064 - val_loss: 138.8682\n",
      "Epoch 3659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3781 - val_loss: 161.7236\n",
      "Epoch 3660/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 106.2660 - val_loss: 137.4506\n",
      "Epoch 3661/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.3478 - val_loss: 150.0572\n",
      "Epoch 3662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 113.1936 - val_loss: 145.6793\n",
      "Epoch 3663/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.7582 - val_loss: 140.7377\n",
      "Epoch 3664/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 106.3738 - val_loss: 152.6346\n",
      "Epoch 3665/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 100.5311 - val_loss: 153.8395\n",
      "Epoch 3666/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.6016 - val_loss: 206.5595\n",
      "Epoch 3667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1417 - val_loss: 142.3547\n",
      "Epoch 3668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.7119 - val_loss: 146.5689\n",
      "Epoch 3669/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.0167 - val_loss: 160.1463\n",
      "Epoch 3670/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.1815 - val_loss: 145.2934\n",
      "Epoch 3671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.6618 - val_loss: 149.5496\n",
      "Epoch 3672/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.6784 - val_loss: 141.3216\n",
      "Epoch 3673/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.1913 - val_loss: 152.4006\n",
      "Epoch 3674/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.8098 - val_loss: 138.7295\n",
      "Epoch 3675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.0179 - val_loss: 141.8692\n",
      "Epoch 3676/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.5780 - val_loss: 202.9922\n",
      "Epoch 3677/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.9375 - val_loss: 141.0255\n",
      "Epoch 3678/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.9103 - val_loss: 162.2388\n",
      "Epoch 3679/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.7675 - val_loss: 156.5295\n",
      "Epoch 3680/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.2678 - val_loss: 173.7235\n",
      "Epoch 3681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.8890 - val_loss: 153.1925\n",
      "Epoch 3682/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.6607 - val_loss: 140.6561\n",
      "Epoch 3683/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.9023 - val_loss: 202.4325\n",
      "Epoch 3684/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5997 - val_loss: 148.4527\n",
      "Epoch 3685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3815 - val_loss: 149.3255\n",
      "Epoch 3686/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 105.1811 - val_loss: 135.6499\n",
      "Epoch 3687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.2671 - val_loss: 141.3803\n",
      "Epoch 3688/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 98.9666 - val_loss: 136.6465\n",
      "Epoch 3689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 105.0003 - val_loss: 158.6438\n",
      "Epoch 3690/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.2211 - val_loss: 140.5208\n",
      "Epoch 3691/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.6430 - val_loss: 169.0092\n",
      "Epoch 3692/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.2259 - val_loss: 132.6438\n",
      "Epoch 3693/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.1593 - val_loss: 190.7862\n",
      "Epoch 3694/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.4360 - val_loss: 164.7044\n",
      "Epoch 3695/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.8810 - val_loss: 155.9984\n",
      "Epoch 3696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.0468 - val_loss: 152.0735\n",
      "Epoch 3697/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.3335 - val_loss: 230.9659\n",
      "Epoch 3698/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.5006 - val_loss: 139.8410\n",
      "Epoch 3699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.8557 - val_loss: 169.5331\n",
      "Epoch 3700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.4379 - val_loss: 141.3297\n",
      "Epoch 3701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.5909 - val_loss: 141.8093\n",
      "Epoch 3702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.6908 - val_loss: 172.5351\n",
      "Epoch 3703/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.8546 - val_loss: 136.0098\n",
      "Epoch 3704/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.6531 - val_loss: 151.6490\n",
      "Epoch 3705/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.7870 - val_loss: 144.3369\n",
      "Epoch 3706/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.4361 - val_loss: 136.8881\n",
      "Epoch 3707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.5302 - val_loss: 138.8718\n",
      "Epoch 3708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.3806 - val_loss: 150.7347\n",
      "Epoch 3709/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.0804 - val_loss: 143.8625\n",
      "Epoch 3710/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.8798 - val_loss: 155.2408\n",
      "Epoch 3711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.2636 - val_loss: 134.1911\n",
      "Epoch 3712/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 103.6455 - val_loss: 130.7205\n",
      "Epoch 3713/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 110.5901 - val_loss: 170.5992\n",
      "Epoch 3714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.1084 - val_loss: 146.5061\n",
      "Epoch 3715/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 104.3709 - val_loss: 139.5472\n",
      "Epoch 3716/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 113.0545 - val_loss: 142.1331\n",
      "Epoch 3717/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 117.7739 - val_loss: 154.5088\n",
      "Epoch 3718/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 112.9089 - val_loss: 137.0060\n",
      "Epoch 3719/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.4864 - val_loss: 155.2457\n",
      "Epoch 3720/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.6721 - val_loss: 152.8016\n",
      "Epoch 3721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 101.6082 - val_loss: 168.5089\n",
      "Epoch 3722/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.7659 - val_loss: 139.2527\n",
      "Epoch 3723/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.4506 - val_loss: 147.8208\n",
      "Epoch 3724/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 106.3242 - val_loss: 142.3129\n",
      "Epoch 3725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 104.3787 - val_loss: 155.8596\n",
      "Epoch 3726/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.6510 - val_loss: 140.9587\n",
      "Epoch 3727/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.4610 - val_loss: 181.6217\n",
      "Epoch 3728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.9420 - val_loss: 142.8967\n",
      "Epoch 3729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.3941 - val_loss: 141.3558\n",
      "Epoch 3730/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 102.5749 - val_loss: 140.6980\n",
      "Epoch 3731/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.9117 - val_loss: 136.1970\n",
      "Epoch 3732/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.6057 - val_loss: 133.4139\n",
      "Epoch 3733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.4527 - val_loss: 135.6079\n",
      "Epoch 3734/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 101.4963 - val_loss: 140.9788\n",
      "Epoch 3735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.9332 - val_loss: 147.0953\n",
      "Epoch 3736/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.8796 - val_loss: 143.7004\n",
      "Epoch 3737/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.2555 - val_loss: 135.3392\n",
      "Epoch 3738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.3506 - val_loss: 155.5487\n",
      "Epoch 3739/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.7908 - val_loss: 140.7466\n",
      "Epoch 3740/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 231.2799 - val_loss: 227.9611\n",
      "Epoch 3741/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.4663 - val_loss: 156.0600\n",
      "Epoch 3742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.4988 - val_loss: 136.6476\n",
      "Epoch 3743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.6555 - val_loss: 138.5763\n",
      "Epoch 3744/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.5421 - val_loss: 165.3937\n",
      "Epoch 3745/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.4078 - val_loss: 173.7659\n",
      "Epoch 3746/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.0888 - val_loss: 143.5520\n",
      "Epoch 3747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.9648 - val_loss: 146.5753\n",
      "Epoch 3748/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 101.4097 - val_loss: 156.2232\n",
      "Epoch 3749/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.4474 - val_loss: 134.0068\n",
      "Epoch 3750/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 102.7499 - val_loss: 160.3918\n",
      "Epoch 3751/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 107.0742 - val_loss: 142.0000\n",
      "Epoch 3752/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 112.8040 - val_loss: 135.8396\n",
      "Epoch 3753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.0507 - val_loss: 139.8413\n",
      "Epoch 3754/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.2918 - val_loss: 146.4061\n",
      "Epoch 3755/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.9468 - val_loss: 176.2580\n",
      "Epoch 3756/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.3070 - val_loss: 258.4761\n",
      "Epoch 3757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9542 - val_loss: 137.9125\n",
      "Epoch 3758/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.5597 - val_loss: 137.9559\n",
      "Epoch 3759/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.1947 - val_loss: 147.9575\n",
      "Epoch 3760/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.4827 - val_loss: 146.2628\n",
      "Epoch 3761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.8677 - val_loss: 150.3762\n",
      "Epoch 3762/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 103.1258 - val_loss: 149.1311\n",
      "Epoch 3763/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 113.4839 - val_loss: 135.8305\n",
      "Epoch 3764/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 104.9205 - val_loss: 137.1167\n",
      "Epoch 3765/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 107.3268 - val_loss: 137.1166\n",
      "Epoch 3766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.9719 - val_loss: 177.4513\n",
      "Epoch 3767/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.9784 - val_loss: 145.4341\n",
      "Epoch 3768/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.2634 - val_loss: 165.4887\n",
      "Epoch 3769/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.8715 - val_loss: 166.9672\n",
      "Epoch 3770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.4271 - val_loss: 136.3628\n",
      "Epoch 3771/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.1037 - val_loss: 137.6902\n",
      "Epoch 3772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.2816 - val_loss: 156.9811\n",
      "Epoch 3773/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8787 - val_loss: 144.0257\n",
      "Epoch 3774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.2889 - val_loss: 149.7563\n",
      "Epoch 3775/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.6366 - val_loss: 155.0593\n",
      "Epoch 3776/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.5992 - val_loss: 135.6794\n",
      "Epoch 3777/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.6821 - val_loss: 138.1600\n",
      "Epoch 3778/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.6811 - val_loss: 133.8959\n",
      "Epoch 3779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.2220 - val_loss: 147.6963\n",
      "Epoch 3780/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.8275 - val_loss: 133.4463\n",
      "Epoch 3781/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.3222 - val_loss: 211.1439\n",
      "Epoch 3782/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.4493 - val_loss: 137.9623\n",
      "Epoch 3783/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 111.3612 - val_loss: 145.7905\n",
      "Epoch 3784/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.1716 - val_loss: 217.3764\n",
      "Epoch 3785/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.4443 - val_loss: 132.8353\n",
      "Epoch 3786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.4955 - val_loss: 167.7781\n",
      "Epoch 3787/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 100.5809 - val_loss: 139.6418\n",
      "Epoch 3788/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 103.5217 - val_loss: 153.4926\n",
      "Epoch 3789/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 106.7738 - val_loss: 133.7197\n",
      "Epoch 3790/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.1968 - val_loss: 161.7056\n",
      "Epoch 3791/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 100.1747 - val_loss: 139.6072\n",
      "Epoch 3792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.2080 - val_loss: 179.4215\n",
      "Epoch 3793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 100.9514 - val_loss: 148.7922\n",
      "Epoch 3794/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.1841 - val_loss: 143.6059\n",
      "Epoch 3795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4290 - val_loss: 141.7372\n",
      "Epoch 3796/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 103.1400 - val_loss: 152.1134\n",
      "Epoch 3797/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.1432 - val_loss: 144.5793\n",
      "Epoch 3798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 102.7214 - val_loss: 181.1619\n",
      "Epoch 3799/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.2185 - val_loss: 158.8879\n",
      "Epoch 3800/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.5622 - val_loss: 143.4726\n",
      "Epoch 3801/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 240.8942 - val_loss: 218.4428\n",
      "Epoch 3802/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 116.604 - 0s 51us/step - loss: 116.6992 - val_loss: 174.8594\n",
      "Epoch 3803/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.0702 - val_loss: 140.2128\n",
      "Epoch 3804/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.5494 - val_loss: 141.3961\n",
      "Epoch 3805/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.3667 - val_loss: 141.7013\n",
      "Epoch 3806/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.9067 - val_loss: 167.5557\n",
      "Epoch 3807/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.5553 - val_loss: 148.2296\n",
      "Epoch 3808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.0988 - val_loss: 168.0814\n",
      "Epoch 3809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.2462 - val_loss: 136.4576\n",
      "Epoch 3810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.9291 - val_loss: 159.2497\n",
      "Epoch 3811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 105.0990 - val_loss: 147.6090\n",
      "Epoch 3812/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.7823 - val_loss: 171.8827\n",
      "Epoch 3813/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.8409 - val_loss: 146.2458\n",
      "Epoch 3814/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.5083 - val_loss: 169.3143\n",
      "Epoch 3815/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.7061 - val_loss: 158.1913\n",
      "Epoch 3816/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.2299 - val_loss: 152.2212\n",
      "Epoch 3817/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.7220 - val_loss: 152.0448\n",
      "Epoch 3818/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.3133 - val_loss: 142.5602\n",
      "Epoch 3819/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.0348 - val_loss: 166.9980\n",
      "Epoch 3820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.9856 - val_loss: 175.1063\n",
      "Epoch 3821/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 106.0593 - val_loss: 143.8475\n",
      "Epoch 3822/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9240 - val_loss: 146.4406\n",
      "Epoch 3823/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 112.791 - 0s 51us/step - loss: 112.7824 - val_loss: 152.6242\n",
      "Epoch 3824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.6057 - val_loss: 138.7120\n",
      "Epoch 3825/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.4562 - val_loss: 158.8972\n",
      "Epoch 3826/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.9314 - val_loss: 154.3643\n",
      "Epoch 3827/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.5270 - val_loss: 162.4749\n",
      "Epoch 3828/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.9818 - val_loss: 149.9042\n",
      "Epoch 3829/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.1430 - val_loss: 154.8636\n",
      "Epoch 3830/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.6476 - val_loss: 161.4257\n",
      "Epoch 3831/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.4976 - val_loss: 155.6661\n",
      "Epoch 3832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 103.4910 - val_loss: 134.0901\n",
      "Epoch 3833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 101.5083 - val_loss: 148.6029\n",
      "Epoch 3834/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.3018 - val_loss: 140.6524\n",
      "Epoch 3835/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3581 - val_loss: 165.3997\n",
      "Epoch 3836/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.0640 - val_loss: 157.2804\n",
      "Epoch 3837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.5184 - val_loss: 141.0295\n",
      "Epoch 3838/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.6516 - val_loss: 139.9863\n",
      "Epoch 3839/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.9129 - val_loss: 144.8345\n",
      "Epoch 3840/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.6432 - val_loss: 293.9321\n",
      "Epoch 3841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.2741 - val_loss: 138.1978\n",
      "Epoch 3842/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 97.9073 - val_loss: 132.0171\n",
      "Epoch 3843/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.7293 - val_loss: 149.0330\n",
      "Epoch 3844/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.2683 - val_loss: 142.1118\n",
      "Epoch 3845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 104.3647 - val_loss: 137.6851\n",
      "Epoch 3846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.5593 - val_loss: 137.6702\n",
      "Epoch 3847/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 104.0062 - val_loss: 135.0909\n",
      "Epoch 3848/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 101.4968 - val_loss: 137.1039\n",
      "Epoch 3849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.7228 - val_loss: 156.1899\n",
      "Epoch 3850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4543 - val_loss: 183.1090\n",
      "Epoch 3851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.2502 - val_loss: 141.5809\n",
      "Epoch 3852/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.8533 - val_loss: 153.6330\n",
      "Epoch 3853/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.0048 - val_loss: 163.5187\n",
      "Epoch 3854/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 107.0332 - val_loss: 141.0638\n",
      "Epoch 3855/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.0843 - val_loss: 139.8141\n",
      "Epoch 3856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.5241 - val_loss: 148.5363\n",
      "Epoch 3857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.1676 - val_loss: 157.8111\n",
      "Epoch 3858/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.7631 - val_loss: 136.3993\n",
      "Epoch 3859/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.6501 - val_loss: 142.4822\n",
      "Epoch 3860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 106.4734 - val_loss: 144.2080\n",
      "Epoch 3861/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 106.7111 - val_loss: 137.3240\n",
      "Epoch 3862/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 108.2770 - val_loss: 152.7139\n",
      "Epoch 3863/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 101.3208 - val_loss: 152.5897\n",
      "Epoch 3864/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 108.5825 - val_loss: 147.4466\n",
      "Epoch 3865/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.4360 - val_loss: 1604.7372\n",
      "Epoch 3866/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5001 - val_loss: 136.8409\n",
      "Epoch 3867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 100.9107 - val_loss: 138.3211\n",
      "Epoch 3868/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 100.7513 - val_loss: 143.4174\n",
      "Epoch 3869/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 99.0871 - val_loss: 144.8716\n",
      "Epoch 3870/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 100.7810 - val_loss: 148.6494\n",
      "Epoch 3871/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 105.2904 - val_loss: 138.6884\n",
      "Epoch 3872/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.1077 - val_loss: 196.8739\n",
      "Epoch 3873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.0023 - val_loss: 132.8540\n",
      "Epoch 3874/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.2336 - val_loss: 142.0193\n",
      "Epoch 3875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.3305 - val_loss: 159.1383\n",
      "Epoch 3876/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.3992 - val_loss: 141.6249\n",
      "Epoch 3877/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 102.8315 - val_loss: 161.9955\n",
      "Epoch 3878/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.0677 - val_loss: 141.0269\n",
      "Epoch 3879/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.7511 - val_loss: 143.9214\n",
      "Epoch 3880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.1154 - val_loss: 139.7125\n",
      "Epoch 3881/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 101.7119 - val_loss: 156.7655\n",
      "Epoch 3882/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.3756 - val_loss: 134.2423\n",
      "Epoch 3883/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 110.7391 - val_loss: 141.5152\n",
      "Epoch 3884/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.7738 - val_loss: 139.1145\n",
      "Epoch 3885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.0316 - val_loss: 152.0605\n",
      "Epoch 3886/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.1529 - val_loss: 149.4383\n",
      "Epoch 3887/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.0125 - val_loss: 154.2640\n",
      "Epoch 3888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 111.1854 - val_loss: 148.3468\n",
      "Epoch 3889/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 105.3341 - val_loss: 139.0085\n",
      "Epoch 3890/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 104.7072 - val_loss: 156.5287\n",
      "Epoch 3891/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 106.2975 - val_loss: 271.3109\n",
      "Epoch 3892/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.8711 - val_loss: 168.7813\n",
      "Epoch 3893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 112.7959 - val_loss: 137.5783\n",
      "Epoch 3894/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.2080 - val_loss: 187.2164\n",
      "Epoch 3895/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.0942 - val_loss: 146.3946\n",
      "Epoch 3896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.9104 - val_loss: 143.3376\n",
      "Epoch 3897/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.1847 - val_loss: 164.6116\n",
      "Epoch 3898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2473 - val_loss: 135.4348\n",
      "Epoch 3899/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8144 - val_loss: 188.1079\n",
      "Epoch 3900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.9370 - val_loss: 151.3082\n",
      "Epoch 3901/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 102.9505 - val_loss: 152.0528\n",
      "Epoch 3902/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.0880 - val_loss: 134.7383\n",
      "Epoch 3903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 102.8121 - val_loss: 152.1679\n",
      "Epoch 3904/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.0883 - val_loss: 156.1001\n",
      "Epoch 3905/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.2750 - val_loss: 163.7549\n",
      "Epoch 3906/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.3371 - val_loss: 177.6801\n",
      "Epoch 3907/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.2967 - val_loss: 151.4911\n",
      "Epoch 3908/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.4921 - val_loss: 146.9155\n",
      "Epoch 3909/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 109.4963 - val_loss: 190.4418\n",
      "Epoch 3910/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 115.5658 - val_loss: 171.3475\n",
      "Epoch 3911/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.2815 - val_loss: 151.6291\n",
      "Epoch 3912/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.1318 - val_loss: 138.8703\n",
      "Epoch 3913/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.7206 - val_loss: 144.7199\n",
      "Epoch 3914/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 105.7542 - val_loss: 136.6417\n",
      "Epoch 3915/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.2024 - val_loss: 141.1149\n",
      "Epoch 3916/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 112.1234 - val_loss: 135.9485\n",
      "Epoch 3917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6400 - val_loss: 160.1998\n",
      "Epoch 3918/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 103.3342 - val_loss: 145.6060\n",
      "Epoch 3919/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.7955 - val_loss: 155.6055\n",
      "Epoch 3920/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 107.7426 - val_loss: 167.4810\n",
      "Epoch 3921/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 105.2990 - val_loss: 141.7827\n",
      "Epoch 3922/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 102.4552 - val_loss: 143.0294\n",
      "Epoch 3923/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 101.5204 - val_loss: 172.3083\n",
      "Epoch 3924/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.0560 - val_loss: 149.4700\n",
      "Epoch 3925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.6389 - val_loss: 141.3894\n",
      "Epoch 3926/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 106.1030 - val_loss: 143.9855\n",
      "Epoch 3927/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 102.3597 - val_loss: 164.9785\n",
      "Epoch 3928/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 103.6540 - val_loss: 135.7118\n",
      "Epoch 3929/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 109.0823 - val_loss: 158.3719\n",
      "Epoch 3930/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 104.3917 - val_loss: 164.7445\n",
      "Epoch 3931/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 110.5826 - val_loss: 145.4896\n",
      "Epoch 3932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 103.3770 - val_loss: 144.7788\n",
      "Epoch 3933/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.2895 - val_loss: 154.3317\n",
      "Epoch 3934/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.2649 - val_loss: 141.2349\n",
      "Epoch 3935/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 107.7991 - val_loss: 143.8457\n",
      "Epoch 3936/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 114.0281 - val_loss: 149.4297\n",
      "Epoch 3937/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 106.2078 - val_loss: 146.0298\n",
      "Epoch 3938/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3889 - val_loss: 158.7066\n",
      "Epoch 3939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 101.9306 - val_loss: 142.3771\n",
      "Epoch 3940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 106.6515 - val_loss: 151.2917\n",
      "Epoch 3941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.6697 - val_loss: 137.3737\n",
      "Epoch 3942/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 107.6512 - val_loss: 146.3782\n",
      "Epoch 3943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.5636 - val_loss: 146.5738\n",
      "Epoch 3944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.0188 - val_loss: 144.0165\n",
      "Epoch 3945/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.0067 - val_loss: 172.5483\n",
      "Epoch 3946/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 111.9059 - val_loss: 136.0023\n",
      "Epoch 3947/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 108.6745 - val_loss: 139.1232\n",
      "Epoch 3948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 110.5514 - val_loss: 141.7647\n",
      "Epoch 3949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 111.4975 - val_loss: 180.7213\n",
      "Epoch 3950/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.8501 - val_loss: 154.4341\n",
      "Epoch 3951/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.6290 - val_loss: 148.3067\n",
      "Epoch 3952/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 104.8146 - val_loss: 147.5631\n",
      "Epoch 3953/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.3449 - val_loss: 173.4834\n",
      "Epoch 3954/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 107.0867 - val_loss: 154.6880\n",
      "Epoch 3955/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.9832 - val_loss: 155.1438\n",
      "Epoch 3956/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.0169 - val_loss: 139.5042\n",
      "Epoch 3957/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.4253 - val_loss: 148.7458\n",
      "Epoch 3958/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 105.9468 - val_loss: 139.7709\n",
      "Epoch 3959/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.7886 - val_loss: 140.1462\n",
      "Epoch 3960/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 100.5833 - val_loss: 144.0706\n",
      "Epoch 3961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.8292 - val_loss: 207.7511\n",
      "Epoch 3962/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.9278 - val_loss: 164.1689\n",
      "Epoch 3963/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 103.8286 - val_loss: 154.3338\n",
      "Epoch 3964/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.1530 - val_loss: 132.2778\n",
      "Epoch 3965/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.5190 - val_loss: 137.6352\n",
      "Epoch 3966/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 102.6660 - val_loss: 142.4502\n",
      "Epoch 3967/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 113.0645 - val_loss: 142.5247\n",
      "Epoch 3968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 99.2517 - val_loss: 149.8747\n",
      "Epoch 3969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.4312 - val_loss: 136.9689\n",
      "Epoch 3970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 105.4475 - val_loss: 136.6729\n",
      "Epoch 3971/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 109.4536 - val_loss: 159.2501\n",
      "Epoch 3972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 100.3501 - val_loss: 143.7665\n",
      "Epoch 3973/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.5804 - val_loss: 139.6468\n",
      "Epoch 3974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 103.1499 - val_loss: 137.8515\n",
      "Epoch 3975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 108.9518 - val_loss: 159.0793\n",
      "Epoch 3976/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 105.4686 - val_loss: 149.7517\n",
      "Epoch 3977/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.3773 - val_loss: 179.0431\n",
      "Epoch 3978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2792 - val_loss: 140.9878\n",
      "Epoch 3979/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.9281 - val_loss: 148.6221\n",
      "Epoch 3980/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 108.9303 - val_loss: 152.5801\n",
      "Epoch 3981/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 102.3092 - val_loss: 161.8998\n",
      "Epoch 3982/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 113.4980 - val_loss: 153.1980\n",
      "Epoch 3983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.7919 - val_loss: 148.9668\n",
      "Epoch 3984/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 101.7362 - val_loss: 138.9601\n",
      "Epoch 3985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 104.6450 - val_loss: 160.0364\n",
      "Epoch 3986/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.6232 - val_loss: 137.9446\n",
      "Epoch 3987/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.5504 - val_loss: 141.7709\n",
      "Epoch 3988/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.3867 - val_loss: 194.0339\n",
      "Epoch 3989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8548 - val_loss: 148.5491\n",
      "Epoch 3990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 109.1363 - val_loss: 152.1129\n",
      "Epoch 3991/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 103.6840 - val_loss: 145.6966\n",
      "Epoch 3992/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 98.0240 - val_loss: 173.3038\n",
      "Epoch 3993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 101.5305 - val_loss: 143.8691\n",
      "Epoch 3994/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 100.1123 - val_loss: 183.6638\n",
      "Epoch 3995/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.6996 - val_loss: 177.8556\n",
      "Epoch 3996/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 113.0089 - val_loss: 156.9564\n",
      "Epoch 3997/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.4019 - val_loss: 166.0133\n",
      "Epoch 3998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 107.4093 - val_loss: 141.1938\n",
      "Epoch 3999/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9823 - val_loss: 144.7342\n",
      "Epoch 4000/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 98.0094 - val_loss: 132.8717\n",
      "Epoch 4001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 104.8962 - val_loss: 153.3000\n",
      "Epoch 4002/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.4858 - val_loss: 223.5269\n",
      "Epoch 4003/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 102.1384 - val_loss: 147.7813\n",
      "Epoch 4004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 100.7235 - val_loss: 142.6153\n",
      "Epoch 4005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 102.3492 - val_loss: 145.9634\n",
      "Epoch 4006/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 105.5023 - val_loss: 137.8641\n",
      "Epoch 4007/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.3768 - val_loss: 155.4116\n",
      "Epoch 4008/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 106.5088 - val_loss: 150.7070\n",
      "Epoch 4009/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 108.4959 - val_loss: 134.3001\n",
      "Epoch 4010/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 98.7215 - val_loss: 136.0899\n",
      "Epoch 4011/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 114.3631 - val_loss: 154.2833\n",
      "Epoch 4012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 106.4029 - val_loss: 149.4011\n",
      "Epoch 04012: early stopping\n",
      "Fold score (RMSE): 12.17536449432373\n",
      "Fold #3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 5836.5428 - val_loss: 4954.9418\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4465.6103 - val_loss: 4323.9316\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 4296.6127 - val_loss: 4457.5094\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4132.6517 - val_loss: 4224.4500\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 4033.2650 - val_loss: 4064.7490\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3908.6850 - val_loss: 4037.0094\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3906.9539 - val_loss: 3975.8768\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3856.8618 - val_loss: 3842.3962\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 3787.9950 - val_loss: 3910.0447\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3646.8225 - val_loss: 3809.6317\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3464.0483 - val_loss: 3523.0786\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 3543.5968 - val_loss: 3186.4162\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3076.0818 - val_loss: 2803.5919\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2828.7844 - val_loss: 2428.1028\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2528.3394 - val_loss: 3910.5281\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2389.9300 - val_loss: 3492.8857\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 2096.3596 - val_loss: 1466.0908\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 1708.8153 - val_loss: 1432.3187\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 1234.5514 - val_loss: 1248.1257\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 1090.0685 - val_loss: 683.1243\n",
      "Epoch 21/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 964.0455 - val_loss: 525.0047\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 869.6742 - val_loss: 825.0568\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 922.3469 - val_loss: 793.4508\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 712.5602 - val_loss: 446.4766\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 652.9954 - val_loss: 516.5665\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 770.6723 - val_loss: 604.4667\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 706.5603 - val_loss: 384.6317\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 543.3400 - val_loss: 439.6626\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 688.4181 - val_loss: 406.6760\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 546.0601 - val_loss: 364.9800\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 721.3750 - val_loss: 918.0070\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 465.0705 - val_loss: 359.2169\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 555.4099 - val_loss: 540.9639\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 587.7387 - val_loss: 313.2027\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 478.5940 - val_loss: 325.0216\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 444.1090 - val_loss: 315.7123\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 549.3239 - val_loss: 410.9295\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 465.4512 - val_loss: 416.6304\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 472.6760 - val_loss: 320.2629\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 432.7717 - val_loss: 721.4120\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 472.7882 - val_loss: 305.1519\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 428.0963 - val_loss: 1031.3556\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 493.0874 - val_loss: 1153.3078\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 376.5100 - val_loss: 462.7340\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 387.1184 - val_loss: 573.3160\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 360.0353 - val_loss: 375.9494\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 366.8111 - val_loss: 312.8552\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 479.2590 - val_loss: 1097.8517\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 530.4554 - val_loss: 269.7426\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 311.2208 - val_loss: 302.9036\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 386.9756 - val_loss: 603.4572\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 446.5572 - val_loss: 796.8728\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 440.8591 - val_loss: 446.4707\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 362.4879 - val_loss: 392.4552\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 487.5705 - val_loss: 244.7049\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 318.5337 - val_loss: 411.5425\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 416.3213 - val_loss: 383.6745\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 359.7394 - val_loss: 273.7265\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 278.8123 - val_loss: 234.3436\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 340.9125 - val_loss: 243.3343\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 319.5425 - val_loss: 580.9126\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 360.4456 - val_loss: 278.9278\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 307.5608 - val_loss: 248.8211\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 329.0940 - val_loss: 368.5731\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 334.0988 - val_loss: 386.9147\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 343.0846 - val_loss: 487.9713\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 329.8724 - val_loss: 368.6904\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 362.4880 - val_loss: 259.4059\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 287.2353 - val_loss: 220.1562\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 365.0719 - val_loss: 237.7864\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 331.1034 - val_loss: 320.9633\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.1603 - val_loss: 231.4577\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 384.9465 - val_loss: 385.1881\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 267.6137 - val_loss: 205.8368\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 362.6943 - val_loss: 349.5279\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 277.9225 - val_loss: 209.7200\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 378.6166 - val_loss: 231.3876\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 274.6904 - val_loss: 363.4143\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 269.0195 - val_loss: 199.9630\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 500.0102 - val_loss: 269.1880\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 276.8571 - val_loss: 208.1818\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 312.1646 - val_loss: 201.5364\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 396.9447 - val_loss: 212.4263\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 263.0791 - val_loss: 258.5912\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 268.9144 - val_loss: 298.3640\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 385.5015 - val_loss: 268.0068\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 303.5394 - val_loss: 384.7079\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 254.1943 - val_loss: 220.5396\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 250.2971 - val_loss: 410.5784\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 300.7560 - val_loss: 248.1106\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 395.9202 - val_loss: 215.7117\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 352.1433 - val_loss: 236.7889\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 353.5243 - val_loss: 230.8671\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 336.0708 - val_loss: 196.2229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 371.2147 - val_loss: 194.2593\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 234.2654 - val_loss: 198.9975\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.9169 - val_loss: 190.8989\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 277.4418 - val_loss: 177.5241\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.3247 - val_loss: 212.0034\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.3523 - val_loss: 189.6048\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 316.3885 - val_loss: 275.7470\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 333.6992 - val_loss: 366.9058\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 317.9754 - val_loss: 217.1497\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.5959 - val_loss: 201.4217\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 343.2899 - val_loss: 180.5920\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 288.1208 - val_loss: 288.4051\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.3949 - val_loss: 172.1191\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 257.5886 - val_loss: 211.7414\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.2949 - val_loss: 191.1927\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 286.4789 - val_loss: 266.6685\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 273.1740 - val_loss: 519.4244\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 268.1016 - val_loss: 322.0892\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.0663 - val_loss: 393.5555\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 312.6712 - val_loss: 225.5916\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 279.7172 - val_loss: 170.0484\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.4330 - val_loss: 180.9990\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 296.9468 - val_loss: 207.4545\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 300.2757 - val_loss: 655.8228\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 346.1297 - val_loss: 188.6946\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 245.0587 - val_loss: 208.2422\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.6570 - val_loss: 356.8510\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.3264 - val_loss: 387.4772\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.7488 - val_loss: 219.5794\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 265.2621 - val_loss: 170.7993\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 231.5898 - val_loss: 190.6952\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 239.1530 - val_loss: 216.9648\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 237.0472 - val_loss: 234.3067\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.7502 - val_loss: 220.2481\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 235.6989 - val_loss: 261.6715\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 297.0679 - val_loss: 183.3568\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.6646 - val_loss: 188.7514\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 328.0092 - val_loss: 187.2664\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 217.5024 - val_loss: 208.2712\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 287.9056 - val_loss: 198.8512\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 234.7245 - val_loss: 178.9186\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.6903 - val_loss: 162.7952\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 215.1016 - val_loss: 169.9899\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 192.6709 - val_loss: 322.5178\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 236.8239 - val_loss: 197.6842\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 333.7118 - val_loss: 263.4378\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 217.6698 - val_loss: 196.4712\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 211.2441 - val_loss: 159.2866\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.4769 - val_loss: 221.5035\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 284.6919 - val_loss: 219.4683\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 239.7186 - val_loss: 170.0036\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.7058 - val_loss: 281.2320\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.3537 - val_loss: 168.8529\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.5619 - val_loss: 172.8751\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 237.7520 - val_loss: 162.3187\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 243.5601 - val_loss: 186.5811\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.2334 - val_loss: 162.1143\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.7727 - val_loss: 172.9680\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.8915 - val_loss: 294.1400\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 337.0169 - val_loss: 210.4880\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 223.6450 - val_loss: 263.0271\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.4093 - val_loss: 472.0578\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 266.3937 - val_loss: 163.9049\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 276.1204 - val_loss: 207.1738\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.3777 - val_loss: 171.7230\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 231.8917 - val_loss: 180.4029\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.4369 - val_loss: 199.6431\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 239.248 - 0s 50us/step - loss: 242.3206 - val_loss: 254.0180\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 288.0363 - val_loss: 152.5977\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 186.0863 - val_loss: 160.3838\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.6127 - val_loss: 167.7768\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 261.0636 - val_loss: 211.9527\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.0886 - val_loss: 155.1697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.4735 - val_loss: 156.9756\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 264.4614 - val_loss: 217.6856\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.8405 - val_loss: 236.3578\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 297.7993 - val_loss: 199.5143\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.8520 - val_loss: 195.9379\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.1413 - val_loss: 214.4117\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.6603 - val_loss: 678.9664\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 261.5411 - val_loss: 319.5453\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.3218 - val_loss: 179.1533\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.9689 - val_loss: 186.2858\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 256.8579 - val_loss: 248.8340\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.7853 - val_loss: 170.2895\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 319.6447 - val_loss: 387.5592\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.0499 - val_loss: 275.5459\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.7826 - val_loss: 167.2310\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.4793 - val_loss: 199.4066\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.1902 - val_loss: 152.5139\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 244.4508 - val_loss: 198.0764\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.7515 - val_loss: 283.0531\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 214.3234 - val_loss: 175.8683\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.6686 - val_loss: 165.4944\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.3077 - val_loss: 186.7504\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 238.8570 - val_loss: 165.9853\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.9526 - val_loss: 183.0879\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.5671 - val_loss: 155.5796\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.1140 - val_loss: 160.7655\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 222.6166 - val_loss: 195.2563\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 301.5009 - val_loss: 151.2297\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.3471 - val_loss: 157.3259\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 189.0193 - val_loss: 151.2441\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 286.9154 - val_loss: 160.3417\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.9486 - val_loss: 293.6684\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.2380 - val_loss: 355.1098\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 246.7694 - val_loss: 341.5367\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 299.2831 - val_loss: 167.1834\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.4430 - val_loss: 150.7490\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.4894 - val_loss: 352.9804\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 414.8037 - val_loss: 218.1915\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.9171 - val_loss: 250.4362\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 210.1046 - val_loss: 244.7862\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.6876 - val_loss: 148.7894\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.0974 - val_loss: 175.7034\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 164.6744 - val_loss: 147.8467\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 185.1567 - val_loss: 133.1079\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 217.4885 - val_loss: 384.9631\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 196.2464 - val_loss: 139.0422\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.2166 - val_loss: 153.0734\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.2569 - val_loss: 170.3125\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.9650 - val_loss: 140.4804\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 275.0009 - val_loss: 168.5564\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.6257 - val_loss: 235.2788\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.5549 - val_loss: 150.4246\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.6792 - val_loss: 233.4100\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 270.8200 - val_loss: 223.9401\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.7467 - val_loss: 203.1949\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.9549 - val_loss: 145.3579\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.0667 - val_loss: 185.3062\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 273.2742 - val_loss: 153.3491\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.2837 - val_loss: 140.5664\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.4395 - val_loss: 141.0340\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.5628 - val_loss: 143.2294\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.0481 - val_loss: 186.5358\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 220.6612 - val_loss: 435.2138\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.3636 - val_loss: 199.6028\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.4405 - val_loss: 153.0568\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.0589 - val_loss: 152.3837\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.0949 - val_loss: 144.7388\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.7267 - val_loss: 132.8307\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 238.5835 - val_loss: 347.7968\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 245.4688 - val_loss: 446.4551\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 185.7036 - val_loss: 148.8698\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.4129 - val_loss: 134.9771\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 184.771 - 0s 51us/step - loss: 186.4149 - val_loss: 186.3256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.5330 - val_loss: 307.9619\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.1660 - val_loss: 145.0376\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 206.4506 - val_loss: 167.2896\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.5249 - val_loss: 151.9404\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.1130 - val_loss: 141.3647\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.6996 - val_loss: 165.9003\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.0248 - val_loss: 155.9275\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.0972 - val_loss: 179.7428\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 333.4996 - val_loss: 153.9949\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.6480 - val_loss: 246.2485\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.4579 - val_loss: 209.7979\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.2219 - val_loss: 141.1547\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.0414 - val_loss: 162.9591\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.9033 - val_loss: 169.6718\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4883 - val_loss: 155.3676\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.0155 - val_loss: 225.6711\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.7665 - val_loss: 304.6145\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.7322 - val_loss: 257.0954\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 212.0060 - val_loss: 195.8976\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.9408 - val_loss: 231.7485\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 193.4859 - val_loss: 135.7949\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.6772 - val_loss: 176.7804\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 249.0065 - val_loss: 169.0697\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0422 - val_loss: 134.9716\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.4605 - val_loss: 141.6061\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.4844 - val_loss: 179.3711\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.3784 - val_loss: 144.4489\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5825 - val_loss: 132.3063\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.2521 - val_loss: 135.3218\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 262.6092 - val_loss: 126.0611\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7733 - val_loss: 235.2283\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.9055 - val_loss: 142.6955\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.7922 - val_loss: 189.6859\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.1686 - val_loss: 174.7896\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.8100 - val_loss: 216.2333\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.1809 - val_loss: 436.5067\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.5223 - val_loss: 296.9151\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.2660 - val_loss: 391.6123\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.5911 - val_loss: 151.8759\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.1056 - val_loss: 131.8381\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 396.8456 - val_loss: 228.6626\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.9695 - val_loss: 139.1431\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 147.8581 - val_loss: 181.4321\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 172.5861 - val_loss: 124.4908\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 195.5752 - val_loss: 215.7946\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 191.6436 - val_loss: 153.6138\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.9737 - val_loss: 134.5309\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 246.6683 - val_loss: 1450.9041\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 313.6322 - val_loss: 195.3865\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2317 - val_loss: 131.5505\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.3245 - val_loss: 141.4861\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7496 - val_loss: 135.2541\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.3081 - val_loss: 316.9662\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.8103 - val_loss: 349.7237\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.6280 - val_loss: 132.8508\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 158.3499 - val_loss: 137.3284\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.2256 - val_loss: 141.4485\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.4518 - val_loss: 139.9765\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.3833 - val_loss: 188.9526\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.1849 - val_loss: 139.6964\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.0706 - val_loss: 137.6378\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 294.6509 - val_loss: 145.0040\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.1302 - val_loss: 178.9121\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.8607 - val_loss: 135.8824\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0668 - val_loss: 146.5944\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.0224 - val_loss: 181.8814\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.9692 - val_loss: 776.5693\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 230.6848 - val_loss: 127.9683\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.8751 - val_loss: 166.6712\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.4985 - val_loss: 132.6251\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.4574 - val_loss: 229.5849- ETA: 0s - loss: 149\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.8053 - val_loss: 217.9495\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.5509 - val_loss: 196.0375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.2339 - val_loss: 131.8795\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.1222 - val_loss: 257.3377\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 234.0027 - val_loss: 593.5740\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 234.2322 - val_loss: 224.4918\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.6499 - val_loss: 258.1898\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7334 - val_loss: 144.7646\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3404 - val_loss: 138.0789\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 167.0956 - val_loss: 138.0713\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.1420 - val_loss: 186.4539\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.4573 - val_loss: 206.5040\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.8470 - val_loss: 195.4803\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.4652 - val_loss: 133.3628\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.0708 - val_loss: 138.2062\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.4662 - val_loss: 154.1068\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.8826 - val_loss: 215.8898\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.7722 - val_loss: 143.5716\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.2534 - val_loss: 201.9818\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 154.739 - 0s 51us/step - loss: 156.4096 - val_loss: 244.7525\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 268.3808 - val_loss: 154.9920\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.8569 - val_loss: 369.2358\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.7384 - val_loss: 146.5229\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.3777 - val_loss: 135.5129\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.9668 - val_loss: 331.2609\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.4696 - val_loss: 136.0706\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.8087 - val_loss: 157.8998\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.8003 - val_loss: 134.1633\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.0672 - val_loss: 163.2376\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.2426 - val_loss: 189.9880\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5623 - val_loss: 142.4277\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.8907 - val_loss: 134.9622\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7966 - val_loss: 173.8064\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.0653 - val_loss: 139.4833\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.7904 - val_loss: 355.3126\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.9262 - val_loss: 179.6150\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.8448 - val_loss: 161.2698\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.2593 - val_loss: 129.9305\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8419 - val_loss: 195.3046\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.6411 - val_loss: 132.7292\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.2207 - val_loss: 141.3595\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8065 - val_loss: 129.3233\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.7967 - val_loss: 135.1750\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 169.6299 - val_loss: 189.2286\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 186.8676 - val_loss: 144.7753\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 181.0303 - val_loss: 140.1423\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 189.2344 - val_loss: 250.0385\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8091 - val_loss: 591.2289\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.9024 - val_loss: 173.9917\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.2929 - val_loss: 156.5179\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7617 - val_loss: 162.4158\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.9259 - val_loss: 176.4435\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.2853 - val_loss: 133.4365\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 315.6999 - val_loss: 143.3649\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.3408 - val_loss: 160.5009\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.0644 - val_loss: 141.0351\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.4882 - val_loss: 157.9086\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.9305 - val_loss: 236.9543\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.4972 - val_loss: 124.9018\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.8481 - val_loss: 130.3922\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.0972 - val_loss: 129.9962\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8450 - val_loss: 372.4668\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.7318 - val_loss: 293.5218\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 459.5865 - val_loss: 169.4600\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.5580 - val_loss: 133.9101\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1702 - val_loss: 135.4212\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5001 - val_loss: 150.6292\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4030 - val_loss: 269.5450\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.9307 - val_loss: 145.5139\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.1689 - val_loss: 124.6903\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5790 - val_loss: 257.4253\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.7437 - val_loss: 126.9391\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 418.2507 - val_loss: 202.3544\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.8786 - val_loss: 481.0808\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 206.5922 - val_loss: 157.4131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.2528 - val_loss: 151.7972\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.0203 - val_loss: 164.6638\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.1828 - val_loss: 154.0795\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.1361 - val_loss: 257.6575\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3904 - val_loss: 195.4685\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.5260 - val_loss: 136.1339\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.3559 - val_loss: 188.6937\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.7489 - val_loss: 165.7755\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.2120 - val_loss: 182.6171\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.3914 - val_loss: 191.0150\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5610 - val_loss: 194.5531\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.1344 - val_loss: 247.3887\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3116 - val_loss: 254.4697\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 271.5038 - val_loss: 250.5257\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.7613 - val_loss: 148.6727\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7964 - val_loss: 155.5939\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 268.6335 - val_loss: 134.5522\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.7340 - val_loss: 365.0500\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 176.7856 - val_loss: 170.3941\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 208.636 - 0s 51us/step - loss: 208.5445 - val_loss: 220.0569\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.5248 - val_loss: 143.8476\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6711 - val_loss: 166.2342\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.4569 - val_loss: 199.1438\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6942 - val_loss: 153.0109\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0772 - val_loss: 143.5555\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.9282 - val_loss: 206.7448\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 266.9997 - val_loss: 416.5064\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 175.1959 - val_loss: 131.6413\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2339 - val_loss: 191.4143\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 238.7549 - val_loss: 178.4641\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.3956 - val_loss: 144.9241\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 161.6779 - val_loss: 134.1042\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.0515 - val_loss: 146.0394\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.7030 - val_loss: 163.7106\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 231.7148 - val_loss: 157.6166\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 169.3581 - val_loss: 151.7392\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9380 - val_loss: 137.9540\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.8445 - val_loss: 146.9377\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.9683 - val_loss: 145.1022\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.7432 - val_loss: 155.2949\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 155.6093 - val_loss: 136.8773\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 153.0699 - val_loss: 267.6538\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 190.9027 - val_loss: 152.0002\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 171.9954 - val_loss: 140.6255\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.6825 - val_loss: 142.7558\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.1055 - val_loss: 154.2545\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3807 - val_loss: 197.0383\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7248 - val_loss: 156.5511\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.8405 - val_loss: 130.6236\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.7541 - val_loss: 158.1888\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3982 - val_loss: 168.3990\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.9360 - val_loss: 163.6299\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.8575 - val_loss: 134.5005\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.1074 - val_loss: 131.1654\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.5356 - val_loss: 177.5753\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0502 - val_loss: 189.6068\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.4609 - val_loss: 148.7801\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.8592 - val_loss: 227.1069\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8011 - val_loss: 157.5457\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4829 - val_loss: 154.0764\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0735 - val_loss: 164.4746\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.8169 - val_loss: 185.7763\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.6882 - val_loss: 151.6886\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.5529 - val_loss: 249.0714\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.9642 - val_loss: 762.1004\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.1648 - val_loss: 159.1638\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.9249 - val_loss: 133.2226\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1569 - val_loss: 139.2666\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.6202 - val_loss: 163.5420\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.8013 - val_loss: 177.1565\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2492 - val_loss: 241.9308\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.5027 - val_loss: 134.7990\n",
      "Epoch 459/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.1242 - val_loss: 142.2129\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.2342 - val_loss: 135.3917\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5464 - val_loss: 137.4780\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.2059 - val_loss: 134.8340\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3637 - val_loss: 158.4966\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 221.1451 - val_loss: 232.4389\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.5047 - val_loss: 132.8386\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.3310 - val_loss: 126.1233\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4846 - val_loss: 134.0173\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.8940 - val_loss: 166.2058\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.6485 - val_loss: 176.7915\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6555 - val_loss: 140.1596\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 140.5155 - val_loss: 153.7562\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0461 - val_loss: 170.6557\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 159.5981 - val_loss: 123.3594\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4740 - val_loss: 126.9539\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 226.0108 - val_loss: 373.3635\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.1528 - val_loss: 134.7386\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.2416 - val_loss: 135.8777\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.6996 - val_loss: 251.6318\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.0595 - val_loss: 134.7278\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.6714 - val_loss: 157.8822\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.3559 - val_loss: 166.1456\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1956 - val_loss: 137.4879\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6548 - val_loss: 130.2245\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.4869 - val_loss: 132.7333\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.1580 - val_loss: 162.8819\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.8005 - val_loss: 146.0576\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 361.9477 - val_loss: 140.4462\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.8869 - val_loss: 322.5512\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8862 - val_loss: 168.8203\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5679 - val_loss: 136.5135\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.7580 - val_loss: 332.3086\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.6232 - val_loss: 131.2972\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.7091 - val_loss: 130.1077\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.7900 - val_loss: 172.0555\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 245.0298 - val_loss: 132.6335\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.9911 - val_loss: 155.3742\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.0333 - val_loss: 160.0389\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.2972 - val_loss: 182.6410\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.3697 - val_loss: 135.6217\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 144.0368 - val_loss: 132.0971\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 154.3470 - val_loss: 209.9310\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 165.3659 - val_loss: 129.6896\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.8568 - val_loss: 147.2177\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.6562 - val_loss: 356.5033\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.9926 - val_loss: 410.2004\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.9211 - val_loss: 165.6289\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.4700 - val_loss: 172.9444\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.5715 - val_loss: 167.3553\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.4223 - val_loss: 192.0208\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.2415 - val_loss: 136.3557\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.5376 - val_loss: 136.4870\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.7069 - val_loss: 123.3242\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6562 - val_loss: 135.8898\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.9791 - val_loss: 211.8043\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 512.7112 - val_loss: 228.4156\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 240.9370 - val_loss: 203.7311\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.7492 - val_loss: 229.2001\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 188.3223 - val_loss: 146.7804\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.2660 - val_loss: 148.8946\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.0157 - val_loss: 151.8122\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.7691 - val_loss: 175.4884\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.6969 - val_loss: 173.3845\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.7332 - val_loss: 146.0659\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.7104 - val_loss: 301.3717\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.6177 - val_loss: 176.5287\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.5926 - val_loss: 141.9427\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 173.1062 - val_loss: 146.4774\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3075 - val_loss: 180.0739\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0568 - val_loss: 147.0568\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.2071 - val_loss: 154.7967\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.2525 - val_loss: 137.3874\n",
      "Epoch 532/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.5810 - val_loss: 146.0683\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4579 - val_loss: 157.3974\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.6007 - val_loss: 143.8757\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.1197 - val_loss: 171.3337\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.1174 - val_loss: 148.9026\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 181.459 - 0s 51us/step - loss: 180.7005 - val_loss: 197.1871\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.0436 - val_loss: 183.7515\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.4812 - val_loss: 128.7962\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1706 - val_loss: 297.3293\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6457 - val_loss: 144.6699\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3884 - val_loss: 237.5066\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.9820 - val_loss: 148.9186\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.2649 - val_loss: 161.7647\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 296.8810 - val_loss: 151.6052\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.2239 - val_loss: 126.1571\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8852 - val_loss: 128.0119\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.5311 - val_loss: 134.8352\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.2525 - val_loss: 133.7211\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.5930 - val_loss: 126.7100\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.8372 - val_loss: 147.0212\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.9294 - val_loss: 210.8120\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.8795 - val_loss: 133.7682\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4401 - val_loss: 137.7389\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1292 - val_loss: 215.6261\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3631 - val_loss: 138.3408\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.4376 - val_loss: 134.2751\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.6257 - val_loss: 142.2950\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 253.6441 - val_loss: 134.7107\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.7779 - val_loss: 150.4053\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.6967 - val_loss: 132.6807\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.9555 - val_loss: 127.4412\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.1098 - val_loss: 221.6656\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.5715 - val_loss: 178.9647\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7535 - val_loss: 171.7851\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.4271 - val_loss: 158.9095\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.3993 - val_loss: 325.1880\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.2999 - val_loss: 140.0503\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.4602 - val_loss: 157.3644\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.3330 - val_loss: 130.9451\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 147.4639 - val_loss: 200.3734\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 151.3082 - val_loss: 194.5069\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 144.7006 - val_loss: 134.5716\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 145.5081 - val_loss: 156.1986\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 157.0351 - val_loss: 129.4335\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2959 - val_loss: 130.1835\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.6223 - val_loss: 127.0259\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.3479 - val_loss: 170.5523\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7482 - val_loss: 589.2657\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.3741 - val_loss: 184.1045\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.4752 - val_loss: 144.4068\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3196 - val_loss: 132.3841\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9642 - val_loss: 161.0159\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.5290 - val_loss: 130.1838\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.1867 - val_loss: 133.8185\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8093 - val_loss: 295.1692\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 173.2857 - val_loss: 139.3611\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2597 - val_loss: 159.0900\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8193 - val_loss: 135.9778\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 259.3282 - val_loss: 138.7247\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1320 - val_loss: 141.1901\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4645 - val_loss: 147.0899\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0060 - val_loss: 130.6088\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7202 - val_loss: 220.8467\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4970 - val_loss: 128.4972\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5942 - val_loss: 131.3171\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4971 - val_loss: 130.5735\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.9849 - val_loss: 140.9183\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9604 - val_loss: 162.8621\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.2685 - val_loss: 142.1029\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 290.0598 - val_loss: 134.4781\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.1969 - val_loss: 208.6887\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.0601 - val_loss: 146.3461\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8481 - val_loss: 165.8317\n",
      "Epoch 605/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2023 - val_loss: 166.9347\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6491 - val_loss: 135.2659\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.2041 - val_loss: 139.6265\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.0044 - val_loss: 127.5377\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6520 - val_loss: 132.3250\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5432 - val_loss: 139.2578\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.6001 - val_loss: 154.9451\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0086 - val_loss: 135.7971\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 189.7015 - val_loss: 172.5377\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6018 - val_loss: 131.2625\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8520 - val_loss: 144.1497\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.2808 - val_loss: 196.8559\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2516 - val_loss: 138.9129\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0625 - val_loss: 139.8482\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4507 - val_loss: 127.4332\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.8135 - val_loss: 139.2955\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2354 - val_loss: 220.2895\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.9342 - val_loss: 143.1908\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.3913 - val_loss: 130.0966\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2001 - val_loss: 144.0099\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1926 - val_loss: 138.9819\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.8350 - val_loss: 136.8194\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0500 - val_loss: 214.8928\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5096 - val_loss: 182.1607\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 261.5105 - val_loss: 146.1576\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 283.2004 - val_loss: 198.0768\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6737 - val_loss: 139.5916\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9891 - val_loss: 209.9901\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3026 - val_loss: 168.1272\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.6822 - val_loss: 122.7796\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2698 - val_loss: 165.0290\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8549 - val_loss: 133.6615\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.9833 - val_loss: 157.6926\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9743 - val_loss: 137.1302\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.2330 - val_loss: 225.3395\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.9065 - val_loss: 143.7142\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.7718 - val_loss: 136.0087\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8409 - val_loss: 143.9221\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3604 - val_loss: 134.7387\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6290 - val_loss: 149.8142\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 248.9121 - val_loss: 145.3066\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 131.8750 - val_loss: 125.8572\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.1691 - val_loss: 179.5664\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.1260 - val_loss: 152.2190\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7478 - val_loss: 216.4987\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8634 - val_loss: 159.8268\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.3070 - val_loss: 135.7896\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.9279 - val_loss: 136.3462\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 300.6460 - val_loss: 533.6233\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0128 - val_loss: 128.3665\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9740 - val_loss: 150.9115\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1583 - val_loss: 123.6026\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0105 - val_loss: 155.2864\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5216 - val_loss: 124.9658\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6330 - val_loss: 125.2232\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.6138 - val_loss: 122.9917\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.9043 - val_loss: 134.7428\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8337 - val_loss: 136.4864\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.1664 - val_loss: 174.4720\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7212 - val_loss: 203.9712\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 270.8091 - val_loss: 125.5219\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3846 - val_loss: 148.6117\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0369 - val_loss: 184.5747\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7109 - val_loss: 178.6141\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 282.7567 - val_loss: 172.5030\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8239 - val_loss: 128.5669\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.2496 - val_loss: 131.5633\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5375 - val_loss: 159.1096\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.6737 - val_loss: 132.5130\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.2394 - val_loss: 141.9686\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 132.3378 - val_loss: 139.8733\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 324.3422 - val_loss: 625.7278\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.7089 - val_loss: 141.7258\n",
      "Epoch 678/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.2851 - val_loss: 134.1354\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8927 - val_loss: 160.5310\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.0922 - val_loss: 166.3803\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.7727 - val_loss: 186.8545\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4934 - val_loss: 130.4914\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6792 - val_loss: 126.5587\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.4568 - val_loss: 138.7669\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 305.1943 - val_loss: 141.2444\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8726 - val_loss: 159.7260\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1940 - val_loss: 136.1072\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.9330 - val_loss: 162.1226\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.6216 - val_loss: 129.8621\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5840 - val_loss: 157.8219\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7498 - val_loss: 265.5939\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0705 - val_loss: 133.6847\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9115 - val_loss: 150.4707\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3395 - val_loss: 147.4640\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1718 - val_loss: 142.9923\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1970 - val_loss: 132.4617\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 359.3920 - val_loss: 148.5399\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0611 - val_loss: 137.6112\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.4599 - val_loss: 133.0394\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.9043 - val_loss: 174.7901\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4038 - val_loss: 137.0724\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5829 - val_loss: 198.0939\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4581 - val_loss: 134.3830\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2442 - val_loss: 129.4777\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.299 - 0s 50us/step - loss: 144.0541 - val_loss: 136.3191\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.4499 - val_loss: 161.7472\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.8152 - val_loss: 159.0905\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7731 - val_loss: 141.3949\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.9590 - val_loss: 171.5887\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.4455 - val_loss: 155.0154\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2818 - val_loss: 159.8000\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8797 - val_loss: 163.3993\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.7116 - val_loss: 137.2368\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3809 - val_loss: 132.5585\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8625 - val_loss: 132.2211\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6517 - val_loss: 127.4937\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.2247 - val_loss: 124.9899\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 146.5799 - val_loss: 136.2120\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 177.3287 - val_loss: 134.2514\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 152.7255 - val_loss: 175.3479\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1119 - val_loss: 157.3885\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 400.3069 - val_loss: 161.8627\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 143.3088 - val_loss: 142.3192\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.0975 - val_loss: 140.1237\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.9848 - val_loss: 136.3563\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3840 - val_loss: 135.1590\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4474 - val_loss: 138.4006\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5521 - val_loss: 179.6072\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2574 - val_loss: 152.2008\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.0940 - val_loss: 140.3199\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4681 - val_loss: 130.5481\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.1355 - val_loss: 125.5129\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1189 - val_loss: 270.2959\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.2385 - val_loss: 304.7392\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.9948 - val_loss: 141.5598\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2739 - val_loss: 166.1704\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.2420 - val_loss: 124.9543\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8403 - val_loss: 138.9494\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6858 - val_loss: 133.1407\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0793 - val_loss: 133.0211\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3606 - val_loss: 185.5441\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.4701 - val_loss: 299.6049\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.5526 - val_loss: 146.5645\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2157 - val_loss: 128.1736\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.9240 - val_loss: 136.0240\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3907 - val_loss: 140.4438\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2432 - val_loss: 128.5499\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3516 - val_loss: 194.6897\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9390 - val_loss: 184.3713\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5486 - val_loss: 183.7614\n",
      "Epoch 751/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7428 - val_loss: 187.8419\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3492 - val_loss: 144.0735\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8756 - val_loss: 140.5560\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.0550 - val_loss: 141.3049\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.6871 - val_loss: 179.2720\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0558 - val_loss: 157.5587\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.6674 - val_loss: 127.1065\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2374 - val_loss: 123.2262\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6414 - val_loss: 166.3676\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.6546 - val_loss: 138.5244\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 270.1779 - val_loss: 149.3945\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.4865 - val_loss: 141.5648\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4160 - val_loss: 148.5817\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8834 - val_loss: 128.5621\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.4793 - val_loss: 143.1686\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 256.3049 - val_loss: 138.2801\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3101 - val_loss: 128.6811\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9579 - val_loss: 155.8716\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.9703 - val_loss: 221.5491\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0497 - val_loss: 126.8152\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8328 - val_loss: 147.6256\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6447 - val_loss: 131.2579\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9108 - val_loss: 175.4076\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5555 - val_loss: 164.6310\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.5807 - val_loss: 134.0372\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.4547 - val_loss: 122.2079\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8804 - val_loss: 134.7678\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.4900 - val_loss: 150.1286\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 139.960 - 0s 51us/step - loss: 139.8755 - val_loss: 126.4966\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.8221 - val_loss: 131.9167\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1943 - val_loss: 133.7125\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.3726 - val_loss: 167.3533\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4428 - val_loss: 150.7358\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5997 - val_loss: 124.0418\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 241.2846 - val_loss: 149.8036\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.6195 - val_loss: 129.9440\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.8433 - val_loss: 131.3958\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0719 - val_loss: 140.6843\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.4828 - val_loss: 216.7745\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.7300 - val_loss: 130.0986\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.9575 - val_loss: 122.1284\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.4373 - val_loss: 133.3492\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3075 - val_loss: 152.3376\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.7596 - val_loss: 136.1866\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 159.0351 - val_loss: 143.1008\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8389 - val_loss: 134.1125\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.8775 - val_loss: 140.3426\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5457 - val_loss: 167.2355\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.0711 - val_loss: 139.5667\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 130.8533 - val_loss: 129.1074\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.5095 - val_loss: 140.9501\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 143.4908 - val_loss: 163.2171\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 148.0634 - val_loss: 140.1211\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8430 - val_loss: 125.7365\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 349.1012 - val_loss: 2121.5442\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 822.1403 - val_loss: 358.9197\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 402.7572 - val_loss: 222.4781\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 292.0134 - val_loss: 200.4512\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 226.4231 - val_loss: 172.0755\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 248.0421 - val_loss: 166.8467\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 212.6721 - val_loss: 152.4070\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 223.2969 - val_loss: 182.6736\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 225.4709 - val_loss: 150.9487\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.8972 - val_loss: 138.8688\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.4068 - val_loss: 189.3373\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.1065 - val_loss: 185.8902\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.6943 - val_loss: 150.2974\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 181.6888 - val_loss: 147.5839\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.5285 - val_loss: 258.0257\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.8200 - val_loss: 139.1678\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 234.8215 - val_loss: 155.7771\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.7299 - val_loss: 172.0445\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 185.7032 - val_loss: 150.2570\n",
      "Epoch 824/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.3051 - val_loss: 159.4858\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.8652 - val_loss: 141.8261\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8874 - val_loss: 127.5266\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0474 - val_loss: 146.7463\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.6008 - val_loss: 402.1189\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 207.1605 - val_loss: 159.6684\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6738 - val_loss: 150.2942\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6954 - val_loss: 131.8479\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.6956 - val_loss: 136.8886\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.5212 - val_loss: 141.9353\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.2510 - val_loss: 134.5907\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.2271 - val_loss: 145.3276\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 200.989 - 0s 51us/step - loss: 201.4783 - val_loss: 153.5583\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.8447 - val_loss: 148.7112\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.5817 - val_loss: 137.4493\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1501 - val_loss: 164.2848\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.1775 - val_loss: 130.6757\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.9753 - val_loss: 165.5556\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8088 - val_loss: 144.1498\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1247 - val_loss: 135.6872\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.8157 - val_loss: 144.5165\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.1392 - val_loss: 185.5488\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8086 - val_loss: 138.8516\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.2948 - val_loss: 142.1467\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1475 - val_loss: 130.0879\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.8394 - val_loss: 156.0070\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.8647 - val_loss: 131.6895\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.4353 - val_loss: 128.7895\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0249 - val_loss: 210.6221\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 211.1300 - val_loss: 139.7809\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.4249 - val_loss: 140.3052\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.9003 - val_loss: 139.4991\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.9833 - val_loss: 150.0776\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.4538 - val_loss: 149.1208\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.6032 - val_loss: 203.4973\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.6496 - val_loss: 127.7389\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3664 - val_loss: 147.4450\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9821 - val_loss: 150.7814\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.5309 - val_loss: 144.8074\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 145.7769 - val_loss: 131.5302\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 196.1494 - val_loss: 158.7737\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 162.2213 - val_loss: 147.2176\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1004 - val_loss: 132.3939\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2306 - val_loss: 132.2663\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.9422 - val_loss: 174.0389\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 144.2498 - val_loss: 140.7691\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.9470 - val_loss: 195.1575\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 321.1229 - val_loss: 203.5614\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.2766 - val_loss: 207.1848\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7117 - val_loss: 129.5475\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0154 - val_loss: 147.5079\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.8065 - val_loss: 386.2922\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.6703 - val_loss: 144.4976\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2565 - val_loss: 165.7123\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.9913 - val_loss: 159.3947\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9302 - val_loss: 133.9269\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.6989 - val_loss: 134.2398\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4190 - val_loss: 232.6968\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 586.6802 - val_loss: 176.6873\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.7021 - val_loss: 147.7202\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0593 - val_loss: 134.5850\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.5347 - val_loss: 124.6621\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5763 - val_loss: 141.5232\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.1719 - val_loss: 127.9886\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3844 - val_loss: 158.7915\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8293 - val_loss: 138.6324\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.4526 - val_loss: 138.6145\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 380.3974 - val_loss: 167.1894\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.9685 - val_loss: 129.6401\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3904 - val_loss: 131.5302\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.6137 - val_loss: 156.9361\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.0510 - val_loss: 150.3701\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.5194 - val_loss: 144.4309\n",
      "Epoch 897/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.7946 - val_loss: 128.6896\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4711 - val_loss: 193.2014\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7716 - val_loss: 144.5350\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7036 - val_loss: 152.6123\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.0447 - val_loss: 195.9523\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0979 - val_loss: 130.7776\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2909 - val_loss: 150.2993\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.2624 - val_loss: 234.3387\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.5968 - val_loss: 163.2660\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8841 - val_loss: 139.1171\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.2884 - val_loss: 130.4375\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2800 - val_loss: 125.9987\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1090 - val_loss: 164.7537\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1401 - val_loss: 127.8662\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.6263 - val_loss: 332.9611\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.8200 - val_loss: 152.8827\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9130 - val_loss: 130.2152\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.8736 - val_loss: 131.8390\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8923 - val_loss: 160.7967\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4267 - val_loss: 148.7088\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1254 - val_loss: 224.1387\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.1703 - val_loss: 239.5630\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 146.9970 - val_loss: 130.3531\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 149.8903 - val_loss: 158.3122\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.7307 - val_loss: 146.5209\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.1546 - val_loss: 290.4444\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2376 - val_loss: 139.8981\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1698 - val_loss: 124.9377\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1791 - val_loss: 123.3209\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.7120 - val_loss: 187.4515\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1855 - val_loss: 138.8474\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6693 - val_loss: 150.2655\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2337 - val_loss: 201.2361\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3727 - val_loss: 150.1101\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.1321 - val_loss: 510.4618\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.3099 - val_loss: 130.2004\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0223 - val_loss: 129.7552\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.1285 - val_loss: 134.6087\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 329.6575 - val_loss: 159.8603\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 138.5752 - val_loss: 139.5072\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 258.3472 - val_loss: 275.8427\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.3909 - val_loss: 137.9986\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3692 - val_loss: 141.1976\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.5623 - val_loss: 148.9018\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.4702 - val_loss: 215.4460\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0079 - val_loss: 155.9681\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.1240 - val_loss: 131.4111\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.3327 - val_loss: 231.1652\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.7911 - val_loss: 127.7883\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6435 - val_loss: 141.3032\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.2761 - val_loss: 196.3284\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6161 - val_loss: 189.3734\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.6499 - val_loss: 130.8713\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.8756 - val_loss: 145.1029\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.1901 - val_loss: 171.0021\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.1304 - val_loss: 125.3894\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.1168 - val_loss: 162.5140\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1313 - val_loss: 135.4752\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.9469 - val_loss: 165.0637\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.0188 - val_loss: 198.8241\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 137.4329 - val_loss: 121.7749\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2296 - val_loss: 233.2997\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.6236 - val_loss: 524.5408\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.0545 - val_loss: 143.3621\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.2100 - val_loss: 132.3793\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.0863 - val_loss: 137.6396\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.6504 - val_loss: 128.9431\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3869 - val_loss: 123.3802\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7759 - val_loss: 150.1963\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6200 - val_loss: 179.5837\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.5788 - val_loss: 131.6833\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 345.2416 - val_loss: 142.2336\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1155 - val_loss: 138.6940\n",
      "Epoch 970/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.6899 - val_loss: 141.2963\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8597 - val_loss: 128.9647\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1794 - val_loss: 140.4940\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8545 - val_loss: 131.0583\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.1141 - val_loss: 129.6264\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3259 - val_loss: 179.1887\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7001 - val_loss: 145.7185\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1634 - val_loss: 132.1502\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4288 - val_loss: 139.3135\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4068 - val_loss: 147.6969\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5392 - val_loss: 139.5936\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 430.1029 - val_loss: 139.9130\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.8252 - val_loss: 142.3030\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.6266 - val_loss: 136.6724\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5976 - val_loss: 131.1584\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 237.5693 - val_loss: 129.4995\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7382 - val_loss: 181.9067\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6624 - val_loss: 148.2375\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.9952 - val_loss: 230.1039\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.4513 - val_loss: 251.0445\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6556 - val_loss: 142.2061\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1727 - val_loss: 325.2775\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.6641 - val_loss: 145.2531\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.1923 - val_loss: 162.2850\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 241.2014 - val_loss: 330.6118\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.2836 - val_loss: 186.2886\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.5427 - val_loss: 133.7781\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.9039 - val_loss: 140.7396\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.9198 - val_loss: 327.2231\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4611 - val_loss: 152.7614\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.5453 - val_loss: 132.3741\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.3223 - val_loss: 135.4156\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.1995 - val_loss: 142.1937\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.8974 - val_loss: 164.0685\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.1142 - val_loss: 222.1668\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 156.6388 - val_loss: 197.7725\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 170.9599 - val_loss: 156.0500\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 164.5359 - val_loss: 130.1556\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6011 - val_loss: 141.3388\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4364 - val_loss: 139.1536\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.1489 - val_loss: 169.2930\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.3831 - val_loss: 142.1700\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9387 - val_loss: 154.5491\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7103 - val_loss: 135.5576\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.0210 - val_loss: 137.9218\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.7460 - val_loss: 177.1808\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7852 - val_loss: 162.1302\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5773 - val_loss: 127.9690\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.7670 - val_loss: 199.6925\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 223.1176 - val_loss: 157.9064\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7959 - val_loss: 300.0763\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9665 - val_loss: 134.9243\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.9542 - val_loss: 135.4235\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9897 - val_loss: 141.2222\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.4686 - val_loss: 127.6709\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.090 - 0s 51us/step - loss: 143.0543 - val_loss: 134.3206\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4965 - val_loss: 153.3736\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.7002 - val_loss: 137.5101\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0981 - val_loss: 167.2257\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0386 - val_loss: 130.6471\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7740 - val_loss: 141.8185\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3897 - val_loss: 135.2789\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 470.2362 - val_loss: 190.0159\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.6757 - val_loss: 144.7710\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 285.7204 - val_loss: 1401.8499\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.9426 - val_loss: 126.3752\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8275 - val_loss: 127.9578\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4419 - val_loss: 122.4006\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.8372 - val_loss: 156.9187\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4481 - val_loss: 122.4470\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5387 - val_loss: 165.0280\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1719 - val_loss: 140.0465\n",
      "Epoch 1042/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.5519 - val_loss: 165.8506\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.6246 - val_loss: 135.9543\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8011 - val_loss: 182.9877\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4736 - val_loss: 153.0610\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.5238 - val_loss: 140.8030\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 682.0019 - val_loss: 486.8503\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 196.3836 - val_loss: 158.8306\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3203 - val_loss: 142.4639\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2242 - val_loss: 124.7937\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6605 - val_loss: 152.1660\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.2464 - val_loss: 183.4422\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9167 - val_loss: 143.8258\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1434 - val_loss: 165.8207\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3177 - val_loss: 128.0152\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5721 - val_loss: 122.5973\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 926.1137 - val_loss: 717.0034\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 579.8581 - val_loss: 1342.8035\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 332.3291 - val_loss: 318.3992\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.7748 - val_loss: 195.0804\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.9860 - val_loss: 171.8878\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 212.8398 - val_loss: 204.7053\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 238.6054 - val_loss: 181.9936\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 187.3197 - val_loss: 148.3566\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.8904 - val_loss: 143.1274\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 216.3874 - val_loss: 162.4879\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.7464 - val_loss: 149.8747\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.5917 - val_loss: 261.7184\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.4548 - val_loss: 194.2529\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 209.2195 - val_loss: 174.6058\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 225.8550 - val_loss: 142.8536\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3608 - val_loss: 167.2043\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.3113 - val_loss: 187.7757\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8294 - val_loss: 161.4022\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.3842 - val_loss: 151.7296\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 161.9843 - val_loss: 159.1204\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 158.6986 - val_loss: 217.9443\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 150.9497 - val_loss: 138.8784\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 182.3130 - val_loss: 156.6767\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.0970 - val_loss: 176.8675\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.0637 - val_loss: 189.5277\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.3871 - val_loss: 141.9169\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2901 - val_loss: 133.1817\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 190.7304 - val_loss: 315.7760\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.7321 - val_loss: 136.6577\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.9357 - val_loss: 137.4573\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.0099 - val_loss: 131.4750\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.3872 - val_loss: 274.0965\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.7539 - val_loss: 125.8370\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.2918 - val_loss: 129.0499\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.3849 - val_loss: 378.7083\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8778 - val_loss: 144.7884\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5249 - val_loss: 130.7699\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.8527 - val_loss: 149.4761\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.3676 - val_loss: 225.3701\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.7441 - val_loss: 224.8201\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.3363 - val_loss: 134.7318\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.7426 - val_loss: 158.6817\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.2376 - val_loss: 202.7670\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.0691 - val_loss: 123.5900\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.6139 - val_loss: 128.5467\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2996 - val_loss: 131.9657\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.3797 - val_loss: 208.7458\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.6440 - val_loss: 169.3238\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4770 - val_loss: 126.1826\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5263 - val_loss: 134.9157\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3904 - val_loss: 183.3396\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7610 - val_loss: 143.5282\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8276 - val_loss: 150.2522\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.7636 - val_loss: 124.9517\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6932 - val_loss: 133.6075\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.4515 - val_loss: 151.5168\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.6626 - val_loss: 130.4481\n",
      "Epoch 1114/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.2560 - val_loss: 283.9263\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.6366 - val_loss: 158.4559\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.7838 - val_loss: 152.0179\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4097 - val_loss: 132.7707\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9454 - val_loss: 261.5995\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.2077 - val_loss: 129.6451\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4484 - val_loss: 135.4490\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7115 - val_loss: 127.0227\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3673 - val_loss: 134.1682\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.3141 - val_loss: 138.4202\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.5212 - val_loss: 134.2886\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8197 - val_loss: 167.4233\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 171.3690 - val_loss: 147.2968\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.3021 - val_loss: 135.7710\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.7722 - val_loss: 138.5287\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 422.6658 - val_loss: 395.7600\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.3089 - val_loss: 182.9024\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.7550 - val_loss: 269.0364\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5889 - val_loss: 148.0723\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 172.5439 - val_loss: 167.0301\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 180.7922 - val_loss: 216.6075\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.2994 - val_loss: 193.3900\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.1636 - val_loss: 143.7356\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7000 - val_loss: 164.4117\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4589 - val_loss: 151.7382\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.4532 - val_loss: 143.5193\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.0136 - val_loss: 279.7584\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.3133 - val_loss: 129.8852\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.4493 - val_loss: 147.3639\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.5194 - val_loss: 175.3215\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 140.841 - 0s 51us/step - loss: 140.9206 - val_loss: 141.4591\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5827 - val_loss: 143.9826\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9542 - val_loss: 148.4453\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0988 - val_loss: 138.3974\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.1046 - val_loss: 135.4278\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 146.1404 - val_loss: 135.6809\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 147.0070 - val_loss: 176.0239\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 164.9705 - val_loss: 131.3766\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.3483 - val_loss: 136.6534\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.0551 - val_loss: 132.5304\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6012 - val_loss: 131.1346\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1464 - val_loss: 144.3960\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8781 - val_loss: 134.2848\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.5489 - val_loss: 131.4681\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0712 - val_loss: 201.7632\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.8620 - val_loss: 125.4494\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.3153 - val_loss: 181.8507\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.0895 - val_loss: 149.3471\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.9442 - val_loss: 131.4140\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.4131 - val_loss: 125.3472\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.4998 - val_loss: 135.9006\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9778 - val_loss: 168.9669\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5346 - val_loss: 181.6444\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0389 - val_loss: 156.2980\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.5609 - val_loss: 131.7214\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.5360 - val_loss: 153.9874\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4170 - val_loss: 131.1642\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6023 - val_loss: 149.1333\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0767 - val_loss: 139.3499\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7827 - val_loss: 154.4289\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.6702 - val_loss: 132.7843\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8419 - val_loss: 128.4778\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 452.3447 - val_loss: 184.2392\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.2306 - val_loss: 191.9376\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.9200 - val_loss: 141.1418\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7296 - val_loss: 141.5766\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.2838 - val_loss: 141.5583\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.6113 - val_loss: 132.5262\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 162.5308 - val_loss: 224.6010\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.4210 - val_loss: 240.9992\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8882 - val_loss: 136.7931\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.8148 - val_loss: 173.6799\n",
      "Epoch 1186/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6374 - val_loss: 132.0011\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5979 - val_loss: 144.4636\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 275.0059 - val_loss: 154.0354\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.2139 - val_loss: 145.7966\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.7121 - val_loss: 134.5509\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2553 - val_loss: 133.7814\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5823 - val_loss: 137.9492\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.4312 - val_loss: 132.5555\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2191 - val_loss: 146.1110\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.4849 - val_loss: 146.0773\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.7797 - val_loss: 139.3881\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.0542 - val_loss: 143.3124\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6047 - val_loss: 179.9267\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.9074 - val_loss: 140.3507\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.1487 - val_loss: 141.8047\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8598 - val_loss: 154.6196\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7439 - val_loss: 135.6541\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1579 - val_loss: 138.8580\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2135 - val_loss: 126.1857\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4638 - val_loss: 149.3649\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1249 - val_loss: 132.7687\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.1673 - val_loss: 143.0431\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5817 - val_loss: 153.4814\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 185.7285 - val_loss: 132.3830\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7878 - val_loss: 148.5379\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2568 - val_loss: 152.7899\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.1951 - val_loss: 130.3760\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.9559 - val_loss: 178.7211\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.8380 - val_loss: 142.6130\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3587 - val_loss: 151.8734\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 250.8003 - val_loss: 159.6858\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4018 - val_loss: 153.4551\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.7271 - val_loss: 129.2933\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.4746 - val_loss: 124.7088\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9661 - val_loss: 127.0175\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.9838 - val_loss: 136.8710\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 137.3540 - val_loss: 131.2788\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.7815 - val_loss: 130.1745\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.6405 - val_loss: 133.1797\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5689 - val_loss: 172.1015\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3408 - val_loss: 141.7180\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6203 - val_loss: 150.2552\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.2913 - val_loss: 140.7677\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.8797 - val_loss: 155.4556\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.9551 - val_loss: 128.7968\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 145.6753 - val_loss: 128.9548\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.3763 - val_loss: 169.9974\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1021 - val_loss: 147.0468\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0232 - val_loss: 136.3362\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 235.8526 - val_loss: 125.8498\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4909 - val_loss: 132.4718\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3762 - val_loss: 139.5116\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3578 - val_loss: 152.4504\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7325 - val_loss: 131.0684\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.2236 - val_loss: 126.0237\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.9715 - val_loss: 137.8217\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8461 - val_loss: 146.2938\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.7272 - val_loss: 149.1713\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.4851 - val_loss: 149.0709\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0941 - val_loss: 167.7960\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3725 - val_loss: 125.7577\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7129 - val_loss: 150.5222\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2332 - val_loss: 132.8634\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7363 - val_loss: 129.7249\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.0856 - val_loss: 179.0961\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9263 - val_loss: 152.0403\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.2788 - val_loss: 179.8551\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.3776 - val_loss: 132.8066\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.9476 - val_loss: 132.4086\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.1053 - val_loss: 120.9002\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2764 - val_loss: 153.1685\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2903 - val_loss: 133.3680\n",
      "Epoch 1258/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.7655 - val_loss: 198.5803\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 281.9857 - val_loss: 180.5134\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.5513 - val_loss: 124.3752\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 125.0837 - val_loss: 131.7347\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.4820 - val_loss: 201.1229\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3985 - val_loss: 185.5315\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7586 - val_loss: 136.4789\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5209 - val_loss: 132.1604\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8858 - val_loss: 128.4416\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1867 - val_loss: 159.9941\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5998 - val_loss: 148.3107\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 138.8675 - val_loss: 211.2101\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6637 - val_loss: 124.3403\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.4560 - val_loss: 150.1172\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2523 - val_loss: 129.8655\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.2182 - val_loss: 128.5553- ETA: 0s - loss: 11\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0434 - val_loss: 174.3404\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 186.9802 - val_loss: 134.5059\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1126 - val_loss: 124.7956\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1145 - val_loss: 132.9882\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.2112 - val_loss: 151.5790\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7774 - val_loss: 132.6361\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.0809 - val_loss: 181.5602\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0529 - val_loss: 126.1754\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5140 - val_loss: 136.5248\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7877 - val_loss: 128.0941\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6035 - val_loss: 161.4295\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9719 - val_loss: 226.6006\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.4592 - val_loss: 137.4069\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1870 - val_loss: 169.3270\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 139.7249 - val_loss: 192.0595\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9018 - val_loss: 135.0570\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5951 - val_loss: 138.8013\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7015 - val_loss: 147.8404\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.1072 - val_loss: 177.3146\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 159.6197 - val_loss: 162.9444\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 188.2527 - val_loss: 183.5528\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 132.4699 - val_loss: 135.0929\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 290.2524 - val_loss: 129.6871\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.6777 - val_loss: 128.8035\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7201 - val_loss: 140.2528\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5792 - val_loss: 123.3920\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9157 - val_loss: 126.4144\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.3919 - val_loss: 138.6552\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7675 - val_loss: 141.1154\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2246 - val_loss: 127.8123\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6274 - val_loss: 134.0650\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0260 - val_loss: 135.4352\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.4280 - val_loss: 145.0807\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6128 - val_loss: 132.7680\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3132 - val_loss: 122.9395\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2473 - val_loss: 158.5710\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1650 - val_loss: 125.3075\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4239 - val_loss: 182.8798\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 289.4603 - val_loss: 142.2298\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.6181 - val_loss: 132.6140\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8692 - val_loss: 134.9880\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8699 - val_loss: 137.8413\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8571 - val_loss: 204.4703\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9147 - val_loss: 134.9224\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.0334 - val_loss: 124.4481\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5944 - val_loss: 124.1081\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1012 - val_loss: 129.5358\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.4579 - val_loss: 130.9704\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.9291 - val_loss: 130.6004\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 138.3905 - val_loss: 129.0716\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.4316 - val_loss: 130.0708\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3590 - val_loss: 123.8944\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 290.3814 - val_loss: 171.3763\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9520 - val_loss: 173.0194\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2114 - val_loss: 128.5028\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.3791 - val_loss: 128.9573\n",
      "Epoch 1330/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.2416 - val_loss: 145.9837\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3971 - val_loss: 123.3403\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9458 - val_loss: 152.0305\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.0905 - val_loss: 146.2289\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0501 - val_loss: 134.1858\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5710 - val_loss: 131.2612\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.4650 - val_loss: 159.5057\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 340.4200 - val_loss: 194.4230\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1225 - val_loss: 201.2007\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.2757 - val_loss: 133.7237\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.8471 - val_loss: 130.3498\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.5947 - val_loss: 147.5611\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3013 - val_loss: 126.0641\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8064 - val_loss: 139.3555\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2764 - val_loss: 128.2127\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.2867 - val_loss: 131.4918\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9565 - val_loss: 123.6529\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.8290 - val_loss: 127.5226\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7757 - val_loss: 135.9347\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.5214 - val_loss: 128.8409\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.7382 - val_loss: 158.0130\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3545 - val_loss: 129.7346\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2951 - val_loss: 221.3130\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.8873 - val_loss: 124.7406\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9699 - val_loss: 144.4291\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 137.9922 - val_loss: 132.0489\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.8399 - val_loss: 143.6636\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1095 - val_loss: 133.5665\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 404.7013 - val_loss: 151.0909\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5717 - val_loss: 136.5986\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3616 - val_loss: 156.0052\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4552 - val_loss: 240.4322\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0238 - val_loss: 139.0206\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.3977 - val_loss: 123.9793\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1483 - val_loss: 123.0380\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 129.3567 - val_loss: 153.9039\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 138.5442 - val_loss: 139.4156\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 228.0554 - val_loss: 232.2958\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.2608 - val_loss: 135.3608\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.1567 - val_loss: 142.5680\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8352 - val_loss: 172.4667\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.7141 - val_loss: 128.1033\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.7002 - val_loss: 125.6515\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.335 - 0s 51us/step - loss: 130.8554 - val_loss: 163.7538\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.3405 - val_loss: 131.7236\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.0616 - val_loss: 124.7209\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5228 - val_loss: 136.8133\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.4373 - val_loss: 128.3823\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5244 - val_loss: 142.3584\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.2123 - val_loss: 171.1447\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4395 - val_loss: 172.9278\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.2881 - val_loss: 119.9642\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7159 - val_loss: 149.7683\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.8126 - val_loss: 250.9440\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3306 - val_loss: 123.4577\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9020 - val_loss: 121.5945\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.6808 - val_loss: 144.1743\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7281 - val_loss: 133.5343\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6811 - val_loss: 127.6664\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5554 - val_loss: 128.4104\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.0128 - val_loss: 137.2314\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.2851 - val_loss: 138.3107\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.5205 - val_loss: 158.4260\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.7028 - val_loss: 133.7546\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.3825 - val_loss: 126.9299\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.7328 - val_loss: 131.3399\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1410 - val_loss: 122.5694\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9348 - val_loss: 178.9450\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 328.6853 - val_loss: 136.8139\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8500 - val_loss: 136.3094\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6080 - val_loss: 132.7210\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.7353 - val_loss: 149.8936\n",
      "Epoch 1402/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.1064 - val_loss: 144.1128\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2185 - val_loss: 133.0650\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5941 - val_loss: 134.0721\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.6209 - val_loss: 1825.1348\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 356.2977 - val_loss: 163.2481\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.2549 - val_loss: 144.9395\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.0970 - val_loss: 138.1701\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4209 - val_loss: 148.3993\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4760 - val_loss: 130.4731\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6580 - val_loss: 135.9943\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1077 - val_loss: 162.5036\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9949 - val_loss: 127.2815\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8121 - val_loss: 155.8518\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5273 - val_loss: 134.5423\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5567 - val_loss: 132.3912\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.8658 - val_loss: 126.2839\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.8676 - val_loss: 138.2486\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2662 - val_loss: 268.3992\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3431 - val_loss: 124.4544\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3728 - val_loss: 161.6171\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0835 - val_loss: 171.1667\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2617 - val_loss: 143.8325\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.4638 - val_loss: 126.6541\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8329 - val_loss: 191.5300\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2473 - val_loss: 128.7138\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4957 - val_loss: 128.6913\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 144.6492 - val_loss: 122.4012\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9270 - val_loss: 129.6309\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.0412 - val_loss: 146.2636\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3627 - val_loss: 236.8428\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.0417 - val_loss: 169.7178\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1067 - val_loss: 134.5204\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.4944 - val_loss: 146.4250\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6521 - val_loss: 199.8329\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0751 - val_loss: 139.7690\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.8954 - val_loss: 127.9421\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 174.6167 - val_loss: 139.7249\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 175.9189 - val_loss: 127.1476\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 136.1268 - val_loss: 123.8934\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0151 - val_loss: 135.1996\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5399 - val_loss: 220.5623\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.0393 - val_loss: 127.1913\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8214 - val_loss: 148.7616\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2433 - val_loss: 127.4923\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2841 - val_loss: 131.8278\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9990 - val_loss: 142.8820\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7563 - val_loss: 169.1529\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8497 - val_loss: 135.7692\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.7401 - val_loss: 125.9584\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3317 - val_loss: 139.2244\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.5963 - val_loss: 125.3175\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0090 - val_loss: 124.4529\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.9907 - val_loss: 1848.0096\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 240.7922 - val_loss: 139.9180\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8346 - val_loss: 129.6700\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.8882 - val_loss: 131.5856\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.8113 - val_loss: 133.3303\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2957 - val_loss: 133.6482\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4954 - val_loss: 187.5153\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8025 - val_loss: 130.4988\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9601 - val_loss: 122.2297\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5191 - val_loss: 148.3374\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8253 - val_loss: 152.5898\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7454 - val_loss: 129.3316\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2565 - val_loss: 168.9337\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.7664 - val_loss: 128.3045\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.1839 - val_loss: 148.7106\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.6878 - val_loss: 129.4892\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5409 - val_loss: 127.3668\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.6142 - val_loss: 136.7002\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1466 - val_loss: 127.8702\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.1117 - val_loss: 132.6498\n",
      "Epoch 1474/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 237.8373 - val_loss: 783.6608\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 502.3649 - val_loss: 139.8454\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9530 - val_loss: 129.4298\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4556 - val_loss: 129.5791\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1158 - val_loss: 128.3532\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0018 - val_loss: 127.1341\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1695 - val_loss: 296.8266\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7880 - val_loss: 124.6874\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 300.6982 - val_loss: 128.1776\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6736 - val_loss: 129.6679\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8549 - val_loss: 126.4909\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1478 - val_loss: 129.4080\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.5199 - val_loss: 139.5522\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8594 - val_loss: 138.6471\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9206 - val_loss: 163.6380\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.9997 - val_loss: 141.4570\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.8940 - val_loss: 151.1804\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9651 - val_loss: 129.8649\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.2185 - val_loss: 157.7599\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8023 - val_loss: 143.2512\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3584 - val_loss: 134.4213\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.1543 - val_loss: 135.5444\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 128.2800 - val_loss: 190.3164\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7174 - val_loss: 125.1499\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1069 - val_loss: 127.1966\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0714 - val_loss: 124.5757\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.9397 - val_loss: 143.5461\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5231 - val_loss: 126.2912\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3154 - val_loss: 132.8864\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7383 - val_loss: 142.8549\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6642 - val_loss: 139.6514\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8397 - val_loss: 123.7577\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6697 - val_loss: 139.2976\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.7911 - val_loss: 160.9504\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6254 - val_loss: 130.4248\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 559.6502 - val_loss: 146.2606\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 132.4404 - val_loss: 127.7120\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.0470 - val_loss: 128.6866\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 131.6550 - val_loss: 134.9458\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 128.4470 - val_loss: 144.0284\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.8838 - val_loss: 135.6908\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.6393 - val_loss: 126.3232\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.2415 - val_loss: 136.0472\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.5500 - val_loss: 137.2275\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.7965 - val_loss: 126.7217\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 139.3096 - val_loss: 176.6825\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 133.0483 - val_loss: 127.1293\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 138.8511 - val_loss: 125.2529\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 133.1351 - val_loss: 122.3758\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.188 - 0s 50us/step - loss: 127.1994 - val_loss: 138.6850\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3759 - val_loss: 144.4404\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.3087 - val_loss: 133.9471\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5220 - val_loss: 152.7734\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6696 - val_loss: 145.3745\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.4724 - val_loss: 130.9983\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9337 - val_loss: 146.3807\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8845 - val_loss: 142.7505\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0571 - val_loss: 125.8156\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4752 - val_loss: 161.1256\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 1205.3374 - val_loss: 807.3329\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 537.0530 - val_loss: 360.9070\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 327.9455 - val_loss: 262.2844\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 278.6172 - val_loss: 239.1345\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 256.9333 - val_loss: 202.1916\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 228.3840 - val_loss: 212.9601\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 236.6690 - val_loss: 192.1422\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 206.0290 - val_loss: 156.4703\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 223.6298 - val_loss: 161.4291\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 184.4842 - val_loss: 167.2431\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 208.5303 - val_loss: 172.6276\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.9446 - val_loss: 191.0611\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.4626 - val_loss: 157.7372\n",
      "Epoch 1546/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 179.6614 - val_loss: 232.4115\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.3808 - val_loss: 181.2110\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.3207 - val_loss: 196.7553\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.6496 - val_loss: 139.3996\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.8180 - val_loss: 156.1829\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.7476 - val_loss: 153.3789\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.1952 - val_loss: 160.3221\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.8707 - val_loss: 178.2554\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.0587 - val_loss: 177.2638\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.0815 - val_loss: 162.1423\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.3393 - val_loss: 183.7497\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.2890 - val_loss: 136.4887\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.8320 - val_loss: 406.5409\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.0018 - val_loss: 143.7994\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.4696 - val_loss: 147.6289\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 170.9400 - val_loss: 147.5230\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6951 - val_loss: 187.8717\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 202.5048 - val_loss: 147.8281\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.3256 - val_loss: 146.1798\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.4464 - val_loss: 202.3439\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.0592 - val_loss: 147.1396\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.3182 - val_loss: 228.7423\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 189.8277 - val_loss: 161.0911\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.2538 - val_loss: 135.7461\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7386 - val_loss: 151.0066\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6171 - val_loss: 148.3213\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.1603 - val_loss: 177.0628\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8983 - val_loss: 158.7088\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.3997 - val_loss: 131.0438\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5847 - val_loss: 178.1971\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.7188 - val_loss: 162.2903\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4872 - val_loss: 133.8664\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.3526 - val_loss: 175.4590\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8979 - val_loss: 146.3233\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7902 - val_loss: 144.7099\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.4586 - val_loss: 150.5418\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 144.9192 - val_loss: 152.0318\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 152.1692 - val_loss: 124.9033\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 137.0516 - val_loss: 134.2544\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9159 - val_loss: 132.6026\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8299 - val_loss: 172.5419\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 319.3332 - val_loss: 142.0383\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7859 - val_loss: 129.4438\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6441 - val_loss: 138.1085\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2793 - val_loss: 142.0761\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5172 - val_loss: 147.5151\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6904 - val_loss: 143.0402\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0505 - val_loss: 135.2647\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3350 - val_loss: 136.7230\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.3401 - val_loss: 169.4835\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0200 - val_loss: 145.9388\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2648 - val_loss: 153.8981\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6963 - val_loss: 165.7194\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3502 - val_loss: 164.6263\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8163 - val_loss: 143.4507\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5933 - val_loss: 151.9641\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.9924 - val_loss: 157.2953\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9427 - val_loss: 133.0817\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2453 - val_loss: 142.7148\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 420.0174 - val_loss: 210.7620\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.8358 - val_loss: 135.3632\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.2389 - val_loss: 130.5034\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2251 - val_loss: 146.4224\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1551 - val_loss: 134.0843\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6951 - val_loss: 185.1049\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1891 - val_loss: 153.5246\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7201 - val_loss: 149.6471\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.8721 - val_loss: 153.5221\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.0502 - val_loss: 133.3778\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 344.1527 - val_loss: 154.2158\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.1059 - val_loss: 136.7702\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.1352 - val_loss: 171.9163\n",
      "Epoch 1618/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 137.1849 - val_loss: 134.4865\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.1505 - val_loss: 134.3379\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0995 - val_loss: 172.9497\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4347 - val_loss: 124.5361\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2459 - val_loss: 201.5626\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.8583 - val_loss: 124.0492\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5963 - val_loss: 142.5611\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7824 - val_loss: 144.8492\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.0844 - val_loss: 136.5811\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8867 - val_loss: 128.4372\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1045 - val_loss: 146.6341\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4768 - val_loss: 195.5137\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2922 - val_loss: 137.9606\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5371 - val_loss: 140.2865\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3705 - val_loss: 165.4847\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7724 - val_loss: 137.6419\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5372 - val_loss: 126.1665\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8611 - val_loss: 130.4285\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9067 - val_loss: 171.5096\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2601 - val_loss: 141.4769\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.8213 - val_loss: 139.8020\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9749 - val_loss: 133.5787\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 138.7388 - val_loss: 144.3118\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.7362 - val_loss: 224.7789\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7926 - val_loss: 169.6081\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5558 - val_loss: 142.6689\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.0430 - val_loss: 148.6079\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6941 - val_loss: 138.4414\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6015 - val_loss: 167.5465\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4116 - val_loss: 127.7738\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4477 - val_loss: 126.2434\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8683 - val_loss: 125.4973\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4934 - val_loss: 137.4753\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7922 - val_loss: 130.2692\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6993 - val_loss: 151.2622\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 133.6151 - val_loss: 128.8750\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 139.2478 - val_loss: 128.8104\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 139.6042 - val_loss: 132.7763\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.0851 - val_loss: 138.8013\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4428 - val_loss: 142.2762\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8333 - val_loss: 129.3769\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.0686 - val_loss: 127.9037\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9706 - val_loss: 152.6562\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.2586 - val_loss: 132.9319\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.3425 - val_loss: 132.5518\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0007 - val_loss: 164.4312\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3421 - val_loss: 172.0564\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.0432 - val_loss: 141.9967\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2626 - val_loss: 139.3900\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9057 - val_loss: 161.0006\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4996 - val_loss: 163.6334\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.0530 - val_loss: 332.7680\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 451.6196 - val_loss: 165.9017\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.3328 - val_loss: 146.8672\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.5028 - val_loss: 223.6606\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5327 - val_loss: 143.7637\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.8039 - val_loss: 134.8911\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.6052 - val_loss: 142.5991\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.0956 - val_loss: 144.1287\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1309 - val_loss: 133.0469\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.3751 - val_loss: 133.1074\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 125.1796 - val_loss: 146.3233\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3237 - val_loss: 157.6444\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 225.6778 - val_loss: 1299.2867\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.0519 - val_loss: 127.5367\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.1362 - val_loss: 128.0685\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5931 - val_loss: 138.3243\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.3191 - val_loss: 137.6586\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5518 - val_loss: 173.0561\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5871 - val_loss: 155.5580\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4545 - val_loss: 141.6439\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.568 - 0s 51us/step - loss: 131.2954 - val_loss: 125.3236\n",
      "Epoch 1690/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2184 - val_loss: 124.5446\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4711 - val_loss: 149.9431\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6891 - val_loss: 124.8016\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8969 - val_loss: 135.5507\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2573 - val_loss: 124.6830\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5835 - val_loss: 166.1974\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8553 - val_loss: 141.7053\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9953 - val_loss: 126.6239\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.0571 - val_loss: 152.0758\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.6658 - val_loss: 122.5723\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1563 - val_loss: 133.6349\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5406 - val_loss: 211.3324\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1773 - val_loss: 133.7361\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.2917 - val_loss: 130.4866\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2756 - val_loss: 129.5959\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5043 - val_loss: 142.7675\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2160 - val_loss: 165.0702\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3332 - val_loss: 123.8661\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.4461 - val_loss: 131.2644\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.0039 - val_loss: 152.7803\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.8888 - val_loss: 154.3464\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5489 - val_loss: 123.8584\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.5115 - val_loss: 174.7865\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.5279 - val_loss: 130.9792\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0016 - val_loss: 131.5237\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0883 - val_loss: 152.3130\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5639 - val_loss: 161.3550\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2644 - val_loss: 126.2592\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.8891 - val_loss: 141.5925\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 387.6005 - val_loss: 185.2226\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.0889 - val_loss: 146.9115\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5851 - val_loss: 130.6955\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.5745 - val_loss: 118.0583\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1810 - val_loss: 147.2245\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 124.3588 - val_loss: 123.3780\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 129.3464 - val_loss: 166.3133\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 127.1224 - val_loss: 142.5051\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.2555 - val_loss: 124.7828\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6720 - val_loss: 137.1176\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8311 - val_loss: 195.0886\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1973 - val_loss: 137.0654\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2492 - val_loss: 156.6983\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8197 - val_loss: 139.2588\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5543 - val_loss: 134.1189\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2263 - val_loss: 167.2745\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8904 - val_loss: 136.6152\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7749 - val_loss: 151.8267\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3541 - val_loss: 124.1413\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5962 - val_loss: 166.2876\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.9134 - val_loss: 171.9360\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0086 - val_loss: 128.7392\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.3818 - val_loss: 122.7043\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2321 - val_loss: 164.0558\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6640 - val_loss: 122.0328\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.7625 - val_loss: 141.2552\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4165 - val_loss: 129.1824\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1089 - val_loss: 145.4850\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2625 - val_loss: 127.9773\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0445 - val_loss: 122.6371\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.7483 - val_loss: 132.7191\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1893 - val_loss: 120.9631\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7018 - val_loss: 127.9875\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1262 - val_loss: 131.7285\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 210.9943 - val_loss: 131.2244\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3949 - val_loss: 128.2783\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0541 - val_loss: 123.7070\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9434 - val_loss: 125.8800\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8925 - val_loss: 130.2926\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5343 - val_loss: 134.9823\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.3925 - val_loss: 239.6882\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.7167 - val_loss: 128.9752\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5997 - val_loss: 147.7270\n",
      "Epoch 1762/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0471 - val_loss: 120.8445\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7979 - val_loss: 647.9428\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 413.6544 - val_loss: 142.0348\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8530 - val_loss: 136.2307\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.8414 - val_loss: 142.5634\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.4708 - val_loss: 131.5854\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2796 - val_loss: 120.3371\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.2690 - val_loss: 146.4354\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 160.7185 - val_loss: 122.5768\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.4401 - val_loss: 128.9893\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5570 - val_loss: 130.4010\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7414 - val_loss: 122.3883\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.5427 - val_loss: 175.4611\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2439 - val_loss: 132.5790\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.0106 - val_loss: 133.5906\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7753 - val_loss: 134.0933\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6333 - val_loss: 137.3192\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3639 - val_loss: 172.7648\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0164 - val_loss: 131.3251\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7024 - val_loss: 135.2868\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.9238 - val_loss: 128.7908\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3369 - val_loss: 190.4985\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.1321 - val_loss: 121.6774\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0030 - val_loss: 231.1343\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.2681 - val_loss: 131.5376\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3498 - val_loss: 132.9244\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.4572 - val_loss: 126.7940\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.6446 - val_loss: 126.0924\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5027 - val_loss: 144.4332\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5601 - val_loss: 130.8031\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7716 - val_loss: 144.8632\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0419 - val_loss: 120.2863\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.9867 - val_loss: 139.7191\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8395 - val_loss: 141.8678\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6517 - val_loss: 135.0419\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.6485 - val_loss: 150.5716\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 466.8174 - val_loss: 136.8115\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 135.2391 - val_loss: 178.8217\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7155 - val_loss: 127.6945\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.8528 - val_loss: 126.4901\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.2473 - val_loss: 159.4596\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.1027 - val_loss: 145.6667\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.7866 - val_loss: 134.5545\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.1470 - val_loss: 128.8361\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.5595 - val_loss: 138.6593\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 123.629 - 0s 51us/step - loss: 123.4388 - val_loss: 143.2023\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.6470 - val_loss: 147.5888\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0065 - val_loss: 151.6694\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.7867 - val_loss: 126.8174\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2062 - val_loss: 145.4366\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.8193 - val_loss: 138.2679\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1124 - val_loss: 130.7070\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5707 - val_loss: 138.4011\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.6832 - val_loss: 161.6446\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8537 - val_loss: 127.3735\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.0842 - val_loss: 131.7313\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7257 - val_loss: 142.1676\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6920 - val_loss: 196.9203\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2078 - val_loss: 150.1752\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7659 - val_loss: 175.3918\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7290 - val_loss: 142.3968\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2665 - val_loss: 145.0546\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.1170 - val_loss: 127.6985\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8558 - val_loss: 156.9508\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.0587 - val_loss: 136.1485\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7280 - val_loss: 127.0607\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 762.4271 - val_loss: 482.1674\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 326.0134 - val_loss: 199.9890\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 242.8376 - val_loss: 204.6860\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 213.8389 - val_loss: 155.5909\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.7878 - val_loss: 162.8154\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.7967 - val_loss: 321.3156\n",
      "Epoch 1834/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.3397 - val_loss: 229.0710\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.5102 - val_loss: 183.1959\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.1234 - val_loss: 230.3905\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.5837 - val_loss: 213.7592\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.4896 - val_loss: 333.6485\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3036 - val_loss: 149.8611\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.6880 - val_loss: 154.1507\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.2318 - val_loss: 217.3157\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.6187 - val_loss: 199.6137\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.2408 - val_loss: 162.4542\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4499 - val_loss: 179.3481\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.6112 - val_loss: 194.2621\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.1533 - val_loss: 150.4617\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 172.8049 - val_loss: 140.6804\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.7253 - val_loss: 170.3734\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 166.0034 - val_loss: 146.7615\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5697 - val_loss: 137.5538\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2822 - val_loss: 229.3668\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 154.2903 - val_loss: 193.3288\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2842 - val_loss: 144.2385\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.4174 - val_loss: 133.5867\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.8595 - val_loss: 158.3362\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8370 - val_loss: 194.1251\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.0024 - val_loss: 188.9549\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7788 - val_loss: 137.5175\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1174 - val_loss: 202.9856\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.1095 - val_loss: 492.6353\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9061 - val_loss: 140.5263\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.1509 - val_loss: 130.7458\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4905 - val_loss: 145.8133\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8168 - val_loss: 156.6573\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.0642 - val_loss: 184.6952\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7766 - val_loss: 172.4072\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9032 - val_loss: 154.6363\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5160 - val_loss: 168.7825\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.5782 - val_loss: 162.1847\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 143.3623 - val_loss: 163.6602\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.5151 - val_loss: 126.6373\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 130.3323 - val_loss: 198.8673\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2929 - val_loss: 134.6873\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7585 - val_loss: 132.5291\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9328 - val_loss: 229.2890\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0464 - val_loss: 150.3035\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.6680 - val_loss: 124.9413\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.1805 - val_loss: 141.0351\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3053 - val_loss: 216.0057\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6383 - val_loss: 138.0814\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8250 - val_loss: 138.1640\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.0150 - val_loss: 205.2151\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.6042 - val_loss: 138.0992\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0270 - val_loss: 165.6122\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6539 - val_loss: 128.1904\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7768 - val_loss: 138.6626\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.7765 - val_loss: 123.0975\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.4580 - val_loss: 152.3327\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9063 - val_loss: 144.1943\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1997 - val_loss: 147.9836\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4750 - val_loss: 123.3832\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.8538 - val_loss: 149.2599\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.0904 - val_loss: 131.7156\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.5280 - val_loss: 138.5235\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.0711 - val_loss: 288.1066\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.4592 - val_loss: 166.9700\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.2897 - val_loss: 130.9865\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1137 - val_loss: 147.9983\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2194 - val_loss: 142.1136\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2897 - val_loss: 138.5589\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2349 - val_loss: 128.8774\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.0714 - val_loss: 135.8144\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.5554 - val_loss: 151.9045\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1289 - val_loss: 142.5036\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4088 - val_loss: 127.6342\n",
      "Epoch 1906/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1874 - val_loss: 146.6016\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2601 - val_loss: 146.8364\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2616 - val_loss: 131.7957\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6667 - val_loss: 201.4019\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8757 - val_loss: 167.9994\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8951 - val_loss: 186.2519\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8048 - val_loss: 142.3995\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4376 - val_loss: 122.1642\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5264 - val_loss: 175.6681\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4862 - val_loss: 154.2256\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2678 - val_loss: 145.6207\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5007 - val_loss: 123.7114\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.5929 - val_loss: 164.9494\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4500 - val_loss: 128.7776\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2438 - val_loss: 129.5769\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.5583 - val_loss: 123.1867\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5560 - val_loss: 127.8618\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.0002 - val_loss: 142.7812\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2251 - val_loss: 128.5269\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6842 - val_loss: 133.3786\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0571 - val_loss: 131.5018\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7412 - val_loss: 190.6884\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 481.1162 - val_loss: 224.2569\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.9691 - val_loss: 125.7666\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.4300 - val_loss: 136.8010\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2996 - val_loss: 133.5376\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0305 - val_loss: 121.8742\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8148 - val_loss: 123.6808\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8590 - val_loss: 131.0294\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5414 - val_loss: 132.3297\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.9388 - val_loss: 125.3363\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2414 - val_loss: 140.6033\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2291 - val_loss: 131.1769\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4196 - val_loss: 120.5184\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.2973 - val_loss: 123.8326\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.3867 - val_loss: 130.5803\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 147.9521 - val_loss: 140.7799\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 128.2209 - val_loss: 135.9219\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 138.3841 - val_loss: 127.6253\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.0255 - val_loss: 133.3906\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9496 - val_loss: 133.5543\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1625 - val_loss: 155.1567\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.3735 - val_loss: 144.6731\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1534 - val_loss: 136.9331\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4445 - val_loss: 146.6855\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.8868 - val_loss: 246.4109\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6952 - val_loss: 426.9744\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 139.278 - 0s 51us/step - loss: 138.8287 - val_loss: 210.6865\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0434 - val_loss: 129.8927\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.5539 - val_loss: 134.9244\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6381 - val_loss: 147.2034\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.1553 - val_loss: 143.5675\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.8044 - val_loss: 190.9674\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.3537 - val_loss: 124.0804\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9542 - val_loss: 136.2874\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1760 - val_loss: 128.6202\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.1895 - val_loss: 233.5915\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.5898 - val_loss: 147.3245\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4477 - val_loss: 133.9917\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6129 - val_loss: 152.5801\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7699 - val_loss: 160.7146\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9698 - val_loss: 147.2806\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4129 - val_loss: 166.2278\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 171.7530 - val_loss: 156.0926\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0863 - val_loss: 147.0747\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.9779 - val_loss: 132.9086\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4307 - val_loss: 154.9604\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3145 - val_loss: 142.6298\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7650 - val_loss: 133.7821\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.5648 - val_loss: 129.5845\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.8494 - val_loss: 128.4397\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3511 - val_loss: 186.1636\n",
      "Epoch 1978/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5198 - val_loss: 180.0584\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0109 - val_loss: 138.3847\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.0825 - val_loss: 148.0190\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.5882 - val_loss: 157.0855\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6300 - val_loss: 123.7941\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2320 - val_loss: 125.6514\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5986 - val_loss: 158.9320\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4416 - val_loss: 133.0918\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7449 - val_loss: 185.9046\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.6555 - val_loss: 121.0792\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.1116 - val_loss: 128.9262\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.3022 - val_loss: 145.8981\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.4525 - val_loss: 314.8026\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.6427 - val_loss: 133.9373\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1629 - val_loss: 127.5917\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.2010 - val_loss: 126.3828\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2431 - val_loss: 122.4794\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5984 - val_loss: 121.0715\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.5948 - val_loss: 127.4438\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7463 - val_loss: 136.5092\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.9089 - val_loss: 154.6191\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 132.410 - 0s 51us/step - loss: 131.3635 - val_loss: 130.5549\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4790 - val_loss: 154.9947\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.4631 - val_loss: 125.6141\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0609 - val_loss: 138.3948\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6021 - val_loss: 145.4167\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.3412 - val_loss: 125.0688\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.6351 - val_loss: 149.7160\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0696 - val_loss: 140.9404\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7325 - val_loss: 129.3823\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.8809 - val_loss: 144.4607\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.5372 - val_loss: 125.4959\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.7893 - val_loss: 126.8474\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2286 - val_loss: 126.8314\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.5268 - val_loss: 131.5459\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.8183 - val_loss: 131.4314\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.5863 - val_loss: 147.4107\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 126.9998 - val_loss: 190.7384\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 134.7240 - val_loss: 135.6476\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.5340 - val_loss: 144.0965\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9812 - val_loss: 136.0716\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3690 - val_loss: 266.8039\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4220 - val_loss: 124.4778\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3660 - val_loss: 129.9904\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0553 - val_loss: 183.7030\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1213 - val_loss: 141.8759\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.8188 - val_loss: 121.5012\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9510 - val_loss: 156.2321\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8425 - val_loss: 149.1452\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.4184 - val_loss: 128.8834\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3644 - val_loss: 142.9544\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.4354 - val_loss: 136.1747\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6418 - val_loss: 162.5447\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3704 - val_loss: 209.2854\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5823 - val_loss: 120.7258\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.4676 - val_loss: 146.9864\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.8002 - val_loss: 156.5440\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.5670 - val_loss: 130.9083\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9536 - val_loss: 125.6598\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9415 - val_loss: 162.4832\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.7247 - val_loss: 160.7338\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.0533 - val_loss: 291.7167\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.4949 - val_loss: 139.6608\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.2907 - val_loss: 130.6713\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.7021 - val_loss: 152.7176\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5068 - val_loss: 125.9725\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1861 - val_loss: 189.5112\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1510 - val_loss: 144.9995\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.9219 - val_loss: 124.9227\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9067 - val_loss: 136.8187\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.2858 - val_loss: 144.4299\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1294 - val_loss: 127.5171\n",
      "Epoch 2050/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0648 - val_loss: 126.0810\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9665 - val_loss: 146.5473\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1135 - val_loss: 132.5470\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.3715 - val_loss: 144.6473\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2431 - val_loss: 154.3852\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1485 - val_loss: 176.5811\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3230 - val_loss: 126.5374\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.0569 - val_loss: 131.0920\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9990 - val_loss: 131.6825\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0874 - val_loss: 124.1321\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4972 - val_loss: 231.9284\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.3532 - val_loss: 136.5388\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0028 - val_loss: 132.7536\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.5476 - val_loss: 124.0192\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8279 - val_loss: 129.0141\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 192.7997 - val_loss: 127.3552\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5274 - val_loss: 148.7810\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3819 - val_loss: 121.8160\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.6620 - val_loss: 135.8292\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.2855 - val_loss: 132.2051\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.9249 - val_loss: 124.7066\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.1598 - val_loss: 120.2872\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7534 - val_loss: 130.8200\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.0978 - val_loss: 131.8636\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1770 - val_loss: 125.3756\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 128.7181 - val_loss: 123.2880\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8718 - val_loss: 134.5617\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9767 - val_loss: 138.7094\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.1467 - val_loss: 193.4945\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.2011 - val_loss: 123.6701\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7204 - val_loss: 128.6608\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7701 - val_loss: 135.1128\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3132 - val_loss: 129.6375\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.1884 - val_loss: 124.6841\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2197 - val_loss: 126.6748\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6008 - val_loss: 122.2319\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5674 - val_loss: 136.2742\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.3597 - val_loss: 121.5571\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 134.3414 - val_loss: 126.0850\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.2673 - val_loss: 138.1495\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.0575 - val_loss: 129.8955\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8102 - val_loss: 148.9697\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3608 - val_loss: 193.8932\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7127 - val_loss: 123.9623\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0498 - val_loss: 122.8307\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8025 - val_loss: 138.8635\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.6744 - val_loss: 127.7881\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.2569 - val_loss: 152.1539\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1409 - val_loss: 157.0593\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4667 - val_loss: 123.0614\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.9663 - val_loss: 131.9315\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.4019 - val_loss: 132.9694\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.2221 - val_loss: 134.6218\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5513 - val_loss: 194.9480\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 122.446 - 0s 51us/step - loss: 122.9232 - val_loss: 150.3359\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.8043 - val_loss: 121.3577\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3256 - val_loss: 126.8322\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.2851 - val_loss: 131.0350\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9151 - val_loss: 155.3992\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8790 - val_loss: 122.6977\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.6302 - val_loss: 135.4018\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1573 - val_loss: 130.7327\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.0863 - val_loss: 146.0464\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1617 - val_loss: 162.5922\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6535 - val_loss: 133.0773\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.1865 - val_loss: 129.1883\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.5809 - val_loss: 155.7398\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8757 - val_loss: 133.4381\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9566 - val_loss: 139.2189\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0042 - val_loss: 126.9871\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6209 - val_loss: 177.8522\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2827 - val_loss: 128.3095\n",
      "Epoch 2122/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.5723 - val_loss: 212.8732\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4385 - val_loss: 127.0570\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4793 - val_loss: 151.6284\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4986 - val_loss: 139.5442\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.6226 - val_loss: 169.5635\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2754 - val_loss: 135.0940\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8281 - val_loss: 184.3613\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1364 - val_loss: 128.3162\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1899 - val_loss: 142.3928\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2022 - val_loss: 138.9898\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.0322 - val_loss: 238.2345\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3250 - val_loss: 139.9529\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2439 - val_loss: 130.5551\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0582 - val_loss: 137.8329\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4868 - val_loss: 196.7060\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1800 - val_loss: 123.7274\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2917 - val_loss: 159.0950\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2963 - val_loss: 123.5951\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2265 - val_loss: 127.0903\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.4302 - val_loss: 140.6311\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.3112 - val_loss: 1086.9467\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.8921 - val_loss: 131.7741\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.6427 - val_loss: 127.8437\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.7658 - val_loss: 126.8998\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.9286 - val_loss: 124.6980\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1689 - val_loss: 156.9821\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9132 - val_loss: 160.5970\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7927 - val_loss: 123.8089\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.2435 - val_loss: 161.1815\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5012 - val_loss: 119.4432\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.3976 - val_loss: 140.3731\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9129 - val_loss: 126.8038\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.5870 - val_loss: 124.9962\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.3772 - val_loss: 142.0255\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8175 - val_loss: 126.0966\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8754 - val_loss: 144.7215\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 200.7604 - val_loss: 129.6978\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 119.7152 - val_loss: 135.6013\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 120.7843 - val_loss: 138.0190\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 125.9964 - val_loss: 124.3593\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.6479 - val_loss: 152.6245\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6112 - val_loss: 124.5340\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.4598 - val_loss: 147.5273\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8330 - val_loss: 138.2645\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.9452 - val_loss: 138.0606\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4481 - val_loss: 201.9762\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5750 - val_loss: 126.1856\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.0113 - val_loss: 167.0425\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9108 - val_loss: 141.6458\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.7794 - val_loss: 137.8473\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7152 - val_loss: 121.9067\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6470 - val_loss: 131.9407\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7303 - val_loss: 139.8395\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6026 - val_loss: 127.3216\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1013 - val_loss: 131.2840\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8546 - val_loss: 173.7041\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.9383 - val_loss: 121.9991\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7483 - val_loss: 132.3274\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1597 - val_loss: 130.8905\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.6077 - val_loss: 134.0715\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.0374 - val_loss: 145.5147\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0463 - val_loss: 145.9474\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.9526 - val_loss: 123.6045\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2588 - val_loss: 207.0408\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6272 - val_loss: 125.3162\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.6306 - val_loss: 153.1681\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 329.5822 - val_loss: 170.9114\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.5615 - val_loss: 125.6970\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0932 - val_loss: 124.2296\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.6213 - val_loss: 138.0639\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.0161 - val_loss: 125.0210\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.3358 - val_loss: 133.2829\n",
      "Epoch 2194/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3638 - val_loss: 158.0594\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9341 - val_loss: 129.4554\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4559 - val_loss: 145.6272\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 136.833 - 0s 51us/step - loss: 137.3198 - val_loss: 131.1556\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.1303 - val_loss: 140.7001\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0688 - val_loss: 155.2157\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4093 - val_loss: 152.1450\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3168 - val_loss: 148.0726\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.0490 - val_loss: 129.6349\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1097 - val_loss: 149.1503\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0126 - val_loss: 262.1281\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.6561 - val_loss: 129.4048\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0464 - val_loss: 140.9087\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0727 - val_loss: 153.7833\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8048 - val_loss: 122.2481\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6350 - val_loss: 200.7116\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9989 - val_loss: 123.7299\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.6703 - val_loss: 129.4652\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9721 - val_loss: 127.0293\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4151 - val_loss: 140.9839\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3147 - val_loss: 157.3760\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0606 - val_loss: 143.0131\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.8485 - val_loss: 132.2771\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.4692 - val_loss: 125.7702\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0995 - val_loss: 124.2952\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6397 - val_loss: 349.1753\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.8732 - val_loss: 215.1835\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3366 - val_loss: 129.7185\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7566 - val_loss: 129.3380\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.0987 - val_loss: 177.7045\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0056 - val_loss: 137.4579\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3935 - val_loss: 281.0078\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8343 - val_loss: 176.6091\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5428 - val_loss: 128.9945\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.1870 - val_loss: 160.1332\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3084 - val_loss: 125.6621\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7976 - val_loss: 126.2291\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.2223 - val_loss: 150.3213\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2600 - val_loss: 132.5623\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.8609 - val_loss: 133.1582\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.4894 - val_loss: 130.1938\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6170 - val_loss: 211.3579\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1786 - val_loss: 188.1315\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9843 - val_loss: 122.9284\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4126 - val_loss: 130.8729\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5622 - val_loss: 127.3455\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.8879 - val_loss: 140.3297\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1172 - val_loss: 141.6425\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 132.5183 - val_loss: 128.2981\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 122.4337 - val_loss: 127.2269\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.7151 - val_loss: 141.9457\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.6542 - val_loss: 131.8691\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9949 - val_loss: 176.7540\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2240 - val_loss: 153.5749\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7085 - val_loss: 142.0757\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.9338 - val_loss: 214.1973\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8452 - val_loss: 155.2065\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.8750 - val_loss: 171.5164\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0238 - val_loss: 134.2044\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9054 - val_loss: 138.6980\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6102 - val_loss: 138.7800\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2621 - val_loss: 142.3795\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.8134 - val_loss: 189.5998\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.2594 - val_loss: 166.9472\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.9856 - val_loss: 126.3301\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 183.2737 - val_loss: 135.9118\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0887 - val_loss: 125.7300\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4172 - val_loss: 129.5773\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.1007 - val_loss: 124.5884\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.1993 - val_loss: 140.7550\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.9585 - val_loss: 123.1810\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.9227 - val_loss: 137.8310\n",
      "Epoch 2266/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.4737 - val_loss: 126.1718\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7751 - val_loss: 127.0538\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.8069 - val_loss: 125.6593\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0447 - val_loss: 122.6477\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3166 - val_loss: 127.2217\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.7794 - val_loss: 133.7621\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3422 - val_loss: 137.9710\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5128 - val_loss: 184.9508\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.8920 - val_loss: 131.1407\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0654 - val_loss: 126.7123\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.8918 - val_loss: 131.5295\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6652 - val_loss: 133.1152\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7340 - val_loss: 123.9041\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.1435 - val_loss: 137.0877\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.9512 - val_loss: 140.7397\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2919 - val_loss: 170.4398\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.7163 - val_loss: 132.9071\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6393 - val_loss: 176.1052\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.5602 - val_loss: 148.1543\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5277 - val_loss: 125.5973\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7937 - val_loss: 129.2499\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.7508 - val_loss: 149.0467\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.0667 - val_loss: 163.8599\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.1059 - val_loss: 169.0260\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.2760 - val_loss: 130.3773\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.6593 - val_loss: 141.3222\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.027 - 0s 51us/step - loss: 126.7401 - val_loss: 136.2976\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7304 - val_loss: 123.2983\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5168 - val_loss: 131.2766\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3547 - val_loss: 124.0361\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.5836 - val_loss: 183.4413\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6522 - val_loss: 122.0674\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.3527 - val_loss: 129.0751\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8387 - val_loss: 129.4870\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0615 - val_loss: 141.1004\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.3397 - val_loss: 141.2787\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0373 - val_loss: 160.9382\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.8943 - val_loss: 126.3026\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.1770 - val_loss: 137.9335\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 119.2683 - val_loss: 128.9730\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 127.7475 - val_loss: 119.5652\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 136.2113 - val_loss: 128.9739\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 367.6764 - val_loss: 144.2279\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3462 - val_loss: 134.1990\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2885 - val_loss: 121.2688\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.1687 - val_loss: 138.7244\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.4374 - val_loss: 124.7083\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0741 - val_loss: 132.5902\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1476 - val_loss: 130.7374\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.2638 - val_loss: 120.4833\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.3513 - val_loss: 135.4313\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1259 - val_loss: 122.4953\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.7281 - val_loss: 132.3031\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.4096 - val_loss: 202.3973\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.8429 - val_loss: 137.8742\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2953 - val_loss: 136.9966\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5950 - val_loss: 121.8738\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5772 - val_loss: 215.2831\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.3751 - val_loss: 121.1883\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.5054 - val_loss: 122.7133\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5143 - val_loss: 121.3297\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5926 - val_loss: 150.1709\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4106 - val_loss: 126.8427\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5277 - val_loss: 135.0600\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5517 - val_loss: 135.7333\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5540 - val_loss: 133.0809\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 199.6966 - val_loss: 191.6246\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5220 - val_loss: 127.8695\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.1406 - val_loss: 166.9053\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.0939 - val_loss: 125.3852\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8120 - val_loss: 136.7344\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.0059 - val_loss: 125.5578\n",
      "Epoch 2338/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.8910 - val_loss: 138.4063\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.8381 - val_loss: 146.1915\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7539 - val_loss: 123.6961\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2205 - val_loss: 139.2049\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0584 - val_loss: 150.4927\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9615 - val_loss: 136.7937\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.8334 - val_loss: 140.8051\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9050 - val_loss: 143.4886\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9668 - val_loss: 170.5844\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.3275 - val_loss: 120.6227\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.5228 - val_loss: 134.2206\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9103 - val_loss: 221.6308\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.8178 - val_loss: 151.2116\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8412 - val_loss: 119.7552\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.2096 - val_loss: 123.3042\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.0108 - val_loss: 130.9272\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 431.5394 - val_loss: 130.7161\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.7626 - val_loss: 125.2664\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.6718 - val_loss: 132.0022\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.1214 - val_loss: 125.6343\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.2917 - val_loss: 133.0885\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.5045 - val_loss: 140.7523\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.0036 - val_loss: 136.0471\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1551 - val_loss: 127.1210\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.3032 - val_loss: 133.6398\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6584 - val_loss: 125.9722\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.4261 - val_loss: 174.6378\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9955 - val_loss: 130.9797\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.9591 - val_loss: 122.3966\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4359 - val_loss: 146.1198\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9080 - val_loss: 139.8053\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9306 - val_loss: 131.0293\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.2473 - val_loss: 125.5500\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6848 - val_loss: 119.9098\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.5077 - val_loss: 141.6945\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.1052 - val_loss: 124.7740\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4157 - val_loss: 127.1159\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5383 - val_loss: 129.9007\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 124.1900 - val_loss: 140.8283\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 125.3645 - val_loss: 131.6443\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 123.3731 - val_loss: 208.2404\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 169.7549 - val_loss: 621.1932\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.2440 - val_loss: 168.5324\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.0008 - val_loss: 125.1359\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.6903 - val_loss: 161.5011\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4203 - val_loss: 193.9399\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4409 - val_loss: 135.3485\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.6005 - val_loss: 132.0076\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.3956 - val_loss: 127.1887\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.2191 - val_loss: 131.8951\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.0931 - val_loss: 126.5664\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5326 - val_loss: 130.2916\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7906 - val_loss: 133.8461\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5083 - val_loss: 125.2870\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2409 - val_loss: 190.5091\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2592 - val_loss: 146.6001\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4464 - val_loss: 374.6283\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.2800 - val_loss: 135.7640\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.5085 - val_loss: 153.8936\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.4806 - val_loss: 141.5472\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.5200 - val_loss: 131.5866\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4124 - val_loss: 137.9628\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7769 - val_loss: 138.4703\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6834 - val_loss: 130.7256\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.6409 - val_loss: 128.1240\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 117.9736 - val_loss: 124.4910\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5161 - val_loss: 202.9657\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.9789 - val_loss: 208.1370\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.0233 - val_loss: 128.7847\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0165 - val_loss: 121.0660\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.3308 - val_loss: 121.9297\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 116.4271 - val_loss: 142.2995\n",
      "Epoch 2410/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.8151 - val_loss: 122.4541\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.0598 - val_loss: 135.4534\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1482 - val_loss: 124.0982\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 115.1070 - val_loss: 123.7364\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.1045 - val_loss: 122.8445\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6183 - val_loss: 216.0936\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.0557 - val_loss: 140.5665\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9795 - val_loss: 128.3497\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7359 - val_loss: 165.3298\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6207 - val_loss: 124.0199\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4119 - val_loss: 144.4337\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2372 - val_loss: 131.7899\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9899 - val_loss: 210.3519\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6103 - val_loss: 122.8631\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0415 - val_loss: 166.6024\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 307.3606 - val_loss: 142.7412\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.4206 - val_loss: 134.1154\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4132 - val_loss: 175.9462\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.7972 - val_loss: 129.9615\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.9883 - val_loss: 123.4937\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.4367 - val_loss: 133.9745\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9636 - val_loss: 141.8495\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.8248 - val_loss: 129.7688\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3830 - val_loss: 130.3952\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 233.7555 - val_loss: 156.0702\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.2870 - val_loss: 129.4673\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.1220 - val_loss: 126.0493\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.9096 - val_loss: 132.9384\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.4415 - val_loss: 138.7815\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.5311 - val_loss: 133.7212\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.3414 - val_loss: 129.6723\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.3447 - val_loss: 148.6058\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.8069 - val_loss: 131.7428\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.0059 - val_loss: 149.3012\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3654 - val_loss: 144.1521\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5583 - val_loss: 130.6364\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.8651 - val_loss: 193.0438\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 124.2400 - val_loss: 146.6520\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.7253 - val_loss: 126.5917\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 125.8946 - val_loss: 155.8685\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 122.9334 - val_loss: 137.7272\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 127.3697 - val_loss: 128.6789\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.5746 - val_loss: 140.8667\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.9139 - val_loss: 129.4156\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 132.3216 - val_loss: 133.8774\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 121.9452 - val_loss: 146.0654\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 127.6162 - val_loss: 161.7297\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.2963 - val_loss: 138.2665\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.3283 - val_loss: 127.6194\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.8478 - val_loss: 140.4327\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.2481 - val_loss: 128.5573\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.9021 - val_loss: 134.3663\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0956 - val_loss: 201.5303\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.4604 - val_loss: 125.2148\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.3615 - val_loss: 136.1609\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.7567 - val_loss: 122.6127\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.0701 - val_loss: 147.0292\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.1626 - val_loss: 129.8214\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.2580 - val_loss: 130.4569\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.3751 - val_loss: 151.4053\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6951 - val_loss: 132.4902\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1088 - val_loss: 126.4471\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8842 - val_loss: 158.9024\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.7013 - val_loss: 156.8563\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.9749 - val_loss: 151.8445\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5146 - val_loss: 154.7952\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.9161 - val_loss: 141.7210\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.6915 - val_loss: 134.0415\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.6387 - val_loss: 215.4057\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.0198 - val_loss: 228.9283\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.8338 - val_loss: 152.8311\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.9106 - val_loss: 140.8918\n",
      "Epoch 2482/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 66us/step - loss: 123.1814 - val_loss: 150.5092\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.0085 - val_loss: 165.0361\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.3075 - val_loss: 121.5270\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.4459 - val_loss: 194.4771\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1573 - val_loss: 126.2152\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.2555 - val_loss: 141.5197\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.0388 - val_loss: 230.8243\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.2666 - val_loss: 126.6701\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.1302 - val_loss: 123.0285\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.7628 - val_loss: 143.1523\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.4577 - val_loss: 139.9632\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 126.1052 - val_loss: 131.8400\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 125.9079 - val_loss: 119.9826\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.6376 - val_loss: 126.9886\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.2089 - val_loss: 128.1264\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.3899 - val_loss: 209.8863\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.1279 - val_loss: 121.2666\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4336 - val_loss: 145.9850\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.1575 - val_loss: 143.4425\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.3507 - val_loss: 124.6694\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 126.8045 - val_loss: 123.4088\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8972 - val_loss: 124.0616\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 133.9335 - val_loss: 174.1604\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3506 - val_loss: 172.6089\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.4095 - val_loss: 126.0945\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 128.4603 - val_loss: 155.9385\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.6880 - val_loss: 125.3456\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6476 - val_loss: 129.8439\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.9916 - val_loss: 124.2978\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1971 - val_loss: 127.2809\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9150 - val_loss: 212.6982\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6770 - val_loss: 122.0975\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1485 - val_loss: 196.5104\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 184.3133 - val_loss: 660.7798\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.5867 - val_loss: 128.6677\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.9598 - val_loss: 133.0174\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 122.8961 - val_loss: 133.5047\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 118.2132 - val_loss: 129.9981\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 137.1482 - val_loss: 140.1022\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2005 - val_loss: 131.5612\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.3341 - val_loss: 143.9306\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.7123 - val_loss: 149.6454\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.1731 - val_loss: 123.4011\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.4359 - val_loss: 183.0577\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3749 - val_loss: 144.3048\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5980 - val_loss: 124.6081\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6665 - val_loss: 143.2934\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.3614 - val_loss: 134.1212\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8613 - val_loss: 137.1263\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.7408 - val_loss: 140.3584\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.5721 - val_loss: 127.3799\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.0288 - val_loss: 145.9422\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.5553 - val_loss: 136.3654\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9255 - val_loss: 131.0605\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.0916 - val_loss: 119.7461\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4678 - val_loss: 178.4902\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.8662 - val_loss: 129.2183\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.2171 - val_loss: 154.7581\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0231 - val_loss: 133.9576\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.2437 - val_loss: 122.4961\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2723 - val_loss: 139.6137\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4384 - val_loss: 143.5283\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.4049 - val_loss: 126.4798\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 128.1605 - val_loss: 169.6061\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 134.1744 - val_loss: 125.5027\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.2918 - val_loss: 127.1748\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.2592 - val_loss: 130.5373\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.2050 - val_loss: 133.7374\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 117.7094 - val_loss: 142.0923\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.2256 - val_loss: 126.2090\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6442 - val_loss: 126.7251\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.3263 - val_loss: 123.1421\n",
      "Epoch 2554/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.9326 - val_loss: 134.4409\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.8761 - val_loss: 140.4201\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.2395 - val_loss: 138.8726\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0391 - val_loss: 132.8301\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.1973 - val_loss: 125.5210\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7960 - val_loss: 129.9241\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0954 - val_loss: 133.7685\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.6383 - val_loss: 124.6848\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1351 - val_loss: 137.8094\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3896 - val_loss: 130.4622\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6089 - val_loss: 139.9642\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.0971 - val_loss: 157.7628\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.1854 - val_loss: 128.8133\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4388 - val_loss: 156.6761\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8544 - val_loss: 121.6235\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.6252 - val_loss: 129.2332\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6092 - val_loss: 188.2803\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.1385 - val_loss: 145.6528\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.3348 - val_loss: 171.0295\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.5931 - val_loss: 166.6512\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.4192 - val_loss: 158.7666\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.4614 - val_loss: 151.8591\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.2783 - val_loss: 141.2386\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.7291 - val_loss: 131.5299\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8820 - val_loss: 133.5041\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.0006 - val_loss: 143.1671\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.2648 - val_loss: 127.3766\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1253 - val_loss: 158.5141\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.7342 - val_loss: 156.6067\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3870 - val_loss: 165.3375\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5809 - val_loss: 130.6003\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 131.1286 - val_loss: 123.8102\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0855 - val_loss: 136.5054\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 559.2814 - val_loss: 154.5053\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.4074 - val_loss: 145.8018\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8824 - val_loss: 134.0380\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 121.1291 - val_loss: 137.6469\n",
      "Epoch 2591/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 119.2896 - val_loss: 125.7321\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 120.0786 - val_loss: 134.4901\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.8009 - val_loss: 133.2254\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.0627 - val_loss: 262.9993\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1629 - val_loss: 136.4511\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.1314 - val_loss: 137.0550\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5634 - val_loss: 191.6437\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5653 - val_loss: 142.5520\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0777 - val_loss: 169.4291\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.6723 - val_loss: 190.6032\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.2477 - val_loss: 139.3951\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.5436 - val_loss: 129.4468\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.6926 - val_loss: 140.8656\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6915 - val_loss: 128.3433\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0183 - val_loss: 130.5324\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.4074 - val_loss: 137.0318\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7139 - val_loss: 130.9633\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5051 - val_loss: 142.7379\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.6727 - val_loss: 140.1816\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.9400 - val_loss: 134.8771\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.4750 - val_loss: 143.3097\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2335 - val_loss: 123.8403\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8109 - val_loss: 159.6039\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.9237 - val_loss: 171.1894\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.6012 - val_loss: 131.6239\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.1161 - val_loss: 137.2889\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 341.1932 - val_loss: 141.4651\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.0200 - val_loss: 173.8178\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8069 - val_loss: 134.1768\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.8300 - val_loss: 123.7421\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3471 - val_loss: 127.6153\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7276 - val_loss: 124.8915\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6067 - val_loss: 157.2798\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.7317 - val_loss: 134.6779\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.8575 - val_loss: 123.2178\n",
      "Epoch 2626/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.4344 - val_loss: 139.5990\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1577 - val_loss: 144.9810\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.9806 - val_loss: 152.0344\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0722 - val_loss: 131.4135\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.6749 - val_loss: 127.3843\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.5870 - val_loss: 122.9596\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.1796 - val_loss: 130.6384\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 230.6471 - val_loss: 144.6949\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.7588 - val_loss: 125.8994\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0019 - val_loss: 131.5415\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6899 - val_loss: 123.4198\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1731 - val_loss: 226.6226\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8837 - val_loss: 128.0057\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0375 - val_loss: 127.5893\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.6291 - val_loss: 126.9679\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 287.6493 - val_loss: 166.1099\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1972 - val_loss: 130.3525\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.5773 - val_loss: 132.1293\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4042 - val_loss: 126.8129\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.6485 - val_loss: 133.9220\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7293 - val_loss: 130.6076\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0179 - val_loss: 129.2908\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.5164 - val_loss: 127.4149\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.5433 - val_loss: 130.8614\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6523 - val_loss: 132.5581\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8487 - val_loss: 154.5556\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5613 - val_loss: 129.8196\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5729 - val_loss: 183.0279\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9030 - val_loss: 136.3548\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0052 - val_loss: 122.3221\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 243.9830 - val_loss: 272.5414\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 352.0701 - val_loss: 141.0914\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.5603 - val_loss: 127.6644\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.1952 - val_loss: 133.7272\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.8404 - val_loss: 122.2072\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.9613 - val_loss: 127.0336\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.3088 - val_loss: 131.5806\n",
      "Epoch 2663/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 121.0071 - val_loss: 182.6246\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 122.3447 - val_loss: 195.7235\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 124.7606 - val_loss: 120.3630\n",
      "Epoch 2666/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.1828 - val_loss: 140.7899\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5986 - val_loss: 150.2294\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6075 - val_loss: 199.6753\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.2541 - val_loss: 128.9766\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3752 - val_loss: 144.2498\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.6514 - val_loss: 162.6603\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.3803 - val_loss: 132.3674\n",
      "Epoch 2673/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.6260 - val_loss: 161.6851\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.7198 - val_loss: 148.6228\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.4274 - val_loss: 131.8413\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.8825 - val_loss: 131.3065\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8611 - val_loss: 175.6963\n",
      "Epoch 2678/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3539 - val_loss: 137.9829\n",
      "Epoch 2679/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5333 - val_loss: 134.9113\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.2563 - val_loss: 130.0394\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.3002 - val_loss: 132.8863\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.1928 - val_loss: 138.4473\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.1081 - val_loss: 153.9036\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.1827 - val_loss: 214.4653\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0697 - val_loss: 176.2245\n",
      "Epoch 2686/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.4357 - val_loss: 126.4707\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.3406 - val_loss: 166.6955\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0833 - val_loss: 137.8383\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.2601 - val_loss: 128.0827\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 440.5591 - val_loss: 145.2184\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.7098 - val_loss: 128.0153\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.6778 - val_loss: 135.1000\n",
      "Epoch 2693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 114.0220 - val_loss: 135.1956\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 117.7479 - val_loss: 121.9969\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5276 - val_loss: 137.6898\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0888 - val_loss: 128.2155\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.8533 - val_loss: 124.3654\n",
      "Epoch 2698/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 114.4799 - val_loss: 150.5463\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8872 - val_loss: 126.1417\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.8138 - val_loss: 142.0324\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.3583 - val_loss: 137.8324\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 232.3554 - val_loss: 126.2309\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 119.4670 - val_loss: 128.8956\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.2383 - val_loss: 122.3947\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.8473 - val_loss: 127.3481\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.2815 - val_loss: 129.0809\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0553 - val_loss: 123.8252\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.8535 - val_loss: 134.8643\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 115.1605 - val_loss: 131.4676\n",
      "Epoch 2710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5542 - val_loss: 137.1863\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.6265 - val_loss: 123.6925\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 116.0208 - val_loss: 138.9085\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5903 - val_loss: 125.9895\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 278.1252 - val_loss: 180.3348\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.9228 - val_loss: 134.6394\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.4315 - val_loss: 127.7939\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.3099 - val_loss: 135.7118\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4142 - val_loss: 213.7941\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.7477 - val_loss: 127.4955\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0790 - val_loss: 137.9958\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.2855 - val_loss: 124.8210\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4228 - val_loss: 131.7969\n",
      "Epoch 02722: early stopping\n",
      "Fold score (RMSE): 11.455849647521973\n",
      "Fold #4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 5224.0950 - val_loss: 4608.1058\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4537.5375 - val_loss: 4391.3038\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4316.0118 - val_loss: 4392.3376\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 4078.2872 - val_loss: 5051.9490\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4064.7011 - val_loss: 4096.6676\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 3953.3101 - val_loss: 3898.9265\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 3920.8054 - val_loss: 4158.8525\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 3841.1828 - val_loss: 3787.7398\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 3677.5770 - val_loss: 3628.0480\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 3515.7586 - val_loss: 3445.6156\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 3443.1915 - val_loss: 3756.8988\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 3171.4551 - val_loss: 2598.8702\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 2912.1966 - val_loss: 2405.8452\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 2883.2554 - val_loss: 2335.9546\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 2625.4571 - val_loss: 2182.7898\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 2105.9420 - val_loss: 1600.4635\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1672.0532 - val_loss: 1041.5890\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1524.9881 - val_loss: 872.7076\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1348.9625 - val_loss: 869.5547\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 1114.1532 - val_loss: 622.6310\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 879.9808 - val_loss: 686.5840\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 884.9694 - val_loss: 1042.0470\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 728.5426 - val_loss: 1555.4273\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 686.1905 - val_loss: 416.6738\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 585.7543 - val_loss: 1180.2083\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 562.5291 - val_loss: 326.7593\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 538.5558 - val_loss: 439.1183\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 524.4496 - val_loss: 329.3395\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 528.3567 - val_loss: 391.6435\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 520.1621 - val_loss: 770.6131\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 498.6185 - val_loss: 394.7708\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 672.1133 - val_loss: 2096.1981\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 706.1715 - val_loss: 339.1701\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 439.8493 - val_loss: 306.9128\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 414.2537 - val_loss: 386.8477\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 451.9557 - val_loss: 486.6957\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 490.1650 - val_loss: 272.5134\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 453.5639 - val_loss: 280.7394\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 395.9349 - val_loss: 262.3999\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 429.2655 - val_loss: 385.1498\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 454.1281 - val_loss: 296.0992\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 456.0537 - val_loss: 346.7204\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 422.3932 - val_loss: 223.7427\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 389.8278 - val_loss: 509.4093\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 401.7848 - val_loss: 346.2625\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 465.2445 - val_loss: 242.8779\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 475.7536 - val_loss: 314.8888\n",
      "Epoch 48/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 332.5339 - val_loss: 194.2560\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 510.8379 - val_loss: 256.2429\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 344.9323 - val_loss: 212.1389\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 346.6366 - val_loss: 264.7300\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 314.5223 - val_loss: 236.1788\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 416.6218 - val_loss: 194.2141\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 335.5748 - val_loss: 211.7221\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 341.4638 - val_loss: 181.9725\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 287.1986 - val_loss: 187.4197\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 372.2412 - val_loss: 353.0985\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 325.2232 - val_loss: 289.0182\n",
      "Epoch 59/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 315.1175 - val_loss: 202.2149\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 343.6860 - val_loss: 182.5825\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 486.1899 - val_loss: 311.0061\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 403.9504 - val_loss: 468.8870\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 381.0537 - val_loss: 426.3815\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 337.2801 - val_loss: 253.4907\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 402.0613 - val_loss: 305.7689\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 273.4778 - val_loss: 186.3242\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 359.2405 - val_loss: 173.9933\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 258.1834 - val_loss: 168.5582\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 290.7592 - val_loss: 200.7904\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 323.8062 - val_loss: 181.5873\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 334.5489 - val_loss: 265.9157\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 350.7043 - val_loss: 173.1990\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.9147 - val_loss: 274.9441\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.5819 - val_loss: 163.1913\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.1485 - val_loss: 289.0038\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 367.4854 - val_loss: 185.1672\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 283.8994 - val_loss: 320.9766\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 407.4684 - val_loss: 178.7912\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 290.8082 - val_loss: 217.5515\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.7615 - val_loss: 153.5072\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 418.1350 - val_loss: 383.1568\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 406.8058 - val_loss: 309.0194\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 314.9618 - val_loss: 226.9680\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 448.3944 - val_loss: 254.0916\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 354.0937 - val_loss: 193.3690\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 316.2713 - val_loss: 293.8275\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 319.9536 - val_loss: 249.5793\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 320.1715 - val_loss: 185.9282\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 332.9317 - val_loss: 339.7532\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 290.3484 - val_loss: 175.3645\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 302.5789 - val_loss: 156.1102\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 279.4961 - val_loss: 455.1038\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 304.7252 - val_loss: 229.5825\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 331.3024 - val_loss: 258.9109\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 292.4229 - val_loss: 176.4144\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 241.0402 - val_loss: 146.9205\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 287.6247 - val_loss: 195.6806\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 254.7090 - val_loss: 173.8801\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 306.2365 - val_loss: 236.5173\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 286.4036 - val_loss: 162.8202\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 240.2078 - val_loss: 189.7721\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 258.8862 - val_loss: 208.1289\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 317.6563 - val_loss: 139.8278\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 299.0821 - val_loss: 408.7735\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 271.520 - 0s 50us/step - loss: 270.5879 - val_loss: 328.2981\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.2146 - val_loss: 187.3634\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 348.6021 - val_loss: 687.7887\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 265.9389 - val_loss: 161.4420\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.3063 - val_loss: 169.1496\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 277.4228 - val_loss: 146.6068\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 293.7986 - val_loss: 158.2220\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 360.0624 - val_loss: 180.2226\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.9146 - val_loss: 169.6667\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 351.1412 - val_loss: 632.6950\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 253.6002 - val_loss: 240.1077\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.7428 - val_loss: 205.4226\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 302.6632 - val_loss: 145.2530\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.5936 - val_loss: 172.1888\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.9471 - val_loss: 205.1848\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 275.4761 - val_loss: 165.1053\n",
      "Epoch 121/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.8588 - val_loss: 430.8358\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.2005 - val_loss: 166.6839\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 243.3472 - val_loss: 183.2921\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.0053 - val_loss: 244.5969\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 334.7079 - val_loss: 222.3431\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 334.9537 - val_loss: 142.0710\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.1979 - val_loss: 211.1519\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 327.6991 - val_loss: 278.2850\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 242.2120 - val_loss: 181.4920\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.0451 - val_loss: 198.8628\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 225.5565 - val_loss: 144.3120\n",
      "Epoch 132/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 251.3247 - val_loss: 180.6024\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.6143 - val_loss: 150.2157\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 253.7492 - val_loss: 150.1892\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.0958 - val_loss: 144.0827\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.0154 - val_loss: 173.1373\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 228.5877 - val_loss: 133.1577\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.6586 - val_loss: 149.2955\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 317.0113 - val_loss: 138.1496\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.0149 - val_loss: 879.2685\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 263.5719 - val_loss: 314.5063\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 266.5500 - val_loss: 357.2541\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.4223 - val_loss: 298.4151\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.1853 - val_loss: 232.5857\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 302.9874 - val_loss: 153.6541\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 314.5368 - val_loss: 132.6915\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.8678 - val_loss: 135.8892\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.8275 - val_loss: 124.4687\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 267.6096 - val_loss: 164.0232\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.5753 - val_loss: 156.1596\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.1921 - val_loss: 154.0285\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 269.5064 - val_loss: 216.0101\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 230.0289 - val_loss: 164.8114\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 239.0524 - val_loss: 157.3853\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 243.7458 - val_loss: 263.0885\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 254.8190 - val_loss: 126.7028\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 259.2473 - val_loss: 133.7101\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.5130 - val_loss: 164.2138\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 330.4435 - val_loss: 365.0032\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 232.3043 - val_loss: 150.3682\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.3295 - val_loss: 171.5914\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 207.253 - 0s 51us/step - loss: 207.7499 - val_loss: 145.6573\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 204.5674 - val_loss: 248.8964\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 290.9287 - val_loss: 133.9542\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 240.4217 - val_loss: 121.8692\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.6423 - val_loss: 131.9187\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.5990 - val_loss: 127.7348\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 205.6697 - val_loss: 145.7660\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.1208 - val_loss: 136.8784\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.2661 - val_loss: 161.3240\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 259.2956 - val_loss: 122.7545\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.5837 - val_loss: 144.0116\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 285.4382 - val_loss: 204.4249\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.4751 - val_loss: 127.8904\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.1159 - val_loss: 174.9415\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.3702 - val_loss: 181.2541\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.1238 - val_loss: 148.3783\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 194.3451 - val_loss: 408.5323\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 350.0171 - val_loss: 129.9794\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5528 - val_loss: 260.0908\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 247.0024 - val_loss: 160.2727\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.7146 - val_loss: 144.6825\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 229.6778 - val_loss: 171.0069\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.4152 - val_loss: 197.7316\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 225.2047 - val_loss: 125.8863\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.4776 - val_loss: 217.4232\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.7453 - val_loss: 144.7251\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.0066 - val_loss: 328.5416\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.8619 - val_loss: 122.8190\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.9781 - val_loss: 151.6716\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.3842 - val_loss: 159.0564\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.1720 - val_loss: 218.7614\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 221.2921 - val_loss: 182.2156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.9128 - val_loss: 155.7184\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 270.0776 - val_loss: 343.9587\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.1893 - val_loss: 327.5080\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 230.4722 - val_loss: 186.5105\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.8376 - val_loss: 150.9211\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.8492 - val_loss: 122.0352\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 405.6617 - val_loss: 183.3007\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.3507 - val_loss: 201.4924\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.5059 - val_loss: 241.5787\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.8729 - val_loss: 327.4370\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.9630 - val_loss: 161.3291\n",
      "Epoch 205/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.3679 - val_loss: 151.1830\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 320.0264 - val_loss: 132.1535\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 253.4785 - val_loss: 197.8892\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.8040 - val_loss: 119.3380\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 243.7335 - val_loss: 143.9246\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 200.2739 - val_loss: 130.8686\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.3836 - val_loss: 131.4124\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.5155 - val_loss: 152.6328\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 193.0588 - val_loss: 133.5721\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 202.0329 - val_loss: 140.6774\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 175.8932 - val_loss: 115.5848\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.5311 - val_loss: 119.2388\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 256.3620 - val_loss: 190.6811\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.2392 - val_loss: 126.4113\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.9741 - val_loss: 132.2865\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 306.5876 - val_loss: 242.7562\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 274.8082 - val_loss: 407.8458\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 247.5727 - val_loss: 155.9240\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 259.0191 - val_loss: 208.4302\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.5248 - val_loss: 159.0529\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.1954 - val_loss: 226.6938\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 264.7725 - val_loss: 235.7936\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 215.7470 - val_loss: 237.7347\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 205.2859 - val_loss: 316.5962\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 279.3966 - val_loss: 246.9797\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.8790 - val_loss: 274.9757\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 240.0274 - val_loss: 216.0718\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 217.7391 - val_loss: 143.1160\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.3986 - val_loss: 130.3545\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.7165 - val_loss: 179.5990\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.1002 - val_loss: 209.7724\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 238.9125 - val_loss: 158.2723\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 207.1008 - val_loss: 121.0358\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 217.1106 - val_loss: 130.0579\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 195.9914 - val_loss: 273.3659\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 211.1122 - val_loss: 121.4876\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.7397 - val_loss: 125.7512\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.1159 - val_loss: 137.1504\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.1504 - val_loss: 130.0992\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.6540 - val_loss: 233.7451\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 335.3546 - val_loss: 156.8762\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.5683 - val_loss: 171.6553\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.3842 - val_loss: 155.3374\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.7857 - val_loss: 150.2658\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.7682 - val_loss: 125.0077\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.5384 - val_loss: 173.0524\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.2345 - val_loss: 144.1630\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.1985 - val_loss: 191.1661\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 307.4609 - val_loss: 114.5924\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.0514 - val_loss: 133.0482\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 184.1242 - val_loss: 163.7036\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.3483 - val_loss: 139.3084\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.0798 - val_loss: 150.8296\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.3598 - val_loss: 118.8337\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.8440 - val_loss: 179.0947\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.4004 - val_loss: 261.8660\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 296.7955 - val_loss: 158.7481\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.2667 - val_loss: 164.3647\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.5398 - val_loss: 207.7411\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.0112 - val_loss: 136.2463\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.8327 - val_loss: 166.0847\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.1422 - val_loss: 124.1430\n",
      "Epoch 267/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.4030 - val_loss: 115.6697\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.1593 - val_loss: 240.1296\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.3199 - val_loss: 156.4175\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 243.8354 - val_loss: 140.0652\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.2038 - val_loss: 136.1428\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.4852 - val_loss: 129.6546\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 220.9777 - val_loss: 123.0454\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.7564 - val_loss: 259.0920\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.5497 - val_loss: 125.5513\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.9250 - val_loss: 123.9558\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.8475 - val_loss: 118.1896\n",
      "Epoch 278/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.3473 - val_loss: 187.3623\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.6843 - val_loss: 136.7585\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.6593 - val_loss: 130.3823\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 204.6504 - val_loss: 275.3748\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.1331 - val_loss: 124.5467\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.3291 - val_loss: 125.6038\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.8691 - val_loss: 127.7475\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.2425 - val_loss: 113.2596\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.8538 - val_loss: 120.0407\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.4549 - val_loss: 137.7435\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.5336 - val_loss: 125.1086\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.1950 - val_loss: 145.3124\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.6834 - val_loss: 115.6288\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 270.6097 - val_loss: 153.2410\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.1553 - val_loss: 177.7599\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.0442 - val_loss: 130.5962\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.3898 - val_loss: 183.5626\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 211.9101 - val_loss: 112.0950\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.5920 - val_loss: 137.1639\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 179.1137 - val_loss: 149.0334\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 171.0923 - val_loss: 127.3773\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 261.1164 - val_loss: 156.8636\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 165.1405 - val_loss: 147.6079\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.7941 - val_loss: 134.8029\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 222.9574 - val_loss: 129.4989\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 175.3207 - val_loss: 122.1550\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6625 - val_loss: 123.5796\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.0106 - val_loss: 181.3256\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.1586 - val_loss: 184.0761\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.8527 - val_loss: 133.0204\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.7516 - val_loss: 121.7961\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.9346 - val_loss: 142.2115\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.2885 - val_loss: 117.2771\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.7108 - val_loss: 123.7483\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.9085 - val_loss: 122.1774\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.9770 - val_loss: 146.5190\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.3059 - val_loss: 146.5225\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.9046 - val_loss: 132.9007\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.0120 - val_loss: 226.7138\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 254.2368 - val_loss: 185.5009\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.7968 - val_loss: 113.9378\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2962 - val_loss: 209.6992\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 351.8851 - val_loss: 145.5099\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 195.0462 - val_loss: 116.7063\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.8443 - val_loss: 230.0893\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.8338 - val_loss: 131.2070\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 174.2564 - val_loss: 116.7580\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.5769 - val_loss: 125.3003\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.3887 - val_loss: 130.6418\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 173.6654 - val_loss: 115.5409\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.8583 - val_loss: 133.0437\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.9943 - val_loss: 137.9114\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.1091 - val_loss: 800.5585\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.3480 - val_loss: 212.2389\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.9518 - val_loss: 335.4037\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.2244 - val_loss: 168.8839\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.7207 - val_loss: 119.6773\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.4735 - val_loss: 477.3604\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 259.9401 - val_loss: 144.5165\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.1696 - val_loss: 203.5955\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.7993 - val_loss: 130.8706\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.4751 - val_loss: 110.6279\n",
      "Epoch 340/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.5045 - val_loss: 162.3896\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.3655 - val_loss: 129.6941\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.3793 - val_loss: 216.0287\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 318.6605 - val_loss: 314.0591\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 316.8320 - val_loss: 1003.5160\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.4427 - val_loss: 142.1606\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.1205 - val_loss: 129.1516\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.8371 - val_loss: 127.4685\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.3700 - val_loss: 170.1111\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.4840 - val_loss: 126.2029\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3224 - val_loss: 190.5325\n",
      "Epoch 351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 184.1311 - val_loss: 124.7346\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.3611 - val_loss: 140.9149\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.4265 - val_loss: 330.3652\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.7513 - val_loss: 168.4610\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.9632 - val_loss: 111.4708\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.0251 - val_loss: 117.2193\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 215.7789 - val_loss: 197.8093\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.6549 - val_loss: 133.1945\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.2930 - val_loss: 129.8399\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 148.400 - 0s 51us/step - loss: 151.2286 - val_loss: 175.9909\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.5851 - val_loss: 117.0199\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 229.2534 - val_loss: 278.0931\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.9146 - val_loss: 123.8354\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.8448 - val_loss: 271.5624\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.6149 - val_loss: 109.7902\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.3017 - val_loss: 165.7469\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 841.7208 - val_loss: 1865.1773\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 610.2365 - val_loss: 548.8101\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 497.4336 - val_loss: 216.8314\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 270.8419 - val_loss: 220.2349\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 305.5761 - val_loss: 145.9558\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 251.3678 - val_loss: 228.4589\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.0024 - val_loss: 147.4659\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.9773 - val_loss: 149.0634\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 224.4432 - val_loss: 133.3451\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.3213 - val_loss: 145.3939\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.8428 - val_loss: 207.2474\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.2087 - val_loss: 411.5014\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.7223 - val_loss: 159.8001\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.0791 - val_loss: 164.0174\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 236.7072 - val_loss: 370.3185\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.2703 - val_loss: 132.2284\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.6446 - val_loss: 127.4752\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.6931 - val_loss: 131.2090\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 245.7662 - val_loss: 143.2827\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.7734 - val_loss: 201.4147\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 278.8988 - val_loss: 198.3448\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.7973 - val_loss: 159.7935\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.3379 - val_loss: 137.3609\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.1204 - val_loss: 123.6249\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.0822 - val_loss: 142.5884\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 255.1355 - val_loss: 119.7101\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 198.6727 - val_loss: 137.8028\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 177.4075 - val_loss: 157.1266\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 238.2269 - val_loss: 196.9853\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 500.6042 - val_loss: 164.5231\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 263.4330 - val_loss: 192.6614\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 231.6226 - val_loss: 126.9074\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 194.6562 - val_loss: 192.8205\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.6058 - val_loss: 132.2992\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 262.6817 - val_loss: 164.4128\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.9698 - val_loss: 126.2746\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.9016 - val_loss: 133.1648\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.5599 - val_loss: 158.9560\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.5127 - val_loss: 143.9376\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.5765 - val_loss: 115.4060\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 238.9094 - val_loss: 176.3736\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.2556 - val_loss: 207.0940\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 193.5952 - val_loss: 151.6420\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.3262 - val_loss: 121.1397\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.8932 - val_loss: 141.7255\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 215.930 - 0s 51us/step - loss: 216.5843 - val_loss: 315.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.6883 - val_loss: 117.9230\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.1435 - val_loss: 121.6014\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 210.9969 - val_loss: 167.1129\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.6325 - val_loss: 286.2298\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.8560 - val_loss: 154.3896\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2393 - val_loss: 510.7600\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.0202 - val_loss: 209.9205\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.2474 - val_loss: 149.7689\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.9270 - val_loss: 155.9688\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.1831 - val_loss: 188.8498\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.0925 - val_loss: 136.7326\n",
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.9861 - val_loss: 129.6907\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.0031 - val_loss: 126.3414\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.5377 - val_loss: 153.6756\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 289.8834 - val_loss: 252.8736\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.4328 - val_loss: 247.8285\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.0593 - val_loss: 163.3565\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.3387 - val_loss: 123.1408\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 195.2161 - val_loss: 144.2778\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.1398 - val_loss: 235.6591\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.9449 - val_loss: 315.2004\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 301.7300 - val_loss: 135.2584\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7202 - val_loss: 117.1322\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.3177 - val_loss: 127.0199\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.5208 - val_loss: 121.4392\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.6710 - val_loss: 295.8243\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5124 - val_loss: 128.9450\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.5362 - val_loss: 115.2578\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.9650 - val_loss: 146.1963\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 203.3191 - val_loss: 115.3181\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 164.2236 - val_loss: 180.7918\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 201.2870 - val_loss: 138.0318\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.1859 - val_loss: 143.7157\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.6982 - val_loss: 202.0438\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.6637 - val_loss: 122.0942\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.0994 - val_loss: 130.8681\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.2213 - val_loss: 158.3740\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.0238 - val_loss: 158.3021\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 292.8324 - val_loss: 566.3451\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.6828 - val_loss: 114.4447\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 181.7982 - val_loss: 132.2007\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8496 - val_loss: 110.3814\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.3415 - val_loss: 117.7707\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4301 - val_loss: 128.3121\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.9698 - val_loss: 135.4031\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.7298 - val_loss: 123.0474\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.4588 - val_loss: 332.6982\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.9680 - val_loss: 133.2448\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 222.4850 - val_loss: 140.0057\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9426 - val_loss: 124.8072\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8114 - val_loss: 130.1780\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2028 - val_loss: 120.5930\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.5747 - val_loss: 245.8646\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.4256 - val_loss: 130.5054\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3972 - val_loss: 139.8495\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 272.2848 - val_loss: 159.2601\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 165.2864 - val_loss: 109.7211\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.1197 - val_loss: 170.1670\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7495 - val_loss: 146.2746\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.0570 - val_loss: 138.5563\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.2510 - val_loss: 120.9095\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.7373 - val_loss: 118.9434\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.2585 - val_loss: 712.0543\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.8804 - val_loss: 114.4840\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.7953 - val_loss: 151.1187\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.8591 - val_loss: 150.3523\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.3142 - val_loss: 118.0566\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.8721 - val_loss: 306.8750\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 236.1339 - val_loss: 297.4701\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.9833 - val_loss: 189.9427\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.3193 - val_loss: 110.4321\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.4139 - val_loss: 133.6643\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.3724 - val_loss: 112.6444\n",
      "Epoch 486/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.2584 - val_loss: 112.7777\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.0484 - val_loss: 136.8887\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7434 - val_loss: 161.6577\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.5027 - val_loss: 113.9017\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.7469 - val_loss: 903.3539\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.6314 - val_loss: 124.2587\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.1617 - val_loss: 147.1024\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.5311 - val_loss: 134.5914\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.9339 - val_loss: 126.7867\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.7155 - val_loss: 131.3279\n",
      "Epoch 496/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.1163 - val_loss: 111.6759\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.9636 - val_loss: 138.9727\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.8804 - val_loss: 249.2723\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.1074 - val_loss: 115.8080\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5873 - val_loss: 167.9214\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 164.1689 - val_loss: 130.1236\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.3686 - val_loss: 121.9207\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.5424 - val_loss: 141.3752\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.2174 - val_loss: 179.6600\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 225.8675 - val_loss: 128.9578\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9937 - val_loss: 110.2361\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1218 - val_loss: 133.9173\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.0214 - val_loss: 122.1708\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3675 - val_loss: 109.9135\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.7669 - val_loss: 233.4946\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6081 - val_loss: 114.2222\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 290.8351 - val_loss: 160.3909\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1627 - val_loss: 253.5317\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 182.3120 - val_loss: 200.8358\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 173.2187 - val_loss: 126.3206\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 412.6011 - val_loss: 187.4222\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.0068 - val_loss: 144.0521\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.1551 - val_loss: 124.5557\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.5806 - val_loss: 143.0722\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2203 - val_loss: 116.0854\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.4607 - val_loss: 111.1509\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8317 - val_loss: 154.6827\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2162 - val_loss: 168.4175\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.7767 - val_loss: 115.1174\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.3772 - val_loss: 120.1771\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1422 - val_loss: 112.3681\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9553 - val_loss: 122.8461\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 182.663 - 0s 51us/step - loss: 182.3107 - val_loss: 210.9628\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.3774 - val_loss: 137.8525\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.4440 - val_loss: 124.1906\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.3248 - val_loss: 151.7051\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.1349 - val_loss: 150.5825\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 223.3035 - val_loss: 110.7826\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.2885 - val_loss: 274.2803\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1813 - val_loss: 196.3901\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.3142 - val_loss: 172.1355\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4245 - val_loss: 155.9951\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.9038 - val_loss: 187.5588\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.5873 - val_loss: 153.2535\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.4906 - val_loss: 128.5532\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.1480 - val_loss: 131.1785\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.8357 - val_loss: 140.4789\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.1919 - val_loss: 117.0942\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.8466 - val_loss: 144.8280\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.9128 - val_loss: 154.1587\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 273.9715 - val_loss: 121.5558\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.7021 - val_loss: 145.4394\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.0836 - val_loss: 112.7622\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.8435 - val_loss: 152.0042\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2780 - val_loss: 110.2999\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4456 - val_loss: 148.1424\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.5654 - val_loss: 143.3710\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.3318 - val_loss: 229.9967\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.3671 - val_loss: 148.0527\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.8669 - val_loss: 119.8549\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.3391 - val_loss: 148.3111\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.9172 - val_loss: 186.8709\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 205.5658 - val_loss: 130.7936\n",
      "Epoch 559/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.6506 - val_loss: 224.3395\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4220 - val_loss: 108.1061\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7275 - val_loss: 121.4819\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 321.7065 - val_loss: 112.9251\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5780 - val_loss: 124.3674\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.9272 - val_loss: 134.5134\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.6254 - val_loss: 115.1886\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7876 - val_loss: 131.4675\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.8962 - val_loss: 126.6215\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7157 - val_loss: 114.5168\n",
      "Epoch 569/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.6246 - val_loss: 494.7123\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 235.9222 - val_loss: 113.7775\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0560 - val_loss: 112.1893\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.1924 - val_loss: 245.6281\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.8226 - val_loss: 152.5153\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.2378 - val_loss: 108.1054\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.1521 - val_loss: 219.0898\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2377 - val_loss: 112.6374\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1177 - val_loss: 114.6879\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5218 - val_loss: 111.7757\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.3184 - val_loss: 353.6683\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.3254 - val_loss: 112.8997\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.2958 - val_loss: 132.0698\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4442 - val_loss: 176.3871\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.6255 - val_loss: 187.9404\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.4974 - val_loss: 115.5247\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.6445 - val_loss: 112.1975\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 190.9936 - val_loss: 121.3212\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 169.5729 - val_loss: 120.5254\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 157.7499 - val_loss: 107.4148\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 169.5299 - val_loss: 115.8214\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 171.3768 - val_loss: 133.1066\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.9551 - val_loss: 126.1068\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.9954 - val_loss: 111.4462\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2011 - val_loss: 118.4095\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.9458 - val_loss: 138.6725\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.1497 - val_loss: 110.3637\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4834 - val_loss: 176.6175\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.9459 - val_loss: 121.9106\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.5087 - val_loss: 121.1568\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.8735 - val_loss: 128.2569\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2662 - val_loss: 114.3232\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8963 - val_loss: 113.1783\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9577 - val_loss: 143.8043\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4691 - val_loss: 174.7186\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1948 - val_loss: 122.5153\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 164.885 - 0s 51us/step - loss: 164.2842 - val_loss: 129.8187\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.6085 - val_loss: 591.6002\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 229.1612 - val_loss: 110.3287\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9770 - val_loss: 154.0137\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4917 - val_loss: 114.7130\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 223.6207 - val_loss: 127.7373\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8478 - val_loss: 240.6983\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.6038 - val_loss: 118.5760\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.9924 - val_loss: 115.3396\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.1314 - val_loss: 110.7940\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.0992 - val_loss: 135.0884\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4884 - val_loss: 127.7568\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5920 - val_loss: 130.3129\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 333.1151 - val_loss: 296.1871\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 272.6817 - val_loss: 208.7453\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.9746 - val_loss: 120.7458\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 202.132 - 0s 50us/step - loss: 203.3066 - val_loss: 123.2562\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.9998 - val_loss: 136.5313\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.3295 - val_loss: 144.2725\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.3667 - val_loss: 127.2102\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.6107 - val_loss: 133.2946\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.1830 - val_loss: 139.5886\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5627 - val_loss: 183.8015\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.2896 - val_loss: 230.9839\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6229 - val_loss: 122.8725\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3857 - val_loss: 123.4114\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.6412 - val_loss: 122.4128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.7702 - val_loss: 126.1277\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6908 - val_loss: 113.1642\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 252.6866 - val_loss: 168.0618\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.7462 - val_loss: 146.3497\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.6481 - val_loss: 155.3297\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.0154 - val_loss: 154.2826\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.8871 - val_loss: 156.5182\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.8766 - val_loss: 269.6514\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.8123 - val_loss: 129.9149\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.9518 - val_loss: 233.9896\n",
      "Epoch 642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.0064 - val_loss: 122.5869\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 160.9378 - val_loss: 122.4534\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6381 - val_loss: 122.5798\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.6593 - val_loss: 209.4054\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 316.8565 - val_loss: 177.9196\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.2043 - val_loss: 142.6279\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.9951 - val_loss: 119.8896\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9684 - val_loss: 134.1236\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4753 - val_loss: 113.9163\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.6316 - val_loss: 114.1205\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2448 - val_loss: 136.7471\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0648 - val_loss: 118.7280\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6131 - val_loss: 114.8314\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.9416 - val_loss: 301.0299\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.9964 - val_loss: 155.8774\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 285.8853 - val_loss: 522.8528\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 229.4999 - val_loss: 149.9171\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 158.1316 - val_loss: 121.1375\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 164.9783 - val_loss: 121.9567\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8266 - val_loss: 173.8323\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5858 - val_loss: 117.6947\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.8405 - val_loss: 117.1980\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4941 - val_loss: 117.8736\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.1892 - val_loss: 160.6367\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7618 - val_loss: 167.7224\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.0666 - val_loss: 136.1243\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.8203 - val_loss: 143.1886\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.3614 - val_loss: 133.6552\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7755 - val_loss: 155.3875\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 269.4234 - val_loss: 147.4162\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9627 - val_loss: 202.7487\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 167.844 - 0s 51us/step - loss: 167.3393 - val_loss: 130.3270\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 162.4887 - val_loss: 112.4334\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4317 - val_loss: 119.5059\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.6225 - val_loss: 131.3473\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.7361 - val_loss: 123.5192\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.4463 - val_loss: 144.7388\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.0640 - val_loss: 111.9723\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2708 - val_loss: 142.9405\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.7403 - val_loss: 143.3752\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 262.1591 - val_loss: 151.9069\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.0363 - val_loss: 126.8138\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.8644 - val_loss: 133.6650\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.6384 - val_loss: 139.9807\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0279 - val_loss: 120.1837\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6186 - val_loss: 135.1921\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5899 - val_loss: 151.1612\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.3480 - val_loss: 151.6521\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.0974 - val_loss: 242.1678\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.5810 - val_loss: 112.6727\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7894 - val_loss: 115.2536\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8111 - val_loss: 121.6843\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.5233 - val_loss: 170.4842\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2064 - val_loss: 156.0889\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.4911 - val_loss: 143.2846\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.9443 - val_loss: 131.9308\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.2314 - val_loss: 109.1568\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.1787 - val_loss: 121.6701\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0427 - val_loss: 143.9783\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.5435 - val_loss: 106.1548\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.1336 - val_loss: 157.3294\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.6148 - val_loss: 151.7832\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.6515 - val_loss: 115.3280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0205 - val_loss: 106.8472\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.2013 - val_loss: 112.3774\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6301 - val_loss: 147.0479\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4278 - val_loss: 114.1020\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9310 - val_loss: 133.2470\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 312.7204 - val_loss: 152.6836\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.0299 - val_loss: 111.2785\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8862 - val_loss: 122.8973\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2378 - val_loss: 118.2363\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.2669 - val_loss: 133.6263\n",
      "Epoch 715/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.6701 - val_loss: 132.0755\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.9399 - val_loss: 149.6532\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.1479 - val_loss: 126.8890\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.2479 - val_loss: 125.7231\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8442 - val_loss: 149.2842\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9518 - val_loss: 116.7683\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.3771 - val_loss: 114.7220\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.6140 - val_loss: 129.2132\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.4325 - val_loss: 127.0874\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.0857 - val_loss: 131.1817\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.9531 - val_loss: 112.5683\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.8860 - val_loss: 113.6918\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 378.0989 - val_loss: 152.7149\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1309 - val_loss: 117.6258\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1800 - val_loss: 126.5927\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 144.1344 - val_loss: 111.0915\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 141.4410 - val_loss: 126.9481\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 147.4662 - val_loss: 119.6420\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 167.2082 - val_loss: 165.3015\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 150.0202 - val_loss: 113.8063\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 158.4307 - val_loss: 169.9156\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9657 - val_loss: 112.3848\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.7057 - val_loss: 233.1369\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.9889 - val_loss: 148.5430\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1509 - val_loss: 133.9079\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9408 - val_loss: 126.1765\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 238.6590 - val_loss: 331.8278\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 330.3264 - val_loss: 134.7773\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.4312 - val_loss: 157.8853\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.7791 - val_loss: 211.3634\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8854 - val_loss: 114.2340\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.0106 - val_loss: 117.6770\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2654 - val_loss: 147.6543\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2541 - val_loss: 174.0796\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 413.8444 - val_loss: 150.6144\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 258.9378 - val_loss: 153.9311\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.9260 - val_loss: 349.6861\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.9396 - val_loss: 130.1051\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.7473 - val_loss: 168.3396\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 226.3850 - val_loss: 130.2050\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 210.4418 - val_loss: 189.2901\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.0977 - val_loss: 128.4773\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.2269 - val_loss: 127.4352\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.4230 - val_loss: 140.3857\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.4806 - val_loss: 144.5894\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.5086 - val_loss: 122.4501\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.2241 - val_loss: 125.4513\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 208.5250 - val_loss: 134.8013\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.2478 - val_loss: 131.5416\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9335 - val_loss: 131.3421\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.8806 - val_loss: 181.6351\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 280.0141 - val_loss: 524.8177\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.6514 - val_loss: 136.8772\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8945 - val_loss: 113.7927\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.6272 - val_loss: 123.3076\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0229 - val_loss: 122.5638\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.0898 - val_loss: 334.2238\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.4879 - val_loss: 113.5751\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.2400 - val_loss: 127.8712\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.5723 - val_loss: 117.3887\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2421 - val_loss: 138.5019\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6636 - val_loss: 129.2617\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 155.1940 - val_loss: 137.0212\n",
      "Epoch 778/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.3201 - val_loss: 119.7987\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9837 - val_loss: 225.5416\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.1158 - val_loss: 136.9468\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.2025 - val_loss: 221.7812\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.4690 - val_loss: 121.6686\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 475.7827 - val_loss: 131.7726\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4816 - val_loss: 118.4888\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.7539 - val_loss: 153.0331\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3162 - val_loss: 113.9804\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.4496 - val_loss: 115.4188\n",
      "Epoch 788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.7266 - val_loss: 121.2389\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.5612 - val_loss: 111.7543\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 182.3049 - val_loss: 114.1013\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9063 - val_loss: 172.2319\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0750 - val_loss: 135.3192\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0801 - val_loss: 110.6401\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 248.9339 - val_loss: 756.5947\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 259.6737 - val_loss: 114.9062\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6224 - val_loss: 122.1228\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.5633 - val_loss: 121.6268\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4194 - val_loss: 118.0884\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1060 - val_loss: 113.6305\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1622 - val_loss: 147.1153\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.3452 - val_loss: 116.4959\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.9764 - val_loss: 164.6333\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 163.3972 - val_loss: 110.1511\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.0482 - val_loss: 109.9191\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 228.8265 - val_loss: 112.5535\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 251.7657 - val_loss: 108.1623\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2648 - val_loss: 154.6716\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4660 - val_loss: 128.3798\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5496 - val_loss: 112.1587\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9788 - val_loss: 109.8774\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.9024 - val_loss: 109.4690\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.7604 - val_loss: 117.7695\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.6254 - val_loss: 123.7312\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 161.1170 - val_loss: 279.2359\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3062 - val_loss: 139.0141\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.8059 - val_loss: 172.4167\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 249.0867 - val_loss: 114.1665\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4451 - val_loss: 119.6570\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2200 - val_loss: 116.9576\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7846 - val_loss: 222.3281\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.9336 - val_loss: 133.7870\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6428 - val_loss: 110.9504\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6102 - val_loss: 114.2924\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.4571 - val_loss: 183.8476\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 244.8686 - val_loss: 169.8875\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1616 - val_loss: 119.4410\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7704 - val_loss: 131.0321\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.1064 - val_loss: 115.1385\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.0754 - val_loss: 110.8721\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8426 - val_loss: 122.2538\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5631 - val_loss: 138.0150\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.4691 - val_loss: 138.1864\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1832 - val_loss: 111.8586\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.7057 - val_loss: 112.8367\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.8877 - val_loss: 116.5780\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.7485 - val_loss: 138.0979\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.9572 - val_loss: 112.2193\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 169.9092 - val_loss: 135.0529\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.1259 - val_loss: 126.0859\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.9297 - val_loss: 113.7388\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7840 - val_loss: 257.0243\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.6755 - val_loss: 130.7968\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7833 - val_loss: 137.6496\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6893 - val_loss: 123.3061\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 140.713 - 0s 51us/step - loss: 140.1876 - val_loss: 117.5952\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5903 - val_loss: 187.9435\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2785 - val_loss: 144.8717\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3316 - val_loss: 136.8112\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.2862 - val_loss: 181.8015\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.4943 - val_loss: 189.7246\n",
      "Epoch 851/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.6883 - val_loss: 126.0920\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.3316 - val_loss: 158.3386\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0163 - val_loss: 158.2367\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 281.1480 - val_loss: 124.8316\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2026 - val_loss: 164.0682\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2014 - val_loss: 167.9859\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0708 - val_loss: 122.4856\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 284.1932 - val_loss: 114.5021\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.2160 - val_loss: 105.9522\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9973 - val_loss: 111.0132\n",
      "Epoch 861/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.7378 - val_loss: 128.6674\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1175 - val_loss: 156.8462\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7423 - val_loss: 131.7798\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.2493 - val_loss: 167.5334\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.1579 - val_loss: 157.8094\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3700 - val_loss: 111.4092\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 143.6162 - val_loss: 155.4901\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6929 - val_loss: 135.1899\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2703 - val_loss: 120.4483\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 405.5183 - val_loss: 408.4018\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 291.4638 - val_loss: 140.2088\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 204.929 - 0s 51us/step - loss: 203.9326 - val_loss: 151.9639\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.7307 - val_loss: 235.0500\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.2574 - val_loss: 128.4380\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 180.0622 - val_loss: 186.7253\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 169.4744 - val_loss: 112.6848\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 197.2467 - val_loss: 172.4638\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.2091 - val_loss: 121.6665\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.3666 - val_loss: 144.9930\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.7324 - val_loss: 136.8092\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1162 - val_loss: 115.2550\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4387 - val_loss: 124.0901\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.2638 - val_loss: 184.3077\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6165 - val_loss: 133.5757\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.8933 - val_loss: 230.8511\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.4995 - val_loss: 139.7697\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.8115 - val_loss: 211.3909\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.0596 - val_loss: 119.9794\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8025 - val_loss: 152.3665\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.9033 - val_loss: 113.8811\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.9756 - val_loss: 128.0545\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.3736 - val_loss: 187.0621\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 197.9471 - val_loss: 155.0959\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 262.7109 - val_loss: 141.1265\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.0062 - val_loss: 168.9775\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8626 - val_loss: 114.2618\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7370 - val_loss: 111.9196\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4336 - val_loss: 126.6255\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.3587 - val_loss: 192.0628\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.4392 - val_loss: 150.6522\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6162 - val_loss: 123.5121\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9938 - val_loss: 122.7518\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6183 - val_loss: 128.6765\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.3064 - val_loss: 183.5645\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.3076 - val_loss: 178.0341\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2148 - val_loss: 107.7964\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4059 - val_loss: 161.9559\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.8588 - val_loss: 116.7625\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2434 - val_loss: 114.5942\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0995 - val_loss: 130.4788\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3069 - val_loss: 135.3575\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.1641 - val_loss: 121.6195\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.8038 - val_loss: 125.6550\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.4711 - val_loss: 150.0526\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.4980 - val_loss: 226.9903\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.5672 - val_loss: 123.5763\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.0588 - val_loss: 124.1143\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1591 - val_loss: 112.6217\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 313.9119 - val_loss: 187.8978\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.7549 - val_loss: 109.7433\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 140.267 - 0s 51us/step - loss: 140.2759 - val_loss: 126.7821\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0119 - val_loss: 134.4475\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2997 - val_loss: 109.8823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.1160 - val_loss: 128.2008\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2998 - val_loss: 128.8009\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8696 - val_loss: 124.3434\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.3474 - val_loss: 119.2431\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 175.5844 - val_loss: 107.9671\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.4956 - val_loss: 150.8103\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 157.3654 - val_loss: 112.0882\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6151 - val_loss: 123.5039\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.0523 - val_loss: 111.9426\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.3632 - val_loss: 133.4164\n",
      "Epoch 934/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0114 - val_loss: 111.7390\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6151 - val_loss: 119.9646\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.3462 - val_loss: 129.5216\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5690 - val_loss: 128.4125\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.6202 - val_loss: 119.6940\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0269 - val_loss: 195.9445\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3370 - val_loss: 127.2288\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1031 - val_loss: 148.0723\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.4076 - val_loss: 115.2495\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.8898 - val_loss: 108.0716\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7257 - val_loss: 163.9863\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9842 - val_loss: 113.3719\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.1375 - val_loss: 127.0412\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 165.1694 - val_loss: 157.6437\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.4027 - val_loss: 165.2286\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.5597 - val_loss: 145.8729\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.2155 - val_loss: 173.3169\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.6168 - val_loss: 115.7868\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.5890 - val_loss: 117.8929\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3981 - val_loss: 131.2597\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.1164 - val_loss: 139.7959\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9940 - val_loss: 122.4623\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 157.2311 - val_loss: 180.2827\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 159.2923 - val_loss: 109.2283\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.9338 - val_loss: 118.4522\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 140.2453 - val_loss: 152.0823\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 145.5956 - val_loss: 117.7294\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3878 - val_loss: 159.6283\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 164.6319 - val_loss: 109.4206\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 264.5316 - val_loss: 339.7216\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.1401 - val_loss: 152.0338\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 244.8551 - val_loss: 278.2978\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.7598 - val_loss: 111.5863\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1520 - val_loss: 129.5660\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7818 - val_loss: 119.0706\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.7077 - val_loss: 113.3154\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0163 - val_loss: 118.1073\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0717 - val_loss: 165.6864\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.9339 - val_loss: 111.9452\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 164.0993 - val_loss: 136.4680\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.9987 - val_loss: 205.6319\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 262.5587 - val_loss: 115.2831\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9342 - val_loss: 116.9118\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7586 - val_loss: 167.7563\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.8431 - val_loss: 121.0126\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4144 - val_loss: 116.4662\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.2783 - val_loss: 115.2339\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2066 - val_loss: 111.8764\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5055 - val_loss: 109.5669\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8597 - val_loss: 147.1904\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.0887 - val_loss: 116.3489\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4583 - val_loss: 114.2666\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 190.3003 - val_loss: 125.9905\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.2170 - val_loss: 114.9808\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 139.5079 - val_loss: 120.1434\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3212 - val_loss: 136.7797\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.5851 - val_loss: 139.6760\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1891 - val_loss: 295.9122\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9270 - val_loss: 113.3851\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.8060 - val_loss: 127.0482\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.7440 - val_loss: 275.1764\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.2848 - val_loss: 149.1900\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.6158 - val_loss: 115.1939\n",
      "Epoch 997/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5405 - val_loss: 120.2465\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8124 - val_loss: 122.4954\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.0977 - val_loss: 172.3201\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8243 - val_loss: 111.3434\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7907 - val_loss: 131.1816\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.5043 - val_loss: 114.5303\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.7315 - val_loss: 151.5880\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0980 - val_loss: 141.8611\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7652 - val_loss: 111.2760\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7850 - val_loss: 118.1186\n",
      "Epoch 1007/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 226.6258 - val_loss: 1208.6136\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 305.8340 - val_loss: 118.4637\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.9722 - val_loss: 129.8843\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7659 - val_loss: 110.8465\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.1461 - val_loss: 119.6014\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 156.1577 - val_loss: 119.3812\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2852 - val_loss: 114.5616\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2015 - val_loss: 140.2044\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.0827 - val_loss: 142.4741\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4388 - val_loss: 152.1908\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1386 - val_loss: 114.6566\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.0518 - val_loss: 126.9517\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 159.0239 - val_loss: 126.8033\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 137.0158 - val_loss: 109.7358\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.1514 - val_loss: 119.3864\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 162.1803 - val_loss: 134.1926\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.9827 - val_loss: 112.3298\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 157.1000 - val_loss: 130.7822\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.7394 - val_loss: 129.8585\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.1691 - val_loss: 211.0901\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.6975 - val_loss: 214.8471\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.5852 - val_loss: 112.4989\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1524 - val_loss: 116.9807\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7770 - val_loss: 120.1044\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8285 - val_loss: 127.4239\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2682 - val_loss: 171.6748\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.9974 - val_loss: 113.1095\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.2493 - val_loss: 131.0465\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0106 - val_loss: 115.8225\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1110 - val_loss: 161.5302\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.9974 - val_loss: 110.8217\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1464 - val_loss: 172.7669\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5352 - val_loss: 108.7912\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.2326 - val_loss: 117.3794\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.9327 - val_loss: 206.4365\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.4997 - val_loss: 148.8007\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.6222 - val_loss: 118.5199\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1479 - val_loss: 229.3590\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.1716 - val_loss: 118.2915\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.3930 - val_loss: 119.5089\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9426 - val_loss: 111.2314\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1862 - val_loss: 115.4723\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5616 - val_loss: 127.4256\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5969 - val_loss: 117.9426\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0604 - val_loss: 133.6167\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0605 - val_loss: 108.7643\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2384 - val_loss: 134.3832\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 187.1853 - val_loss: 113.1607\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 208.7332 - val_loss: 156.8389\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5396 - val_loss: 207.3504\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.1374 - val_loss: 145.3923\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 187.8542 - val_loss: 118.6260\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.6763 - val_loss: 113.1258\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.3012 - val_loss: 120.3048\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9866 - val_loss: 163.7082\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.1704 - val_loss: 111.1381\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.1752 - val_loss: 170.2799\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7842 - val_loss: 114.6021\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.9786 - val_loss: 121.6392\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5222 - val_loss: 112.2997\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.6668 - val_loss: 181.2052\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.8278 - val_loss: 159.1137\n",
      "Epoch 1069/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.1164 - val_loss: 116.9945\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9006 - val_loss: 132.4784\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 157.6395 - val_loss: 147.3876\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1753 - val_loss: 130.4325\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5737 - val_loss: 118.8323\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.2844 - val_loss: 207.8698\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.9912 - val_loss: 214.2944\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0660 - val_loss: 125.8667\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.6181 - val_loss: 124.1498\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 136.3005 - val_loss: 123.3067\n",
      "Epoch 1079/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 172.2319 - val_loss: 142.7416\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 188.8778 - val_loss: 114.9662\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.9260 - val_loss: 234.8751\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2909 - val_loss: 132.1879\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3428 - val_loss: 112.6666\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.4775 - val_loss: 401.3206\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.7935 - val_loss: 115.2748\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2369 - val_loss: 109.0671\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4710 - val_loss: 140.4030\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0524 - val_loss: 123.9023\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.0629 - val_loss: 127.3972\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 143.4399 - val_loss: 122.0374\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 278.7488 - val_loss: 120.2344\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 135.0666 - val_loss: 110.6083\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.1110 - val_loss: 160.2237\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8870 - val_loss: 113.9786\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4709 - val_loss: 123.1672\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9423 - val_loss: 112.4266\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.2466 - val_loss: 108.8157\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1448 - val_loss: 111.7774\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6154 - val_loss: 136.5423\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.2155 - val_loss: 106.4181\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 197.0207 - val_loss: 122.7301\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9233 - val_loss: 118.5654\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5838 - val_loss: 186.2950\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.8930 - val_loss: 123.1025\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7814 - val_loss: 151.1924\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7380 - val_loss: 130.5501\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.4439 - val_loss: 111.1179\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.0109 - val_loss: 115.4914\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.6641 - val_loss: 117.7830\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.5899 - val_loss: 127.3254\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.9708 - val_loss: 145.3506\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 211.1825 - val_loss: 134.0003\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.4416 - val_loss: 116.2100\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1867 - val_loss: 109.8297\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2783 - val_loss: 119.9938\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5597 - val_loss: 108.9984\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4144 - val_loss: 136.3794\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1177 - val_loss: 111.9407\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0206 - val_loss: 157.4330\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9473 - val_loss: 125.6467\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.6352 - val_loss: 123.0121\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 157.3798 - val_loss: 167.5773\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.9074 - val_loss: 154.0707\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.5962 - val_loss: 148.9697\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1577 - val_loss: 121.6988\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4331 - val_loss: 115.0543\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.6079 - val_loss: 124.1183\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.5923 - val_loss: 160.4427\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.4147 - val_loss: 145.7262\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.7475 - val_loss: 478.8297\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 213.1115 - val_loss: 127.6685\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8915 - val_loss: 130.6691\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4980 - val_loss: 122.4974\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.6218 - val_loss: 173.2172\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.8519 - val_loss: 124.6505\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7050 - val_loss: 113.9786\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.5237 - val_loss: 145.4504\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0041 - val_loss: 116.3736\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9318 - val_loss: 233.4794\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7597 - val_loss: 159.2048\n",
      "Epoch 1141/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2449 - val_loss: 110.3553\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5133 - val_loss: 111.8345\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9763 - val_loss: 114.1370\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8789 - val_loss: 124.1664\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.1307 - val_loss: 130.3619\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.1157 - val_loss: 116.5499\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.2505 - val_loss: 113.5291\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0503 - val_loss: 167.4266\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0764 - val_loss: 119.4224\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.9221 - val_loss: 152.5943\n",
      "Epoch 1151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5517 - val_loss: 125.5063\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9662 - val_loss: 119.8003\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6257 - val_loss: 116.1293\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4820 - val_loss: 122.9277\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.232 - 0s 51us/step - loss: 144.0266 - val_loss: 149.8337\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 217.8998 - val_loss: 125.7044\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.0420 - val_loss: 134.1718\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8159 - val_loss: 112.8491\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6403 - val_loss: 128.6932\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8226 - val_loss: 163.5112\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.6582 - val_loss: 123.1483\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 135.7087 - val_loss: 163.5956\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 150.8102 - val_loss: 124.5549\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 130.6702 - val_loss: 115.3156\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 250.2805 - val_loss: 121.2115\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5954 - val_loss: 148.6768\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4087 - val_loss: 249.4906\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8705 - val_loss: 164.6249\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.7264 - val_loss: 110.0806\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9340 - val_loss: 124.8331\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.5434 - val_loss: 175.2205\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5252 - val_loss: 115.3094\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.9751 - val_loss: 113.4858\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3459 - val_loss: 111.1992\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0031 - val_loss: 131.1513\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0468 - val_loss: 148.7939\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.4108 - val_loss: 165.5337\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.8157 - val_loss: 165.8701\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.6988 - val_loss: 110.4242\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0141 - val_loss: 113.9803\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.8623 - val_loss: 109.0716\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4195 - val_loss: 117.6601\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.0129 - val_loss: 135.0405\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9521 - val_loss: 143.8701\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0354 - val_loss: 135.9040\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.1433 - val_loss: 137.0257\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0331 - val_loss: 120.4343\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.4601 - val_loss: 125.2473\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0359 - val_loss: 114.7054\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.1855 - val_loss: 114.6236\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.7138 - val_loss: 114.0994\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7794 - val_loss: 120.7314\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9390 - val_loss: 199.6731\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7101 - val_loss: 129.4517\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8299 - val_loss: 115.0472\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.6037 - val_loss: 120.4372\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8491 - val_loss: 191.1851\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.6720 - val_loss: 119.9520\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 242.7227 - val_loss: 138.5495\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.6779 - val_loss: 108.3002\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8620 - val_loss: 129.0152\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.9510 - val_loss: 113.9334\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4269 - val_loss: 109.0171\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.3868 - val_loss: 114.3261\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.0929 - val_loss: 137.3596\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7251 - val_loss: 127.2060\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.9237 - val_loss: 108.8766\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 237.6070 - val_loss: 118.2794\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 121.7895 - val_loss: 110.6426\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.4005 - val_loss: 122.3511\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 124.8172 - val_loss: 111.1289\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.9208 - val_loss: 149.0721\n",
      "Epoch 1213/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0936 - val_loss: 204.6055\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 142.9869 - val_loss: 115.5853\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.9285 - val_loss: 150.2184\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 142.0441 - val_loss: 122.0353\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.9159 - val_loss: 149.1534\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.1364 - val_loss: 112.4063\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.2095 - val_loss: 116.6883\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.3523 - val_loss: 121.6457\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 205.1878 - val_loss: 131.8908\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6586 - val_loss: 108.7591\n",
      "Epoch 1223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2114 - val_loss: 116.5691\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.7406 - val_loss: 117.8567\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8547 - val_loss: 122.8783\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.3195 - val_loss: 132.2331\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8750 - val_loss: 118.6432\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7654 - val_loss: 114.6765\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1436 - val_loss: 125.9860\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1614 - val_loss: 163.5289\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3492 - val_loss: 114.7288\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.7378 - val_loss: 183.9524\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 132.7537 - val_loss: 115.7657\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 142.7239 - val_loss: 120.9646\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.8581 - val_loss: 117.6590\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0826 - val_loss: 115.2902\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1832 - val_loss: 118.0359\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8695 - val_loss: 114.6219\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9798 - val_loss: 117.1261\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 406.0419 - val_loss: 128.3598\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.1992 - val_loss: 124.3195\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0004 - val_loss: 130.3676\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 183.5813 - val_loss: 128.3493\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.6307 - val_loss: 114.1480\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.6652 - val_loss: 183.3868\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2636 - val_loss: 112.9474\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7742 - val_loss: 114.4540\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6521 - val_loss: 172.6372\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.9620 - val_loss: 108.8159\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.1355 - val_loss: 112.4674\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.3341 - val_loss: 127.4903\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0008 - val_loss: 150.4562\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2127 - val_loss: 113.8823\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9680 - val_loss: 111.9131\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.9384 - val_loss: 121.4860\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.7405 - val_loss: 228.4542\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3174 - val_loss: 125.4878\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5136 - val_loss: 179.2946\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.2940 - val_loss: 147.4731\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6011 - val_loss: 184.9725\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.6870 - val_loss: 119.5688\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3382 - val_loss: 153.0836\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.7184 - val_loss: 272.6444\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 200.2842 - val_loss: 139.7959\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.3798 - val_loss: 128.8287\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.9901 - val_loss: 129.7645\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0124 - val_loss: 108.9882\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6782 - val_loss: 115.4191\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.2249 - val_loss: 126.5987\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6158 - val_loss: 159.6946\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.2846 - val_loss: 115.3876\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3306 - val_loss: 108.7298\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.0442 - val_loss: 143.6604\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.9591 - val_loss: 126.9942\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.3306 - val_loss: 175.3938\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 154.0793 - val_loss: 173.6929\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4199 - val_loss: 137.8800\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3721 - val_loss: 146.9116\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1740 - val_loss: 109.1242\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.4913 - val_loss: 112.2030\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.6678 - val_loss: 111.3261\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 144.0512 - val_loss: 126.5471\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2805 - val_loss: 119.7331\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8579 - val_loss: 154.8232\n",
      "Epoch 1285/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.2137 - val_loss: 147.0308\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.2498 - val_loss: 293.0038\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 231.8102 - val_loss: 189.7571\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.2800 - val_loss: 112.8788\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2465 - val_loss: 151.6093\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0089 - val_loss: 116.0452\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.3223 - val_loss: 161.2633\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6906 - val_loss: 228.8612\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9589 - val_loss: 116.0273\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8688 - val_loss: 112.9209\n",
      "Epoch 1295/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0972 - val_loss: 130.9103\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1223 - val_loss: 116.2456\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0526 - val_loss: 118.1721\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9961 - val_loss: 110.3348\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.7779 - val_loss: 111.9718\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.0454 - val_loss: 114.0714\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.7160 - val_loss: 157.9760\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9066 - val_loss: 149.8238\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 168.8620 - val_loss: 243.7751\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 129.6778 - val_loss: 111.4852\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 131.6850 - val_loss: 110.2926\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 132.0689 - val_loss: 138.8443\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 142.2778 - val_loss: 152.3368\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1965 - val_loss: 120.5297\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0744 - val_loss: 122.5094\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8640 - val_loss: 114.9947\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0253 - val_loss: 119.3455\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5434 - val_loss: 109.9144\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 191.3671 - val_loss: 156.3183\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.4174 - val_loss: 112.8498\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.7129 - val_loss: 118.0533\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5224 - val_loss: 119.2646\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7733 - val_loss: 174.3776\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4961 - val_loss: 192.5905\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8382 - val_loss: 116.0284\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8463 - val_loss: 120.8109\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.3055 - val_loss: 135.2614\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5180 - val_loss: 128.9881\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5779 - val_loss: 111.5989\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.6279 - val_loss: 113.4115\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8921 - val_loss: 120.9007\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6708 - val_loss: 115.9115\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 133.4063 - val_loss: 223.2652\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1907 - val_loss: 109.7629\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.2427 - val_loss: 123.6808\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0797 - val_loss: 122.1661\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 271.7058 - val_loss: 1625.2138\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 267.1867 - val_loss: 116.9864\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6512 - val_loss: 113.6435\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7106 - val_loss: 151.8880\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.6331 - val_loss: 124.3660\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8668 - val_loss: 110.6391\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7557 - val_loss: 107.7167\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.4833 - val_loss: 113.0413\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.9204 - val_loss: 118.9816\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9863 - val_loss: 106.5543\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3412 - val_loss: 114.7373\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.5658 - val_loss: 155.4425\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.1966 - val_loss: 145.0919\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.8968 - val_loss: 125.7919\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6054 - val_loss: 112.6370\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4570 - val_loss: 141.1599\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3496 - val_loss: 111.2668\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0195 - val_loss: 111.3170\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1323 - val_loss: 107.3460\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.3031 - val_loss: 120.9901\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.8200 - val_loss: 152.1045\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9547 - val_loss: 170.8656\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.6260 - val_loss: 111.0667\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.8566 - val_loss: 118.0234\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.8676 - val_loss: 206.5131\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.2168 - val_loss: 113.4047\n",
      "Epoch 1357/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4955 - val_loss: 132.9602\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8012 - val_loss: 111.1134\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5334 - val_loss: 135.2560\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3979 - val_loss: 113.1944\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4276 - val_loss: 120.2788\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1470 - val_loss: 116.5611\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9626 - val_loss: 169.6116\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2801 - val_loss: 126.6953\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9742 - val_loss: 142.8746\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 216.6943 - val_loss: 114.3692\n",
      "Epoch 1367/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.8802 - val_loss: 112.5617\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2973 - val_loss: 131.9729\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7466 - val_loss: 111.5224\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.0414 - val_loss: 114.2661\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.0779 - val_loss: 110.7339\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.6359 - val_loss: 128.7647\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0840 - val_loss: 107.7491\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.4105 - val_loss: 131.4008\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4952 - val_loss: 129.1055\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 136.4988 - val_loss: 121.2171\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.3006 - val_loss: 124.4637\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 139.2441 - val_loss: 133.8530\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.0640 - val_loss: 108.7213\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.6848 - val_loss: 113.8809\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3597 - val_loss: 125.3016\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0903 - val_loss: 144.4389\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8860 - val_loss: 117.3999\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9156 - val_loss: 119.2078\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3058 - val_loss: 114.1648\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.7775 - val_loss: 144.1284\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5369 - val_loss: 112.5093\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7587 - val_loss: 116.4418\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.5357 - val_loss: 110.5647\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0341 - val_loss: 127.0446\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3813 - val_loss: 110.6938\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8811 - val_loss: 116.3137\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6213 - val_loss: 201.2498\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 202.3720 - val_loss: 120.4749\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.1553 - val_loss: 109.9215\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1296 - val_loss: 117.5191\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.2420 - val_loss: 112.5119\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.2778 - val_loss: 111.1996\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.1050 - val_loss: 147.3374\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 175.4779 - val_loss: 117.1013\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 172.2479 - val_loss: 116.5181\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.4662 - val_loss: 240.1399\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.6855 - val_loss: 115.6023\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7649 - val_loss: 157.4172\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1084 - val_loss: 111.3859\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7129 - val_loss: 128.7457\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0101 - val_loss: 124.3125\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3256 - val_loss: 147.8726\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5750 - val_loss: 198.2357\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 177.7214 - val_loss: 188.3395\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0741 - val_loss: 127.3632\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9613 - val_loss: 110.8734\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7471 - val_loss: 124.0309\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7833 - val_loss: 132.6129\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0398 - val_loss: 108.6100\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 129.3583 - val_loss: 154.8503\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.3525 - val_loss: 198.7486\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2628 - val_loss: 113.8028\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9910 - val_loss: 115.4393\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4864 - val_loss: 115.6327\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7555 - val_loss: 220.8820\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1200 - val_loss: 123.1703\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.8909 - val_loss: 113.2060\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.6941 - val_loss: 139.1162\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3178 - val_loss: 314.5465\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.3907 - val_loss: 146.8691\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6727 - val_loss: 111.4628\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8745 - val_loss: 119.2070\n",
      "Epoch 1429/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.2832 - val_loss: 109.4095\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7121 - val_loss: 122.2703\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2638 - val_loss: 145.6365\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2645 - val_loss: 109.5861\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7129 - val_loss: 138.0310\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3288 - val_loss: 133.3964\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.7443 - val_loss: 162.4410\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.4659 - val_loss: 122.5633\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1091 - val_loss: 120.1877\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9743 - val_loss: 122.3592\n",
      "Epoch 1439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2420 - val_loss: 110.0623\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.1909 - val_loss: 2527.9850\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.0117 - val_loss: 131.9701\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1137 - val_loss: 113.4068\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.9733 - val_loss: 119.2803\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2477 - val_loss: 123.2415\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5014 - val_loss: 118.0884\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1954 - val_loss: 122.7676\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.1740 - val_loss: 206.3479\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 150.1128 - val_loss: 107.9907\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 128.1930 - val_loss: 143.4717\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 131.3139 - val_loss: 128.3696\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 131.8864 - val_loss: 116.1180\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3937 - val_loss: 112.7497\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.3978 - val_loss: 117.1064\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8855 - val_loss: 125.4016\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 284.2886 - val_loss: 125.9158\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5220 - val_loss: 114.4508\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.4109 - val_loss: 112.2587\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0369 - val_loss: 114.3234\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8279 - val_loss: 107.3442\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3866 - val_loss: 118.1847\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.0392 - val_loss: 126.8441\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4235 - val_loss: 304.4329\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 274.6396 - val_loss: 126.3599\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7587 - val_loss: 114.6241\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0811 - val_loss: 186.3259\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.8791 - val_loss: 123.1785\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0725 - val_loss: 157.5283\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3528 - val_loss: 111.1847\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6055 - val_loss: 173.7349\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.8752 - val_loss: 158.6863\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6589 - val_loss: 108.3721\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4916 - val_loss: 116.1105\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7759 - val_loss: 120.8712\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1402 - val_loss: 177.4738\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6397 - val_loss: 111.1659\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.4761 - val_loss: 116.6869\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.5874 - val_loss: 157.6638\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 205.1391 - val_loss: 352.0948\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 154.9401 - val_loss: 115.8257\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.3557 - val_loss: 132.6168\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4031 - val_loss: 122.2782\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4305 - val_loss: 108.4327\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9975 - val_loss: 106.4016\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.4870 - val_loss: 114.7021\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9461 - val_loss: 110.8016\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8256 - val_loss: 132.8039\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0340 - val_loss: 121.8390\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0611 - val_loss: 112.0922\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.9385 - val_loss: 121.1196\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 128.7736 - val_loss: 129.1360\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 330.0683 - val_loss: 2377.6986\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 287.0327 - val_loss: 123.4992\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4959 - val_loss: 110.4928\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4398 - val_loss: 111.0127\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4851 - val_loss: 119.0527\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3756 - val_loss: 115.6360\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7166 - val_loss: 112.3947\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7336 - val_loss: 115.6679\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 300.8114 - val_loss: 128.4034\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3826 - val_loss: 106.8238\n",
      "Epoch 1501/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5421 - val_loss: 114.0444\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.7600 - val_loss: 119.6997\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.0511 - val_loss: 116.3509\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.3929 - val_loss: 128.2107\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9199 - val_loss: 146.1842\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.8773 - val_loss: 108.2985\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4978 - val_loss: 133.0971\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9416 - val_loss: 146.9241\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.4006 - val_loss: 124.9749\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1981 - val_loss: 118.6855\n",
      "Epoch 1511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3671 - val_loss: 112.9760\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.0408 - val_loss: 139.2741\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8260 - val_loss: 123.7216\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.3393 - val_loss: 110.5988\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1943 - val_loss: 148.4314\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9202 - val_loss: 113.2910\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1480 - val_loss: 112.6831\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3683 - val_loss: 110.1926\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.6517 - val_loss: 121.4785\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 172.3861 - val_loss: 162.1653\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 134.1334 - val_loss: 116.7562\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 126.0399 - val_loss: 105.9208\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.4767 - val_loss: 115.7279\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 136.6986 - val_loss: 129.1297\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 142.4224 - val_loss: 122.0391\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4439 - val_loss: 119.6525\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.1361 - val_loss: 113.6073\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8080 - val_loss: 128.7737\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3702 - val_loss: 116.4323\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8700 - val_loss: 113.6338\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 272.1944 - val_loss: 112.2120\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6246 - val_loss: 135.4526\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9709 - val_loss: 110.2826\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.2098 - val_loss: 133.3805\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2782 - val_loss: 141.8369\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.7099 - val_loss: 121.1786\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.1709 - val_loss: 178.6553\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.6630 - val_loss: 119.7968\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3430 - val_loss: 126.5315\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.1045 - val_loss: 107.5411\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4658 - val_loss: 169.7498\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5999 - val_loss: 127.3338\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1091 - val_loss: 109.4126\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.6014 - val_loss: 115.1964\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.2634 - val_loss: 119.1900\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 145.7578 - val_loss: 138.1383\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 202.3512 - val_loss: 126.6517\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.7329 - val_loss: 212.9804\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.3521 - val_loss: 114.2621\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2152 - val_loss: 135.1656\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4292 - val_loss: 305.5296\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 163.9320 - val_loss: 112.5853\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.4108 - val_loss: 122.0443\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 124.9934 - val_loss: 131.8576\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.3484 - val_loss: 122.9120\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 138.2950 - val_loss: 132.0942\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1020 - val_loss: 115.3098\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 294.5638 - val_loss: 127.1126\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.2898 - val_loss: 109.1918\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4144 - val_loss: 111.3848\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9175 - val_loss: 112.7284\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0057 - val_loss: 125.0405\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2507 - val_loss: 108.9752\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1917 - val_loss: 121.5206\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7783 - val_loss: 132.6746\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9304 - val_loss: 113.1563\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.3504 - val_loss: 110.0836\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.3113 - val_loss: 133.5322\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 234.1046 - val_loss: 187.8270\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 152.9877 - val_loss: 138.8923\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0111 - val_loss: 114.0270\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.4956 - val_loss: 113.9483\n",
      "Epoch 1573/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.8469 - val_loss: 112.3741\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0196 - val_loss: 135.1332\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3185 - val_loss: 113.0191\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.0920 - val_loss: 201.0821\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 168.8574 - val_loss: 112.2086\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8434 - val_loss: 114.4571\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4386 - val_loss: 114.9349\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0743 - val_loss: 109.4453\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 185.9565 - val_loss: 125.0892\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7706 - val_loss: 122.2198\n",
      "Epoch 1583/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0592 - val_loss: 112.3097\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3561 - val_loss: 143.4784\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0984 - val_loss: 131.0280\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3627 - val_loss: 122.2024\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8977 - val_loss: 124.8623\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 136.2197 - val_loss: 177.9063\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.6308 - val_loss: 117.6739\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.5124 - val_loss: 134.1471\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 147.7009 - val_loss: 111.3017\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.7433 - val_loss: 169.5942\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 507.1735 - val_loss: 172.7922\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 197.6267 - val_loss: 144.3093\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.2269 - val_loss: 248.0005\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.9351 - val_loss: 129.2515\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.5582 - val_loss: 121.5868\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.6976 - val_loss: 144.2953\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.5918 - val_loss: 126.8419\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.4464 - val_loss: 132.7812\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.2784 - val_loss: 118.3632\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.4620 - val_loss: 120.7114\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2899 - val_loss: 140.7563\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6160 - val_loss: 130.4203\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5559 - val_loss: 137.2491\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.5414 - val_loss: 124.1769\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.0102 - val_loss: 108.7930\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.7591 - val_loss: 136.4993\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.3876 - val_loss: 133.4179\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.7279 - val_loss: 116.1087\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.1870 - val_loss: 157.4131\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3808 - val_loss: 237.2068\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0833 - val_loss: 119.2985\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.9328 - val_loss: 225.2692\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.3625 - val_loss: 233.5293\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.5036 - val_loss: 113.4540\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5611 - val_loss: 117.3275\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7084 - val_loss: 153.6353\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.3463 - val_loss: 145.3209\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2453 - val_loss: 130.7233\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5340 - val_loss: 136.0246\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.8967 - val_loss: 173.9888\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.0462 - val_loss: 124.4808\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2801 - val_loss: 119.3391\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.6663 - val_loss: 113.2335\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.4583 - val_loss: 118.5917\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8835 - val_loss: 118.9911\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.3603 - val_loss: 125.2709\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9281 - val_loss: 130.6887\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2233 - val_loss: 157.7938\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 138.225 - 0s 51us/step - loss: 140.0856 - val_loss: 158.8976\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 160.9560 - val_loss: 120.8111\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.3041 - val_loss: 115.5089\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3040 - val_loss: 111.8120\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.5380 - val_loss: 114.4110\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3024 - val_loss: 117.7521\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.4821 - val_loss: 158.5486\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2448 - val_loss: 120.5352\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.5054 - val_loss: 138.5096\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.2425 - val_loss: 112.1316\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3320 - val_loss: 123.7646\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9814 - val_loss: 136.9149\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.5858 - val_loss: 141.3296\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 141.9732 - val_loss: 109.9240\n",
      "Epoch 1645/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9772 - val_loss: 135.7335\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.7576 - val_loss: 116.6861\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 146.958 - 0s 51us/step - loss: 147.3347 - val_loss: 126.0321\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.3758 - val_loss: 124.8383\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8137 - val_loss: 171.4504\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.1836 - val_loss: 151.9526\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.1076 - val_loss: 125.6689\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.6504 - val_loss: 135.7958\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3364 - val_loss: 129.3885\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0908 - val_loss: 132.9629\n",
      "Epoch 1655/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.6919 - val_loss: 119.0695\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.3299 - val_loss: 112.7650\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2629 - val_loss: 114.8109\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.8282 - val_loss: 115.6747\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0912 - val_loss: 111.1785\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8167 - val_loss: 162.1407\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9703 - val_loss: 132.9936\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4414 - val_loss: 130.2283\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5333 - val_loss: 153.2201\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.0433 - val_loss: 110.8651\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1793 - val_loss: 145.5897\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.7789 - val_loss: 245.2657\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.9643 - val_loss: 120.1613\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2067 - val_loss: 127.7019\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.8632 - val_loss: 118.1401\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.3735 - val_loss: 121.7248\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1145 - val_loss: 111.4756\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 148.7546 - val_loss: 127.1865\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0262 - val_loss: 118.8384\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 129.2433 - val_loss: 133.7608\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 145.9687 - val_loss: 560.6496\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 144.4209 - val_loss: 139.8326\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.5729 - val_loss: 111.5155\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9444 - val_loss: 115.3410\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0389 - val_loss: 111.5198\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5297 - val_loss: 114.6244\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6642 - val_loss: 121.2642\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3676 - val_loss: 123.4945\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.4385 - val_loss: 132.7003\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 136.305 - 0s 50us/step - loss: 137.6738 - val_loss: 128.9170\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2095 - val_loss: 115.5604\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.4772 - val_loss: 141.4926\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3531 - val_loss: 125.4678\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.4484 - val_loss: 117.9929\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.0203 - val_loss: 125.6569\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.3627 - val_loss: 111.9055\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1253 - val_loss: 113.6516\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7981 - val_loss: 206.3321\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9507 - val_loss: 138.0594\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7146 - val_loss: 115.5727\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.2558 - val_loss: 114.2237\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.6582 - val_loss: 118.3357\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8094 - val_loss: 141.4078\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.2062 - val_loss: 137.3200\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8138 - val_loss: 112.9335\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8010 - val_loss: 115.9125\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1594 - val_loss: 114.1346\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0750 - val_loss: 138.2428\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8909 - val_loss: 114.5249\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2818 - val_loss: 133.2812\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7762 - val_loss: 122.3740\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.8655 - val_loss: 121.5784\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.1940 - val_loss: 130.2348\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.2871 - val_loss: 115.5211\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6323 - val_loss: 162.3822\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9185 - val_loss: 125.9596\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4210 - val_loss: 112.2845\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5806 - val_loss: 119.7431\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1755 - val_loss: 110.2506\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4406 - val_loss: 119.5566\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 165.4342 - val_loss: 121.7082\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0058 - val_loss: 113.6448\n",
      "Epoch 1717/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6117 - val_loss: 185.4441\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.9406 - val_loss: 150.8838\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1782 - val_loss: 113.4364\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8552 - val_loss: 117.7705\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4368 - val_loss: 167.8704\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5485 - val_loss: 133.4268\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9162 - val_loss: 120.5797\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1563 - val_loss: 128.6699\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9745 - val_loss: 122.7411\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1809 - val_loss: 144.9368\n",
      "Epoch 1727/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3433 - val_loss: 112.5084\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.5193 - val_loss: 146.7705\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9722 - val_loss: 110.0667\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9410 - val_loss: 111.8215\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.0597 - val_loss: 118.3427\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.9080 - val_loss: 151.7649\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7942 - val_loss: 158.9552\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2907 - val_loss: 150.9595\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8629 - val_loss: 155.6988\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 145.7173 - val_loss: 128.2001\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 139.0607 - val_loss: 163.2505\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 134.0884 - val_loss: 111.5099\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.4676 - val_loss: 121.1644\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 196.1959 - val_loss: 128.9169\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8327 - val_loss: 125.8187\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7066 - val_loss: 114.2652\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.5075 - val_loss: 115.1409\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.8438 - val_loss: 112.7034\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8683 - val_loss: 130.9653\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8866 - val_loss: 120.2406\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.5703 - val_loss: 123.7043\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3628 - val_loss: 114.5554\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0291 - val_loss: 136.0695\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3453 - val_loss: 117.3127\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.7572 - val_loss: 178.8291\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1914 - val_loss: 145.4903\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.0512 - val_loss: 116.4279\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.9525 - val_loss: 111.4310\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6153 - val_loss: 112.1622\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 142.1865 - val_loss: 120.2301\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0328 - val_loss: 204.1175\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 140.6376 - val_loss: 128.7049\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1594 - val_loss: 148.0370\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6925 - val_loss: 118.9065\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.2069 - val_loss: 121.9982\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1932 - val_loss: 120.6360\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2577 - val_loss: 131.5271\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8845 - val_loss: 137.2499\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.7826 - val_loss: 119.4871\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9102 - val_loss: 117.2872\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.4377 - val_loss: 135.0373\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.9932 - val_loss: 110.4802\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.7338 - val_loss: 130.3602\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 130.8952 - val_loss: 114.5783\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 129.8922 - val_loss: 116.1461\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5665 - val_loss: 117.3827\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8767 - val_loss: 114.3772\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8162 - val_loss: 136.3640\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.7754 - val_loss: 113.4893\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0618 - val_loss: 118.8443\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9588 - val_loss: 122.7516\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9882 - val_loss: 114.6694\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.9015 - val_loss: 116.2509\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4633 - val_loss: 120.0109\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0278 - val_loss: 113.4467\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2596 - val_loss: 118.1286\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.9802 - val_loss: 132.9373\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0374 - val_loss: 112.5156\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1376 - val_loss: 110.0374\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2411 - val_loss: 150.8952\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8171 - val_loss: 121.0928\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.8415 - val_loss: 118.8725\n",
      "Epoch 1789/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9988 - val_loss: 136.0495\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7616 - val_loss: 113.6156\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3276 - val_loss: 120.6927\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 130.6530 - val_loss: 111.2813\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.7085 - val_loss: 108.9320\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.7274 - val_loss: 173.9324\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4051 - val_loss: 119.0306\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.5418 - val_loss: 117.4681\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.5630 - val_loss: 140.0768\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4956 - val_loss: 155.2103\n",
      "Epoch 1799/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.5233 - val_loss: 235.2440\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.2069 - val_loss: 158.5180\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8635 - val_loss: 111.6293\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9568 - val_loss: 109.7377\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9459 - val_loss: 117.6865\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.8842 - val_loss: 112.7969\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0119 - val_loss: 147.8441\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4421 - val_loss: 112.6165\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2188 - val_loss: 119.7141\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 134.1667 - val_loss: 194.0374\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 145.4429 - val_loss: 127.9892\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 128.0739 - val_loss: 122.7265\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.6341 - val_loss: 123.9052\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2636 - val_loss: 144.5997\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1236 - val_loss: 111.4597\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.8783 - val_loss: 111.6765\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2621 - val_loss: 135.5806\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.2438 - val_loss: 171.2812\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.0096 - val_loss: 121.8127\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.6044 - val_loss: 135.3100\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.6991 - val_loss: 150.9059\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.7989 - val_loss: 111.1718\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1669 - val_loss: 179.4574\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.9178 - val_loss: 126.3715\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9156 - val_loss: 111.4725\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2245 - val_loss: 113.1524\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7988 - val_loss: 130.6248\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6357 - val_loss: 138.8964\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9498 - val_loss: 225.3202\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 156.2007 - val_loss: 125.0451\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8715 - val_loss: 107.5672\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6591 - val_loss: 120.3156\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0550 - val_loss: 108.3896\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.1621 - val_loss: 122.8901\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3564 - val_loss: 134.5993\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3359 - val_loss: 110.7758\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6733 - val_loss: 123.3503\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0059 - val_loss: 113.8833\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3921 - val_loss: 182.1690\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2773 - val_loss: 118.7918\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.6279 - val_loss: 120.9667\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.9868 - val_loss: 114.8005\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.7677 - val_loss: 150.2201\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9226 - val_loss: 111.0839\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.0027 - val_loss: 202.4385\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9282 - val_loss: 122.8917\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5343 - val_loss: 128.7407\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4257 - val_loss: 113.6620\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.0981 - val_loss: 119.3603\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 120.6893 - val_loss: 115.8455\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4998 - val_loss: 119.5635\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9669 - val_loss: 106.7431\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.3952 - val_loss: 138.2531\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2142 - val_loss: 114.9461\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8454 - val_loss: 126.5858\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9246 - val_loss: 259.6069\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.2691 - val_loss: 129.0475\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6685 - val_loss: 163.3754\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6724 - val_loss: 113.5993\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.4240 - val_loss: 113.2718\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6846 - val_loss: 150.2550\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 146.1093 - val_loss: 125.8487\n",
      "Epoch 1861/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5072 - val_loss: 122.3049\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.3939 - val_loss: 118.7277\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0031 - val_loss: 148.4744\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.5908 - val_loss: 114.5460\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 125.7353 - val_loss: 108.7050\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 140.5246 - val_loss: 207.2769\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 125.2752 - val_loss: 131.9160\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7524 - val_loss: 112.3034\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5755 - val_loss: 123.4243\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.1667 - val_loss: 114.2956\n",
      "Epoch 1871/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7446 - val_loss: 159.1303\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.4999 - val_loss: 144.0728\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3393 - val_loss: 125.8226\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5408 - val_loss: 122.0368\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.3990 - val_loss: 117.5280\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8141 - val_loss: 143.2657\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.5129 - val_loss: 108.4127\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.0774 - val_loss: 108.5350\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.8702 - val_loss: 110.3124\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 133.1483 - val_loss: 133.0067\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.2492 - val_loss: 130.4466\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 150.2984 - val_loss: 151.7029\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 144.7160 - val_loss: 148.7598\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2782 - val_loss: 118.2762\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.8609 - val_loss: 128.8529\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3836 - val_loss: 124.3719\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.2399 - val_loss: 117.9324\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.0095 - val_loss: 125.8848\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6027 - val_loss: 145.5156\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0073 - val_loss: 108.7734\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5357 - val_loss: 178.2590\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1983 - val_loss: 114.0703\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0579 - val_loss: 112.4935\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.9428 - val_loss: 119.3812\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8274 - val_loss: 118.8745\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7804 - val_loss: 107.4319\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.1759 - val_loss: 118.0437\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.2392 - val_loss: 137.0395\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 182.6334 - val_loss: 148.5408\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5548 - val_loss: 115.0448\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5029 - val_loss: 118.9655\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.3229 - val_loss: 120.6846\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0569 - val_loss: 118.9523\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2931 - val_loss: 142.6626\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7310 - val_loss: 131.8162\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6581 - val_loss: 128.8694\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.4525 - val_loss: 133.6668\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.3045 - val_loss: 115.6744\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6591 - val_loss: 111.5913\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.0820 - val_loss: 109.3262\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9322 - val_loss: 113.2461\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9388 - val_loss: 166.8396\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.7127 - val_loss: 180.3750\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 165.8806 - val_loss: 153.0495\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 149.2561 - val_loss: 124.2475\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.7047 - val_loss: 112.1503\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6228 - val_loss: 118.1159\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.1479 - val_loss: 115.7044\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4306 - val_loss: 121.1597\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6020 - val_loss: 145.0764\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1824 - val_loss: 131.6119\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.3687 - val_loss: 132.8479\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5051 - val_loss: 130.4857\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0747 - val_loss: 138.0111\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.8679 - val_loss: 117.5904\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.5176 - val_loss: 117.0251\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 135.9465 - val_loss: 119.7661\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.2871 - val_loss: 226.6476\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6427 - val_loss: 132.5632\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6713 - val_loss: 121.7853\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4190 - val_loss: 142.3205\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.4184 - val_loss: 130.0456\n",
      "Epoch 1933/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7271 - val_loss: 121.7892\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.0222 - val_loss: 118.2259\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0563 - val_loss: 118.2545\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.9706 - val_loss: 120.8453\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1511 - val_loss: 121.2616\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.6727 - val_loss: 141.5040\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8032 - val_loss: 123.7857\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.0150 - val_loss: 246.2842\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9233 - val_loss: 128.9307\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 179.5696 - val_loss: 203.5331\n",
      "Epoch 1943/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.7135 - val_loss: 152.7234\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0702 - val_loss: 135.8539\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.2980 - val_loss: 112.3478\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.3696 - val_loss: 133.1989\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0709 - val_loss: 111.1251\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0322 - val_loss: 125.2996\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 118.3602 - val_loss: 113.5221\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.6158 - val_loss: 122.8429\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9673 - val_loss: 112.8261\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.4561 - val_loss: 120.0154\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 132.4138 - val_loss: 112.8141\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 134.6241 - val_loss: 148.3341\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.2096 - val_loss: 133.7618\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 153.5538 - val_loss: 167.7508\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.3408 - val_loss: 112.2267\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.3995 - val_loss: 121.7154\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4257 - val_loss: 120.0522\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 150.593 - 0s 51us/step - loss: 150.4071 - val_loss: 144.6424\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 125.563 - 0s 51us/step - loss: 126.1178 - val_loss: 113.9942\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6216 - val_loss: 136.6009\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.4413 - val_loss: 113.6841\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.2960 - val_loss: 118.9649\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.2714 - val_loss: 120.0086\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9083 - val_loss: 156.0861\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1841 - val_loss: 124.4371\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.2636 - val_loss: 161.7906\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3189 - val_loss: 116.8455\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8336 - val_loss: 111.8586\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6215 - val_loss: 109.9854\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1369 - val_loss: 124.7518\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7742 - val_loss: 133.7520\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 231.7946 - val_loss: 113.8032\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9660 - val_loss: 111.4555\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.6376 - val_loss: 116.6165\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.9241 - val_loss: 121.3387\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9979 - val_loss: 132.5104\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1679 - val_loss: 141.8582\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4324 - val_loss: 175.8658\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.1821 - val_loss: 116.2487\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.3834 - val_loss: 116.5289\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1856 - val_loss: 122.1456\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7277 - val_loss: 113.2734\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8457 - val_loss: 123.2639\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9268 - val_loss: 164.9279\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7796 - val_loss: 116.6691\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1340 - val_loss: 116.1635\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.0536 - val_loss: 141.3773\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9423 - val_loss: 119.0539\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2280 - val_loss: 141.4312\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.8602 - val_loss: 129.3781\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3258 - val_loss: 123.4366\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1815 - val_loss: 126.3588\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9159 - val_loss: 114.3939\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8220 - val_loss: 161.7431\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1775 - val_loss: 140.0286\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5273 - val_loss: 125.0019\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4668 - val_loss: 113.3732\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3870 - val_loss: 115.6906\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5675 - val_loss: 133.2338\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5181 - val_loss: 119.1869\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.4942 - val_loss: 141.6610\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0314 - val_loss: 119.3702\n",
      "Epoch 2005/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8331 - val_loss: 233.4973\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.9011 - val_loss: 152.6073\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.7286 - val_loss: 162.1396\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.019 - 0s 51us/step - loss: 126.8161 - val_loss: 155.8587\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.0977 - val_loss: 120.6510\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4814 - val_loss: 109.0247\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.4584 - val_loss: 116.3711\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.7341 - val_loss: 169.7019\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.5346 - val_loss: 190.0672\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.5049 - val_loss: 113.6587\n",
      "Epoch 2015/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 127.622 - 0s 51us/step - loss: 127.2358 - val_loss: 130.1980\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7386 - val_loss: 124.8548\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8915 - val_loss: 251.6048\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.2956 - val_loss: 124.8485\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5070 - val_loss: 111.3510\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8255 - val_loss: 111.3469\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5037 - val_loss: 166.5064\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.1017 - val_loss: 137.1691\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.8513 - val_loss: 113.3321\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7157 - val_loss: 147.6667\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.9960 - val_loss: 127.5908\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 135.6366 - val_loss: 170.0695\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 144.8258 - val_loss: 123.7944\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 131.4580 - val_loss: 119.6172\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.3888 - val_loss: 119.9571\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.9314 - val_loss: 114.7244\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9487 - val_loss: 138.7379\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1235 - val_loss: 128.2424\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 176.1019 - val_loss: 117.7754\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 128.4392 - val_loss: 114.4864\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.2727 - val_loss: 108.4149\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.4029 - val_loss: 129.0408\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.4784 - val_loss: 133.6309\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.204 - 0s 51us/step - loss: 133.7023 - val_loss: 127.9271\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.5015 - val_loss: 149.0534\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.1620 - val_loss: 124.8002\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.9352 - val_loss: 159.2993\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1281 - val_loss: 114.1336\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1362 - val_loss: 121.6459\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3408 - val_loss: 117.8753\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.1800 - val_loss: 121.4550\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1614 - val_loss: 122.6055\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7232 - val_loss: 124.1232\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.2628 - val_loss: 130.9642\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.2346 - val_loss: 370.4331\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.5238 - val_loss: 125.6831\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1718 - val_loss: 141.6458\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0386 - val_loss: 112.9289\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.0483 - val_loss: 116.2848\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9296 - val_loss: 116.6249\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2696 - val_loss: 119.5323\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2711 - val_loss: 133.7345\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.1124 - val_loss: 130.5467\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.9891 - val_loss: 133.9991\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.4103 - val_loss: 119.0138\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.4836 - val_loss: 137.5563\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0148 - val_loss: 126.5429\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6856 - val_loss: 121.3213\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5868 - val_loss: 155.0426\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5592 - val_loss: 152.2569\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7419 - val_loss: 131.4430\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5973 - val_loss: 112.2330\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7491 - val_loss: 141.1641\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8692 - val_loss: 113.5190\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6643 - val_loss: 135.1287\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3090 - val_loss: 158.7842\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9169 - val_loss: 133.0888\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2765 - val_loss: 130.8235\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0185 - val_loss: 131.9353\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1628 - val_loss: 162.4614\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.2134 - val_loss: 118.2729\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3215 - val_loss: 131.0838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5095 - val_loss: 147.9000\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.2856 - val_loss: 117.7089\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 122.0506 - val_loss: 110.7818\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.5509 - val_loss: 183.6796\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.4216 - val_loss: 120.8909\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5212 - val_loss: 114.6845\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.9958 - val_loss: 128.1746\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.2470 - val_loss: 126.4938\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2751 - val_loss: 118.1091\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.1980 - val_loss: 116.1382\n",
      "Epoch 2087/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3059 - val_loss: 135.7828\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1701 - val_loss: 118.2201\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9769 - val_loss: 130.5477\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.6221 - val_loss: 119.4817\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9459 - val_loss: 117.1857\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.2344 - val_loss: 123.8413\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7865 - val_loss: 143.3904\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7863 - val_loss: 109.6380\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0735 - val_loss: 120.7708\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.2480 - val_loss: 114.0423\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9020 - val_loss: 117.8130\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.4329 - val_loss: 240.2057\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 138.3486 - val_loss: 121.7325\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 131.7983 - val_loss: 114.5547\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6117 - val_loss: 111.0443\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.0745 - val_loss: 113.3114\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3242 - val_loss: 128.9059\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 174.0414 - val_loss: 154.5597\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1879 - val_loss: 164.4691\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6673 - val_loss: 143.7313\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 131.480 - 0s 50us/step - loss: 131.8261 - val_loss: 133.5169\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.3971 - val_loss: 129.5731\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3676 - val_loss: 115.1125\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6893 - val_loss: 187.0421\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5679 - val_loss: 128.5940\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2059 - val_loss: 138.9425\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.4669 - val_loss: 122.7758\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.0193 - val_loss: 124.7307\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.2267 - val_loss: 120.2743\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2780 - val_loss: 144.1430\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.7058 - val_loss: 122.4487\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4067 - val_loss: 168.6863\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1762 - val_loss: 117.3079\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6520 - val_loss: 133.2751\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1168 - val_loss: 123.4108\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6134 - val_loss: 129.7144\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2399 - val_loss: 119.4168\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8847 - val_loss: 237.9984\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.1547 - val_loss: 122.1223\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.8476 - val_loss: 124.6171\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.1634 - val_loss: 184.4044\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.0999 - val_loss: 129.2222\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7034 - val_loss: 127.1457\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.5291 - val_loss: 124.4997\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.5045 - val_loss: 120.7038\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.7051 - val_loss: 118.6705\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.6819 - val_loss: 117.1117\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5005 - val_loss: 110.3800\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6105 - val_loss: 184.8484\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3701 - val_loss: 148.0491\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.3796 - val_loss: 125.3739\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6489 - val_loss: 121.1671\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1870 - val_loss: 125.8818\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.9804 - val_loss: 145.1932\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.1785 - val_loss: 126.1049\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1401 - val_loss: 116.5793\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5613 - val_loss: 127.2290\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 125.2638 - val_loss: 178.6081\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7122 - val_loss: 133.8299\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.7703 - val_loss: 109.9880\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1863 - val_loss: 129.1277\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3638 - val_loss: 116.3807\n",
      "Epoch 2149/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8368 - val_loss: 148.7096\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8879 - val_loss: 116.2896\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.2073 - val_loss: 171.1098\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.1932 - val_loss: 128.1762\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5917 - val_loss: 114.4380\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1915 - val_loss: 133.1830\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.5485 - val_loss: 124.1856\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5590 - val_loss: 119.6554\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.9527 - val_loss: 114.0237\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.1041 - val_loss: 120.1461\n",
      "Epoch 2159/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.0867 - val_loss: 116.8235\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1232 - val_loss: 206.1116\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9940 - val_loss: 145.5423\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5958 - val_loss: 147.5086\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0776 - val_loss: 113.7367\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8186 - val_loss: 114.4351\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9284 - val_loss: 121.9375\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3983 - val_loss: 113.0064\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5515 - val_loss: 133.2241\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.3548 - val_loss: 147.2285\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.1383 - val_loss: 131.8495\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.2698 - val_loss: 127.6094\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 140.1859 - val_loss: 135.5146\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 127.4547 - val_loss: 117.4812\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.1169 - val_loss: 108.8816\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.2170 - val_loss: 114.9781\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2670 - val_loss: 109.3265\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0259 - val_loss: 137.8844\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9050 - val_loss: 110.2774\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3231 - val_loss: 116.3000\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.1714 - val_loss: 172.9914\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.7267 - val_loss: 114.1918\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2072 - val_loss: 115.5532\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.0291 - val_loss: 109.3548\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1073 - val_loss: 109.2159\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6261 - val_loss: 159.8359\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 145.2297 - val_loss: 110.6605\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.7634 - val_loss: 138.0596\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.5427 - val_loss: 116.5256\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.3909 - val_loss: 135.5362\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.7131 - val_loss: 117.1962\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.3524 - val_loss: 108.6490\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4203 - val_loss: 121.3009\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.5305 - val_loss: 114.8839\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3673 - val_loss: 122.3245\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.6651 - val_loss: 111.6805\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5585 - val_loss: 125.4391\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8475 - val_loss: 128.8105\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8330 - val_loss: 121.5889\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.6115 - val_loss: 112.6018\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.7557 - val_loss: 132.8690\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.8383 - val_loss: 127.8433\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7450 - val_loss: 134.9628\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 118.8486 - val_loss: 143.9185\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4796 - val_loss: 125.7341\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.1709 - val_loss: 116.8290\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.0757 - val_loss: 137.6016\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7723 - val_loss: 121.0554\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8889 - val_loss: 107.8439\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7486 - val_loss: 119.9638\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.7255 - val_loss: 127.8676\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1990 - val_loss: 131.2061\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2578 - val_loss: 132.8117\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.7604 - val_loss: 118.4499\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3733 - val_loss: 122.5255\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3255 - val_loss: 119.3884\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1566 - val_loss: 120.6300\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5540 - val_loss: 127.9381\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.8752 - val_loss: 111.8308\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9163 - val_loss: 108.8116\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.7417 - val_loss: 129.2586\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9315 - val_loss: 129.3321\n",
      "Epoch 2221/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.1529 - val_loss: 113.4034\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1476 - val_loss: 122.9232\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.4356 - val_loss: 126.4988\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.0451 - val_loss: 125.2607\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5444 - val_loss: 140.0171\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.7603 - val_loss: 160.6990\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9544 - val_loss: 111.9289\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.5839 - val_loss: 136.5975\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.0646 - val_loss: 116.4092\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9445 - val_loss: 111.0944\n",
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.8842 - val_loss: 127.3624\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0334 - val_loss: 170.8136\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.9597 - val_loss: 126.1461\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3130 - val_loss: 112.1346\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.3319 - val_loss: 121.5553\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9992 - val_loss: 123.5745\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.3817 - val_loss: 126.0738\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1030 - val_loss: 115.7315\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7059 - val_loss: 168.0722\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 138.446 - 0s 50us/step - loss: 138.0499 - val_loss: 111.7049\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.4750 - val_loss: 119.3435\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 125.5616 - val_loss: 118.7645\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.0348 - val_loss: 258.7521\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 133.6530 - val_loss: 158.9301\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 127.8077 - val_loss: 124.3178\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0553 - val_loss: 112.6893\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0555 - val_loss: 129.7197\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.6313 - val_loss: 139.6880\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5724 - val_loss: 136.0670\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6158 - val_loss: 122.6764\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.8873 - val_loss: 125.1162\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.4195 - val_loss: 114.4359\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.1740 - val_loss: 115.4134\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4005 - val_loss: 126.5898\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.8235 - val_loss: 122.7244\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6962 - val_loss: 113.8459\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.1950 - val_loss: 119.5129\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.4605 - val_loss: 193.3487\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 155.2530 - val_loss: 124.0497\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.4625 - val_loss: 110.5893\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.3196 - val_loss: 151.2039\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9385 - val_loss: 146.6598\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.7557 - val_loss: 111.0253\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8995 - val_loss: 110.9691\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8547 - val_loss: 158.8698\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7258 - val_loss: 134.5496\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.3997 - val_loss: 119.4749\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.6244 - val_loss: 123.8987\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8294 - val_loss: 148.1611\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9995 - val_loss: 127.4159\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0092 - val_loss: 109.5908\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.0526 - val_loss: 160.1443\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6393 - val_loss: 155.1438\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7195 - val_loss: 122.2415\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.9146 - val_loss: 121.2980\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.3013 - val_loss: 136.3723\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.2035 - val_loss: 111.0664\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1226 - val_loss: 112.1551\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2113 - val_loss: 134.6235\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0797 - val_loss: 111.3171\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4509 - val_loss: 121.5263\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.1696 - val_loss: 142.7660\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9290 - val_loss: 142.5294\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.3518 - val_loss: 147.1170\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 129.4491 - val_loss: 127.3203\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.7867 - val_loss: 110.0961\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.7545 - val_loss: 132.1920\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 128.732 - 0s 50us/step - loss: 128.0675 - val_loss: 120.7343\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.6558 - val_loss: 116.3752\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8092 - val_loss: 123.0927\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4050 - val_loss: 136.5717\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 132.0316 - val_loss: 114.7073\n",
      "Epoch 2293/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0001 - val_loss: 115.0853\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3536 - val_loss: 120.0830\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.8290 - val_loss: 114.1394\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.8070 - val_loss: 118.0818\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.3128 - val_loss: 119.6342\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5984 - val_loss: 114.6566\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.5585 - val_loss: 115.1997\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.3015 - val_loss: 150.1086\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9183 - val_loss: 122.6057\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5743 - val_loss: 115.4096\n",
      "Epoch 2303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.1357 - val_loss: 172.2426\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.4341 - val_loss: 137.0055\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3957 - val_loss: 179.0494\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.1782 - val_loss: 158.7289\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.5209 - val_loss: 118.4730\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.5596 - val_loss: 112.5038\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 123.6258 - val_loss: 118.1962\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.3074 - val_loss: 135.7460\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6025 - val_loss: 128.4581\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7716 - val_loss: 126.5829\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6860 - val_loss: 113.2942\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.7888 - val_loss: 109.5279\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 120.3369 - val_loss: 119.5064\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 122.3154 - val_loss: 114.3523\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 118.3330 - val_loss: 118.0885\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5071 - val_loss: 122.5316\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0968 - val_loss: 127.8054\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.0925 - val_loss: 120.4887\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.9314 - val_loss: 125.5594\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.3060 - val_loss: 121.9756\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9810 - val_loss: 129.8250\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.0662 - val_loss: 120.4887\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 265.2331 - val_loss: 121.6084\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7824 - val_loss: 111.0041\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.8113 - val_loss: 127.4069\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 117.5097 - val_loss: 151.8115\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.6436 - val_loss: 121.7080\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.7198 - val_loss: 124.3334\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 123.6608 - val_loss: 117.4384\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.4410 - val_loss: 136.2131\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7508 - val_loss: 123.7596\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9648 - val_loss: 117.8758\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.4049 - val_loss: 155.2292\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.7939 - val_loss: 113.5789\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.7696 - val_loss: 139.7232\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9038 - val_loss: 113.1622\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3413 - val_loss: 118.3097\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3502 - val_loss: 113.9508\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.6918 - val_loss: 140.7127\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3996 - val_loss: 117.9334\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4739 - val_loss: 155.7019\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5796 - val_loss: 116.8926\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 150.8454 - val_loss: 126.9475\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.4335 - val_loss: 128.6778\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2376 - val_loss: 110.6978\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.4447 - val_loss: 111.3419\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.9992 - val_loss: 116.3419\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4348 - val_loss: 126.1410\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.8480 - val_loss: 109.6641\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9206 - val_loss: 134.3439\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.8393 - val_loss: 112.8997\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 148.4765 - val_loss: 142.0983\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4211 - val_loss: 155.1584\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.1773 - val_loss: 115.7080\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4528 - val_loss: 112.4775\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 121.1836 - val_loss: 117.8431\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8193 - val_loss: 132.8068\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.4426 - val_loss: 115.8774\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.2536 - val_loss: 113.1656\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1774 - val_loss: 170.3444\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7627 - val_loss: 126.5877\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.8562 - val_loss: 111.4082\n",
      "Epoch 2365/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.8684 - val_loss: 129.0856\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.1119 - val_loss: 113.7107\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.5809 - val_loss: 126.6066\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.9632 - val_loss: 126.6209\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.7275 - val_loss: 125.5530\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2685 - val_loss: 130.0399\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.7706 - val_loss: 122.6675\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.8953 - val_loss: 133.8946\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 164.0098 - val_loss: 228.3774\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3005 - val_loss: 203.6430\n",
      "Epoch 2375/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.9226 - val_loss: 117.6879\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.3223 - val_loss: 189.6049\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.5234 - val_loss: 125.8590\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.2263 - val_loss: 120.1500\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.9443 - val_loss: 145.0216\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.6119 - val_loss: 132.9970\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.8928 - val_loss: 125.2488\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5363 - val_loss: 111.7724\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.3170 - val_loss: 119.0488\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.9917 - val_loss: 132.3199\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.5538 - val_loss: 112.7156\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.8858 - val_loss: 120.8328\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 116.3437 - val_loss: 118.6339\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.4030 - val_loss: 157.1886\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.2929 - val_loss: 114.4522\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.4161 - val_loss: 113.1525\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7320 - val_loss: 124.6080\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.6073 - val_loss: 132.7656\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0622 - val_loss: 186.9434\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.6049 - val_loss: 120.0940\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.2154 - val_loss: 113.1607\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 121.6591 - val_loss: 114.9272\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 187.6962 - val_loss: 117.1926\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 115.6421 - val_loss: 110.9364\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 126.0563 - val_loss: 141.3462\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.6877 - val_loss: 112.2643\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 116.8296 - val_loss: 199.2365\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.9429 - val_loss: 191.6301\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.5668 - val_loss: 125.2473\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.9622 - val_loss: 112.9212\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 126.5853 - val_loss: 136.2742\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.0728 - val_loss: 112.2437\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7314 - val_loss: 130.8985\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.1830 - val_loss: 120.5860\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 127.6342 - val_loss: 151.0023\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5030 - val_loss: 120.7191\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.8594 - val_loss: 116.7715\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 119.1624 - val_loss: 127.9613\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.7921 - val_loss: 150.5506\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 129.3321 - val_loss: 125.6333\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 177.0426 - val_loss: 111.9435\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 121.4336 - val_loss: 121.0023\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 126.8590 - val_loss: 110.1405\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 135.1630 - val_loss: 163.2033\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 133.4871 - val_loss: 125.9996\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.3288 - val_loss: 139.5349\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 127.7808 - val_loss: 137.4028\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 122.7364 - val_loss: 126.1628\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 115.2014 - val_loss: 108.6496\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 270.9567 - val_loss: 114.6790\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.8251 - val_loss: 123.8041\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 130.4099 - val_loss: 118.4588\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 119.0091 - val_loss: 115.5278\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 125.8917 - val_loss: 112.5082\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 121.5086 - val_loss: 113.0336\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 123.3455 - val_loss: 112.9915\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 122.1900 - val_loss: 116.0492\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 119.7665 - val_loss: 134.7153\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 121.9417 - val_loss: 120.4262\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 125.2418 - val_loss: 121.7324\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.6679 - val_loss: 167.5098\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 123.1041 - val_loss: 120.7097\n",
      "Epoch 2437/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 65us/step - loss: 134.2398 - val_loss: 120.3074\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.4501 - val_loss: 117.8897\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 120.2094 - val_loss: 115.6903\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9027 - val_loss: 111.0453\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.7189 - val_loss: 149.5224\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 125.8412 - val_loss: 129.5496\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 145.4453 - val_loss: 117.1257\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.6279 - val_loss: 120.5760\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 125.8729 - val_loss: 119.9546\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 122.4665 - val_loss: 123.4405\n",
      "Epoch 2447/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.8554 - val_loss: 142.0867\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 136.9595 - val_loss: 124.1799\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 119.1604 - val_loss: 113.3301\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 120.9833 - val_loss: 133.4889\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 120.9958 - val_loss: 118.9998\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.5704 - val_loss: 166.5169\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 125.4766 - val_loss: 146.4351\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 131.0843 - val_loss: 112.5689\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.2790 - val_loss: 130.0627\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 150.8700 - val_loss: 120.4483\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 120.5630 - val_loss: 124.0589\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 119.3085 - val_loss: 128.4372\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 122.6953 - val_loss: 115.1974\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 234.0852 - val_loss: 150.3426\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 127.0440 - val_loss: 117.2293\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 116.6091 - val_loss: 115.3341\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 120.1931 - val_loss: 116.5168\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 119.1317 - val_loss: 122.4566\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 119.4638 - val_loss: 111.8450\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 123.0773 - val_loss: 126.6628\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 116.2658 - val_loss: 119.5331\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 145.7741 - val_loss: 120.0357\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.6984 - val_loss: 115.6726\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.5144 - val_loss: 111.7356\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0937 - val_loss: 133.4579\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1183 - val_loss: 137.4102\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.1547 - val_loss: 124.9602\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.8244 - val_loss: 170.5807\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.9598 - val_loss: 158.9063\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9030 - val_loss: 111.0187\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9087 - val_loss: 121.0720\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 261.2837 - val_loss: 116.0854\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.1665 - val_loss: 115.6948\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6074 - val_loss: 132.9620\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.3403 - val_loss: 121.6181\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.6663 - val_loss: 120.1518\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1878 - val_loss: 111.2278\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 115.0507 - val_loss: 144.5753\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.0760 - val_loss: 115.1785\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.7981 - val_loss: 151.9699\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.0011 - val_loss: 125.1369\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.2209 - val_loss: 163.8603- ETA: 0s - loss: 111.230 - ETA: 0s - loss: 118\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.7333 - val_loss: 114.8904\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3454 - val_loss: 110.3284\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.3797 - val_loss: 113.0109\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 122.3127 - val_loss: 138.6680\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9698 - val_loss: 122.7913\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9339 - val_loss: 137.0130\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7290 - val_loss: 240.6850\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6511 - val_loss: 128.6382\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5441 - val_loss: 127.6972\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3104 - val_loss: 119.5562\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6294 - val_loss: 114.8011\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1768 - val_loss: 113.1161\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3855 - val_loss: 117.8661\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.4374 - val_loss: 119.8411\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.1994 - val_loss: 130.5488\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 120.5820 - val_loss: 117.7963\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.9111 - val_loss: 123.9106\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0932 - val_loss: 114.7015\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9876 - val_loss: 111.9657\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.3706 - val_loss: 120.8239\n",
      "Epoch 2509/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9473 - val_loss: 118.9832\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8747 - val_loss: 130.6324\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.0182 - val_loss: 200.3046\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.1228 - val_loss: 121.5570\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4038 - val_loss: 109.2983\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.7438 - val_loss: 120.5438\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5338 - val_loss: 119.2129\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.5906 - val_loss: 114.8215\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.6141 - val_loss: 114.7506\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 179.2041 - val_loss: 113.6474\n",
      "Epoch 2519/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 140.0379 - val_loss: 121.7145\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.1372 - val_loss: 125.4909\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 134.0242 - val_loss: 126.2859\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.0564 - val_loss: 133.2192\n",
      "Epoch 02522: early stopping\n",
      "Fold score (RMSE): 11.508071899414062\n",
      "Fold #5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 5428.2706 - val_loss: 4404.4021\n",
      "Epoch 2/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 4578.9784 - val_loss: 3896.2419\n",
      "Epoch 3/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 4532.3932 - val_loss: 4573.0516\n",
      "Epoch 4/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4250.2973 - val_loss: 3669.4244\n",
      "Epoch 5/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 4116.9054 - val_loss: 3825.3687\n",
      "Epoch 6/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 4048.4401 - val_loss: 3289.9551\n",
      "Epoch 7/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3917.0437 - val_loss: 2967.6726\n",
      "Epoch 8/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 4030.3761 - val_loss: 3480.7601\n",
      "Epoch 9/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 3761.7563 - val_loss: 3374.0425\n",
      "Epoch 10/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 3635.9486 - val_loss: 2805.3597\n",
      "Epoch 11/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 3404.5195 - val_loss: 2933.1766\n",
      "Epoch 12/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 3061.2597 - val_loss: 3844.2142\n",
      "Epoch 13/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2754.3491 - val_loss: 1843.4911\n",
      "Epoch 14/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 2358.0883 - val_loss: 1810.5366\n",
      "Epoch 15/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 1921.1125 - val_loss: 1377.2650\n",
      "Epoch 16/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1607.6857 - val_loss: 847.5016\n",
      "Epoch 17/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1508.9378 - val_loss: 881.1597\n",
      "Epoch 18/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 1226.8601 - val_loss: 1033.4055\n",
      "Epoch 19/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 968.0159 - val_loss: 1491.1224\n",
      "Epoch 20/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 960.7458 - val_loss: 1819.0767\n",
      "Epoch 21/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 731.0223 - val_loss: 785.7166\n",
      "Epoch 22/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 974.8226 - val_loss: 928.4721\n",
      "Epoch 23/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 697.5026 - val_loss: 411.1934\n",
      "Epoch 24/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 633.7652 - val_loss: 377.6630\n",
      "Epoch 25/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 584.2715 - val_loss: 918.3055\n",
      "Epoch 26/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 850.8551 - val_loss: 382.7612\n",
      "Epoch 27/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 588.6574 - val_loss: 350.9388\n",
      "Epoch 28/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 516.7742 - val_loss: 357.1772\n",
      "Epoch 29/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 552.9240 - val_loss: 423.5539\n",
      "Epoch 30/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 646.7314 - val_loss: 360.8003\n",
      "Epoch 31/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 607.5999 - val_loss: 943.9288\n",
      "Epoch 32/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 539.4070 - val_loss: 332.4467\n",
      "Epoch 33/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 542.3179 - val_loss: 390.8237\n",
      "Epoch 34/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 458.9321 - val_loss: 330.4877\n",
      "Epoch 35/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 472.4791 - val_loss: 427.4114\n",
      "Epoch 36/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 756.9885 - val_loss: 266.5050\n",
      "Epoch 37/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 435.4450 - val_loss: 351.9995\n",
      "Epoch 38/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 411.7609 - val_loss: 383.4297\n",
      "Epoch 39/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 453.4056 - val_loss: 491.9658\n",
      "Epoch 40/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 465.5240 - val_loss: 491.4001\n",
      "Epoch 41/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 496.1462 - val_loss: 287.5869\n",
      "Epoch 42/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 449.6835 - val_loss: 384.0498\n",
      "Epoch 43/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 493.1672 - val_loss: 287.9069\n",
      "Epoch 44/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 425.7570 - val_loss: 256.4645\n",
      "Epoch 45/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 372.2073 - val_loss: 363.8421\n",
      "Epoch 46/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 367.1715 - val_loss: 315.8057\n",
      "Epoch 47/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 457.0965 - val_loss: 281.4199\n",
      "Epoch 48/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 441.0206 - val_loss: 339.7382\n",
      "Epoch 49/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 446.0174 - val_loss: 747.2690\n",
      "Epoch 50/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 374.3003 - val_loss: 830.3982\n",
      "Epoch 51/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 368.4374 - val_loss: 237.6259\n",
      "Epoch 52/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 392.8074 - val_loss: 315.9365\n",
      "Epoch 53/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 419.2190 - val_loss: 228.9547\n",
      "Epoch 54/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 340.4343 - val_loss: 221.2906\n",
      "Epoch 55/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 424.4153 - val_loss: 219.5241\n",
      "Epoch 56/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 294.7038 - val_loss: 413.6147\n",
      "Epoch 57/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 327.9357 - val_loss: 262.7635\n",
      "Epoch 58/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 465.7464 - val_loss: 292.9538\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 472.7743 - val_loss: 205.6267\n",
      "Epoch 60/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 331.3227 - val_loss: 189.0329\n",
      "Epoch 61/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 304.7018 - val_loss: 217.0365\n",
      "Epoch 62/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 456.4675 - val_loss: 233.8590\n",
      "Epoch 63/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 392.7520 - val_loss: 196.2050\n",
      "Epoch 64/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 333.6398 - val_loss: 210.8016\n",
      "Epoch 65/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 335.2316 - val_loss: 183.1824\n",
      "Epoch 66/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 332.1134 - val_loss: 295.2612\n",
      "Epoch 67/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 366.2460 - val_loss: 220.4687\n",
      "Epoch 68/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 376.9817 - val_loss: 351.4571\n",
      "Epoch 69/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 303.5626 - val_loss: 243.2076\n",
      "Epoch 70/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 304.8980 - val_loss: 380.6182\n",
      "Epoch 71/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 319.8816 - val_loss: 233.3651\n",
      "Epoch 72/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 333.2348 - val_loss: 218.1858\n",
      "Epoch 73/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 371.0201 - val_loss: 407.4939\n",
      "Epoch 74/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 269.8854 - val_loss: 173.3131\n",
      "Epoch 75/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 288.9594 - val_loss: 193.0366\n",
      "Epoch 76/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 322.6205 - val_loss: 201.7261\n",
      "Epoch 77/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 333.4120 - val_loss: 257.0892\n",
      "Epoch 78/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 285.2844 - val_loss: 170.1121\n",
      "Epoch 79/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 394.5858 - val_loss: 357.2769\n",
      "Epoch 80/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 300.4454 - val_loss: 172.8115\n",
      "Epoch 81/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 338.6728 - val_loss: 262.4345\n",
      "Epoch 82/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 295.9184 - val_loss: 202.4349\n",
      "Epoch 83/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 301.1914 - val_loss: 297.6943\n",
      "Epoch 84/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 347.7901 - val_loss: 256.1261\n",
      "Epoch 85/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 350.5055 - val_loss: 277.6835\n",
      "Epoch 86/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 291.5400 - val_loss: 165.4758\n",
      "Epoch 87/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 310.5558 - val_loss: 385.9741\n",
      "Epoch 88/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 249.5787 - val_loss: 242.3205\n",
      "Epoch 89/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 290.7294 - val_loss: 217.9977\n",
      "Epoch 90/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 347.4248 - val_loss: 235.0425\n",
      "Epoch 91/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 349.4129 - val_loss: 276.8460\n",
      "Epoch 92/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 262.9638 - val_loss: 177.0771\n",
      "Epoch 93/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 258.8210 - val_loss: 212.5475\n",
      "Epoch 94/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 257.2905 - val_loss: 206.9192\n",
      "Epoch 95/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 317.7740 - val_loss: 317.1674\n",
      "Epoch 96/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 237.7326 - val_loss: 157.2195\n",
      "Epoch 97/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 282.8699 - val_loss: 206.2318\n",
      "Epoch 98/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 243.4737 - val_loss: 272.9632\n",
      "Epoch 99/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 403.2687 - val_loss: 192.9777\n",
      "Epoch 100/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 321.7639 - val_loss: 186.7554\n",
      "Epoch 101/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 342.2880 - val_loss: 196.6495\n",
      "Epoch 102/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 256.2283 - val_loss: 440.0197\n",
      "Epoch 103/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 268.6644 - val_loss: 145.2528\n",
      "Epoch 104/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 278.7456 - val_loss: 156.2162\n",
      "Epoch 105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 236.4474 - val_loss: 162.2004\n",
      "Epoch 106/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 272.3023 - val_loss: 226.5511\n",
      "Epoch 107/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 333.1311 - val_loss: 171.1885\n",
      "Epoch 108/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 292.9393 - val_loss: 196.2064\n",
      "Epoch 109/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 334.9396 - val_loss: 170.9497\n",
      "Epoch 110/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 263.4278 - val_loss: 143.1486\n",
      "Epoch 111/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 236.1178 - val_loss: 146.4926\n",
      "Epoch 112/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 265.8346 - val_loss: 241.3127\n",
      "Epoch 113/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 273.3764 - val_loss: 600.3049\n",
      "Epoch 114/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 246.9786 - val_loss: 165.3554\n",
      "Epoch 115/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 280.4345 - val_loss: 209.5731\n",
      "Epoch 116/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 247.2026 - val_loss: 163.9777\n",
      "Epoch 117/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 244.2753 - val_loss: 151.9411\n",
      "Epoch 118/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.2354 - val_loss: 149.7707\n",
      "Epoch 119/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 392.6457 - val_loss: 146.0041\n",
      "Epoch 120/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 257.8596 - val_loss: 154.3101\n",
      "Epoch 121/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 277.2295 - val_loss: 145.7646\n",
      "Epoch 122/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 239.7870 - val_loss: 150.0803\n",
      "Epoch 123/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 238.2968 - val_loss: 178.3331\n",
      "Epoch 124/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.3813 - val_loss: 325.0301\n",
      "Epoch 125/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 374.6717 - val_loss: 524.3212\n",
      "Epoch 126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 272.5753 - val_loss: 148.9693\n",
      "Epoch 127/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 209.3133 - val_loss: 235.2902\n",
      "Epoch 128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.7719 - val_loss: 141.4387\n",
      "Epoch 129/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.6658 - val_loss: 137.4339\n",
      "Epoch 130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 373.7022 - val_loss: 161.1887\n",
      "Epoch 131/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 273.8039 - val_loss: 205.6230\n",
      "Epoch 132/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 208.3321 - val_loss: 135.9714\n",
      "Epoch 133/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 212.9887 - val_loss: 247.4901\n",
      "Epoch 134/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 308.7717 - val_loss: 218.6357\n",
      "Epoch 135/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 242.1561 - val_loss: 150.3939\n",
      "Epoch 136/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 241.0688 - val_loss: 175.6346\n",
      "Epoch 137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.5016 - val_loss: 517.5211\n",
      "Epoch 138/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 247.7108 - val_loss: 361.2065\n",
      "Epoch 139/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 341.6095 - val_loss: 151.1551\n",
      "Epoch 140/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 251.7711 - val_loss: 236.4264\n",
      "Epoch 141/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.0616 - val_loss: 228.1763\n",
      "Epoch 142/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 223.7016 - val_loss: 138.4064\n",
      "Epoch 143/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 218.5956 - val_loss: 249.0875\n",
      "Epoch 144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.3386 - val_loss: 142.4050\n",
      "Epoch 145/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 261.2756 - val_loss: 137.1589\n",
      "Epoch 146/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 248.9416 - val_loss: 273.0199\n",
      "Epoch 147/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 209.8067 - val_loss: 147.4127\n",
      "Epoch 148/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 340.5549 - val_loss: 151.3365\n",
      "Epoch 149/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 199.9426 - val_loss: 183.0043\n",
      "Epoch 150/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 215.7970 - val_loss: 152.5624\n",
      "Epoch 151/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 256.6866 - val_loss: 139.3960\n",
      "Epoch 152/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 221.6596 - val_loss: 136.3122\n",
      "Epoch 153/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 240.3343 - val_loss: 131.8389\n",
      "Epoch 154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 233.7400 - val_loss: 315.0099\n",
      "Epoch 155/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 242.5608 - val_loss: 167.7129\n",
      "Epoch 156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 350.8254 - val_loss: 153.7150\n",
      "Epoch 157/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 200.4091 - val_loss: 372.8578\n",
      "Epoch 158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.6179 - val_loss: 149.0838\n",
      "Epoch 159/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 235.9330 - val_loss: 238.5356\n",
      "Epoch 160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 284.3732 - val_loss: 156.1779\n",
      "Epoch 161/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 264.6810 - val_loss: 138.0699\n",
      "Epoch 162/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 220.7024 - val_loss: 184.3447\n",
      "Epoch 163/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.4140 - val_loss: 164.4516\n",
      "Epoch 164/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 221.5201 - val_loss: 150.5654\n",
      "Epoch 165/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.4864 - val_loss: 151.5326\n",
      "Epoch 166/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 231.8405 - val_loss: 600.3778\n",
      "Epoch 167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.1181 - val_loss: 202.7515\n",
      "Epoch 168/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.4843 - val_loss: 129.9363\n",
      "Epoch 169/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.3801 - val_loss: 262.1292\n",
      "Epoch 170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 343.7635 - val_loss: 311.0611\n",
      "Epoch 171/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.1881 - val_loss: 257.8844\n",
      "Epoch 172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 214.4855 - val_loss: 148.6267\n",
      "Epoch 173/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.3101 - val_loss: 143.5809\n",
      "Epoch 174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.5717 - val_loss: 154.0041\n",
      "Epoch 175/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 262.8796 - val_loss: 132.8320\n",
      "Epoch 176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 231.4150 - val_loss: 126.5094\n",
      "Epoch 177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.6637 - val_loss: 426.3736\n",
      "Epoch 178/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.9408 - val_loss: 149.7975\n",
      "Epoch 179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.2008 - val_loss: 147.4974\n",
      "Epoch 180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.2155 - val_loss: 164.1960\n",
      "Epoch 181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 222.8248 - val_loss: 146.5478\n",
      "Epoch 182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 210.5872 - val_loss: 151.4686\n",
      "Epoch 183/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 256.1263 - val_loss: 178.6922\n",
      "Epoch 184/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 183.9255 - val_loss: 172.4189\n",
      "Epoch 185/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 254.8458 - val_loss: 162.8807\n",
      "Epoch 186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 252.6365 - val_loss: 755.2637\n",
      "Epoch 187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 223.1691 - val_loss: 159.5481\n",
      "Epoch 188/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 206.6018 - val_loss: 229.5064\n",
      "Epoch 189/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 275.7129 - val_loss: 168.9440\n",
      "Epoch 190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.9666 - val_loss: 209.5881\n",
      "Epoch 191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 218.6921 - val_loss: 159.2981\n",
      "Epoch 192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 177.1742 - val_loss: 202.6517\n",
      "Epoch 193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.2871 - val_loss: 148.4128\n",
      "Epoch 194/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.5045 - val_loss: 149.2523\n",
      "Epoch 195/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.8872 - val_loss: 170.3983\n",
      "Epoch 196/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 250.5966 - val_loss: 129.2208\n",
      "Epoch 197/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.8518 - val_loss: 178.1559\n",
      "Epoch 198/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.3030 - val_loss: 210.9093\n",
      "Epoch 199/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 250.928 - 0s 50us/step - loss: 250.3317 - val_loss: 150.1414\n",
      "Epoch 200/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.2572 - val_loss: 151.7279\n",
      "Epoch 201/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.6616 - val_loss: 126.7439\n",
      "Epoch 202/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.3457 - val_loss: 126.5522\n",
      "Epoch 203/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.9780 - val_loss: 131.7611\n",
      "Epoch 204/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 202.1334 - val_loss: 146.0360\n",
      "Epoch 205/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 66us/step - loss: 206.7554 - val_loss: 279.4865\n",
      "Epoch 206/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 229.6321 - val_loss: 274.7531\n",
      "Epoch 207/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 203.2524 - val_loss: 175.3931\n",
      "Epoch 208/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 231.6048 - val_loss: 374.8826\n",
      "Epoch 209/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 183.6436 - val_loss: 130.5248\n",
      "Epoch 210/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.4246 - val_loss: 140.6765\n",
      "Epoch 211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.6727 - val_loss: 126.8175\n",
      "Epoch 212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3205 - val_loss: 174.3225\n",
      "Epoch 213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.9232 - val_loss: 142.6196\n",
      "Epoch 214/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.7581 - val_loss: 138.4696\n",
      "Epoch 215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 308.2014 - val_loss: 456.1478\n",
      "Epoch 216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.0966 - val_loss: 123.9680\n",
      "Epoch 217/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 203.9581 - val_loss: 123.2248\n",
      "Epoch 218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.8712 - val_loss: 135.4531\n",
      "Epoch 219/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.2106 - val_loss: 118.0380\n",
      "Epoch 220/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 232.1300 - val_loss: 347.1348\n",
      "Epoch 221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.7109 - val_loss: 125.1609\n",
      "Epoch 222/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.5525 - val_loss: 129.7607\n",
      "Epoch 223/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.1603 - val_loss: 118.1267\n",
      "Epoch 224/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5784 - val_loss: 141.5400\n",
      "Epoch 225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 549.1367 - val_loss: 216.2490\n",
      "Epoch 226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.1892 - val_loss: 164.2680\n",
      "Epoch 227/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 218.5144 - val_loss: 167.0239\n",
      "Epoch 228/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 318.7190 - val_loss: 128.2062\n",
      "Epoch 229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 217.5994 - val_loss: 231.3498\n",
      "Epoch 230/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 240.0264 - val_loss: 434.6387\n",
      "Epoch 231/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 203.2663 - val_loss: 144.3587\n",
      "Epoch 232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.7398 - val_loss: 129.4423\n",
      "Epoch 233/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 206.1421 - val_loss: 135.8853\n",
      "Epoch 234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.4852 - val_loss: 134.8359\n",
      "Epoch 235/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.7998 - val_loss: 145.2979\n",
      "Epoch 236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.6559 - val_loss: 287.6394\n",
      "Epoch 237/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.2207 - val_loss: 174.5409\n",
      "Epoch 238/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 225.4134 - val_loss: 162.2933\n",
      "Epoch 239/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 224.8455 - val_loss: 145.2348\n",
      "Epoch 240/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.9202 - val_loss: 126.1801\n",
      "Epoch 241/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 211.3914 - val_loss: 141.0023\n",
      "Epoch 242/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 196.9261 - val_loss: 172.8143\n",
      "Epoch 243/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.5189 - val_loss: 133.6840\n",
      "Epoch 244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.1405 - val_loss: 241.5183\n",
      "Epoch 245/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 246.6898 - val_loss: 182.6796\n",
      "Epoch 246/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 232.0816 - val_loss: 897.9332\n",
      "Epoch 247/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 257.3727 - val_loss: 157.6173\n",
      "Epoch 248/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.5695 - val_loss: 120.2084\n",
      "Epoch 249/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.7298 - val_loss: 129.7736\n",
      "Epoch 250/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.8990 - val_loss: 128.7701\n",
      "Epoch 251/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.1003 - val_loss: 123.8397\n",
      "Epoch 252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.5926 - val_loss: 199.7915\n",
      "Epoch 253/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 189.0259 - val_loss: 134.1959\n",
      "Epoch 254/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.2315 - val_loss: 174.6672\n",
      "Epoch 255/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 266.5286 - val_loss: 138.9253\n",
      "Epoch 256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.3167 - val_loss: 158.8430\n",
      "Epoch 257/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.9670 - val_loss: 129.0059\n",
      "Epoch 258/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.1661 - val_loss: 384.3585\n",
      "Epoch 259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 404.9764 - val_loss: 131.2509\n",
      "Epoch 260/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.1906 - val_loss: 126.7592\n",
      "Epoch 261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.9322 - val_loss: 162.7559\n",
      "Epoch 262/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.4314 - val_loss: 177.2133\n",
      "Epoch 263/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 215.4236 - val_loss: 309.2546\n",
      "Epoch 264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 200.4789 - val_loss: 267.5079\n",
      "Epoch 265/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.6223 - val_loss: 126.6738\n",
      "Epoch 266/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.2390 - val_loss: 143.0074\n",
      "Epoch 267/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 219.6816 - val_loss: 198.6009\n",
      "Epoch 268/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.3396 - val_loss: 142.2500\n",
      "Epoch 269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.5315 - val_loss: 153.8533\n",
      "Epoch 270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.8772 - val_loss: 512.0468\n",
      "Epoch 271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3283 - val_loss: 119.5768\n",
      "Epoch 272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.1327 - val_loss: 160.7795\n",
      "Epoch 273/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.0094 - val_loss: 243.0669\n",
      "Epoch 274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.0934 - val_loss: 121.9290\n",
      "Epoch 275/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 205.1279 - val_loss: 129.3297\n",
      "Epoch 276/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 205.8926 - val_loss: 726.0265\n",
      "Epoch 277/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 340.9800 - val_loss: 167.3568\n",
      "Epoch 278/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 67us/step - loss: 217.0814 - val_loss: 151.1016\n",
      "Epoch 279/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.9280 - val_loss: 127.8061\n",
      "Epoch 280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.7511 - val_loss: 141.7898\n",
      "Epoch 281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.1899 - val_loss: 181.2001\n",
      "Epoch 282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.5999 - val_loss: 124.6784\n",
      "Epoch 283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 251.2988 - val_loss: 139.0771\n",
      "Epoch 284/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.6357 - val_loss: 148.9272\n",
      "Epoch 285/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.3659 - val_loss: 170.5396\n",
      "Epoch 286/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.2908 - val_loss: 126.1240\n",
      "Epoch 287/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.4030 - val_loss: 135.1410\n",
      "Epoch 288/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.1741 - val_loss: 118.1097\n",
      "Epoch 289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.4049 - val_loss: 122.0787\n",
      "Epoch 290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.7040 - val_loss: 571.6720\n",
      "Epoch 291/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 259.8152 - val_loss: 153.8098\n",
      "Epoch 292/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.9247 - val_loss: 248.8468\n",
      "Epoch 293/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.6997 - val_loss: 165.9691\n",
      "Epoch 294/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 180.6284 - val_loss: 146.9249\n",
      "Epoch 295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.4378 - val_loss: 164.8236\n",
      "Epoch 296/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8229 - val_loss: 117.3994\n",
      "Epoch 297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.4351 - val_loss: 120.3816\n",
      "Epoch 298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.5690 - val_loss: 162.5626\n",
      "Epoch 299/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 182.4594 - val_loss: 188.2257\n",
      "Epoch 300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 286.7745 - val_loss: 145.2659\n",
      "Epoch 301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 186.6378 - val_loss: 119.5096\n",
      "Epoch 302/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.9853 - val_loss: 113.1901\n",
      "Epoch 303/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.7580 - val_loss: 134.6375\n",
      "Epoch 304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.5301 - val_loss: 314.0468\n",
      "Epoch 305/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 220.4741 - val_loss: 114.5792\n",
      "Epoch 306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.5146 - val_loss: 117.6353\n",
      "Epoch 307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.8444 - val_loss: 123.9153\n",
      "Epoch 308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.6620 - val_loss: 156.2557\n",
      "Epoch 309/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 153.8347 - val_loss: 127.6502\n",
      "Epoch 310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.7748 - val_loss: 152.3599\n",
      "Epoch 311/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.6369 - val_loss: 117.5177\n",
      "Epoch 312/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2206 - val_loss: 167.9978\n",
      "Epoch 313/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.4183 - val_loss: 116.9911\n",
      "Epoch 314/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.7024 - val_loss: 175.6545\n",
      "Epoch 315/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 780.6690 - val_loss: 200.9098\n",
      "Epoch 316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 278.1122 - val_loss: 158.2887\n",
      "Epoch 317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.8558 - val_loss: 427.8402\n",
      "Epoch 318/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 445.6984 - val_loss: 158.2097\n",
      "Epoch 319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.2053 - val_loss: 131.1656\n",
      "Epoch 320/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.0856 - val_loss: 137.7238\n",
      "Epoch 321/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.2335 - val_loss: 287.5323\n",
      "Epoch 322/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 199.3916 - val_loss: 129.3860\n",
      "Epoch 323/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 257.9405 - val_loss: 219.2792\n",
      "Epoch 324/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.8521 - val_loss: 192.6882\n",
      "Epoch 325/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.4993 - val_loss: 133.0472\n",
      "Epoch 326/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.9001 - val_loss: 154.3735\n",
      "Epoch 327/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.5500 - val_loss: 144.7339\n",
      "Epoch 328/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.7482 - val_loss: 136.0833\n",
      "Epoch 329/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.1961 - val_loss: 144.2661\n",
      "Epoch 330/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.2866 - val_loss: 143.9005\n",
      "Epoch 331/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.8430 - val_loss: 146.8714\n",
      "Epoch 332/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.0047 - val_loss: 124.9545\n",
      "Epoch 333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.5474 - val_loss: 119.8620\n",
      "Epoch 334/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.7839 - val_loss: 127.7913\n",
      "Epoch 335/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 236.9072 - val_loss: 125.7291\n",
      "Epoch 336/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.9278 - val_loss: 313.8297\n",
      "Epoch 337/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 227.3686 - val_loss: 236.2249\n",
      "Epoch 338/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.6766 - val_loss: 147.6011\n",
      "Epoch 339/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.1499 - val_loss: 153.4569\n",
      "Epoch 340/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.5038 - val_loss: 141.5963\n",
      "Epoch 341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.0665 - val_loss: 135.9209\n",
      "Epoch 342/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.1879 - val_loss: 126.9317\n",
      "Epoch 343/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.4072 - val_loss: 122.0023\n",
      "Epoch 344/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.5367 - val_loss: 179.5282\n",
      "Epoch 345/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.8047 - val_loss: 125.6902\n",
      "Epoch 346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.2758 - val_loss: 126.9674\n",
      "Epoch 347/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 282.1315 - val_loss: 151.3164\n",
      "Epoch 348/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 173.5505 - val_loss: 125.3258\n",
      "Epoch 349/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 183.3677 - val_loss: 129.7022\n",
      "Epoch 350/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 166.6914 - val_loss: 235.8104\n",
      "Epoch 351/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.1164 - val_loss: 509.4705\n",
      "Epoch 352/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 204.0445 - val_loss: 166.6173\n",
      "Epoch 353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.2529 - val_loss: 437.9102\n",
      "Epoch 354/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 277.1539 - val_loss: 132.2679\n",
      "Epoch 355/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.4137 - val_loss: 112.7895\n",
      "Epoch 356/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 165.9424 - val_loss: 172.1699\n",
      "Epoch 357/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 216.1738 - val_loss: 149.8461\n",
      "Epoch 358/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.4210 - val_loss: 116.8261\n",
      "Epoch 359/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 185.1741 - val_loss: 121.8883\n",
      "Epoch 360/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.4256 - val_loss: 125.0784\n",
      "Epoch 361/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 219.6486 - val_loss: 275.0463\n",
      "Epoch 362/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 219.4879 - val_loss: 566.6567\n",
      "Epoch 363/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.9421 - val_loss: 123.2744\n",
      "Epoch 364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.6925 - val_loss: 125.7428\n",
      "Epoch 365/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2053 - val_loss: 214.0278\n",
      "Epoch 366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.3189 - val_loss: 116.9386\n",
      "Epoch 367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.9656 - val_loss: 117.5583\n",
      "Epoch 368/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9005 - val_loss: 164.9735\n",
      "Epoch 369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.0638 - val_loss: 281.7120\n",
      "Epoch 370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 228.7169 - val_loss: 177.8567\n",
      "Epoch 371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 201.6655 - val_loss: 122.8819\n",
      "Epoch 372/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.5200 - val_loss: 121.2041\n",
      "Epoch 373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.5558 - val_loss: 134.5101\n",
      "Epoch 374/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.1768 - val_loss: 221.8953\n",
      "Epoch 375/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 178.6678 - val_loss: 126.4779\n",
      "Epoch 376/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.4155 - val_loss: 252.4139\n",
      "Epoch 377/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.6228 - val_loss: 181.9569\n",
      "Epoch 378/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.6984 - val_loss: 127.6071\n",
      "Epoch 379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0493 - val_loss: 181.8939\n",
      "Epoch 380/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.9214 - val_loss: 149.7633\n",
      "Epoch 381/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 213.2883 - val_loss: 176.5415\n",
      "Epoch 382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.6974 - val_loss: 119.7961\n",
      "Epoch 383/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.4049 - val_loss: 184.4462\n",
      "Epoch 384/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.0012 - val_loss: 130.4298\n",
      "Epoch 385/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.2870 - val_loss: 141.0402\n",
      "Epoch 386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5343 - val_loss: 178.7128\n",
      "Epoch 387/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.5407 - val_loss: 120.0305\n",
      "Epoch 388/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.8141 - val_loss: 117.7422\n",
      "Epoch 389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.5138 - val_loss: 114.6441\n",
      "Epoch 390/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 369.6110 - val_loss: 130.1138\n",
      "Epoch 391/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 193.7854 - val_loss: 136.1428\n",
      "Epoch 392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.7667 - val_loss: 122.1386\n",
      "Epoch 393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0084 - val_loss: 116.1166\n",
      "Epoch 394/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.0217 - val_loss: 110.1680\n",
      "Epoch 395/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9225 - val_loss: 117.2224\n",
      "Epoch 396/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.8563 - val_loss: 193.2066\n",
      "Epoch 397/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2588 - val_loss: 118.3503\n",
      "Epoch 398/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.6398 - val_loss: 118.5954\n",
      "Epoch 399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.0162 - val_loss: 125.1425\n",
      "Epoch 400/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3478 - val_loss: 218.3142\n",
      "Epoch 401/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 248.383 - 0s 51us/step - loss: 249.7703 - val_loss: 136.2481\n",
      "Epoch 402/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.2490 - val_loss: 124.6765\n",
      "Epoch 403/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3854 - val_loss: 121.9020\n",
      "Epoch 404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.2756 - val_loss: 114.4723\n",
      "Epoch 405/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.4658 - val_loss: 146.6932\n",
      "Epoch 406/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 183.6714 - val_loss: 134.3433\n",
      "Epoch 407/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.8397 - val_loss: 114.1928\n",
      "Epoch 408/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.2816 - val_loss: 121.7707\n",
      "Epoch 409/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.1085 - val_loss: 110.1525\n",
      "Epoch 410/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.9932 - val_loss: 115.2647\n",
      "Epoch 411/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3608 - val_loss: 213.2502\n",
      "Epoch 412/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.4443 - val_loss: 113.7376\n",
      "Epoch 413/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 324.451 - 0s 51us/step - loss: 324.1138 - val_loss: 123.1722\n",
      "Epoch 414/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.6689 - val_loss: 116.3876\n",
      "Epoch 415/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 303.9026 - val_loss: 352.0549\n",
      "Epoch 416/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 194.3338 - val_loss: 145.3026\n",
      "Epoch 417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.1300 - val_loss: 179.6883\n",
      "Epoch 418/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 235.6094 - val_loss: 160.2647\n",
      "Epoch 419/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 163.0442 - val_loss: 110.9343\n",
      "Epoch 420/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 159.3161 - val_loss: 195.2390\n",
      "Epoch 421/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 153.9910 - val_loss: 114.2638\n",
      "Epoch 422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5191 - val_loss: 136.3961\n",
      "Epoch 423/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.3664 - val_loss: 115.3903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.5514 - val_loss: 189.9403\n",
      "Epoch 425/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 182.6733 - val_loss: 324.6077\n",
      "Epoch 426/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 331.7393 - val_loss: 125.1820\n",
      "Epoch 427/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 174.232 - 0s 51us/step - loss: 172.4556 - val_loss: 110.3065\n",
      "Epoch 428/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0541 - val_loss: 193.7937\n",
      "Epoch 429/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.7743 - val_loss: 146.5455\n",
      "Epoch 430/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.3059 - val_loss: 116.2409\n",
      "Epoch 431/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1665 - val_loss: 122.7749\n",
      "Epoch 432/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2101 - val_loss: 125.7944\n",
      "Epoch 433/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 185.6079 - val_loss: 127.2660\n",
      "Epoch 434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 169.2312 - val_loss: 133.4661\n",
      "Epoch 435/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.2820 - val_loss: 289.2284\n",
      "Epoch 436/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 246.1079 - val_loss: 203.0789\n",
      "Epoch 437/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 241.0845 - val_loss: 483.8718\n",
      "Epoch 438/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.0091 - val_loss: 118.4018\n",
      "Epoch 439/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.5420 - val_loss: 112.1089\n",
      "Epoch 440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.4078 - val_loss: 160.6155\n",
      "Epoch 441/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3929 - val_loss: 111.2310\n",
      "Epoch 442/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.7854 - val_loss: 132.9125\n",
      "Epoch 443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1932 - val_loss: 109.8520\n",
      "Epoch 444/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.5774 - val_loss: 128.5543\n",
      "Epoch 445/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 157.9303 - val_loss: 181.7695\n",
      "Epoch 446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.6126 - val_loss: 119.7011\n",
      "Epoch 447/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0373 - val_loss: 127.9860\n",
      "Epoch 448/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 336.9166 - val_loss: 257.3510\n",
      "Epoch 449/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 257.1197 - val_loss: 122.7882\n",
      "Epoch 450/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.2905 - val_loss: 123.7968\n",
      "Epoch 451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.0153 - val_loss: 110.5995\n",
      "Epoch 452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.5975 - val_loss: 191.3067\n",
      "Epoch 453/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.2404 - val_loss: 109.9318\n",
      "Epoch 454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.7102 - val_loss: 134.6298\n",
      "Epoch 455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0391 - val_loss: 146.4740\n",
      "Epoch 456/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.7128 - val_loss: 440.1879\n",
      "Epoch 457/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.9106 - val_loss: 246.6064\n",
      "Epoch 458/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.3414 - val_loss: 152.4254\n",
      "Epoch 459/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.6538 - val_loss: 133.1571\n",
      "Epoch 460/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2730 - val_loss: 149.8404\n",
      "Epoch 461/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.7192 - val_loss: 129.4838\n",
      "Epoch 462/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 151.8347 - val_loss: 114.9684\n",
      "Epoch 463/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 317.8955 - val_loss: 136.6173\n",
      "Epoch 464/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.3589 - val_loss: 118.1142\n",
      "Epoch 465/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.9685 - val_loss: 120.0490\n",
      "Epoch 466/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.4372 - val_loss: 173.1739\n",
      "Epoch 467/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 144.2919 - val_loss: 110.6293\n",
      "Epoch 468/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.4551 - val_loss: 108.7710\n",
      "Epoch 469/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 216.2739 - val_loss: 153.3813\n",
      "Epoch 470/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.9709 - val_loss: 327.8630\n",
      "Epoch 471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.9242 - val_loss: 214.8548\n",
      "Epoch 472/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1777 - val_loss: 121.6633\n",
      "Epoch 473/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5380 - val_loss: 112.3473\n",
      "Epoch 474/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.5711 - val_loss: 126.0801\n",
      "Epoch 475/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.6725 - val_loss: 132.9182\n",
      "Epoch 476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.5399 - val_loss: 119.2117\n",
      "Epoch 477/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1316 - val_loss: 115.2524\n",
      "Epoch 478/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6776 - val_loss: 112.0759\n",
      "Epoch 479/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0693 - val_loss: 113.5321\n",
      "Epoch 480/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 192.9738 - val_loss: 2940.6305\n",
      "Epoch 481/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 471.2864 - val_loss: 129.1279\n",
      "Epoch 482/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 186.214 - 0s 51us/step - loss: 185.7862 - val_loss: 153.0503\n",
      "Epoch 483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.6868 - val_loss: 151.6518\n",
      "Epoch 484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.4380 - val_loss: 334.8559\n",
      "Epoch 485/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 280.9138 - val_loss: 250.7573\n",
      "Epoch 486/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.2502 - val_loss: 119.7064\n",
      "Epoch 487/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 186.0453 - val_loss: 139.1839\n",
      "Epoch 488/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.8410 - val_loss: 131.6107\n",
      "Epoch 489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.3530 - val_loss: 126.9446\n",
      "Epoch 490/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 160.4294 - val_loss: 207.3041\n",
      "Epoch 491/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 166.9549 - val_loss: 135.8879\n",
      "Epoch 492/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 148.1356 - val_loss: 116.0464\n",
      "Epoch 493/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 242.5167 - val_loss: 188.0599\n",
      "Epoch 494/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.8723 - val_loss: 121.9015\n",
      "Epoch 495/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.9156 - val_loss: 182.4396\n",
      "Epoch 496/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.4223 - val_loss: 113.9767\n",
      "Epoch 497/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.9121 - val_loss: 136.4805\n",
      "Epoch 498/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1253 - val_loss: 113.9517\n",
      "Epoch 499/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 418.7238 - val_loss: 257.1564\n",
      "Epoch 500/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.9328 - val_loss: 115.6538\n",
      "Epoch 501/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.1775 - val_loss: 128.5094\n",
      "Epoch 502/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 207.7391 - val_loss: 138.3316\n",
      "Epoch 503/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6848 - val_loss: 179.7785\n",
      "Epoch 504/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 268.1438 - val_loss: 117.9377\n",
      "Epoch 505/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 159.1452 - val_loss: 133.7175\n",
      "Epoch 506/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 161.4106 - val_loss: 120.1763\n",
      "Epoch 507/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.7918 - val_loss: 141.1025\n",
      "Epoch 508/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.5815 - val_loss: 116.2961\n",
      "Epoch 509/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7911 - val_loss: 115.0822\n",
      "Epoch 510/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9580 - val_loss: 115.2479\n",
      "Epoch 511/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.8272 - val_loss: 115.6338\n",
      "Epoch 512/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 199.5255 - val_loss: 213.4713\n",
      "Epoch 513/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 403.4704 - val_loss: 140.8693\n",
      "Epoch 514/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0940 - val_loss: 113.0125\n",
      "Epoch 515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2819 - val_loss: 128.2916\n",
      "Epoch 516/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.2933 - val_loss: 112.2201\n",
      "Epoch 517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.4254 - val_loss: 160.9582\n",
      "Epoch 518/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.8917 - val_loss: 119.3467\n",
      "Epoch 519/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 174.3226 - val_loss: 114.7951\n",
      "Epoch 520/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3471 - val_loss: 118.1486\n",
      "Epoch 521/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 203.8432 - val_loss: 122.4268\n",
      "Epoch 522/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 230.0004 - val_loss: 111.9867\n",
      "Epoch 523/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 163.3571 - val_loss: 126.5025\n",
      "Epoch 524/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 187.9047 - val_loss: 142.8571\n",
      "Epoch 525/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 239.3102 - val_loss: 115.0617\n",
      "Epoch 526/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8267 - val_loss: 237.7946\n",
      "Epoch 527/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.2992 - val_loss: 155.3919\n",
      "Epoch 528/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 161.8798 - val_loss: 120.1592\n",
      "Epoch 529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 157.6092 - val_loss: 111.7657\n",
      "Epoch 530/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.8947 - val_loss: 198.5592\n",
      "Epoch 531/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 531.7973 - val_loss: 216.5239\n",
      "Epoch 532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.0553 - val_loss: 122.5547\n",
      "Epoch 533/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.2780 - val_loss: 251.3154\n",
      "Epoch 534/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.5984 - val_loss: 127.9512\n",
      "Epoch 535/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 172.3936 - val_loss: 119.2237\n",
      "Epoch 536/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 206.1746 - val_loss: 508.0394\n",
      "Epoch 537/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.2598 - val_loss: 116.2926\n",
      "Epoch 538/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.4425 - val_loss: 162.6915\n",
      "Epoch 539/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.2743 - val_loss: 107.5122\n",
      "Epoch 540/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 323.7759 - val_loss: 150.4155\n",
      "Epoch 541/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.5395 - val_loss: 157.5523\n",
      "Epoch 542/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 266.3842 - val_loss: 429.1561\n",
      "Epoch 543/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.1909 - val_loss: 202.9167\n",
      "Epoch 544/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.2729 - val_loss: 121.8860\n",
      "Epoch 545/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1242 - val_loss: 109.7512\n",
      "Epoch 546/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5972 - val_loss: 135.0197\n",
      "Epoch 547/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.2385 - val_loss: 144.5264\n",
      "Epoch 548/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 176.4961 - val_loss: 108.6596\n",
      "Epoch 549/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.6075 - val_loss: 125.7039\n",
      "Epoch 550/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.7622 - val_loss: 110.1916\n",
      "Epoch 551/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 230.1560 - val_loss: 129.9842\n",
      "Epoch 552/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.1848 - val_loss: 178.6317\n",
      "Epoch 553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.1927 - val_loss: 150.6390\n",
      "Epoch 554/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.4029 - val_loss: 114.1162\n",
      "Epoch 555/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 213.4369 - val_loss: 128.3207\n",
      "Epoch 556/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.5928 - val_loss: 113.6092\n",
      "Epoch 557/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0573 - val_loss: 110.6734\n",
      "Epoch 558/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 325.9508 - val_loss: 138.2868\n",
      "Epoch 559/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.3264 - val_loss: 115.5220\n",
      "Epoch 560/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7534 - val_loss: 244.5917\n",
      "Epoch 561/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.3948 - val_loss: 175.8600\n",
      "Epoch 562/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 161.377 - 1s 76us/step - loss: 164.2942 - val_loss: 129.9968\n",
      "Epoch 563/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 194.9227 - val_loss: 119.9837\n",
      "Epoch 564/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 165.7745 - val_loss: 183.0882\n",
      "Epoch 565/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 200.8399 - val_loss: 114.6204\n",
      "Epoch 566/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 144.4703 - val_loss: 137.5443\n",
      "Epoch 567/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 175.3013 - val_loss: 165.5501\n",
      "Epoch 568/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 227.5724 - val_loss: 133.6121\n",
      "Epoch 569/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 180.2782 - val_loss: 126.1236\n",
      "Epoch 570/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 179.9560 - val_loss: 394.5904\n",
      "Epoch 571/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.1095 - val_loss: 111.5351\n",
      "Epoch 572/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 334.0963 - val_loss: 156.3659\n",
      "Epoch 573/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 196.5269 - val_loss: 140.4795\n",
      "Epoch 574/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 199.5313 - val_loss: 157.1098\n",
      "Epoch 575/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 154.8161 - val_loss: 113.9894\n",
      "Epoch 576/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 238.7486 - val_loss: 109.8532\n",
      "Epoch 577/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 144.6793 - val_loss: 109.3888\n",
      "Epoch 578/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 163.5853 - val_loss: 137.4119\n",
      "Epoch 579/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 307.8698 - val_loss: 132.8215\n",
      "Epoch 580/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 196.4479 - val_loss: 111.9038\n",
      "Epoch 581/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 147.8933 - val_loss: 122.9826\n",
      "Epoch 582/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 166.5610 - val_loss: 139.0835\n",
      "Epoch 583/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 163.2252 - val_loss: 115.8108\n",
      "Epoch 584/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 157.1744 - val_loss: 135.0808\n",
      "Epoch 585/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 227.5289 - val_loss: 525.0922\n",
      "Epoch 586/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 176.6524 - val_loss: 107.1688\n",
      "Epoch 587/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.9258 - val_loss: 110.2155\n",
      "Epoch 588/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 153.7920 - val_loss: 118.0129\n",
      "Epoch 589/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 201.5446 - val_loss: 112.2581\n",
      "Epoch 590/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 172.7071 - val_loss: 154.7973\n",
      "Epoch 591/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 162.2140 - val_loss: 115.8547\n",
      "Epoch 592/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 144.5559 - val_loss: 136.9124\n",
      "Epoch 593/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 218.2574 - val_loss: 124.1673\n",
      "Epoch 594/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 209.1203 - val_loss: 108.2563\n",
      "Epoch 595/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 172.5061 - val_loss: 157.5169\n",
      "Epoch 596/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 150.9285 - val_loss: 111.8864\n",
      "Epoch 597/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 176.4143 - val_loss: 120.3902\n",
      "Epoch 598/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 209.2193 - val_loss: 111.6709\n",
      "Epoch 599/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 281.3975 - val_loss: 133.0522\n",
      "Epoch 600/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 149.8739 - val_loss: 141.7572\n",
      "Epoch 601/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 195.8291 - val_loss: 137.9494\n",
      "Epoch 602/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 163.4621 - val_loss: 105.8394\n",
      "Epoch 603/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 156.9293 - val_loss: 111.6799\n",
      "Epoch 604/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 146.6825 - val_loss: 148.3411\n",
      "Epoch 605/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 173.8517 - val_loss: 117.9555\n",
      "Epoch 606/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 161.4828 - val_loss: 114.7996\n",
      "Epoch 607/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 153.5947 - val_loss: 126.1289\n",
      "Epoch 608/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 148.9156 - val_loss: 120.3448\n",
      "Epoch 609/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 204.0065 - val_loss: 108.3998\n",
      "Epoch 610/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 158.9864 - val_loss: 121.4487\n",
      "Epoch 611/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 319.8699 - val_loss: 127.4156\n",
      "Epoch 612/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 757.6506 - val_loss: 379.5546\n",
      "Epoch 613/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 268.1945 - val_loss: 121.0733\n",
      "Epoch 614/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 224.6003 - val_loss: 170.5294\n",
      "Epoch 615/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 227.1887 - val_loss: 404.2031\n",
      "Epoch 616/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 377.6663 - val_loss: 158.3648\n",
      "Epoch 617/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 224.6124 - val_loss: 139.9442\n",
      "Epoch 618/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 193.0205 - val_loss: 122.9211\n",
      "Epoch 619/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 207.9511 - val_loss: 129.0823\n",
      "Epoch 620/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.7619 - val_loss: 134.4843\n",
      "Epoch 621/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 206.3617 - val_loss: 143.3134\n",
      "Epoch 622/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 180.9816 - val_loss: 116.8939\n",
      "Epoch 623/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 194.5785 - val_loss: 158.2741\n",
      "Epoch 624/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 167.6230 - val_loss: 145.5942\n",
      "Epoch 625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.3657 - val_loss: 130.7415\n",
      "Epoch 626/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 226.1041 - val_loss: 150.1103\n",
      "Epoch 627/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 175.2246 - val_loss: 123.5513\n",
      "Epoch 628/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 197.7857 - val_loss: 133.1642\n",
      "Epoch 629/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.4187 - val_loss: 127.9050\n",
      "Epoch 630/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.9465 - val_loss: 126.9634\n",
      "Epoch 631/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 370.6606 - val_loss: 193.4691\n",
      "Epoch 632/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 227.0900 - val_loss: 154.9030\n",
      "Epoch 633/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.5753 - val_loss: 121.8682\n",
      "Epoch 634/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 215.1109 - val_loss: 124.7496\n",
      "Epoch 635/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.5023 - val_loss: 110.3286\n",
      "Epoch 636/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 153.2331 - val_loss: 144.9841\n",
      "Epoch 637/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.5267 - val_loss: 112.9064\n",
      "Epoch 638/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1560 - val_loss: 118.7168\n",
      "Epoch 639/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.4086 - val_loss: 110.3950\n",
      "Epoch 640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9318 - val_loss: 145.7297\n",
      "Epoch 641/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.5664 - val_loss: 128.2261\n",
      "Epoch 642/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 165.1747 - val_loss: 122.7995\n",
      "Epoch 643/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1128 - val_loss: 113.4067\n",
      "Epoch 644/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2632 - val_loss: 865.5248\n",
      "Epoch 645/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 311.0352 - val_loss: 128.9839\n",
      "Epoch 646/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3607 - val_loss: 114.3420\n",
      "Epoch 647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.0315 - val_loss: 118.6515\n",
      "Epoch 648/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 347.6734 - val_loss: 173.0561\n",
      "Epoch 649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 194.7687 - val_loss: 133.7561\n",
      "Epoch 650/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.4704 - val_loss: 135.5569\n",
      "Epoch 651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.4554 - val_loss: 200.8153\n",
      "Epoch 652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 182.0436 - val_loss: 118.9908\n",
      "Epoch 653/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.8331 - val_loss: 127.1902\n",
      "Epoch 654/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.7779 - val_loss: 311.4585\n",
      "Epoch 655/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.0126 - val_loss: 126.9271\n",
      "Epoch 656/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.3408 - val_loss: 365.2703\n",
      "Epoch 657/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.9170 - val_loss: 113.9121\n",
      "Epoch 658/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.9253 - val_loss: 333.2309\n",
      "Epoch 659/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 172.1555 - val_loss: 119.1913\n",
      "Epoch 660/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.6327 - val_loss: 112.4222\n",
      "Epoch 661/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0186 - val_loss: 108.0408\n",
      "Epoch 662/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.5683 - val_loss: 127.9716\n",
      "Epoch 663/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8947 - val_loss: 129.4055\n",
      "Epoch 664/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.6685 - val_loss: 112.7945\n",
      "Epoch 665/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7022 - val_loss: 118.4381\n",
      "Epoch 666/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.5100 - val_loss: 108.8495\n",
      "Epoch 667/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 269.8810 - val_loss: 160.3629\n",
      "Epoch 668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.9583 - val_loss: 116.1425\n",
      "Epoch 669/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 179.7484 - val_loss: 148.2507\n",
      "Epoch 670/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7033 - val_loss: 142.3329\n",
      "Epoch 671/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.9605 - val_loss: 133.4595\n",
      "Epoch 672/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 182.7562 - val_loss: 129.4682\n",
      "Epoch 673/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 151.4836 - val_loss: 118.6182\n",
      "Epoch 674/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.0149 - val_loss: 111.6777\n",
      "Epoch 675/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.3536 - val_loss: 109.7967\n",
      "Epoch 676/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.5388 - val_loss: 136.9224\n",
      "Epoch 677/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.6911 - val_loss: 134.1640\n",
      "Epoch 678/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.1040 - val_loss: 109.4766\n",
      "Epoch 679/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.7092 - val_loss: 114.6288\n",
      "Epoch 680/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 245.1725 - val_loss: 150.4264\n",
      "Epoch 681/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4006 - val_loss: 130.9317\n",
      "Epoch 682/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1749 - val_loss: 140.2084\n",
      "Epoch 683/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 242.4304 - val_loss: 147.8718\n",
      "Epoch 684/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.6420 - val_loss: 112.0512\n",
      "Epoch 685/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.7272 - val_loss: 116.8510\n",
      "Epoch 686/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.6286 - val_loss: 114.3383\n",
      "Epoch 687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8159 - val_loss: 127.9922\n",
      "Epoch 688/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.1996 - val_loss: 108.2895\n",
      "Epoch 689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 188.9358 - val_loss: 108.4177\n",
      "Epoch 690/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.8655 - val_loss: 106.8867\n",
      "Epoch 691/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 137.145 - 0s 50us/step - loss: 137.1750 - val_loss: 114.7037\n",
      "Epoch 692/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 188.1229 - val_loss: 124.3181\n",
      "Epoch 693/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 184.2692 - val_loss: 178.0475\n",
      "Epoch 694/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 178.0517 - val_loss: 113.6561\n",
      "Epoch 695/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 170.6061 - val_loss: 119.6351\n",
      "Epoch 696/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.8853 - val_loss: 117.1726\n",
      "Epoch 697/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 362.1246 - val_loss: 173.0075\n",
      "Epoch 698/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 229.3195 - val_loss: 149.6691\n",
      "Epoch 699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 197.7667 - val_loss: 156.5588\n",
      "Epoch 700/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 209.1071 - val_loss: 126.2238\n",
      "Epoch 701/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.5095 - val_loss: 112.6580\n",
      "Epoch 702/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.9509 - val_loss: 111.2336\n",
      "Epoch 703/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.8067 - val_loss: 119.2394\n",
      "Epoch 704/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 196.6312 - val_loss: 125.8198\n",
      "Epoch 705/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.6045 - val_loss: 121.8209\n",
      "Epoch 706/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0434 - val_loss: 112.9119\n",
      "Epoch 707/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.0817 - val_loss: 120.8327\n",
      "Epoch 708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 219.3010 - val_loss: 155.9275\n",
      "Epoch 709/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0143 - val_loss: 125.2873\n",
      "Epoch 710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 301.1472 - val_loss: 131.3467\n",
      "Epoch 711/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.7224 - val_loss: 126.2489\n",
      "Epoch 712/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.7043 - val_loss: 127.0893\n",
      "Epoch 713/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.0281 - val_loss: 118.2418\n",
      "Epoch 714/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 174.8163 - val_loss: 145.6281\n",
      "Epoch 715/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.0913 - val_loss: 127.9361\n",
      "Epoch 716/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.3251 - val_loss: 135.9299\n",
      "Epoch 717/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.5345 - val_loss: 119.0949\n",
      "Epoch 718/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 230.4536 - val_loss: 117.0284\n",
      "Epoch 719/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.6296 - val_loss: 110.0919\n",
      "Epoch 720/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 141.2031 - val_loss: 107.7876\n",
      "Epoch 721/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.1847 - val_loss: 117.0604\n",
      "Epoch 722/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 293.3496 - val_loss: 114.1306\n",
      "Epoch 723/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9238 - val_loss: 124.7200\n",
      "Epoch 724/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 203.9063 - val_loss: 111.3694\n",
      "Epoch 725/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 196.4459 - val_loss: 133.8361\n",
      "Epoch 726/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 201.8684 - val_loss: 128.8159\n",
      "Epoch 727/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.6914 - val_loss: 111.6279\n",
      "Epoch 728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.6422 - val_loss: 115.2031\n",
      "Epoch 729/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.7778 - val_loss: 121.2002\n",
      "Epoch 730/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4853 - val_loss: 151.9612\n",
      "Epoch 731/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.6160 - val_loss: 163.7831\n",
      "Epoch 732/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5857 - val_loss: 105.9717\n",
      "Epoch 733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3158 - val_loss: 112.6934\n",
      "Epoch 734/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.4429 - val_loss: 222.5097\n",
      "Epoch 735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.1621 - val_loss: 631.5882\n",
      "Epoch 736/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 400.4115 - val_loss: 126.6647\n",
      "Epoch 737/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 166.9308 - val_loss: 186.7213\n",
      "Epoch 738/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.7239 - val_loss: 112.6224\n",
      "Epoch 739/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 151.7946 - val_loss: 111.6383\n",
      "Epoch 740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.9366 - val_loss: 112.8249\n",
      "Epoch 741/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8291 - val_loss: 115.8617\n",
      "Epoch 742/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.5227 - val_loss: 130.6968\n",
      "Epoch 743/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.8467 - val_loss: 176.3161\n",
      "Epoch 744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.5990 - val_loss: 115.8466\n",
      "Epoch 745/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 208.3434 - val_loss: 120.0102\n",
      "Epoch 746/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.8745 - val_loss: 117.6484\n",
      "Epoch 747/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7305 - val_loss: 123.9909\n",
      "Epoch 748/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.3272 - val_loss: 177.9754\n",
      "Epoch 749/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 280.4485 - val_loss: 116.6837\n",
      "Epoch 750/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 181.0595 - val_loss: 149.2921\n",
      "Epoch 751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 268.1459 - val_loss: 126.9335\n",
      "Epoch 752/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1403 - val_loss: 106.7002\n",
      "Epoch 753/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.7795 - val_loss: 110.4315\n",
      "Epoch 754/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3281 - val_loss: 121.1616\n",
      "Epoch 755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5920 - val_loss: 133.3569\n",
      "Epoch 756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3285 - val_loss: 108.2647\n",
      "Epoch 757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.6580 - val_loss: 114.4149\n",
      "Epoch 758/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.6791 - val_loss: 122.0719\n",
      "Epoch 759/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8752 - val_loss: 109.1192\n",
      "Epoch 760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.6317 - val_loss: 128.7144\n",
      "Epoch 761/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 166.8984 - val_loss: 110.3966\n",
      "Epoch 762/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 193.4237 - val_loss: 121.4016\n",
      "Epoch 763/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8066 - val_loss: 117.3762\n",
      "Epoch 764/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.6363 - val_loss: 108.4430\n",
      "Epoch 765/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 132.7392 - val_loss: 110.0319\n",
      "Epoch 766/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 152.4942 - val_loss: 112.2878\n",
      "Epoch 767/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 166.6280 - val_loss: 110.9625\n",
      "Epoch 768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.2265 - val_loss: 121.7248\n",
      "Epoch 769/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.0005 - val_loss: 127.5720\n",
      "Epoch 770/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.4217 - val_loss: 109.6261\n",
      "Epoch 771/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 274.1556 - val_loss: 156.6065\n",
      "Epoch 772/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.3742 - val_loss: 148.6817\n",
      "Epoch 773/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.7148 - val_loss: 183.4648\n",
      "Epoch 774/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 228.3068 - val_loss: 130.6439\n",
      "Epoch 775/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.3617 - val_loss: 126.9024\n",
      "Epoch 776/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.6896 - val_loss: 135.8782\n",
      "Epoch 777/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.0035 - val_loss: 111.0952\n",
      "Epoch 778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7373 - val_loss: 134.3256\n",
      "Epoch 779/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.1392 - val_loss: 123.4360\n",
      "Epoch 780/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5467 - val_loss: 119.0161\n",
      "Epoch 781/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.1195 - val_loss: 142.6185\n",
      "Epoch 782/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 637.5226 - val_loss: 173.5047\n",
      "Epoch 783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 310.4997 - val_loss: 139.3143\n",
      "Epoch 784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0051 - val_loss: 109.9234\n",
      "Epoch 785/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 165.613 - 0s 51us/step - loss: 165.5496 - val_loss: 118.7242\n",
      "Epoch 786/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.2007 - val_loss: 113.1874\n",
      "Epoch 787/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 139.1187 - val_loss: 116.4448\n",
      "Epoch 788/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.5964 - val_loss: 112.5908\n",
      "Epoch 789/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.4291 - val_loss: 105.6096\n",
      "Epoch 790/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8268 - val_loss: 107.2295\n",
      "Epoch 791/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3841 - val_loss: 129.2074\n",
      "Epoch 792/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.9280 - val_loss: 118.1504\n",
      "Epoch 793/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.0672 - val_loss: 133.6410\n",
      "Epoch 794/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3889 - val_loss: 107.2100\n",
      "Epoch 795/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7941 - val_loss: 105.6246\n",
      "Epoch 796/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 341.2090 - val_loss: 215.2022\n",
      "Epoch 797/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.6351 - val_loss: 144.6862\n",
      "Epoch 798/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.2008 - val_loss: 111.4952\n",
      "Epoch 799/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.5557 - val_loss: 122.9968\n",
      "Epoch 800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.4001 - val_loss: 136.7516\n",
      "Epoch 801/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.2527 - val_loss: 106.3327\n",
      "Epoch 802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.2260 - val_loss: 137.4629\n",
      "Epoch 803/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.2396 - val_loss: 471.5236\n",
      "Epoch 804/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.3354 - val_loss: 112.7982\n",
      "Epoch 805/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.5283 - val_loss: 190.3942\n",
      "Epoch 806/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.7680 - val_loss: 108.9620\n",
      "Epoch 807/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 243.8166 - val_loss: 144.8416\n",
      "Epoch 808/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.0079 - val_loss: 107.2862\n",
      "Epoch 809/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.7325 - val_loss: 107.3294\n",
      "Epoch 810/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.8612 - val_loss: 174.0974\n",
      "Epoch 811/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 244.3526 - val_loss: 122.0425\n",
      "Epoch 812/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 203.6074 - val_loss: 108.9520\n",
      "Epoch 813/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.9606 - val_loss: 107.1409\n",
      "Epoch 814/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.8362 - val_loss: 115.3066\n",
      "Epoch 815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.7398 - val_loss: 107.0265\n",
      "Epoch 816/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.8454 - val_loss: 138.6376\n",
      "Epoch 817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.0404 - val_loss: 116.4094\n",
      "Epoch 818/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.6223 - val_loss: 109.8485\n",
      "Epoch 819/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6994 - val_loss: 108.1809\n",
      "Epoch 820/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 224.5984 - val_loss: 139.7488\n",
      "Epoch 821/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.9818 - val_loss: 121.7268\n",
      "Epoch 822/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.1300 - val_loss: 116.8450\n",
      "Epoch 823/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 178.9729 - val_loss: 117.4807\n",
      "Epoch 824/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 212.4940 - val_loss: 120.5817\n",
      "Epoch 825/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.0462 - val_loss: 107.1757\n",
      "Epoch 826/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.0675 - val_loss: 145.5865\n",
      "Epoch 827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.5997 - val_loss: 119.7506\n",
      "Epoch 828/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 191.0612 - val_loss: 113.1455\n",
      "Epoch 829/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2996 - val_loss: 163.3580\n",
      "Epoch 830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 270.3728 - val_loss: 389.4090\n",
      "Epoch 831/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 232.9443 - val_loss: 110.9968\n",
      "Epoch 832/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.1343 - val_loss: 124.6936\n",
      "Epoch 833/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.8777 - val_loss: 108.3800\n",
      "Epoch 834/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.7265 - val_loss: 119.7373\n",
      "Epoch 835/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 170.0439 - val_loss: 289.2110\n",
      "Epoch 836/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 169.8714 - val_loss: 123.8970\n",
      "Epoch 837/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 314.9233 - val_loss: 125.9545\n",
      "Epoch 838/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 160.9215 - val_loss: 110.6353\n",
      "Epoch 839/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2015 - val_loss: 109.2207\n",
      "Epoch 840/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.5064 - val_loss: 112.9905\n",
      "Epoch 841/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.1337 - val_loss: 182.1272\n",
      "Epoch 842/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3272 - val_loss: 130.8551\n",
      "Epoch 843/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1809 - val_loss: 108.9734\n",
      "Epoch 844/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.1029 - val_loss: 126.7877\n",
      "Epoch 845/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1125 - val_loss: 141.9562\n",
      "Epoch 846/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 534.6906 - val_loss: 399.9881\n",
      "Epoch 847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 179.8482 - val_loss: 111.5389\n",
      "Epoch 848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.0945 - val_loss: 106.0887\n",
      "Epoch 849/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6923 - val_loss: 124.8588\n",
      "Epoch 850/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.3840 - val_loss: 113.9869\n",
      "Epoch 851/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.9863 - val_loss: 112.6253\n",
      "Epoch 852/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9956 - val_loss: 119.9206\n",
      "Epoch 853/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 256.0436 - val_loss: 145.5565\n",
      "Epoch 854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.8416 - val_loss: 176.1384\n",
      "Epoch 855/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 190.0323 - val_loss: 136.9127\n",
      "Epoch 856/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.4406 - val_loss: 180.0164\n",
      "Epoch 857/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.8098 - val_loss: 115.8343\n",
      "Epoch 858/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3959 - val_loss: 108.7768\n",
      "Epoch 859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.3506 - val_loss: 124.4225\n",
      "Epoch 860/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4932 - val_loss: 111.1718\n",
      "Epoch 861/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2978 - val_loss: 152.3731\n",
      "Epoch 862/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1266 - val_loss: 109.0504\n",
      "Epoch 863/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.7476 - val_loss: 105.5806\n",
      "Epoch 864/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 270.5224 - val_loss: 145.3654\n",
      "Epoch 865/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 332.1050 - val_loss: 118.0785\n",
      "Epoch 866/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.6580 - val_loss: 142.6583\n",
      "Epoch 867/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4632 - val_loss: 122.5117\n",
      "Epoch 868/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.3480 - val_loss: 126.0370\n",
      "Epoch 869/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.4622 - val_loss: 108.6812\n",
      "Epoch 870/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.9540 - val_loss: 109.7467\n",
      "Epoch 871/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.2170 - val_loss: 105.2641\n",
      "Epoch 872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9123 - val_loss: 111.1660\n",
      "Epoch 873/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.1205 - val_loss: 135.7046\n",
      "Epoch 874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.9590 - val_loss: 113.8059\n",
      "Epoch 875/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.3825 - val_loss: 129.5325\n",
      "Epoch 876/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 276.1086 - val_loss: 111.0504\n",
      "Epoch 877/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.0057 - val_loss: 109.3365\n",
      "Epoch 878/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.6082 - val_loss: 118.5566\n",
      "Epoch 879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.1993 - val_loss: 111.8336\n",
      "Epoch 880/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6515 - val_loss: 187.6746\n",
      "Epoch 881/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 210.8382 - val_loss: 120.0618\n",
      "Epoch 882/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.9564 - val_loss: 142.4501\n",
      "Epoch 883/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 174.9862 - val_loss: 207.7522\n",
      "Epoch 884/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.7340 - val_loss: 138.9218\n",
      "Epoch 885/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.1111 - val_loss: 124.2434\n",
      "Epoch 886/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.2382 - val_loss: 129.5970\n",
      "Epoch 887/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 507.7114 - val_loss: 146.1126\n",
      "Epoch 888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.4486 - val_loss: 141.8392\n",
      "Epoch 889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.4780 - val_loss: 128.4108\n",
      "Epoch 890/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.6200 - val_loss: 141.2805\n",
      "Epoch 891/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 235.6475 - val_loss: 188.6758\n",
      "Epoch 892/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 192.6321 - val_loss: 158.2458\n",
      "Epoch 893/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.3074 - val_loss: 210.6170\n",
      "Epoch 894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 174.9006 - val_loss: 115.6711\n",
      "Epoch 895/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.2538 - val_loss: 156.2811\n",
      "Epoch 896/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.4718 - val_loss: 136.8217\n",
      "Epoch 897/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 155.9208 - val_loss: 240.5887\n",
      "Epoch 898/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.9513 - val_loss: 133.9269\n",
      "Epoch 899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.8263 - val_loss: 117.1905\n",
      "Epoch 900/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.9154 - val_loss: 127.7629\n",
      "Epoch 901/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6796 - val_loss: 151.0477\n",
      "Epoch 902/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.9426 - val_loss: 129.7055\n",
      "Epoch 903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7055 - val_loss: 115.4261\n",
      "Epoch 904/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.4940 - val_loss: 122.7672\n",
      "Epoch 905/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 177.2536 - val_loss: 227.5621\n",
      "Epoch 906/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 254.0429 - val_loss: 183.9518\n",
      "Epoch 907/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 181.5031 - val_loss: 300.7489\n",
      "Epoch 908/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 244.8465 - val_loss: 130.9218\n",
      "Epoch 909/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 180.6327 - val_loss: 124.6315\n",
      "Epoch 910/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 202.2483 - val_loss: 131.0163\n",
      "Epoch 911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.1816 - val_loss: 115.5668\n",
      "Epoch 912/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.2446 - val_loss: 138.3062\n",
      "Epoch 913/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 305.4490 - val_loss: 147.5376\n",
      "Epoch 914/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.9333 - val_loss: 126.7281\n",
      "Epoch 915/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 219.6791 - val_loss: 134.6970\n",
      "Epoch 916/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 181.6647 - val_loss: 119.0467\n",
      "Epoch 917/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.4970 - val_loss: 112.9013\n",
      "Epoch 918/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.1755 - val_loss: 131.9446\n",
      "Epoch 919/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 247.3121 - val_loss: 115.5081\n",
      "Epoch 920/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.6773 - val_loss: 112.5720\n",
      "Epoch 921/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.2286 - val_loss: 198.7218\n",
      "Epoch 922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3888 - val_loss: 196.6617\n",
      "Epoch 923/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 202.7530 - val_loss: 158.0684\n",
      "Epoch 924/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.9849 - val_loss: 149.7861\n",
      "Epoch 925/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 172.8701 - val_loss: 222.2634\n",
      "Epoch 926/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.1159 - val_loss: 165.6938\n",
      "Epoch 927/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 175.7386 - val_loss: 144.2179\n",
      "Epoch 928/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 310.1122 - val_loss: 187.9660\n",
      "Epoch 929/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 175.4676 - val_loss: 110.5260\n",
      "Epoch 930/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.5258 - val_loss: 124.1875\n",
      "Epoch 931/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.4216 - val_loss: 112.3068\n",
      "Epoch 932/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2769 - val_loss: 115.9456\n",
      "Epoch 933/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.3578 - val_loss: 118.2322\n",
      "Epoch 934/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 280.0881 - val_loss: 137.8017\n",
      "Epoch 935/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5064 - val_loss: 115.1301\n",
      "Epoch 936/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.2100 - val_loss: 139.5002\n",
      "Epoch 937/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.5166 - val_loss: 111.4142\n",
      "Epoch 938/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.8801 - val_loss: 199.1557\n",
      "Epoch 939/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.2260 - val_loss: 123.4388\n",
      "Epoch 940/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 140.4111 - val_loss: 111.9834\n",
      "Epoch 941/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 152.5255 - val_loss: 120.0971\n",
      "Epoch 942/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.9220 - val_loss: 108.5780\n",
      "Epoch 943/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.9486 - val_loss: 108.2486\n",
      "Epoch 944/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5643 - val_loss: 111.5288\n",
      "Epoch 945/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.1249 - val_loss: 144.6570\n",
      "Epoch 946/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 156.9023 - val_loss: 163.2219\n",
      "Epoch 947/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.7214 - val_loss: 116.3743\n",
      "Epoch 948/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.5729 - val_loss: 113.3270\n",
      "Epoch 949/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.8197 - val_loss: 112.6391\n",
      "Epoch 950/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.5517 - val_loss: 154.7786\n",
      "Epoch 951/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4485 - val_loss: 169.8596\n",
      "Epoch 952/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.0137 - val_loss: 147.7726\n",
      "Epoch 953/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5488 - val_loss: 144.8602\n",
      "Epoch 954/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0851 - val_loss: 115.9980\n",
      "Epoch 955/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6709 - val_loss: 112.3061\n",
      "Epoch 956/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.5485 - val_loss: 150.4713\n",
      "Epoch 957/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.2295 - val_loss: 116.5554\n",
      "Epoch 958/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 322.8779 - val_loss: 172.2815\n",
      "Epoch 959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.2961 - val_loss: 172.6750\n",
      "Epoch 960/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 166.4258 - val_loss: 147.8044\n",
      "Epoch 961/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.7761 - val_loss: 146.1061\n",
      "Epoch 962/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.0328 - val_loss: 126.2591\n",
      "Epoch 963/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.7114 - val_loss: 182.3945\n",
      "Epoch 964/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 148.5060 - val_loss: 115.6904\n",
      "Epoch 965/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.5658 - val_loss: 150.6438\n",
      "Epoch 966/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.5771 - val_loss: 135.2746\n",
      "Epoch 967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.8244 - val_loss: 174.5784\n",
      "Epoch 968/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.5389 - val_loss: 120.6751\n",
      "Epoch 969/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.6622 - val_loss: 139.1903\n",
      "Epoch 970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6441 - val_loss: 153.9291\n",
      "Epoch 971/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5492 - val_loss: 113.4529\n",
      "Epoch 972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3270 - val_loss: 120.2513\n",
      "Epoch 973/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 152.1905 - val_loss: 156.0338\n",
      "Epoch 974/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.2964 - val_loss: 133.3717\n",
      "Epoch 975/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.7561 - val_loss: 123.0944\n",
      "Epoch 976/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.3118 - val_loss: 213.6671\n",
      "Epoch 977/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.3476 - val_loss: 108.8612\n",
      "Epoch 978/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 155.2768 - val_loss: 176.9774\n",
      "Epoch 979/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 196.3845 - val_loss: 115.0343\n",
      "Epoch 980/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 148.6045 - val_loss: 124.9242\n",
      "Epoch 981/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 146.9109 - val_loss: 155.2593\n",
      "Epoch 982/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0898 - val_loss: 114.2574\n",
      "Epoch 983/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.6311 - val_loss: 119.5696\n",
      "Epoch 984/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3914 - val_loss: 118.1860\n",
      "Epoch 985/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9146 - val_loss: 158.2707\n",
      "Epoch 986/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.9896 - val_loss: 122.1520\n",
      "Epoch 987/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7420 - val_loss: 112.7333\n",
      "Epoch 988/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.0592 - val_loss: 122.7519\n",
      "Epoch 989/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 153.9011 - val_loss: 141.4016\n",
      "Epoch 990/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 371.5849 - val_loss: 209.3167\n",
      "Epoch 991/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5822 - val_loss: 111.5283\n",
      "Epoch 992/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.0597 - val_loss: 111.3149\n",
      "Epoch 993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.1392 - val_loss: 119.5213\n",
      "Epoch 994/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.7326 - val_loss: 110.1313\n",
      "Epoch 995/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.4758 - val_loss: 128.8206\n",
      "Epoch 996/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.7586 - val_loss: 107.5422\n",
      "Epoch 997/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.8784 - val_loss: 187.7478\n",
      "Epoch 998/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9865 - val_loss: 142.7992\n",
      "Epoch 999/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2792 - val_loss: 112.6409\n",
      "Epoch 1000/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 216.6911 - val_loss: 135.3991\n",
      "Epoch 1001/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.6149 - val_loss: 138.1322\n",
      "Epoch 1002/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 186.5041 - val_loss: 148.6989\n",
      "Epoch 1003/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0980 - val_loss: 121.3093\n",
      "Epoch 1004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.0709 - val_loss: 137.0743\n",
      "Epoch 1005/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 211.9338 - val_loss: 116.1024\n",
      "Epoch 1006/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.3550 - val_loss: 106.7120\n",
      "Epoch 1007/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.8489 - val_loss: 116.2129\n",
      "Epoch 1008/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.5355 - val_loss: 128.1943\n",
      "Epoch 1009/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.1877 - val_loss: 113.3946\n",
      "Epoch 1010/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.4751 - val_loss: 203.5080\n",
      "Epoch 1011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.7332 - val_loss: 111.9168\n",
      "Epoch 1012/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.1683 - val_loss: 128.5549\n",
      "Epoch 1013/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.4005 - val_loss: 130.9869\n",
      "Epoch 1014/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.2313 - val_loss: 132.0865\n",
      "Epoch 1015/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 239.8699 - val_loss: 136.7093\n",
      "Epoch 1016/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8009 - val_loss: 130.5627\n",
      "Epoch 1017/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.3397 - val_loss: 112.7716\n",
      "Epoch 1018/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6885 - val_loss: 105.6670\n",
      "Epoch 1019/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7086 - val_loss: 110.5488\n",
      "Epoch 1020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.6867 - val_loss: 113.4343\n",
      "Epoch 1021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 415.6911 - val_loss: 150.3049\n",
      "Epoch 1022/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 226.2401 - val_loss: 164.5263\n",
      "Epoch 1023/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.9355 - val_loss: 175.1901\n",
      "Epoch 1024/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 176.0098 - val_loss: 159.8530\n",
      "Epoch 1025/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.8814 - val_loss: 158.6944\n",
      "Epoch 1026/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9335 - val_loss: 122.9059\n",
      "Epoch 1027/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.7454 - val_loss: 135.7892\n",
      "Epoch 1028/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 152.4465 - val_loss: 109.4465\n",
      "Epoch 1029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.5048 - val_loss: 114.3078\n",
      "Epoch 1030/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.7811 - val_loss: 128.1643\n",
      "Epoch 1031/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.4173 - val_loss: 121.9203\n",
      "Epoch 1032/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 181.4214 - val_loss: 654.0719\n",
      "Epoch 1033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 250.1500 - val_loss: 107.3334\n",
      "Epoch 1034/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.9155 - val_loss: 107.1418\n",
      "Epoch 1035/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9783 - val_loss: 113.0839\n",
      "Epoch 1036/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5926 - val_loss: 129.6924\n",
      "Epoch 1037/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7215 - val_loss: 165.0849\n",
      "Epoch 1038/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.4216 - val_loss: 116.6611\n",
      "Epoch 1039/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.9817 - val_loss: 114.6400\n",
      "Epoch 1040/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0665 - val_loss: 119.5697\n",
      "Epoch 1041/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 232.4405 - val_loss: 112.0329\n",
      "Epoch 1042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.9075 - val_loss: 197.9007\n",
      "Epoch 1043/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 205.7037 - val_loss: 163.9597\n",
      "Epoch 1044/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.9878 - val_loss: 107.1607\n",
      "Epoch 1045/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.4360 - val_loss: 109.0422\n",
      "Epoch 1046/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 146.4629 - val_loss: 130.5469\n",
      "Epoch 1047/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.2848 - val_loss: 123.1467\n",
      "Epoch 1048/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.5637 - val_loss: 118.5890\n",
      "Epoch 1049/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 179.6849 - val_loss: 112.8129\n",
      "Epoch 1050/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 145.1814 - val_loss: 122.4884\n",
      "Epoch 1051/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 210.1535 - val_loss: 125.4609\n",
      "Epoch 1052/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 146.6119 - val_loss: 116.0943\n",
      "Epoch 1053/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 156.7872 - val_loss: 126.9761\n",
      "Epoch 1054/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.7452 - val_loss: 186.3324\n",
      "Epoch 1055/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.4558 - val_loss: 124.9375\n",
      "Epoch 1056/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.8047 - val_loss: 104.0841\n",
      "Epoch 1057/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.5731 - val_loss: 121.6327\n",
      "Epoch 1058/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 171.7348 - val_loss: 146.0636\n",
      "Epoch 1059/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.8220 - val_loss: 111.9533\n",
      "Epoch 1060/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 188.6477 - val_loss: 118.5405\n",
      "Epoch 1061/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.9951 - val_loss: 129.4318\n",
      "Epoch 1062/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 163.6342 - val_loss: 118.8433\n",
      "Epoch 1063/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 143.1493 - val_loss: 166.1391\n",
      "Epoch 1064/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 169.9949 - val_loss: 171.8817\n",
      "Epoch 1065/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 364.8771 - val_loss: 184.2926\n",
      "Epoch 1066/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1492 - val_loss: 114.2460\n",
      "Epoch 1067/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2747 - val_loss: 110.4505\n",
      "Epoch 1068/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4141 - val_loss: 106.4230\n",
      "Epoch 1069/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1364 - val_loss: 116.4088\n",
      "Epoch 1070/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.3182 - val_loss: 129.2916\n",
      "Epoch 1071/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5544 - val_loss: 131.1912\n",
      "Epoch 1072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2966 - val_loss: 114.3465\n",
      "Epoch 1073/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 204.1720 - val_loss: 106.2064\n",
      "Epoch 1074/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.0748 - val_loss: 113.1806\n",
      "Epoch 1075/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.7430 - val_loss: 118.5664\n",
      "Epoch 1076/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.9344 - val_loss: 108.6652\n",
      "Epoch 1077/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.8033 - val_loss: 110.3033\n",
      "Epoch 1078/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 159.1666 - val_loss: 109.8676\n",
      "Epoch 1079/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 143.3181 - val_loss: 109.3608\n",
      "Epoch 1080/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.4764 - val_loss: 173.7188\n",
      "Epoch 1081/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.7832 - val_loss: 108.5486\n",
      "Epoch 1082/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.6081 - val_loss: 119.7080\n",
      "Epoch 1083/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6012 - val_loss: 129.8173\n",
      "Epoch 1084/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 152.7250 - val_loss: 132.6757\n",
      "Epoch 1085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.7816 - val_loss: 143.5333\n",
      "Epoch 1086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.8183 - val_loss: 110.4213\n",
      "Epoch 1087/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2378 - val_loss: 111.1567\n",
      "Epoch 1088/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8958 - val_loss: 105.0622\n",
      "Epoch 1089/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7540 - val_loss: 107.9619\n",
      "Epoch 1090/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0134 - val_loss: 106.3386\n",
      "Epoch 1091/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 133.7174 - val_loss: 107.3144\n",
      "Epoch 1092/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8978 - val_loss: 118.2955\n",
      "Epoch 1093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 154.9156 - val_loss: 119.6857\n",
      "Epoch 1094/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0139 - val_loss: 108.2961\n",
      "Epoch 1095/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2480 - val_loss: 124.8194\n",
      "Epoch 1096/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3708 - val_loss: 126.5705\n",
      "Epoch 1097/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.0851 - val_loss: 174.8753\n",
      "Epoch 1098/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.6247 - val_loss: 116.3099\n",
      "Epoch 1099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 194.5763 - val_loss: 113.8295\n",
      "Epoch 1100/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.7027 - val_loss: 139.8587\n",
      "Epoch 1101/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 278.6084 - val_loss: 156.9337\n",
      "Epoch 1102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.5565 - val_loss: 108.5930\n",
      "Epoch 1103/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.0603 - val_loss: 113.7472\n",
      "Epoch 1104/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.3634 - val_loss: 119.3532\n",
      "Epoch 1105/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0090 - val_loss: 104.6396\n",
      "Epoch 1106/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.0497 - val_loss: 271.3061\n",
      "Epoch 1107/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.8487 - val_loss: 129.1469\n",
      "Epoch 1108/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 179.5494 - val_loss: 132.4725\n",
      "Epoch 1109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.0780 - val_loss: 110.0513\n",
      "Epoch 1110/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 191.8924 - val_loss: 155.4152\n",
      "Epoch 1111/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9332 - val_loss: 144.3645\n",
      "Epoch 1112/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.3282 - val_loss: 110.3850\n",
      "Epoch 1113/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 233.5577 - val_loss: 402.7235\n",
      "Epoch 1114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.1087 - val_loss: 115.6462\n",
      "Epoch 1115/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.8015 - val_loss: 108.3539\n",
      "Epoch 1116/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.9038 - val_loss: 106.3451\n",
      "Epoch 1117/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.8322 - val_loss: 116.6584\n",
      "Epoch 1118/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 249.4055 - val_loss: 111.7061\n",
      "Epoch 1119/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5135 - val_loss: 105.8696\n",
      "Epoch 1120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1684 - val_loss: 110.0230\n",
      "Epoch 1121/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.5063 - val_loss: 113.3483\n",
      "Epoch 1122/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 140.6104 - val_loss: 130.8951\n",
      "Epoch 1123/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 171.2053 - val_loss: 106.7759\n",
      "Epoch 1124/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 137.6459 - val_loss: 146.2350\n",
      "Epoch 1125/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7065 - val_loss: 109.2652\n",
      "Epoch 1126/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.6870 - val_loss: 107.4123\n",
      "Epoch 1127/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0545 - val_loss: 122.7829\n",
      "Epoch 1128/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.5366 - val_loss: 131.3399\n",
      "Epoch 1129/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 168.0803 - val_loss: 106.4109\n",
      "Epoch 1130/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.5777 - val_loss: 111.9346\n",
      "Epoch 1131/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 207.6599 - val_loss: 131.8117\n",
      "Epoch 1132/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9785 - val_loss: 131.7275\n",
      "Epoch 1133/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.3098 - val_loss: 152.8243\n",
      "Epoch 1134/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.3510 - val_loss: 117.1041\n",
      "Epoch 1135/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.1901 - val_loss: 106.8266\n",
      "Epoch 1136/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.1049 - val_loss: 129.2900\n",
      "Epoch 1137/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 206.5527 - val_loss: 111.0719\n",
      "Epoch 1138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.2127 - val_loss: 119.8732\n",
      "Epoch 1139/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 134.072 - 0s 50us/step - loss: 133.0105 - val_loss: 123.8523\n",
      "Epoch 1140/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5967 - val_loss: 104.9683\n",
      "Epoch 1141/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2967 - val_loss: 131.7198\n",
      "Epoch 1142/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.2695 - val_loss: 105.6830\n",
      "Epoch 1143/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.1983 - val_loss: 115.2959\n",
      "Epoch 1144/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.4898 - val_loss: 107.5308\n",
      "Epoch 1145/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.6453 - val_loss: 222.1091\n",
      "Epoch 1146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.3864 - val_loss: 106.4820\n",
      "Epoch 1147/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4474 - val_loss: 109.8627\n",
      "Epoch 1148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.2542 - val_loss: 130.9661\n",
      "Epoch 1149/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7245 - val_loss: 110.8135\n",
      "Epoch 1150/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.2933 - val_loss: 125.9338\n",
      "Epoch 1151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.8335 - val_loss: 200.2378\n",
      "Epoch 1152/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9349 - val_loss: 113.4415\n",
      "Epoch 1153/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 153.7999 - val_loss: 119.5234\n",
      "Epoch 1154/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.0720 - val_loss: 107.8350\n",
      "Epoch 1155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5271 - val_loss: 212.5283\n",
      "Epoch 1156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.0230 - val_loss: 106.9262\n",
      "Epoch 1157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.3436 - val_loss: 282.1170\n",
      "Epoch 1158/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.0649 - val_loss: 122.6518\n",
      "Epoch 1159/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 223.1078 - val_loss: 182.2197\n",
      "Epoch 1160/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 197.6623 - val_loss: 124.4736\n",
      "Epoch 1161/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.5158 - val_loss: 108.4219\n",
      "Epoch 1162/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.0617 - val_loss: 110.2069\n",
      "Epoch 1163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.0198 - val_loss: 125.1057\n",
      "Epoch 1164/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.0471 - val_loss: 178.6774\n",
      "Epoch 1165/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.5425 - val_loss: 123.0298\n",
      "Epoch 1166/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 180.8073 - val_loss: 108.9921\n",
      "Epoch 1167/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 169.4340 - val_loss: 138.3487\n",
      "Epoch 1168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.0771 - val_loss: 258.3799\n",
      "Epoch 1169/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2742 - val_loss: 112.0492\n",
      "Epoch 1170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4333 - val_loss: 132.0464\n",
      "Epoch 1171/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.6170 - val_loss: 106.6504\n",
      "Epoch 1172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.0414 - val_loss: 139.0638\n",
      "Epoch 1173/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.5796 - val_loss: 116.7552\n",
      "Epoch 1174/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.1100 - val_loss: 107.7636\n",
      "Epoch 1175/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 173.9386 - val_loss: 198.9039\n",
      "Epoch 1176/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6206 - val_loss: 227.9255\n",
      "Epoch 1177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6410 - val_loss: 130.2637\n",
      "Epoch 1178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.1965 - val_loss: 115.3731\n",
      "Epoch 1179/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6462 - val_loss: 143.9887\n",
      "Epoch 1180/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.3857 - val_loss: 113.5305\n",
      "Epoch 1181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 276.8761 - val_loss: 271.1527\n",
      "Epoch 1182/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.4087 - val_loss: 106.7970\n",
      "Epoch 1183/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.9634 - val_loss: 141.9708\n",
      "Epoch 1184/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0492 - val_loss: 109.2342\n",
      "Epoch 1185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3275 - val_loss: 120.3171\n",
      "Epoch 1186/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3456 - val_loss: 131.0437\n",
      "Epoch 1187/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.0094 - val_loss: 110.8217\n",
      "Epoch 1188/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2258 - val_loss: 186.0719\n",
      "Epoch 1189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 196.3984 - val_loss: 107.5288\n",
      "Epoch 1190/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8900 - val_loss: 151.7220\n",
      "Epoch 1191/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8843 - val_loss: 123.1337\n",
      "Epoch 1192/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.2231 - val_loss: 102.5126\n",
      "Epoch 1193/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8635 - val_loss: 119.9141\n",
      "Epoch 1194/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 142.3291 - val_loss: 105.1705\n",
      "Epoch 1195/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 129.0763 - val_loss: 105.0212\n",
      "Epoch 1196/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 134.6800 - val_loss: 112.2626\n",
      "Epoch 1197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3707 - val_loss: 134.0791\n",
      "Epoch 1198/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.9537 - val_loss: 223.9862\n",
      "Epoch 1199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 193.6989 - val_loss: 150.5709\n",
      "Epoch 1200/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 191.5906 - val_loss: 235.8438\n",
      "Epoch 1201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.7266 - val_loss: 148.7546\n",
      "Epoch 1202/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 162.8530 - val_loss: 213.2586\n",
      "Epoch 1203/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.9127 - val_loss: 111.0905\n",
      "Epoch 1204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 213.6543 - val_loss: 115.6062\n",
      "Epoch 1205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 160.5584 - val_loss: 104.4581\n",
      "Epoch 1206/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 130.0852 - val_loss: 105.0450\n",
      "Epoch 1207/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 205.2009 - val_loss: 138.8574\n",
      "Epoch 1208/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.4570 - val_loss: 142.9208\n",
      "Epoch 1209/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4099 - val_loss: 103.8152\n",
      "Epoch 1210/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.3830 - val_loss: 107.8203\n",
      "Epoch 1211/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.1933 - val_loss: 109.4126\n",
      "Epoch 1212/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.4353 - val_loss: 180.0682\n",
      "Epoch 1213/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9812 - val_loss: 107.2751\n",
      "Epoch 1214/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.9373 - val_loss: 105.1499\n",
      "Epoch 1215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.9864 - val_loss: 382.2635\n",
      "Epoch 1216/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.4251 - val_loss: 103.9010\n",
      "Epoch 1217/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.0453 - val_loss: 113.4513\n",
      "Epoch 1218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1625 - val_loss: 170.5499\n",
      "Epoch 1219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 201.6469 - val_loss: 108.3318\n",
      "Epoch 1220/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9768 - val_loss: 135.5220\n",
      "Epoch 1221/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.4395 - val_loss: 108.5001\n",
      "Epoch 1222/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.4133 - val_loss: 102.8382\n",
      "Epoch 1223/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.0911 - val_loss: 103.6276\n",
      "Epoch 1224/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.5941 - val_loss: 184.0986\n",
      "Epoch 1225/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.4498 - val_loss: 105.0113\n",
      "Epoch 1226/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.5080 - val_loss: 118.8714\n",
      "Epoch 1227/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.9725 - val_loss: 133.2699\n",
      "Epoch 1228/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.2588 - val_loss: 114.6260\n",
      "Epoch 1229/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8685 - val_loss: 116.3087\n",
      "Epoch 1230/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 171.2658 - val_loss: 113.7861\n",
      "Epoch 1231/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9554 - val_loss: 120.7970\n",
      "Epoch 1232/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 144.092 - 0s 51us/step - loss: 143.7850 - val_loss: 110.1036\n",
      "Epoch 1233/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 179.3040 - val_loss: 193.1311\n",
      "Epoch 1234/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.2184 - val_loss: 108.4841\n",
      "Epoch 1235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8135 - val_loss: 112.2827\n",
      "Epoch 1236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.7620 - val_loss: 857.0758\n",
      "Epoch 1237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 1115.6832 - val_loss: 232.3063\n",
      "Epoch 1238/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 310.5973 - val_loss: 135.5270\n",
      "Epoch 1239/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 215.2213 - val_loss: 134.9967\n",
      "Epoch 1240/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 198.1738 - val_loss: 125.7549\n",
      "Epoch 1241/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 220.8996 - val_loss: 151.0865\n",
      "Epoch 1242/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 167.6790 - val_loss: 130.3007\n",
      "Epoch 1243/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.3052 - val_loss: 134.7906\n",
      "Epoch 1244/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 211.0462 - val_loss: 128.7665\n",
      "Epoch 1245/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 176.6891 - val_loss: 131.2975\n",
      "Epoch 1246/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.5604 - val_loss: 118.9158\n",
      "Epoch 1247/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.3447 - val_loss: 116.1986\n",
      "Epoch 1248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 161.3751 - val_loss: 126.7084\n",
      "Epoch 1249/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 163.9338 - val_loss: 121.0773\n",
      "Epoch 1250/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 165.6948 - val_loss: 124.6324\n",
      "Epoch 1251/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 147.6027 - val_loss: 114.0075\n",
      "Epoch 1252/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 203.1600 - val_loss: 123.6111\n",
      "Epoch 1253/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 153.5807 - val_loss: 149.7629\n",
      "Epoch 1254/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 144.3568 - val_loss: 114.0847\n",
      "Epoch 1255/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 212.0293 - val_loss: 125.3755\n",
      "Epoch 1256/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.8370 - val_loss: 127.9730\n",
      "Epoch 1257/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.1522 - val_loss: 117.2921\n",
      "Epoch 1258/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0900 - val_loss: 181.6908\n",
      "Epoch 1259/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.5644 - val_loss: 118.4854\n",
      "Epoch 1260/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.6934 - val_loss: 141.8258\n",
      "Epoch 1261/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6323 - val_loss: 128.7245\n",
      "Epoch 1262/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.9881 - val_loss: 145.7274\n",
      "Epoch 1263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 187.7276 - val_loss: 119.3365\n",
      "Epoch 1264/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 161.9131 - val_loss: 138.3042\n",
      "Epoch 1265/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 207.0160 - val_loss: 122.6275\n",
      "Epoch 1266/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.5737 - val_loss: 111.3911\n",
      "Epoch 1267/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9369 - val_loss: 151.1167\n",
      "Epoch 1268/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 159.2148 - val_loss: 136.5190\n",
      "Epoch 1269/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 235.0869 - val_loss: 155.3768\n",
      "Epoch 1270/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6138 - val_loss: 166.4786\n",
      "Epoch 1271/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.7840 - val_loss: 105.6161\n",
      "Epoch 1272/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3521 - val_loss: 127.8201\n",
      "Epoch 1273/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5845 - val_loss: 114.5078\n",
      "Epoch 1274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.9376 - val_loss: 120.3245\n",
      "Epoch 1275/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 141.7941 - val_loss: 137.7867\n",
      "Epoch 1276/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 145.5267 - val_loss: 127.2275\n",
      "Epoch 1277/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 140.5538 - val_loss: 108.5433\n",
      "Epoch 1278/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 159.2552 - val_loss: 192.3196\n",
      "Epoch 1279/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.4712 - val_loss: 128.3382\n",
      "Epoch 1280/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 150.4946 - val_loss: 109.7129\n",
      "Epoch 1281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7986 - val_loss: 117.3119\n",
      "Epoch 1282/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 162.4804 - val_loss: 162.0457\n",
      "Epoch 1283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.1376 - val_loss: 157.3497\n",
      "Epoch 1284/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.0051 - val_loss: 114.0378\n",
      "Epoch 1285/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1205 - val_loss: 109.8397\n",
      "Epoch 1286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9498 - val_loss: 145.4365\n",
      "Epoch 1287/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 149.5549 - val_loss: 119.6233\n",
      "Epoch 1288/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.9073 - val_loss: 131.6636\n",
      "Epoch 1289/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.2866 - val_loss: 186.9125\n",
      "Epoch 1290/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 191.8000 - val_loss: 134.2053\n",
      "Epoch 1291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5277 - val_loss: 110.5973\n",
      "Epoch 1292/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.9649 - val_loss: 118.3718\n",
      "Epoch 1293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.5370 - val_loss: 187.6205\n",
      "Epoch 1294/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 270.5614 - val_loss: 111.0584\n",
      "Epoch 1295/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.0433 - val_loss: 130.0942\n",
      "Epoch 1296/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6423 - val_loss: 129.6175\n",
      "Epoch 1297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.5242 - val_loss: 158.9545\n",
      "Epoch 1298/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2197 - val_loss: 118.3126\n",
      "Epoch 1299/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0677 - val_loss: 130.8540\n",
      "Epoch 1300/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.1522 - val_loss: 142.5746\n",
      "Epoch 1301/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8299 - val_loss: 106.5434\n",
      "Epoch 1302/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.3179 - val_loss: 187.5206\n",
      "Epoch 1303/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.5356 - val_loss: 165.6549\n",
      "Epoch 1304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.1719 - val_loss: 123.9227\n",
      "Epoch 1305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9655 - val_loss: 150.2268\n",
      "Epoch 1306/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.2443 - val_loss: 109.9506\n",
      "Epoch 1307/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5101 - val_loss: 145.7323\n",
      "Epoch 1308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5021 - val_loss: 156.6061\n",
      "Epoch 1309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.8640 - val_loss: 108.0513\n",
      "Epoch 1310/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5180 - val_loss: 109.3895\n",
      "Epoch 1311/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1804 - val_loss: 112.9029\n",
      "Epoch 1312/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5540 - val_loss: 115.2640\n",
      "Epoch 1313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7808 - val_loss: 203.8543\n",
      "Epoch 1314/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 198.1332 - val_loss: 145.6858\n",
      "Epoch 1315/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0844 - val_loss: 115.9998\n",
      "Epoch 1316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.7037 - val_loss: 112.5784\n",
      "Epoch 1317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1055 - val_loss: 107.5447\n",
      "Epoch 1318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5134 - val_loss: 111.3363\n",
      "Epoch 1319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.7186 - val_loss: 111.7782\n",
      "Epoch 1320/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.3601 - val_loss: 161.5341\n",
      "Epoch 1321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.3464 - val_loss: 126.8139\n",
      "Epoch 1322/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.9315 - val_loss: 107.9312\n",
      "Epoch 1323/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2832 - val_loss: 150.5281\n",
      "Epoch 1324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0119 - val_loss: 118.5213\n",
      "Epoch 1325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.3682 - val_loss: 119.4425\n",
      "Epoch 1326/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.2875 - val_loss: 116.9498\n",
      "Epoch 1327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 195.7228 - val_loss: 172.1680\n",
      "Epoch 1328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 176.5652 - val_loss: 128.1668\n",
      "Epoch 1329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 266.1751 - val_loss: 120.2920\n",
      "Epoch 1330/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 177.276 - 0s 50us/step - loss: 176.1578 - val_loss: 107.3762\n",
      "Epoch 1331/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.4508 - val_loss: 194.4421\n",
      "Epoch 1332/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.0128 - val_loss: 109.6424\n",
      "Epoch 1333/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.8786 - val_loss: 121.5838\n",
      "Epoch 1334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8433 - val_loss: 115.8042\n",
      "Epoch 1335/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 171.9236 - val_loss: 234.0618\n",
      "Epoch 1336/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.5793 - val_loss: 138.3008\n",
      "Epoch 1337/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 157.8087 - val_loss: 120.2288\n",
      "Epoch 1338/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 155.0086 - val_loss: 150.2394\n",
      "Epoch 1339/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 143.0852 - val_loss: 112.3762\n",
      "Epoch 1340/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 160.7718 - val_loss: 109.8893\n",
      "Epoch 1341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.0182 - val_loss: 116.2585\n",
      "Epoch 1342/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.8492 - val_loss: 132.1305\n",
      "Epoch 1343/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 170.0757 - val_loss: 168.5792\n",
      "Epoch 1344/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 167.5651 - val_loss: 111.2789\n",
      "Epoch 1345/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5229 - val_loss: 129.7381\n",
      "Epoch 1346/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.8427 - val_loss: 108.7630\n",
      "Epoch 1347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4200 - val_loss: 123.2019\n",
      "Epoch 1348/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0596 - val_loss: 107.3593\n",
      "Epoch 1349/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.4790 - val_loss: 126.1135\n",
      "Epoch 1350/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9469 - val_loss: 135.6658\n",
      "Epoch 1351/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0183 - val_loss: 162.0545\n",
      "Epoch 1352/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.3570 - val_loss: 147.9961\n",
      "Epoch 1353/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.8627 - val_loss: 138.6510\n",
      "Epoch 1354/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.5587 - val_loss: 175.4452\n",
      "Epoch 1355/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.0008 - val_loss: 164.1111\n",
      "Epoch 1356/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2255 - val_loss: 110.2192\n",
      "Epoch 1357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 397.4496 - val_loss: 355.0340\n",
      "Epoch 1358/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 228.9730 - val_loss: 115.5098\n",
      "Epoch 1359/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.1049 - val_loss: 115.4475\n",
      "Epoch 1360/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.1225 - val_loss: 112.7978\n",
      "Epoch 1361/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 146.6805 - val_loss: 119.2336\n",
      "Epoch 1362/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0426 - val_loss: 120.6998\n",
      "Epoch 1363/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0024 - val_loss: 112.1873\n",
      "Epoch 1364/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.8631 - val_loss: 204.3525\n",
      "Epoch 1365/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.2358 - val_loss: 106.9486\n",
      "Epoch 1366/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.2110 - val_loss: 117.0730\n",
      "Epoch 1367/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.5134 - val_loss: 121.5309\n",
      "Epoch 1368/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 245.5084 - val_loss: 109.5599\n",
      "Epoch 1369/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.3337 - val_loss: 130.9005\n",
      "Epoch 1370/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6004 - val_loss: 106.6639\n",
      "Epoch 1371/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.3035 - val_loss: 112.2509\n",
      "Epoch 1372/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.3480 - val_loss: 122.8381\n",
      "Epoch 1373/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 170.1999 - val_loss: 115.7736\n",
      "Epoch 1374/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 163.0236 - val_loss: 124.5076\n",
      "Epoch 1375/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4786 - val_loss: 117.3649\n",
      "Epoch 1376/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 156.0061 - val_loss: 162.6748\n",
      "Epoch 1377/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.5584 - val_loss: 119.8199\n",
      "Epoch 1378/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 252.6341 - val_loss: 114.8439\n",
      "Epoch 1379/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0047 - val_loss: 119.5398\n",
      "Epoch 1380/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.5626 - val_loss: 105.3313\n",
      "Epoch 1381/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.8000 - val_loss: 106.0042\n",
      "Epoch 1382/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.5698 - val_loss: 219.4646\n",
      "Epoch 1383/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.6381 - val_loss: 120.6187\n",
      "Epoch 1384/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0163 - val_loss: 113.6470\n",
      "Epoch 1385/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.4946 - val_loss: 113.3542\n",
      "Epoch 1386/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5789 - val_loss: 143.9078\n",
      "Epoch 1387/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.6689 - val_loss: 135.9911\n",
      "Epoch 1388/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.9882 - val_loss: 113.8938\n",
      "Epoch 1389/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 330.5837 - val_loss: 159.3353\n",
      "Epoch 1390/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.3535 - val_loss: 133.5752\n",
      "Epoch 1391/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.6252 - val_loss: 106.4224\n",
      "Epoch 1392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.0608 - val_loss: 104.2799\n",
      "Epoch 1393/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.4486 - val_loss: 107.8858\n",
      "Epoch 1394/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 306.0633 - val_loss: 160.1468\n",
      "Epoch 1395/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 146.3499 - val_loss: 128.5194\n",
      "Epoch 1396/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1356 - val_loss: 115.3723\n",
      "Epoch 1397/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.9165 - val_loss: 112.3228\n",
      "Epoch 1398/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.0423 - val_loss: 118.9067\n",
      "Epoch 1399/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.9221 - val_loss: 113.9739\n",
      "Epoch 1400/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.6057 - val_loss: 112.5730\n",
      "Epoch 1401/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1696 - val_loss: 130.9305\n",
      "Epoch 1402/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8328 - val_loss: 122.0736\n",
      "Epoch 1403/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.9001 - val_loss: 131.2522\n",
      "Epoch 1404/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4461 - val_loss: 111.1045\n",
      "Epoch 1405/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 164.6954 - val_loss: 118.1043\n",
      "Epoch 1406/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 146.9929 - val_loss: 215.1644\n",
      "Epoch 1407/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.9691 - val_loss: 115.8166\n",
      "Epoch 1408/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 149.5717 - val_loss: 115.1800\n",
      "Epoch 1409/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 166.1636 - val_loss: 139.8536\n",
      "Epoch 1410/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 263.9829 - val_loss: 122.6469\n",
      "Epoch 1411/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.8105 - val_loss: 106.9641\n",
      "Epoch 1412/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.5665 - val_loss: 107.9831\n",
      "Epoch 1413/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.3195 - val_loss: 106.0227\n",
      "Epoch 1414/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.6256 - val_loss: 123.5009\n",
      "Epoch 1415/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.4240 - val_loss: 119.9209\n",
      "Epoch 1416/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0511 - val_loss: 110.1513\n",
      "Epoch 1417/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.7825 - val_loss: 118.4440\n",
      "Epoch 1418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.8201 - val_loss: 118.1664\n",
      "Epoch 1419/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.9327 - val_loss: 114.4154\n",
      "Epoch 1420/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.0363 - val_loss: 116.8089\n",
      "Epoch 1421/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.5711 - val_loss: 124.9850\n",
      "Epoch 1422/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 199.1809 - val_loss: 112.3951\n",
      "Epoch 1423/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3645 - val_loss: 125.0165\n",
      "Epoch 1424/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.6015 - val_loss: 134.9149\n",
      "Epoch 1425/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.4928 - val_loss: 108.7811\n",
      "Epoch 1426/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 209.0004 - val_loss: 119.5962\n",
      "Epoch 1427/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.0393 - val_loss: 113.2980\n",
      "Epoch 1428/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3460 - val_loss: 136.2877\n",
      "Epoch 1429/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.6936 - val_loss: 114.7224\n",
      "Epoch 1430/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.5801 - val_loss: 121.1269\n",
      "Epoch 1431/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.1965 - val_loss: 107.6020\n",
      "Epoch 1432/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.1709 - val_loss: 113.5138\n",
      "Epoch 1433/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.9215 - val_loss: 159.4788\n",
      "Epoch 1434/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.2389 - val_loss: 113.5542\n",
      "Epoch 1435/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.0852 - val_loss: 110.3062\n",
      "Epoch 1436/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.7075 - val_loss: 155.0132\n",
      "Epoch 1437/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1546 - val_loss: 114.7116\n",
      "Epoch 1438/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.0990 - val_loss: 133.6417\n",
      "Epoch 1439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 189.0592 - val_loss: 137.4530\n",
      "Epoch 1440/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.4553 - val_loss: 125.4191\n",
      "Epoch 1441/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 206.1227 - val_loss: 124.7300\n",
      "Epoch 1442/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.5538 - val_loss: 125.3573\n",
      "Epoch 1443/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 164.2955 - val_loss: 108.4239\n",
      "Epoch 1444/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4389 - val_loss: 127.9979\n",
      "Epoch 1445/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6994 - val_loss: 173.1355\n",
      "Epoch 1446/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.6134 - val_loss: 110.0101\n",
      "Epoch 1447/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 187.0005 - val_loss: 177.6476\n",
      "Epoch 1448/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.8355 - val_loss: 145.6409\n",
      "Epoch 1449/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.9548 - val_loss: 107.5916\n",
      "Epoch 1450/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 264.7916 - val_loss: 137.2921\n",
      "Epoch 1451/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1491 - val_loss: 112.3197\n",
      "Epoch 1452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.2621 - val_loss: 109.0534\n",
      "Epoch 1453/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.2253 - val_loss: 110.7525\n",
      "Epoch 1454/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.8725 - val_loss: 126.0152\n",
      "Epoch 1455/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.1414 - val_loss: 109.9400\n",
      "Epoch 1456/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4350 - val_loss: 119.8274\n",
      "Epoch 1457/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 391.2769 - val_loss: 244.8870\n",
      "Epoch 1458/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 154.5731 - val_loss: 107.1426\n",
      "Epoch 1459/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.4817 - val_loss: 114.7770\n",
      "Epoch 1460/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 129.9157 - val_loss: 126.6422\n",
      "Epoch 1461/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.3106 - val_loss: 120.9984\n",
      "Epoch 1462/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.7947 - val_loss: 118.8244\n",
      "Epoch 1463/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.8258 - val_loss: 115.3892\n",
      "Epoch 1464/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.5081 - val_loss: 104.9987\n",
      "Epoch 1465/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.9246 - val_loss: 130.1295\n",
      "Epoch 1466/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 139.0587 - val_loss: 112.0783\n",
      "Epoch 1467/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.1996 - val_loss: 201.7751\n",
      "Epoch 1468/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 138.2710 - val_loss: 119.5249\n",
      "Epoch 1469/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.4437 - val_loss: 118.3410\n",
      "Epoch 1470/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.0711 - val_loss: 109.3610\n",
      "Epoch 1471/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.0323 - val_loss: 125.0303\n",
      "Epoch 1472/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 149.5126 - val_loss: 118.3892\n",
      "Epoch 1473/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.1062 - val_loss: 125.5412\n",
      "Epoch 1474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2199 - val_loss: 109.1987\n",
      "Epoch 1475/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.2195 - val_loss: 109.1457\n",
      "Epoch 1476/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.3327 - val_loss: 161.1570\n",
      "Epoch 1477/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5146 - val_loss: 110.5604\n",
      "Epoch 1478/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8250 - val_loss: 112.8142\n",
      "Epoch 1479/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.9059 - val_loss: 114.7265\n",
      "Epoch 1480/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 174.1640 - val_loss: 144.7269\n",
      "Epoch 1481/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 155.6166 - val_loss: 111.1568\n",
      "Epoch 1482/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 189.4104 - val_loss: 124.7997\n",
      "Epoch 1483/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.5734 - val_loss: 183.8270\n",
      "Epoch 1484/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 383.3271 - val_loss: 620.1312\n",
      "Epoch 1485/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 295.5070 - val_loss: 139.6867\n",
      "Epoch 1486/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 214.8580 - val_loss: 197.9174\n",
      "Epoch 1487/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 165.7171 - val_loss: 130.8618\n",
      "Epoch 1488/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.1133 - val_loss: 120.0947\n",
      "Epoch 1489/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 167.5010 - val_loss: 117.3133\n",
      "Epoch 1490/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.3684 - val_loss: 180.0680\n",
      "Epoch 1491/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 157.1619 - val_loss: 180.0119\n",
      "Epoch 1492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 153.6187 - val_loss: 114.8744\n",
      "Epoch 1493/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 149.2585 - val_loss: 140.7593\n",
      "Epoch 1494/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.5325 - val_loss: 113.7042\n",
      "Epoch 1495/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 161.5597 - val_loss: 122.2807\n",
      "Epoch 1496/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.2137 - val_loss: 128.0143\n",
      "Epoch 1497/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 154.1195 - val_loss: 113.9733\n",
      "Epoch 1498/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 155.5550 - val_loss: 114.2145\n",
      "Epoch 1499/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.4641 - val_loss: 108.8920\n",
      "Epoch 1500/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 144.6876 - val_loss: 223.0917\n",
      "Epoch 1501/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 150.3144 - val_loss: 123.2427\n",
      "Epoch 1502/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 154.3267 - val_loss: 336.8864\n",
      "Epoch 1503/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.1301 - val_loss: 206.2271\n",
      "Epoch 1504/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 164.7438 - val_loss: 123.8108\n",
      "Epoch 1505/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4847 - val_loss: 111.3419\n",
      "Epoch 1506/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8956 - val_loss: 111.4434\n",
      "Epoch 1507/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 143.3226 - val_loss: 143.6394\n",
      "Epoch 1508/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 158.3103 - val_loss: 140.2943\n",
      "Epoch 1509/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 143.2639 - val_loss: 156.8205\n",
      "Epoch 1510/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 143.9275 - val_loss: 114.1588\n",
      "Epoch 1511/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.6456 - val_loss: 118.0526\n",
      "Epoch 1512/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.7026 - val_loss: 112.8691\n",
      "Epoch 1513/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 161.9307 - val_loss: 177.8085\n",
      "Epoch 1514/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.8012 - val_loss: 130.7257\n",
      "Epoch 1515/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 152.0870 - val_loss: 140.9475\n",
      "Epoch 1516/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.4219 - val_loss: 138.8271\n",
      "Epoch 1517/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.2452 - val_loss: 128.8848\n",
      "Epoch 1518/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.9604 - val_loss: 112.4762\n",
      "Epoch 1519/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.9741 - val_loss: 120.0643\n",
      "Epoch 1520/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0273 - val_loss: 138.9828\n",
      "Epoch 1521/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.7408 - val_loss: 117.5862\n",
      "Epoch 1522/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.3284 - val_loss: 127.9933\n",
      "Epoch 1523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.2230 - val_loss: 120.5503\n",
      "Epoch 1524/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 153.8157 - val_loss: 116.7151\n",
      "Epoch 1525/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.7907 - val_loss: 232.3563\n",
      "Epoch 1526/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 142.4154 - val_loss: 136.5211\n",
      "Epoch 1527/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 144.1005 - val_loss: 170.5949\n",
      "Epoch 1528/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.3983 - val_loss: 107.0532\n",
      "Epoch 1529/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.4734 - val_loss: 111.1412\n",
      "Epoch 1530/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.2136 - val_loss: 251.6261\n",
      "Epoch 1531/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 139.3526 - val_loss: 129.5605\n",
      "Epoch 1532/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 151.7557 - val_loss: 105.8662\n",
      "Epoch 1533/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 145.4339 - val_loss: 111.4866\n",
      "Epoch 1534/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.2644 - val_loss: 114.0573\n",
      "Epoch 1535/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.6338 - val_loss: 133.8281\n",
      "Epoch 1536/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.7013 - val_loss: 148.9544\n",
      "Epoch 1537/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.2762 - val_loss: 126.4513\n",
      "Epoch 1538/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 135.3981 - val_loss: 131.3709\n",
      "Epoch 1539/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 148.2875 - val_loss: 132.8453\n",
      "Epoch 1540/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.0032 - val_loss: 115.3673\n",
      "Epoch 1541/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.0655 - val_loss: 112.7486\n",
      "Epoch 1542/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 153.3515 - val_loss: 122.2309\n",
      "Epoch 1543/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 147.9311 - val_loss: 149.1759\n",
      "Epoch 1544/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8499 - val_loss: 118.9502\n",
      "Epoch 1545/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.8490 - val_loss: 133.8360\n",
      "Epoch 1546/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.3881 - val_loss: 112.6748\n",
      "Epoch 1547/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 141.2776 - val_loss: 114.9900\n",
      "Epoch 1548/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 217.9692 - val_loss: 163.5338\n",
      "Epoch 1549/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 157.3049 - val_loss: 112.0746\n",
      "Epoch 1550/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.3101 - val_loss: 114.7988\n",
      "Epoch 1551/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 155.5734 - val_loss: 138.4612\n",
      "Epoch 1552/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 152.3487 - val_loss: 109.7028\n",
      "Epoch 1553/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 185.2054 - val_loss: 129.3728\n",
      "Epoch 1554/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.2410 - val_loss: 166.6015\n",
      "Epoch 1555/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.7300 - val_loss: 136.3175\n",
      "Epoch 1556/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1394 - val_loss: 118.0161\n",
      "Epoch 1557/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.6409 - val_loss: 111.9193\n",
      "Epoch 1558/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.7949 - val_loss: 203.5755\n",
      "Epoch 1559/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.0700 - val_loss: 109.6546\n",
      "Epoch 1560/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.7157 - val_loss: 111.7089\n",
      "Epoch 1561/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7972 - val_loss: 106.7734\n",
      "Epoch 1562/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5012 - val_loss: 119.1341\n",
      "Epoch 1563/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.3150 - val_loss: 111.4121\n",
      "Epoch 1564/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6947 - val_loss: 116.3300\n",
      "Epoch 1565/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.1278 - val_loss: 107.6803\n",
      "Epoch 1566/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.1210 - val_loss: 114.5767\n",
      "Epoch 1567/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1288 - val_loss: 119.9689\n",
      "Epoch 1568/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6452 - val_loss: 110.5071\n",
      "Epoch 1569/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0601 - val_loss: 109.9083\n",
      "Epoch 1570/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 148.4205 - val_loss: 160.8567\n",
      "Epoch 1571/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.6283 - val_loss: 109.1401\n",
      "Epoch 1572/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.3054 - val_loss: 109.5414\n",
      "Epoch 1573/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8784 - val_loss: 183.8542\n",
      "Epoch 1574/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 152.0537 - val_loss: 110.5261\n",
      "Epoch 1575/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 130.9672 - val_loss: 118.7025\n",
      "Epoch 1576/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.1140 - val_loss: 203.3312\n",
      "Epoch 1577/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.8641 - val_loss: 110.6779\n",
      "Epoch 1578/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8976 - val_loss: 114.0193\n",
      "Epoch 1579/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 150.6036 - val_loss: 134.6679\n",
      "Epoch 1580/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.1834 - val_loss: 106.2805\n",
      "Epoch 1581/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.1931 - val_loss: 113.0389\n",
      "Epoch 1582/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 169.0102 - val_loss: 111.0804\n",
      "Epoch 1583/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4763 - val_loss: 111.0689\n",
      "Epoch 1584/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8770 - val_loss: 115.4146\n",
      "Epoch 1585/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.6866 - val_loss: 115.6293\n",
      "Epoch 1586/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.2348 - val_loss: 108.7627\n",
      "Epoch 1587/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2945 - val_loss: 145.7049\n",
      "Epoch 1588/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.6720 - val_loss: 144.1631\n",
      "Epoch 1589/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7478 - val_loss: 122.3375\n",
      "Epoch 1590/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 170.2546 - val_loss: 137.4024\n",
      "Epoch 1591/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.8230 - val_loss: 106.0391\n",
      "Epoch 1592/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.8353 - val_loss: 104.4936\n",
      "Epoch 1593/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4796 - val_loss: 119.0890\n",
      "Epoch 1594/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.9658 - val_loss: 126.2365\n",
      "Epoch 1595/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.5825 - val_loss: 107.3355\n",
      "Epoch 1596/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.7547 - val_loss: 106.1034\n",
      "Epoch 1597/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 135.4194 - val_loss: 108.9447\n",
      "Epoch 1598/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6558 - val_loss: 106.1660\n",
      "Epoch 1599/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.0004 - val_loss: 131.0600\n",
      "Epoch 1600/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.3397 - val_loss: 124.5707\n",
      "Epoch 1601/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.3537 - val_loss: 133.4915\n",
      "Epoch 1602/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.7521 - val_loss: 111.2891\n",
      "Epoch 1603/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 139.2255 - val_loss: 128.2240\n",
      "Epoch 1604/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.3754 - val_loss: 106.5334\n",
      "Epoch 1605/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.3068 - val_loss: 109.9002\n",
      "Epoch 1606/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 188.7159 - val_loss: 559.8894\n",
      "Epoch 1607/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 165.8564 - val_loss: 130.9023\n",
      "Epoch 1608/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.6969 - val_loss: 110.6616\n",
      "Epoch 1609/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.4329 - val_loss: 113.3591\n",
      "Epoch 1610/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.8322 - val_loss: 107.8054\n",
      "Epoch 1611/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4141 - val_loss: 123.7198\n",
      "Epoch 1612/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.4003 - val_loss: 120.7379\n",
      "Epoch 1613/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 142.7015 - val_loss: 115.9117\n",
      "Epoch 1614/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.5769 - val_loss: 113.7787\n",
      "Epoch 1615/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.2656 - val_loss: 135.3200\n",
      "Epoch 1616/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 135.4301 - val_loss: 153.1263\n",
      "Epoch 1617/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 138.854 - 0s 51us/step - loss: 139.2417 - val_loss: 109.0361\n",
      "Epoch 1618/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.6676 - val_loss: 109.2834\n",
      "Epoch 1619/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 130.1677 - val_loss: 110.7003\n",
      "Epoch 1620/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 129.2631 - val_loss: 138.0955\n",
      "Epoch 1621/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 146.7698 - val_loss: 118.2772\n",
      "Epoch 1622/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.9622 - val_loss: 110.1409\n",
      "Epoch 1623/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6801 - val_loss: 117.4702\n",
      "Epoch 1624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 182.4784 - val_loss: 121.8310\n",
      "Epoch 1625/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.4409 - val_loss: 117.5671\n",
      "Epoch 1626/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6641 - val_loss: 117.3404\n",
      "Epoch 1627/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.0459 - val_loss: 108.7317\n",
      "Epoch 1628/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.1322 - val_loss: 158.2554\n",
      "Epoch 1629/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.6431 - val_loss: 108.6924\n",
      "Epoch 1630/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2185 - val_loss: 131.7719\n",
      "Epoch 1631/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4605 - val_loss: 109.6330\n",
      "Epoch 1632/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 173.5803 - val_loss: 158.1642\n",
      "Epoch 1633/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3607 - val_loss: 111.1856\n",
      "Epoch 1634/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 134.890 - 0s 51us/step - loss: 134.1341 - val_loss: 106.2377\n",
      "Epoch 1635/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.4838 - val_loss: 134.6230\n",
      "Epoch 1636/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.2149 - val_loss: 201.3803\n",
      "Epoch 1637/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.9587 - val_loss: 109.4845\n",
      "Epoch 1638/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.9027 - val_loss: 115.1340\n",
      "Epoch 1639/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 156.3608 - val_loss: 158.4872\n",
      "Epoch 1640/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 148.5701 - val_loss: 129.1795\n",
      "Epoch 1641/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 245.5894 - val_loss: 376.3826\n",
      "Epoch 1642/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 143.6333 - val_loss: 110.0646\n",
      "Epoch 1643/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2803 - val_loss: 115.7925\n",
      "Epoch 1644/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.9355 - val_loss: 106.9604\n",
      "Epoch 1645/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.0474 - val_loss: 111.4966\n",
      "Epoch 1646/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.5852 - val_loss: 111.5014\n",
      "Epoch 1647/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.0335 - val_loss: 104.7524\n",
      "Epoch 1648/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 154.8483 - val_loss: 108.6060\n",
      "Epoch 1649/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8888 - val_loss: 116.5175\n",
      "Epoch 1650/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.2962 - val_loss: 154.7896\n",
      "Epoch 1651/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.8747 - val_loss: 110.6653\n",
      "Epoch 1652/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6316 - val_loss: 126.5104\n",
      "Epoch 1653/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.5030 - val_loss: 107.4332\n",
      "Epoch 1654/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1330 - val_loss: 133.2541\n",
      "Epoch 1655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 141.0894 - val_loss: 111.7634\n",
      "Epoch 1656/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1603 - val_loss: 115.2876\n",
      "Epoch 1657/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.4088 - val_loss: 126.7063\n",
      "Epoch 1658/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.4565 - val_loss: 154.3897\n",
      "Epoch 1659/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5511 - val_loss: 198.8050\n",
      "Epoch 1660/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9676 - val_loss: 132.0259\n",
      "Epoch 1661/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.5824 - val_loss: 130.0901\n",
      "Epoch 1662/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.9916 - val_loss: 114.7270\n",
      "Epoch 1663/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8148 - val_loss: 158.3071\n",
      "Epoch 1664/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.0330 - val_loss: 112.6779\n",
      "Epoch 1665/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.1841 - val_loss: 112.1362\n",
      "Epoch 1666/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.5268 - val_loss: 129.2064\n",
      "Epoch 1667/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8770 - val_loss: 112.7684\n",
      "Epoch 1668/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1595 - val_loss: 111.5586\n",
      "Epoch 1669/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 283.5747 - val_loss: 177.3516\n",
      "Epoch 1670/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.4430 - val_loss: 117.8415\n",
      "Epoch 1671/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.3387 - val_loss: 113.4039\n",
      "Epoch 1672/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.8691 - val_loss: 107.3025\n",
      "Epoch 1673/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 183.9562 - val_loss: 143.7679\n",
      "Epoch 1674/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.5548 - val_loss: 118.7230\n",
      "Epoch 1675/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7699 - val_loss: 123.2537\n",
      "Epoch 1676/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.5601 - val_loss: 110.3238\n",
      "Epoch 1677/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.8239 - val_loss: 124.0878\n",
      "Epoch 1678/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1914 - val_loss: 125.9166\n",
      "Epoch 1679/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.1368 - val_loss: 111.5760\n",
      "Epoch 1680/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7841 - val_loss: 148.2086\n",
      "Epoch 1681/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.9919 - val_loss: 110.0031\n",
      "Epoch 1682/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 129.9109 - val_loss: 106.3184\n",
      "Epoch 1683/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.5702 - val_loss: 112.0264\n",
      "Epoch 1684/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 218.0547 - val_loss: 113.4062\n",
      "Epoch 1685/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.9918 - val_loss: 112.7943\n",
      "Epoch 1686/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.8809 - val_loss: 113.1934\n",
      "Epoch 1687/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.6567 - val_loss: 122.5186\n",
      "Epoch 1688/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6621 - val_loss: 111.4465\n",
      "Epoch 1689/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.8022 - val_loss: 109.8789\n",
      "Epoch 1690/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.6414 - val_loss: 113.5903\n",
      "Epoch 1691/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 145.7161 - val_loss: 150.2241\n",
      "Epoch 1692/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 168.5981 - val_loss: 121.3030\n",
      "Epoch 1693/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 136.6792 - val_loss: 108.6792\n",
      "Epoch 1694/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 166.7341 - val_loss: 240.6040\n",
      "Epoch 1695/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 190.9282 - val_loss: 111.0482\n",
      "Epoch 1696/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.8397 - val_loss: 115.8748\n",
      "Epoch 1697/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.6643 - val_loss: 107.4537\n",
      "Epoch 1698/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2770 - val_loss: 119.2256\n",
      "Epoch 1699/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.4122 - val_loss: 132.0337\n",
      "Epoch 1700/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.5883 - val_loss: 107.3835\n",
      "Epoch 1701/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.0575 - val_loss: 108.6040\n",
      "Epoch 1702/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.7541 - val_loss: 139.9193\n",
      "Epoch 1703/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.6612 - val_loss: 136.0428\n",
      "Epoch 1704/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 174.9756 - val_loss: 159.6788\n",
      "Epoch 1705/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.7992 - val_loss: 129.2221\n",
      "Epoch 1706/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.0740 - val_loss: 145.8538\n",
      "Epoch 1707/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3904 - val_loss: 118.0328\n",
      "Epoch 1708/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.6830 - val_loss: 107.7433\n",
      "Epoch 1709/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9285 - val_loss: 131.7485\n",
      "Epoch 1710/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 195.4223 - val_loss: 157.0100\n",
      "Epoch 1711/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2036 - val_loss: 107.2245\n",
      "Epoch 1712/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5970 - val_loss: 109.8857\n",
      "Epoch 1713/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.2716 - val_loss: 129.1300\n",
      "Epoch 1714/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.8106 - val_loss: 124.6577\n",
      "Epoch 1715/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.8802 - val_loss: 110.7882\n",
      "Epoch 1716/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.9355 - val_loss: 107.4441\n",
      "Epoch 1717/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.6508 - val_loss: 123.8875\n",
      "Epoch 1718/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.3321 - val_loss: 109.5824\n",
      "Epoch 1719/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.4344 - val_loss: 126.3877\n",
      "Epoch 1720/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.5646 - val_loss: 126.0777\n",
      "Epoch 1721/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8060 - val_loss: 113.1445\n",
      "Epoch 1722/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.0833 - val_loss: 109.6550\n",
      "Epoch 1723/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1197 - val_loss: 109.1457\n",
      "Epoch 1724/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.9115 - val_loss: 122.8836\n",
      "Epoch 1725/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 225.8292 - val_loss: 122.4595\n",
      "Epoch 1726/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8809 - val_loss: 124.4884\n",
      "Epoch 1727/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1316 - val_loss: 167.0710\n",
      "Epoch 1728/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.7534 - val_loss: 111.2614\n",
      "Epoch 1729/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.5714 - val_loss: 153.5208\n",
      "Epoch 1730/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.1514 - val_loss: 142.0739\n",
      "Epoch 1731/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1473 - val_loss: 126.2835\n",
      "Epoch 1732/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9248 - val_loss: 113.6979\n",
      "Epoch 1733/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 180.5276 - val_loss: 116.8837\n",
      "Epoch 1734/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.6075 - val_loss: 119.3868\n",
      "Epoch 1735/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0384 - val_loss: 109.6967\n",
      "Epoch 1736/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.3315 - val_loss: 131.9578\n",
      "Epoch 1737/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1356 - val_loss: 111.9999\n",
      "Epoch 1738/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1335 - val_loss: 114.3739\n",
      "Epoch 1739/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 133.410 - 0s 51us/step - loss: 132.7699 - val_loss: 155.6376\n",
      "Epoch 1740/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9696 - val_loss: 110.1108\n",
      "Epoch 1741/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.1431 - val_loss: 107.5786\n",
      "Epoch 1742/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.1554 - val_loss: 123.0359\n",
      "Epoch 1743/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0937 - val_loss: 114.7010\n",
      "Epoch 1744/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4030 - val_loss: 104.7940\n",
      "Epoch 1745/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 167.9848 - val_loss: 265.9216\n",
      "Epoch 1746/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7195 - val_loss: 135.3824\n",
      "Epoch 1747/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0849 - val_loss: 106.3712\n",
      "Epoch 1748/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.8151 - val_loss: 108.3509\n",
      "Epoch 1749/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 169.5261 - val_loss: 151.6183\n",
      "Epoch 1750/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.1725 - val_loss: 132.1051\n",
      "Epoch 1751/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 168.8264 - val_loss: 123.7776\n",
      "Epoch 1752/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 181.0091 - val_loss: 110.4005\n",
      "Epoch 1753/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.6003 - val_loss: 143.6766\n",
      "Epoch 1754/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5249 - val_loss: 122.0073\n",
      "Epoch 1755/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8382 - val_loss: 113.7085\n",
      "Epoch 1756/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0833 - val_loss: 109.0717\n",
      "Epoch 1757/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7844 - val_loss: 112.6185\n",
      "Epoch 1758/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9134 - val_loss: 105.8953\n",
      "Epoch 1759/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.5352 - val_loss: 105.6349\n",
      "Epoch 1760/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5761 - val_loss: 123.7441\n",
      "Epoch 1761/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4689 - val_loss: 114.9746\n",
      "Epoch 1762/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 169.3146 - val_loss: 108.6056\n",
      "Epoch 1763/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 155.7953 - val_loss: 144.5954\n",
      "Epoch 1764/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 128.5872 - val_loss: 108.6222\n",
      "Epoch 1765/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.8444 - val_loss: 107.5635\n",
      "Epoch 1766/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.5610 - val_loss: 139.2401\n",
      "Epoch 1767/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7129 - val_loss: 108.9027\n",
      "Epoch 1768/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2488 - val_loss: 132.6187\n",
      "Epoch 1769/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.9324 - val_loss: 108.1226\n",
      "Epoch 1770/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.1337 - val_loss: 142.0246\n",
      "Epoch 1771/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.7656 - val_loss: 106.7180\n",
      "Epoch 1772/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.9496 - val_loss: 105.1519\n",
      "Epoch 1773/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6305 - val_loss: 134.1455\n",
      "Epoch 1774/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.5131 - val_loss: 193.8946\n",
      "Epoch 1775/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 196.6110 - val_loss: 169.1479\n",
      "Epoch 1776/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 137.5729 - val_loss: 116.6665\n",
      "Epoch 1777/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 141.0476 - val_loss: 119.5133\n",
      "Epoch 1778/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1208 - val_loss: 103.9111\n",
      "Epoch 1779/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 126.3475 - val_loss: 159.1704\n",
      "Epoch 1780/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4842 - val_loss: 105.6279\n",
      "Epoch 1781/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.0134 - val_loss: 119.5560\n",
      "Epoch 1782/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.1632 - val_loss: 108.3423\n",
      "Epoch 1783/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.7570 - val_loss: 109.7736\n",
      "Epoch 1784/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.0525 - val_loss: 136.2190\n",
      "Epoch 1785/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2989 - val_loss: 114.1078\n",
      "Epoch 1786/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9467 - val_loss: 108.3488\n",
      "Epoch 1787/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 164.9902 - val_loss: 135.7836\n",
      "Epoch 1788/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8983 - val_loss: 107.2064\n",
      "Epoch 1789/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.5777 - val_loss: 127.2722\n",
      "Epoch 1790/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.3760 - val_loss: 111.0180\n",
      "Epoch 1791/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.7084 - val_loss: 108.8753\n",
      "Epoch 1792/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.9956 - val_loss: 137.9250\n",
      "Epoch 1793/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.5284 - val_loss: 121.7768\n",
      "Epoch 1794/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.1211 - val_loss: 118.7267\n",
      "Epoch 1795/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.0734 - val_loss: 111.8410\n",
      "Epoch 1796/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 128.6411 - val_loss: 114.4516\n",
      "Epoch 1797/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 225.1406 - val_loss: 113.0473\n",
      "Epoch 1798/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.8777 - val_loss: 126.0078\n",
      "Epoch 1799/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 153.9923 - val_loss: 113.2394\n",
      "Epoch 1800/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9881 - val_loss: 128.5776\n",
      "Epoch 1801/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7032 - val_loss: 161.9675\n",
      "Epoch 1802/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1994 - val_loss: 141.7927\n",
      "Epoch 1803/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.3047 - val_loss: 111.7656\n",
      "Epoch 1804/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3046 - val_loss: 115.4738\n",
      "Epoch 1805/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.3382 - val_loss: 106.8987\n",
      "Epoch 1806/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.7036 - val_loss: 110.1984\n",
      "Epoch 1807/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.8280 - val_loss: 119.3973\n",
      "Epoch 1808/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.3682 - val_loss: 104.8141\n",
      "Epoch 1809/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.4438 - val_loss: 118.0014\n",
      "Epoch 1810/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6465 - val_loss: 124.5964\n",
      "Epoch 1811/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.4131 - val_loss: 114.7773\n",
      "Epoch 1812/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1374 - val_loss: 132.9627\n",
      "Epoch 1813/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.8732 - val_loss: 121.8667\n",
      "Epoch 1814/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 158.4410 - val_loss: 110.2828\n",
      "Epoch 1815/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.6494 - val_loss: 157.7209\n",
      "Epoch 1816/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 212.4424 - val_loss: 119.3010\n",
      "Epoch 1817/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3198 - val_loss: 104.2263\n",
      "Epoch 1818/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.4549 - val_loss: 124.9915\n",
      "Epoch 1819/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.7663 - val_loss: 115.4145\n",
      "Epoch 1820/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.0542 - val_loss: 148.8741\n",
      "Epoch 1821/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.9298 - val_loss: 118.5719\n",
      "Epoch 1822/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.4247 - val_loss: 110.6795\n",
      "Epoch 1823/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.7468 - val_loss: 136.0210\n",
      "Epoch 1824/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8447 - val_loss: 107.8826\n",
      "Epoch 1825/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.8185 - val_loss: 112.2402\n",
      "Epoch 1826/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4471 - val_loss: 115.0265\n",
      "Epoch 1827/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.0142 - val_loss: 112.2755\n",
      "Epoch 1828/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9909 - val_loss: 102.7804\n",
      "Epoch 1829/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6469 - val_loss: 105.2470\n",
      "Epoch 1830/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.1023 - val_loss: 106.6360\n",
      "Epoch 1831/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.5150 - val_loss: 124.0899\n",
      "Epoch 1832/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.3476 - val_loss: 116.6065\n",
      "Epoch 1833/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.2235 - val_loss: 125.4403\n",
      "Epoch 1834/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 163.7378 - val_loss: 111.9763\n",
      "Epoch 1835/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 131.4959 - val_loss: 105.9384\n",
      "Epoch 1836/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 125.8850 - val_loss: 108.8860\n",
      "Epoch 1837/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.0568 - val_loss: 152.3253\n",
      "Epoch 1838/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.1011 - val_loss: 109.0107\n",
      "Epoch 1839/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.6755 - val_loss: 110.4540\n",
      "Epoch 1840/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.1102 - val_loss: 108.2997\n",
      "Epoch 1841/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 217.7117 - val_loss: 119.5796\n",
      "Epoch 1842/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.5236 - val_loss: 106.3226\n",
      "Epoch 1843/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7484 - val_loss: 105.3025\n",
      "Epoch 1844/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.1675 - val_loss: 129.0383\n",
      "Epoch 1845/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.6227 - val_loss: 144.6514\n",
      "Epoch 1846/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4769 - val_loss: 110.4579\n",
      "Epoch 1847/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1826 - val_loss: 108.0363\n",
      "Epoch 1848/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.1312 - val_loss: 112.5045\n",
      "Epoch 1849/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2130 - val_loss: 108.8713\n",
      "Epoch 1850/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9380 - val_loss: 111.3367\n",
      "Epoch 1851/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.2160 - val_loss: 152.9388\n",
      "Epoch 1852/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9335 - val_loss: 117.7291\n",
      "Epoch 1853/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5236 - val_loss: 112.3064\n",
      "Epoch 1854/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 178.4058 - val_loss: 134.8243\n",
      "Epoch 1855/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 189.2939 - val_loss: 127.6851\n",
      "Epoch 1856/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.8291 - val_loss: 126.4525\n",
      "Epoch 1857/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.1664 - val_loss: 172.7115\n",
      "Epoch 1858/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.2950 - val_loss: 125.1002\n",
      "Epoch 1859/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7195 - val_loss: 114.6208\n",
      "Epoch 1860/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.7619 - val_loss: 113.2287\n",
      "Epoch 1861/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5075 - val_loss: 115.2633\n",
      "Epoch 1862/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.1601 - val_loss: 120.6524\n",
      "Epoch 1863/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.1675 - val_loss: 157.6498\n",
      "Epoch 1864/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.2245 - val_loss: 110.2728\n",
      "Epoch 1865/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9394 - val_loss: 106.6368\n",
      "Epoch 1866/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 124.8779 - val_loss: 135.6958\n",
      "Epoch 1867/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.0216 - val_loss: 111.6908\n",
      "Epoch 1868/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9171 - val_loss: 117.2438\n",
      "Epoch 1869/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.3599 - val_loss: 151.7866\n",
      "Epoch 1870/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 142.2788 - val_loss: 107.3923\n",
      "Epoch 1871/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.3706 - val_loss: 117.5311\n",
      "Epoch 1872/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1505 - val_loss: 106.3204\n",
      "Epoch 1873/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.6798 - val_loss: 125.1456\n",
      "Epoch 1874/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 159.0698 - val_loss: 107.7402\n",
      "Epoch 1875/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3761 - val_loss: 106.2719\n",
      "Epoch 1876/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 145.8511 - val_loss: 176.1354\n",
      "Epoch 1877/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2932 - val_loss: 117.3418\n",
      "Epoch 1878/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3407 - val_loss: 104.8824\n",
      "Epoch 1879/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.4304 - val_loss: 120.9172\n",
      "Epoch 1880/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7836 - val_loss: 113.3811\n",
      "Epoch 1881/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7631 - val_loss: 106.4470\n",
      "Epoch 1882/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8489 - val_loss: 118.4212\n",
      "Epoch 1883/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.8007 - val_loss: 104.8651\n",
      "Epoch 1884/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 149.6081 - val_loss: 117.1015\n",
      "Epoch 1885/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.6750 - val_loss: 142.3838\n",
      "Epoch 1886/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.0756 - val_loss: 114.7726\n",
      "Epoch 1887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 139.3652 - val_loss: 104.3839\n",
      "Epoch 1888/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1901 - val_loss: 120.8437\n",
      "Epoch 1889/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.9271 - val_loss: 138.8555\n",
      "Epoch 1890/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.5322 - val_loss: 126.3722\n",
      "Epoch 1891/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9365 - val_loss: 113.5266\n",
      "Epoch 1892/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.4214 - val_loss: 103.9422\n",
      "Epoch 1893/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2583 - val_loss: 108.4020\n",
      "Epoch 1894/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2830 - val_loss: 166.4393\n",
      "Epoch 1895/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.9299 - val_loss: 118.9619\n",
      "Epoch 1896/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.6218 - val_loss: 111.4833\n",
      "Epoch 1897/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.1959 - val_loss: 106.7274\n",
      "Epoch 1898/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 192.2491 - val_loss: 122.2237\n",
      "Epoch 1899/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.3290 - val_loss: 103.9748\n",
      "Epoch 1900/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.5271 - val_loss: 116.9957\n",
      "Epoch 1901/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.3940 - val_loss: 109.6738\n",
      "Epoch 1902/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.4024 - val_loss: 201.4815\n",
      "Epoch 1903/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3266 - val_loss: 132.3640\n",
      "Epoch 1904/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3489 - val_loss: 112.9888\n",
      "Epoch 1905/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.5920 - val_loss: 231.8309\n",
      "Epoch 1906/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 133.8855 - val_loss: 187.0512\n",
      "Epoch 1907/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 126.2068 - val_loss: 110.3001\n",
      "Epoch 1908/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 136.8875 - val_loss: 171.0394\n",
      "Epoch 1909/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 158.9338 - val_loss: 110.4415\n",
      "Epoch 1910/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 184.4721 - val_loss: 140.0277\n",
      "Epoch 1911/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.6721 - val_loss: 116.6140\n",
      "Epoch 1912/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2891 - val_loss: 102.5991\n",
      "Epoch 1913/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.3784 - val_loss: 108.1298\n",
      "Epoch 1914/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.7191 - val_loss: 106.8008\n",
      "Epoch 1915/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8230 - val_loss: 102.8592\n",
      "Epoch 1916/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.7328 - val_loss: 102.8081\n",
      "Epoch 1917/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.8433 - val_loss: 117.2717\n",
      "Epoch 1918/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3837 - val_loss: 132.7051\n",
      "Epoch 1919/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.7508 - val_loss: 115.8372\n",
      "Epoch 1920/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 141.3580 - val_loss: 105.5801\n",
      "Epoch 1921/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.9340 - val_loss: 116.0998\n",
      "Epoch 1922/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1505 - val_loss: 142.6577\n",
      "Epoch 1923/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 139.7758 - val_loss: 125.7782\n",
      "Epoch 1924/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 121.7008 - val_loss: 110.1608\n",
      "Epoch 1925/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.0422 - val_loss: 124.9521\n",
      "Epoch 1926/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 269.7874 - val_loss: 121.5565\n",
      "Epoch 1927/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.2430 - val_loss: 107.9805\n",
      "Epoch 1928/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8351 - val_loss: 114.4415\n",
      "Epoch 1929/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3758 - val_loss: 106.9126\n",
      "Epoch 1930/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.8020 - val_loss: 133.1848\n",
      "Epoch 1931/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3393 - val_loss: 117.6030\n",
      "Epoch 1932/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.4892 - val_loss: 129.4150\n",
      "Epoch 1933/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2741 - val_loss: 142.5558\n",
      "Epoch 1934/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.7020 - val_loss: 113.7456\n",
      "Epoch 1935/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 157.6400 - val_loss: 109.8257\n",
      "Epoch 1936/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5136 - val_loss: 112.1816\n",
      "Epoch 1937/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 137.9005 - val_loss: 144.3331\n",
      "Epoch 1938/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.9009 - val_loss: 125.4770\n",
      "Epoch 1939/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.4185 - val_loss: 106.2890\n",
      "Epoch 1940/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9857 - val_loss: 144.5215\n",
      "Epoch 1941/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.0360 - val_loss: 108.8774\n",
      "Epoch 1942/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.5665 - val_loss: 134.5316\n",
      "Epoch 1943/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.5558 - val_loss: 115.1064\n",
      "Epoch 1944/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.7012 - val_loss: 122.1139\n",
      "Epoch 1945/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.6844 - val_loss: 119.6473\n",
      "Epoch 1946/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 224.9363 - val_loss: 126.8376\n",
      "Epoch 1947/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.0977 - val_loss: 111.6128\n",
      "Epoch 1948/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.1430 - val_loss: 108.9807\n",
      "Epoch 1949/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.9472 - val_loss: 156.4589\n",
      "Epoch 1950/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 126.5710 - val_loss: 113.7644\n",
      "Epoch 1951/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.0867 - val_loss: 114.5229\n",
      "Epoch 1952/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5660 - val_loss: 118.0216\n",
      "Epoch 1953/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.7214 - val_loss: 112.9486\n",
      "Epoch 1954/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.1494 - val_loss: 115.1226\n",
      "Epoch 1955/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8305 - val_loss: 117.6720\n",
      "Epoch 1956/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.9898 - val_loss: 105.4626\n",
      "Epoch 1957/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7676 - val_loss: 153.7062\n",
      "Epoch 1958/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.1390 - val_loss: 104.2395\n",
      "Epoch 1959/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9818 - val_loss: 105.1098\n",
      "Epoch 1960/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.8503 - val_loss: 104.3885\n",
      "Epoch 1961/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.9730 - val_loss: 116.4622\n",
      "Epoch 1962/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 173.0141 - val_loss: 224.4320\n",
      "Epoch 1963/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 184.3670 - val_loss: 109.5476\n",
      "Epoch 1964/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.6693 - val_loss: 117.1523\n",
      "Epoch 1965/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.4865 - val_loss: 143.8690\n",
      "Epoch 1966/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.4165 - val_loss: 113.4758\n",
      "Epoch 1967/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 383.1205 - val_loss: 161.5420\n",
      "Epoch 1968/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.5712 - val_loss: 122.3392\n",
      "Epoch 1969/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 147.217 - 0s 51us/step - loss: 147.6113 - val_loss: 132.2179\n",
      "Epoch 1970/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.5242 - val_loss: 138.8348\n",
      "Epoch 1971/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0860 - val_loss: 115.8263\n",
      "Epoch 1972/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.4124 - val_loss: 108.9786\n",
      "Epoch 1973/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9407 - val_loss: 143.4328\n",
      "Epoch 1974/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.2871 - val_loss: 112.2211\n",
      "Epoch 1975/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.9957 - val_loss: 107.7643\n",
      "Epoch 1976/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 140.3031 - val_loss: 103.4351\n",
      "Epoch 1977/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 125.9346 - val_loss: 117.4127\n",
      "Epoch 1978/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 131.1330 - val_loss: 110.4778\n",
      "Epoch 1979/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 141.2670 - val_loss: 108.0941\n",
      "Epoch 1980/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 130.9308 - val_loss: 124.1644\n",
      "Epoch 1981/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 134.1663 - val_loss: 113.9187\n",
      "Epoch 1982/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 129.9840 - val_loss: 286.0270\n",
      "Epoch 1983/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.5828 - val_loss: 127.5484\n",
      "Epoch 1984/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 134.2057 - val_loss: 111.4960\n",
      "Epoch 1985/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 149.9431 - val_loss: 122.4931\n",
      "Epoch 1986/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 136.4810 - val_loss: 110.0000\n",
      "Epoch 1987/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 129.8008 - val_loss: 103.4710\n",
      "Epoch 1988/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.2053 - val_loss: 121.0104\n",
      "Epoch 1989/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.4281 - val_loss: 108.1799\n",
      "Epoch 1990/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 186.6060 - val_loss: 136.9529\n",
      "Epoch 1991/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.1643 - val_loss: 113.1841\n",
      "Epoch 1992/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.1508 - val_loss: 113.9426\n",
      "Epoch 1993/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 124.1343 - val_loss: 107.8876\n",
      "Epoch 1994/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9389 - val_loss: 176.3814\n",
      "Epoch 1995/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.5426 - val_loss: 112.3043\n",
      "Epoch 1996/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.3437 - val_loss: 154.0447\n",
      "Epoch 1997/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0634 - val_loss: 117.6654\n",
      "Epoch 1998/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.9898 - val_loss: 113.4366\n",
      "Epoch 1999/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.8125 - val_loss: 189.0054\n",
      "Epoch 2000/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.0946 - val_loss: 110.4348\n",
      "Epoch 2001/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.2197 - val_loss: 107.1743\n",
      "Epoch 2002/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.8987 - val_loss: 120.1611\n",
      "Epoch 2003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.0202 - val_loss: 130.4886\n",
      "Epoch 2004/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 132.9565 - val_loss: 104.8920\n",
      "Epoch 2005/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.9145 - val_loss: 113.0090\n",
      "Epoch 2006/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.2364 - val_loss: 111.2569\n",
      "Epoch 2007/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.1937 - val_loss: 126.8349\n",
      "Epoch 2008/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.8609 - val_loss: 144.1245\n",
      "Epoch 2009/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.3092 - val_loss: 127.1159\n",
      "Epoch 2010/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3729 - val_loss: 202.4576\n",
      "Epoch 2011/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3805 - val_loss: 144.4328\n",
      "Epoch 2012/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 160.6043 - val_loss: 140.4385\n",
      "Epoch 2013/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.4103 - val_loss: 105.1830\n",
      "Epoch 2014/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6914 - val_loss: 106.7680\n",
      "Epoch 2015/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.5080 - val_loss: 133.7869\n",
      "Epoch 2016/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 129.1504 - val_loss: 116.0666\n",
      "Epoch 2017/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.2345 - val_loss: 119.1681\n",
      "Epoch 2018/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.3275 - val_loss: 156.7913\n",
      "Epoch 2019/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.7456 - val_loss: 142.8512\n",
      "Epoch 2020/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1801 - val_loss: 125.6343\n",
      "Epoch 2021/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.4427 - val_loss: 120.1422\n",
      "Epoch 2022/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1544 - val_loss: 280.4564\n",
      "Epoch 2023/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.5252 - val_loss: 107.4280\n",
      "Epoch 2024/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 145.5336 - val_loss: 142.5995\n",
      "Epoch 2025/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.3542 - val_loss: 120.2439\n",
      "Epoch 2026/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.2193 - val_loss: 119.1921\n",
      "Epoch 2027/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5406 - val_loss: 114.1990\n",
      "Epoch 2028/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.9318 - val_loss: 109.0261\n",
      "Epoch 2029/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.0703 - val_loss: 111.2773\n",
      "Epoch 2030/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.3137 - val_loss: 128.8685\n",
      "Epoch 2031/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.6849 - val_loss: 130.6962\n",
      "Epoch 2032/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 228.5242 - val_loss: 198.2285\n",
      "Epoch 2033/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 162.1155 - val_loss: 132.7658\n",
      "Epoch 2034/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.0975 - val_loss: 146.5098\n",
      "Epoch 2035/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.8719 - val_loss: 125.8935\n",
      "Epoch 2036/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.9448 - val_loss: 115.2046\n",
      "Epoch 2037/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.3453 - val_loss: 110.7401\n",
      "Epoch 2038/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.8309 - val_loss: 110.2363\n",
      "Epoch 2039/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.8110 - val_loss: 133.2864\n",
      "Epoch 2040/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 137.8041 - val_loss: 111.7754\n",
      "Epoch 2041/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 209.2413 - val_loss: 280.2119\n",
      "Epoch 2042/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.6920 - val_loss: 106.2780\n",
      "Epoch 2043/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.0426 - val_loss: 109.1758\n",
      "Epoch 2044/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.1077 - val_loss: 115.8499\n",
      "Epoch 2045/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 124.3192 - val_loss: 107.0305\n",
      "Epoch 2046/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 122.2056 - val_loss: 105.3135\n",
      "Epoch 2047/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 133.4120 - val_loss: 119.8283\n",
      "Epoch 2048/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.1482 - val_loss: 117.1952\n",
      "Epoch 2049/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3698 - val_loss: 118.2109\n",
      "Epoch 2050/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0004 - val_loss: 109.9263\n",
      "Epoch 2051/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.2824 - val_loss: 150.6934\n",
      "Epoch 2052/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 140.3500 - val_loss: 145.0872\n",
      "Epoch 2053/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 159.0763 - val_loss: 114.7109\n",
      "Epoch 2054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 163.2599 - val_loss: 124.4167\n",
      "Epoch 2055/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.5403 - val_loss: 113.1566\n",
      "Epoch 2056/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 140.8527 - val_loss: 202.8960\n",
      "Epoch 2057/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 137.5788 - val_loss: 131.8463\n",
      "Epoch 2058/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.3520 - val_loss: 106.0856\n",
      "Epoch 2059/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.8816 - val_loss: 132.2499\n",
      "Epoch 2060/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 130.9912 - val_loss: 102.4930\n",
      "Epoch 2061/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.6387 - val_loss: 115.0445\n",
      "Epoch 2062/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.6743 - val_loss: 137.6971\n",
      "Epoch 2063/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.9293 - val_loss: 111.5464\n",
      "Epoch 2064/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.8721 - val_loss: 106.0829\n",
      "Epoch 2065/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5599 - val_loss: 142.6626\n",
      "Epoch 2066/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.9417 - val_loss: 115.7712\n",
      "Epoch 2067/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4486 - val_loss: 129.2773\n",
      "Epoch 2068/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.2737 - val_loss: 114.9801\n",
      "Epoch 2069/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 165.6023 - val_loss: 128.0634\n",
      "Epoch 2070/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.7484 - val_loss: 127.7677\n",
      "Epoch 2071/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.0390 - val_loss: 147.0508\n",
      "Epoch 2072/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6320 - val_loss: 113.2276\n",
      "Epoch 2073/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4616 - val_loss: 107.7979\n",
      "Epoch 2074/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 158.7331 - val_loss: 348.9541\n",
      "Epoch 2075/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 147.0287 - val_loss: 133.4186\n",
      "Epoch 2076/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 155.1619 - val_loss: 114.8862\n",
      "Epoch 2077/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 136.8925 - val_loss: 121.3409\n",
      "Epoch 2078/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1154 - val_loss: 110.1193\n",
      "Epoch 2079/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6735 - val_loss: 113.3389\n",
      "Epoch 2080/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 148.6765 - val_loss: 121.4923\n",
      "Epoch 2081/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.0689 - val_loss: 106.9677\n",
      "Epoch 2082/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 149.0432 - val_loss: 320.6984\n",
      "Epoch 2083/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.4436 - val_loss: 117.0425\n",
      "Epoch 2084/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4291 - val_loss: 122.4801\n",
      "Epoch 2085/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.7956 - val_loss: 109.6061\n",
      "Epoch 2086/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.1172 - val_loss: 113.6478\n",
      "Epoch 2087/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.8390 - val_loss: 114.4641\n",
      "Epoch 2088/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.6101 - val_loss: 188.2493\n",
      "Epoch 2089/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.9119 - val_loss: 127.0768\n",
      "Epoch 2090/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6195 - val_loss: 152.8282\n",
      "Epoch 2091/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.6378 - val_loss: 111.9622\n",
      "Epoch 2092/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.7973 - val_loss: 164.6672\n",
      "Epoch 2093/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7329 - val_loss: 115.5215\n",
      "Epoch 2094/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.6014 - val_loss: 113.8562\n",
      "Epoch 2095/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.9778 - val_loss: 106.8998\n",
      "Epoch 2096/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3088 - val_loss: 143.9172\n",
      "Epoch 2097/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 180.1371 - val_loss: 120.8554\n",
      "Epoch 2098/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.4170 - val_loss: 108.8738\n",
      "Epoch 2099/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.7943 - val_loss: 164.8247\n",
      "Epoch 2100/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9919 - val_loss: 113.8859\n",
      "Epoch 2101/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.6310 - val_loss: 129.6259\n",
      "Epoch 2102/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3627 - val_loss: 135.1224\n",
      "Epoch 2103/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 147.9798 - val_loss: 110.9969\n",
      "Epoch 2104/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.9521 - val_loss: 194.5826\n",
      "Epoch 2105/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5475 - val_loss: 111.8588\n",
      "Epoch 2106/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.9203 - val_loss: 113.1601\n",
      "Epoch 2107/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5734 - val_loss: 109.2086\n",
      "Epoch 2108/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.0622 - val_loss: 130.6074\n",
      "Epoch 2109/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.1694 - val_loss: 140.1447\n",
      "Epoch 2110/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 178.8748 - val_loss: 153.7965\n",
      "Epoch 2111/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 129.8089 - val_loss: 104.8665\n",
      "Epoch 2112/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 131.4909 - val_loss: 112.7244\n",
      "Epoch 2113/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0518 - val_loss: 123.1816\n",
      "Epoch 2114/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0189 - val_loss: 166.5315\n",
      "Epoch 2115/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.3782 - val_loss: 116.1283\n",
      "Epoch 2116/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.9789 - val_loss: 115.7278\n",
      "Epoch 2117/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 126.1514 - val_loss: 127.0424\n",
      "Epoch 2118/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 129.6212 - val_loss: 121.6287\n",
      "Epoch 2119/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 124.8382 - val_loss: 107.1654\n",
      "Epoch 2120/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4904 - val_loss: 123.3161\n",
      "Epoch 2121/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.7690 - val_loss: 107.3020\n",
      "Epoch 2122/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 170.0936 - val_loss: 110.3389\n",
      "Epoch 2123/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.0946 - val_loss: 140.4168\n",
      "Epoch 2124/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 125.0880 - val_loss: 125.2648\n",
      "Epoch 2125/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.2194 - val_loss: 110.7133\n",
      "Epoch 2126/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.6846 - val_loss: 167.9294\n",
      "Epoch 2127/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.7816 - val_loss: 111.1397\n",
      "Epoch 2128/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 134.4479 - val_loss: 137.3976\n",
      "Epoch 2129/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.7843 - val_loss: 104.6407\n",
      "Epoch 2130/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 157.0774 - val_loss: 123.4644\n",
      "Epoch 2131/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 129.124 - 0s 51us/step - loss: 128.7228 - val_loss: 108.3842\n",
      "Epoch 2132/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.6111 - val_loss: 188.1261\n",
      "Epoch 2133/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1027 - val_loss: 105.4261\n",
      "Epoch 2134/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 126.7159 - val_loss: 123.0886\n",
      "Epoch 2135/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.0673 - val_loss: 117.6561\n",
      "Epoch 2136/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.4515 - val_loss: 111.1174\n",
      "Epoch 2137/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.2554 - val_loss: 153.1099\n",
      "Epoch 2138/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0863 - val_loss: 106.4809\n",
      "Epoch 2139/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0436 - val_loss: 108.6386\n",
      "Epoch 2140/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.2915 - val_loss: 103.4880\n",
      "Epoch 2141/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.2967 - val_loss: 133.4735\n",
      "Epoch 2142/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 143.7460 - val_loss: 111.5816\n",
      "Epoch 2143/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.9412 - val_loss: 115.1353\n",
      "Epoch 2144/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 133.5650 - val_loss: 125.8412\n",
      "Epoch 2145/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.6462 - val_loss: 124.4647\n",
      "Epoch 2146/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0537 - val_loss: 108.0728\n",
      "Epoch 2147/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.3476 - val_loss: 133.3412\n",
      "Epoch 2148/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.3322 - val_loss: 111.9057\n",
      "Epoch 2149/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 121.1663 - val_loss: 109.9600\n",
      "Epoch 2150/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.3958 - val_loss: 168.7590\n",
      "Epoch 2151/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.3484 - val_loss: 111.9814\n",
      "Epoch 2152/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1837 - val_loss: 126.3023\n",
      "Epoch 2153/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6799 - val_loss: 106.1692\n",
      "Epoch 2154/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7106 - val_loss: 115.0921\n",
      "Epoch 2155/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.0101 - val_loss: 123.8942\n",
      "Epoch 2156/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 172.4891 - val_loss: 110.1403\n",
      "Epoch 2157/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 121.8136 - val_loss: 105.4343\n",
      "Epoch 2158/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.6690 - val_loss: 127.2752\n",
      "Epoch 2159/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.4214 - val_loss: 113.4067\n",
      "Epoch 2160/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 135.4573 - val_loss: 115.9940\n",
      "Epoch 2161/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.4887 - val_loss: 107.5511\n",
      "Epoch 2162/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.6692 - val_loss: 117.0077\n",
      "Epoch 2163/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.4220 - val_loss: 110.7284\n",
      "Epoch 2164/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.5742 - val_loss: 103.8733\n",
      "Epoch 2165/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 123.9072 - val_loss: 116.9347\n",
      "Epoch 2166/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 117.1273 - val_loss: 111.7496\n",
      "Epoch 2167/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 130.188 - 0s 51us/step - loss: 130.3602 - val_loss: 119.4246\n",
      "Epoch 2168/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.7406 - val_loss: 133.0613\n",
      "Epoch 2169/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5769 - val_loss: 139.2631\n",
      "Epoch 2170/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.6732 - val_loss: 115.4966\n",
      "Epoch 2171/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.2845 - val_loss: 109.3153\n",
      "Epoch 2172/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.1439 - val_loss: 122.4877\n",
      "Epoch 2173/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.1077 - val_loss: 106.5536\n",
      "Epoch 2174/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.0971 - val_loss: 112.8125\n",
      "Epoch 2175/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.3461 - val_loss: 164.3284\n",
      "Epoch 2176/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.9936 - val_loss: 121.7069\n",
      "Epoch 2177/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.9550 - val_loss: 123.6010\n",
      "Epoch 2178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3683 - val_loss: 109.3720\n",
      "Epoch 2179/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.3494 - val_loss: 107.7633\n",
      "Epoch 2180/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 135.3969 - val_loss: 112.3240\n",
      "Epoch 2181/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.1309 - val_loss: 112.0998\n",
      "Epoch 2182/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2300 - val_loss: 153.7945\n",
      "Epoch 2183/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.6248 - val_loss: 107.4535\n",
      "Epoch 2184/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.6511 - val_loss: 110.6104\n",
      "Epoch 2185/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.0864 - val_loss: 303.8612\n",
      "Epoch 2186/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 220.9701 - val_loss: 295.7679\n",
      "Epoch 2187/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 221.3701 - val_loss: 133.8348\n",
      "Epoch 2188/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 143.0590 - val_loss: 118.3721\n",
      "Epoch 2189/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.7071 - val_loss: 114.1578\n",
      "Epoch 2190/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 138.3956 - val_loss: 119.4110\n",
      "Epoch 2191/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.7198 - val_loss: 129.2079\n",
      "Epoch 2192/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 136.9318 - val_loss: 118.1931\n",
      "Epoch 2193/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.8758 - val_loss: 155.0608\n",
      "Epoch 2194/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.7410 - val_loss: 108.2822\n",
      "Epoch 2195/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.9197 - val_loss: 114.3534\n",
      "Epoch 2196/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 135.717 - 0s 51us/step - loss: 136.7454 - val_loss: 109.2008\n",
      "Epoch 2197/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 177.6156 - val_loss: 108.7481\n",
      "Epoch 2198/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 131.5411 - val_loss: 121.5369\n",
      "Epoch 2199/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.8265 - val_loss: 113.5779\n",
      "Epoch 2200/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 128.6150 - val_loss: 142.0172\n",
      "Epoch 2201/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 144.5969 - val_loss: 129.8919\n",
      "Epoch 2202/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 141.2024 - val_loss: 156.3475\n",
      "Epoch 2203/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 147.1719 - val_loss: 139.5787\n",
      "Epoch 2204/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4204 - val_loss: 109.1734\n",
      "Epoch 2205/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 284.5387 - val_loss: 125.5097\n",
      "Epoch 2206/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5089 - val_loss: 108.3755\n",
      "Epoch 2207/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.5726 - val_loss: 118.3336\n",
      "Epoch 2208/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 121.6081 - val_loss: 167.5812\n",
      "Epoch 2209/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.9103 - val_loss: 113.7124\n",
      "Epoch 2210/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0451 - val_loss: 136.9286\n",
      "Epoch 2211/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.6287 - val_loss: 135.6818\n",
      "Epoch 2212/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 154.7832 - val_loss: 126.3253\n",
      "Epoch 2213/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.1615 - val_loss: 119.9328\n",
      "Epoch 2214/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 135.247 - 0s 50us/step - loss: 135.1156 - val_loss: 120.4754\n",
      "Epoch 2215/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 139.9614 - val_loss: 105.9855\n",
      "Epoch 2216/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7749 - val_loss: 120.3120\n",
      "Epoch 2217/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7771 - val_loss: 112.1071\n",
      "Epoch 2218/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 137.4650 - val_loss: 116.6895\n",
      "Epoch 2219/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 162.6405 - val_loss: 106.8363\n",
      "Epoch 2220/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.4851 - val_loss: 120.6384\n",
      "Epoch 2221/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.3584 - val_loss: 117.9379\n",
      "Epoch 2222/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 178.0584 - val_loss: 120.1269\n",
      "Epoch 2223/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 168.6500 - val_loss: 107.8829\n",
      "Epoch 2224/10000\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 151.9696 - val_loss: 108.4376\n",
      "Epoch 2225/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.3756 - val_loss: 114.5803\n",
      "Epoch 2226/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5290 - val_loss: 109.5229\n",
      "Epoch 2227/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9773 - val_loss: 109.6659\n",
      "Epoch 2228/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.5440 - val_loss: 113.2563\n",
      "Epoch 2229/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8073 - val_loss: 142.2349\n",
      "Epoch 2230/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.6926 - val_loss: 118.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2231/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.4872 - val_loss: 111.2936\n",
      "Epoch 2232/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.6497 - val_loss: 107.8711\n",
      "Epoch 2233/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 141.0264 - val_loss: 186.3600\n",
      "Epoch 2234/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 207.0489 - val_loss: 110.8945\n",
      "Epoch 2235/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 118.9344 - val_loss: 111.6268\n",
      "Epoch 2236/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.1708 - val_loss: 112.7205\n",
      "Epoch 2237/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.7861 - val_loss: 116.3928\n",
      "Epoch 2238/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.7864 - val_loss: 108.9027\n",
      "Epoch 2239/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.0070 - val_loss: 123.5826\n",
      "Epoch 2240/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 155.7347 - val_loss: 111.8041\n",
      "Epoch 2241/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.9418 - val_loss: 106.2211\n",
      "Epoch 2242/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.3777 - val_loss: 114.3847\n",
      "Epoch 2243/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.9629 - val_loss: 110.9793\n",
      "Epoch 2244/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 134.3914 - val_loss: 119.9116\n",
      "Epoch 2245/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.8717 - val_loss: 120.7162\n",
      "Epoch 2246/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.7298 - val_loss: 109.1181\n",
      "Epoch 2247/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.3741 - val_loss: 119.5253\n",
      "Epoch 2248/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 147.5431 - val_loss: 127.2070\n",
      "Epoch 2249/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 184.9573 - val_loss: 145.5854\n",
      "Epoch 2250/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 138.0506 - val_loss: 139.7484\n",
      "Epoch 2251/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7076 - val_loss: 114.2729\n",
      "Epoch 2252/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.8036 - val_loss: 104.2860\n",
      "Epoch 2253/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.1308 - val_loss: 110.9471\n",
      "Epoch 2254/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 142.8767 - val_loss: 113.9936\n",
      "Epoch 2255/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.9156 - val_loss: 134.1036\n",
      "Epoch 2256/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 126.3684 - val_loss: 118.7014\n",
      "Epoch 2257/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.1636 - val_loss: 105.2989\n",
      "Epoch 2258/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.6990 - val_loss: 116.9069\n",
      "Epoch 2259/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 127.4836 - val_loss: 114.9304\n",
      "Epoch 2260/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 132.4334 - val_loss: 124.6664\n",
      "Epoch 2261/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 146.5724 - val_loss: 131.8508\n",
      "Epoch 2262/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 138.2237 - val_loss: 119.3280\n",
      "Epoch 2263/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.7605 - val_loss: 115.7884\n",
      "Epoch 2264/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.0177 - val_loss: 116.9723\n",
      "Epoch 2265/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.3975 - val_loss: 115.4210\n",
      "Epoch 2266/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 131.1576 - val_loss: 113.5426\n",
      "Epoch 2267/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 129.3628 - val_loss: 117.4458\n",
      "Epoch 2268/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.9271 - val_loss: 126.2787\n",
      "Epoch 2269/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.2128 - val_loss: 108.2060\n",
      "Epoch 2270/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.2995 - val_loss: 149.5262\n",
      "Epoch 2271/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.5156 - val_loss: 128.1371\n",
      "Epoch 2272/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3404 - val_loss: 104.4887\n",
      "Epoch 2273/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 130.8849 - val_loss: 146.3768\n",
      "Epoch 2274/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 130.7164 - val_loss: 110.6824\n",
      "Epoch 2275/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 183.6996 - val_loss: 126.7070\n",
      "Epoch 2276/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 136.0694 - val_loss: 117.6826\n",
      "Epoch 2277/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 167.7818 - val_loss: 114.8449\n",
      "Epoch 2278/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 128.4929 - val_loss: 111.1806\n",
      "Epoch 2279/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 128.2745 - val_loss: 118.2942\n",
      "Epoch 2280/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.4801 - val_loss: 115.6441\n",
      "Epoch 2281/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7564 - val_loss: 140.9748\n",
      "Epoch 2282/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.6316 - val_loss: 113.5149\n",
      "Epoch 2283/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.4972 - val_loss: 113.1607\n",
      "Epoch 2284/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.5930 - val_loss: 117.4025\n",
      "Epoch 2285/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 149.6736 - val_loss: 257.7368\n",
      "Epoch 2286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 158.5377 - val_loss: 112.1510\n",
      "Epoch 2287/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.7174 - val_loss: 112.2165\n",
      "Epoch 2288/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.3735 - val_loss: 106.4792\n",
      "Epoch 2289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.5217 - val_loss: 140.6649\n",
      "Epoch 2290/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.4907 - val_loss: 113.0505\n",
      "Epoch 2291/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5592 - val_loss: 159.2524\n",
      "Epoch 2292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 137.2016 - val_loss: 106.3081\n",
      "Epoch 2293/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.5768 - val_loss: 112.7280\n",
      "Epoch 2294/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0115 - val_loss: 111.7970\n",
      "Epoch 2295/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.9870 - val_loss: 114.7729\n",
      "Epoch 2296/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0740 - val_loss: 123.8806\n",
      "Epoch 2297/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.0096 - val_loss: 124.6329\n",
      "Epoch 2298/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.7628 - val_loss: 141.2855\n",
      "Epoch 2299/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 138.3534 - val_loss: 145.8201\n",
      "Epoch 2300/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.7369 - val_loss: 109.6146\n",
      "Epoch 2301/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.2804 - val_loss: 164.6182\n",
      "Epoch 2302/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.0575 - val_loss: 117.7268\n",
      "Epoch 2303/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.5755 - val_loss: 114.7301\n",
      "Epoch 2304/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 140.0500 - val_loss: 107.0194\n",
      "Epoch 2305/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 151.7202 - val_loss: 124.0342\n",
      "Epoch 2306/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 145.7124 - val_loss: 105.2284\n",
      "Epoch 2307/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 133.8897 - val_loss: 112.5748\n",
      "Epoch 2308/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 219.0475 - val_loss: 165.2894\n",
      "Epoch 2309/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 198.5188 - val_loss: 141.0145\n",
      "Epoch 2310/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 139.1801 - val_loss: 110.9392\n",
      "Epoch 2311/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 130.9548 - val_loss: 111.5954\n",
      "Epoch 2312/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 122.1374 - val_loss: 110.0901\n",
      "Epoch 2313/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 158.5527 - val_loss: 186.4426\n",
      "Epoch 2314/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.8343 - val_loss: 125.9045\n",
      "Epoch 2315/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.1331 - val_loss: 107.1122\n",
      "Epoch 2316/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.3534 - val_loss: 111.7426\n",
      "Epoch 2317/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.6336 - val_loss: 123.4313\n",
      "Epoch 2318/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.8045 - val_loss: 126.2614\n",
      "Epoch 2319/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5463 - val_loss: 141.3859\n",
      "Epoch 2320/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5586 - val_loss: 139.0410\n",
      "Epoch 2321/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 127.8672 - val_loss: 108.9641\n",
      "Epoch 2322/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.0291 - val_loss: 127.0852\n",
      "Epoch 2323/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 277.3130 - val_loss: 118.9418\n",
      "Epoch 2324/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.5710 - val_loss: 125.1005\n",
      "Epoch 2325/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.7764 - val_loss: 108.3694\n",
      "Epoch 2326/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 120.5802 - val_loss: 108.7546\n",
      "Epoch 2327/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 133.2030 - val_loss: 131.7950\n",
      "Epoch 2328/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 123.1108 - val_loss: 108.3307\n",
      "Epoch 2329/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.2121 - val_loss: 147.1976\n",
      "Epoch 2330/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 197.5983 - val_loss: 121.2616\n",
      "Epoch 2331/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 119.6777 - val_loss: 106.9465\n",
      "Epoch 2332/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 125.0957 - val_loss: 112.2150\n",
      "Epoch 2333/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 121.3223 - val_loss: 110.4845\n",
      "Epoch 2334/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 119.9914 - val_loss: 110.2335\n",
      "Epoch 2335/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.5996 - val_loss: 110.3720\n",
      "Epoch 2336/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 125.5458 - val_loss: 128.1951\n",
      "Epoch 2337/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 131.7045 - val_loss: 117.7212\n",
      "Epoch 2338/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 190.2696 - val_loss: 115.4614\n",
      "Epoch 2339/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.0236 - val_loss: 106.1041\n",
      "Epoch 2340/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.2118 - val_loss: 122.5454\n",
      "Epoch 2341/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.2971 - val_loss: 127.3570\n",
      "Epoch 2342/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 127.8400 - val_loss: 120.2349\n",
      "Epoch 2343/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.0391 - val_loss: 115.7579\n",
      "Epoch 2344/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 131.7469 - val_loss: 124.9003\n",
      "Epoch 2345/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 132.3056 - val_loss: 151.5652\n",
      "Epoch 2346/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 127.5375 - val_loss: 129.3220\n",
      "Epoch 2347/10000\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 126.5657 - val_loss: 110.2709\n",
      "Epoch 2348/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 142.7937 - val_loss: 169.1144\n",
      "Epoch 2349/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.9920 - val_loss: 116.3220\n",
      "Epoch 2350/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9798 - val_loss: 109.5439\n",
      "Epoch 2351/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 151.3536 - val_loss: 144.1873\n",
      "Epoch 2352/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 128.3929 - val_loss: 120.5657\n",
      "Epoch 2353/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.6075 - val_loss: 105.3083\n",
      "Epoch 2354/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 140.3879 - val_loss: 113.8651\n",
      "Epoch 2355/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2594 - val_loss: 110.0950\n",
      "Epoch 2356/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.2749 - val_loss: 110.3142\n",
      "Epoch 2357/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.4076 - val_loss: 145.2445\n",
      "Epoch 2358/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 136.8284 - val_loss: 106.7568\n",
      "Epoch 2359/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 140.7281 - val_loss: 109.5453\n",
      "Epoch 2360/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 166.5134 - val_loss: 134.6231\n",
      "Epoch 2361/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.4420 - val_loss: 114.6273\n",
      "Epoch 2362/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 126.0831 - val_loss: 140.4188\n",
      "Epoch 2363/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.6152 - val_loss: 113.9071\n",
      "Epoch 2364/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.0649 - val_loss: 111.9546\n",
      "Epoch 2365/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 126.1125 - val_loss: 112.9534\n",
      "Epoch 2366/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 144.7737 - val_loss: 112.8194\n",
      "Epoch 2367/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.4742 - val_loss: 105.5445\n",
      "Epoch 2368/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.9182 - val_loss: 149.8147\n",
      "Epoch 2369/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0855 - val_loss: 138.7166\n",
      "Epoch 2370/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 212.9747 - val_loss: 124.6983\n",
      "Epoch 2371/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 129.4377 - val_loss: 111.7136\n",
      "Epoch 2372/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 120.5866 - val_loss: 108.8365\n",
      "Epoch 2373/10000\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 129.7258 - val_loss: 111.2324\n",
      "Epoch 2374/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 122.0118 - val_loss: 110.5862\n",
      "Epoch 2375/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 75us/step - loss: 130.8373 - val_loss: 107.9336\n",
      "Epoch 2376/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 122.8366 - val_loss: 107.6651\n",
      "Epoch 2377/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 125.0922 - val_loss: 104.6856\n",
      "Epoch 2378/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 124.9531 - val_loss: 103.5366\n",
      "Epoch 2379/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 125.9756 - val_loss: 146.6316\n",
      "Epoch 2380/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 129.2122 - val_loss: 114.9836\n",
      "Epoch 2381/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 126.7069 - val_loss: 124.0582\n",
      "Epoch 2382/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 131.9193 - val_loss: 109.6754\n",
      "Epoch 2383/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 242.1118 - val_loss: 114.9390\n",
      "Epoch 2384/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 125.5330 - val_loss: 110.8971\n",
      "Epoch 2385/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.3809 - val_loss: 105.1848\n",
      "Epoch 2386/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 120.6029 - val_loss: 110.4247\n",
      "Epoch 2387/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 119.5252 - val_loss: 111.8249\n",
      "Epoch 2388/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 120.4480 - val_loss: 133.5580\n",
      "Epoch 2389/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 127.8691 - val_loss: 110.0969\n",
      "Epoch 2390/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 124.7273 - val_loss: 108.5347\n",
      "Epoch 2391/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 149.4781 - val_loss: 113.7325\n",
      "Epoch 2392/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 127.1850 - val_loss: 116.7037\n",
      "Epoch 2393/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 136.6755 - val_loss: 142.3183\n",
      "Epoch 2394/10000\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 125.0615 - val_loss: 125.2306\n",
      "Epoch 2395/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 128.5279 - val_loss: 121.9092\n",
      "Epoch 2396/10000\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 134.8385 - val_loss: 122.1656\n",
      "Epoch 2397/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 136.1828 - val_loss: 109.0788\n",
      "Epoch 2398/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 155.5143 - val_loss: 172.4237\n",
      "Epoch 2399/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 163.0038 - val_loss: 108.4624\n",
      "Epoch 2400/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 118.5461 - val_loss: 108.8844\n",
      "Epoch 2401/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 119.9643 - val_loss: 118.9038\n",
      "Epoch 2402/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 125.8912 - val_loss: 115.5698\n",
      "Epoch 2403/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 125.4896 - val_loss: 107.5895\n",
      "Epoch 2404/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 142.0621 - val_loss: 108.0683\n",
      "Epoch 2405/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 122.4050 - val_loss: 117.8420\n",
      "Epoch 2406/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 127.6958 - val_loss: 113.6768\n",
      "Epoch 2407/10000\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 126.5593 - val_loss: 126.3610\n",
      "Epoch 2408/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 135.2150 - val_loss: 116.6829\n",
      "Epoch 2409/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 125.6316 - val_loss: 138.6850\n",
      "Epoch 2410/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 127.7880 - val_loss: 121.0564\n",
      "Epoch 2411/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 160.7284 - val_loss: 117.8971\n",
      "Epoch 2412/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 123.0631 - val_loss: 104.3605\n",
      "Epoch 2413/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 128.8683 - val_loss: 113.4169\n",
      "Epoch 2414/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 128.0335 - val_loss: 116.3607\n",
      "Epoch 2415/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 127.1073 - val_loss: 109.3478\n",
      "Epoch 2416/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 134.6130 - val_loss: 112.8350\n",
      "Epoch 2417/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 130.5271 - val_loss: 114.2486\n",
      "Epoch 2418/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 132.8018 - val_loss: 119.8005\n",
      "Epoch 2419/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 131.7431 - val_loss: 110.0674\n",
      "Epoch 2420/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 130.5425 - val_loss: 132.5663\n",
      "Epoch 2421/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 145.2076 - val_loss: 108.5068\n",
      "Epoch 2422/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 129.0309 - val_loss: 120.6422\n",
      "Epoch 2423/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 156.7391 - val_loss: 140.3112\n",
      "Epoch 2424/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.5765 - val_loss: 176.4460\n",
      "Epoch 2425/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 125.0432 - val_loss: 112.1258\n",
      "Epoch 2426/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 124.1848 - val_loss: 110.8796\n",
      "Epoch 2427/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 119.3049 - val_loss: 107.2765\n",
      "Epoch 2428/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 124.1184 - val_loss: 132.0948\n",
      "Epoch 2429/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 158.2040 - val_loss: 503.3883\n",
      "Epoch 2430/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 197.8194 - val_loss: 136.4267\n",
      "Epoch 2431/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 120.0971 - val_loss: 118.7904\n",
      "Epoch 2432/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 126.5191 - val_loss: 119.9086\n",
      "Epoch 2433/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 118.6601 - val_loss: 135.3217\n",
      "Epoch 2434/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 120.7158 - val_loss: 107.2360\n",
      "Epoch 2435/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 119.7026 - val_loss: 114.7804\n",
      "Epoch 2436/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 124.1762 - val_loss: 111.7399\n",
      "Epoch 2437/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 124.6025 - val_loss: 124.3122\n",
      "Epoch 2438/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 141.1954 - val_loss: 160.4121\n",
      "Epoch 2439/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 135.4952 - val_loss: 123.0666\n",
      "Epoch 2440/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 125.8686 - val_loss: 109.0842\n",
      "Epoch 2441/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 118.3459 - val_loss: 112.3458\n",
      "Epoch 2442/10000\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 126.7863 - val_loss: 115.6135\n",
      "Epoch 2443/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 132.3598 - val_loss: 118.3172\n",
      "Epoch 2444/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 139.2552 - val_loss: 106.1586\n",
      "Epoch 2445/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 131.7797 - val_loss: 110.9066\n",
      "Epoch 2446/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 138.2095 - val_loss: 122.7408\n",
      "Epoch 2447/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 65us/step - loss: 144.8312 - val_loss: 146.4249\n",
      "Epoch 2448/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 119.9317 - val_loss: 118.7263\n",
      "Epoch 2449/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 152.4012 - val_loss: 125.4571\n",
      "Epoch 2450/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.3542 - val_loss: 121.7020\n",
      "Epoch 2451/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 126.3251 - val_loss: 113.7640\n",
      "Epoch 2452/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.1964 - val_loss: 113.5234\n",
      "Epoch 2453/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 124.5695 - val_loss: 107.6384\n",
      "Epoch 2454/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 157.6725 - val_loss: 336.6016\n",
      "Epoch 2455/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 337.5144 - val_loss: 122.9765\n",
      "Epoch 2456/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 132.1417 - val_loss: 113.1188\n",
      "Epoch 2457/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 116.4986 - val_loss: 108.9417\n",
      "Epoch 2458/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 117.8244 - val_loss: 107.0725\n",
      "Epoch 2459/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 119.8969 - val_loss: 125.0312\n",
      "Epoch 2460/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.7052 - val_loss: 110.1917\n",
      "Epoch 2461/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.3334 - val_loss: 114.5522\n",
      "Epoch 2462/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 125.4931 - val_loss: 114.2954\n",
      "Epoch 2463/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 193.0600 - val_loss: 133.4247\n",
      "Epoch 2464/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 137.5375 - val_loss: 116.1371\n",
      "Epoch 2465/10000\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 128.5625 - val_loss: 112.8992\n",
      "Epoch 2466/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 119.7687 - val_loss: 144.9902\n",
      "Epoch 2467/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 122.7180 - val_loss: 115.7835\n",
      "Epoch 2468/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 121.5229 - val_loss: 109.4038\n",
      "Epoch 2469/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 120.9942 - val_loss: 111.2275\n",
      "Epoch 2470/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 126.7917 - val_loss: 140.7768\n",
      "Epoch 2471/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 128.9454 - val_loss: 109.4273\n",
      "Epoch 2472/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 126.6077 - val_loss: 141.3144\n",
      "Epoch 2473/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 128.4524 - val_loss: 140.9512\n",
      "Epoch 2474/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 129.2097 - val_loss: 111.0329A: 0s - lo\n",
      "Epoch 2475/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 133.8492 - val_loss: 125.5654\n",
      "Epoch 2476/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 131.1551 - val_loss: 127.3092\n",
      "Epoch 2477/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 122.1967 - val_loss: 124.9808\n",
      "Epoch 2478/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 126.2707 - val_loss: 135.6009\n",
      "Epoch 2479/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 149.0478 - val_loss: 151.4058\n",
      "Epoch 2480/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 126.6355 - val_loss: 159.0790\n",
      "Epoch 2481/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 133.3416 - val_loss: 121.9489\n",
      "Epoch 2482/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 123.5976 - val_loss: 113.9639\n",
      "Epoch 2483/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.5699 - val_loss: 118.5618\n",
      "Epoch 2484/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 120.6770 - val_loss: 109.3895\n",
      "Epoch 2485/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.0003 - val_loss: 112.7879\n",
      "Epoch 2486/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 139.4841 - val_loss: 105.0492\n",
      "Epoch 2487/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 127.7846 - val_loss: 123.2805\n",
      "Epoch 2488/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 124.3869 - val_loss: 150.7356\n",
      "Epoch 2489/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.1558 - val_loss: 106.9951\n",
      "Epoch 2490/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 131.4709 - val_loss: 136.3631\n",
      "Epoch 2491/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 147.8656 - val_loss: 105.5018\n",
      "Epoch 2492/10000\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 164.9354 - val_loss: 122.5920\n",
      "Epoch 2493/10000\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 134.5974 - val_loss: 114.9319\n",
      "Epoch 2494/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 121.1037 - val_loss: 113.7977\n",
      "Epoch 2495/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 128.2497 - val_loss: 152.1508\n",
      "Epoch 2496/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.2870 - val_loss: 110.0721\n",
      "Epoch 2497/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 122.4086 - val_loss: 119.8298\n",
      "Epoch 2498/10000\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 131.9611 - val_loss: 150.6346\n",
      "Epoch 2499/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 123.0368 - val_loss: 102.2046\n",
      "Epoch 2500/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 129.4546 - val_loss: 110.6507\n",
      "Epoch 2501/10000\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 131.2279 - val_loss: 129.3657\n",
      "Epoch 2502/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 150.6450 - val_loss: 107.7931\n",
      "Epoch 2503/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 130.8514 - val_loss: 111.9489\n",
      "Epoch 2504/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 124.1354 - val_loss: 111.6725\n",
      "Epoch 2505/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 123.8535 - val_loss: 119.1886\n",
      "Epoch 2506/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 120.2151 - val_loss: 107.0912\n",
      "Epoch 2507/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 126.3251 - val_loss: 111.1974\n",
      "Epoch 2508/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 121.6185 - val_loss: 135.8463\n",
      "Epoch 2509/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 137.4254 - val_loss: 215.7517\n",
      "Epoch 2510/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 124.1953 - val_loss: 118.6851\n",
      "Epoch 2511/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 125.3370 - val_loss: 135.3569\n",
      "Epoch 2512/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 125.4340 - val_loss: 107.0765\n",
      "Epoch 2513/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 146.0184 - val_loss: 134.5318\n",
      "Epoch 2514/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 127.5169 - val_loss: 125.7692\n",
      "Epoch 2515/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 127.0507 - val_loss: 103.8430\n",
      "Epoch 2516/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 120.0940 - val_loss: 107.9994\n",
      "Epoch 2517/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 135.1113 - val_loss: 135.1918\n",
      "Epoch 2518/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 126.8686 - val_loss: 128.7200\n",
      "Epoch 2519/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 75us/step - loss: 132.8970 - val_loss: 114.5516\n",
      "Epoch 2520/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 121.5292 - val_loss: 118.3784\n",
      "Epoch 2521/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 129.9879 - val_loss: 117.3626\n",
      "Epoch 2522/10000\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 125.9647 - val_loss: 112.8112\n",
      "Epoch 2523/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.0183 - val_loss: 132.6490\n",
      "Epoch 2524/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.2873 - val_loss: 118.2594\n",
      "Epoch 2525/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.1786 - val_loss: 240.7791\n",
      "Epoch 2526/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 130.7763 - val_loss: 113.2853\n",
      "Epoch 2527/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 139.2602 - val_loss: 108.3675\n",
      "Epoch 2528/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.7980 - val_loss: 154.9815\n",
      "Epoch 2529/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 135.2413 - val_loss: 142.2804\n",
      "Epoch 2530/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.4496 - val_loss: 159.9780\n",
      "Epoch 2531/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.4064 - val_loss: 106.7365\n",
      "Epoch 2532/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.1105 - val_loss: 132.1444\n",
      "Epoch 2533/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.2878 - val_loss: 108.1011\n",
      "Epoch 2534/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 160.1878 - val_loss: 133.1601\n",
      "Epoch 2535/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.0313 - val_loss: 129.7983\n",
      "Epoch 2536/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 123.2838 - val_loss: 118.5342\n",
      "Epoch 2537/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 126.6492 - val_loss: 106.8593\n",
      "Epoch 2538/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.7942 - val_loss: 139.4713\n",
      "Epoch 2539/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.9218 - val_loss: 211.4405\n",
      "Epoch 2540/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.8064 - val_loss: 126.3945\n",
      "Epoch 2541/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.2158 - val_loss: 115.1551\n",
      "Epoch 2542/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 125.3107 - val_loss: 116.6997\n",
      "Epoch 2543/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.3622 - val_loss: 111.0329\n",
      "Epoch 2544/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.5419 - val_loss: 109.7739\n",
      "Epoch 2545/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 130.8489 - val_loss: 106.0979\n",
      "Epoch 2546/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 136.4779 - val_loss: 131.5320\n",
      "Epoch 2547/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 151.9222 - val_loss: 118.7956\n",
      "Epoch 2548/10000\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 130.9390 - val_loss: 109.6437\n",
      "Epoch 2549/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 122.2639 - val_loss: 112.6117\n",
      "Epoch 2550/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 128.5594 - val_loss: 108.9046\n",
      "Epoch 2551/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 126.4544 - val_loss: 111.9021\n",
      "Epoch 2552/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 123.5789 - val_loss: 117.1287\n",
      "Epoch 2553/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 191.7775 - val_loss: 112.8516\n",
      "Epoch 2554/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 127.4633 - val_loss: 111.0320\n",
      "Epoch 2555/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.1132 - val_loss: 113.9579\n",
      "Epoch 2556/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 120.9383 - val_loss: 118.6848\n",
      "Epoch 2557/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.3748 - val_loss: 111.1239\n",
      "Epoch 2558/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 126.9956 - val_loss: 139.7554\n",
      "Epoch 2559/10000\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 125.6211 - val_loss: 132.9459\n",
      "Epoch 2560/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 119.8413 - val_loss: 119.0066\n",
      "Epoch 2561/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 122.5001 - val_loss: 110.3173\n",
      "Epoch 2562/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 127.0577 - val_loss: 143.9818\n",
      "Epoch 2563/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.5382 - val_loss: 114.0361\n",
      "Epoch 2564/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 126.1267 - val_loss: 133.8210\n",
      "Epoch 2565/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 207.9206 - val_loss: 109.3826\n",
      "Epoch 2566/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 119.9520 - val_loss: 114.7842\n",
      "Epoch 2567/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 115.9169 - val_loss: 129.5094\n",
      "Epoch 2568/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 121.7942 - val_loss: 116.3272\n",
      "Epoch 2569/10000\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 117.0937 - val_loss: 113.0142\n",
      "Epoch 2570/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 134.5314 - val_loss: 118.6327\n",
      "Epoch 2571/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 120.1314 - val_loss: 110.8995\n",
      "Epoch 2572/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 126.8548 - val_loss: 108.3144\n",
      "Epoch 2573/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 121.6958 - val_loss: 104.9311\n",
      "Epoch 2574/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 127.2059 - val_loss: 142.5406\n",
      "Epoch 2575/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 131.1652 - val_loss: 268.7549\n",
      "Epoch 2576/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 275.1933 - val_loss: 115.8133\n",
      "Epoch 2577/10000\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 127.4525 - val_loss: 117.8434\n",
      "Epoch 2578/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 122.6603 - val_loss: 107.2205\n",
      "Epoch 2579/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 119.1357 - val_loss: 107.3569\n",
      "Epoch 2580/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 121.0180 - val_loss: 106.7617\n",
      "Epoch 2581/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 117.0653 - val_loss: 139.0026\n",
      "Epoch 2582/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 128.0707 - val_loss: 124.4726\n",
      "Epoch 2583/10000\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 121.9725 - val_loss: 113.1448\n",
      "Epoch 2584/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 124.3723 - val_loss: 118.6298\n",
      "Epoch 2585/10000\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 126.7532 - val_loss: 146.6104\n",
      "Epoch 2586/10000\n",
      "8000/8000 [==============================] - 1s 176us/step - loss: 152.0012 - val_loss: 148.9661\n",
      "Epoch 2587/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 128.1822 - val_loss: 118.3098\n",
      "Epoch 2588/10000\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 119.6501 - val_loss: 106.8657\n",
      "Epoch 2589/10000\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 118.5142 - val_loss: 114.3634\n",
      "Epoch 2590/10000\n",
      "8000/8000 [==============================] - 2s 261us/step - loss: 127.5330 - val_loss: 165.8311\n",
      "Epoch 2591/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 177us/step - loss: 119.9711 - val_loss: 111.7078\n",
      "Epoch 2592/10000\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 123.9293 - val_loss: 117.1005\n",
      "Epoch 2593/10000\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 127.9690 - val_loss: 117.5317\n",
      "Epoch 2594/10000\n",
      "8000/8000 [==============================] - 1s 179us/step - loss: 160.1036 - val_loss: 133.6090\n",
      "Epoch 2595/10000\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 131.3818 - val_loss: 111.5298\n",
      "Epoch 2596/10000\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 125.9878 - val_loss: 113.8713\n",
      "Epoch 2597/10000\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 124.9480 - val_loss: 116.6246\n",
      "Epoch 2598/10000\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 130.1194 - val_loss: 110.9293\n",
      "Epoch 2599/10000\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 136.6234 - val_loss: 112.3646\n",
      "Epoch 2600/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 123.5689 - val_loss: 110.6542\n",
      "Epoch 2601/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 124.3108 - val_loss: 109.3263\n",
      "Epoch 2602/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 119.2945 - val_loss: 115.0714\n",
      "Epoch 2603/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 124.7243 - val_loss: 133.6312\n",
      "Epoch 2604/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 130.0251 - val_loss: 110.7545\n",
      "Epoch 2605/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 123.0349 - val_loss: 116.4631\n",
      "Epoch 2606/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 128.5119 - val_loss: 108.3465\n",
      "Epoch 2607/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.0609 - val_loss: 110.5699\n",
      "Epoch 2608/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.2125 - val_loss: 118.4481\n",
      "Epoch 2609/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.4497 - val_loss: 131.4039\n",
      "Epoch 2610/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 199.5776 - val_loss: 114.3530\n",
      "Epoch 2611/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 120.8081 - val_loss: 112.1005\n",
      "Epoch 2612/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 123.4753 - val_loss: 115.4377\n",
      "Epoch 2613/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 122.6041 - val_loss: 111.7738\n",
      "Epoch 2614/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 120.6736 - val_loss: 111.9916\n",
      "Epoch 2615/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 121.9584 - val_loss: 110.3713\n",
      "Epoch 2616/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.1875 - val_loss: 184.3642\n",
      "Epoch 2617/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 129.0113 - val_loss: 105.7213\n",
      "Epoch 2618/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 160.8537 - val_loss: 111.1022\n",
      "Epoch 2619/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 119.9126 - val_loss: 121.8354\n",
      "Epoch 2620/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.6679 - val_loss: 118.1308\n",
      "Epoch 2621/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.6599 - val_loss: 109.6985\n",
      "Epoch 2622/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.3770 - val_loss: 111.7661\n",
      "Epoch 2623/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.8429 - val_loss: 114.9774\n",
      "Epoch 2624/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.5821 - val_loss: 133.8945\n",
      "Epoch 2625/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.3457 - val_loss: 105.8200\n",
      "Epoch 2626/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 134.3632 - val_loss: 108.5591\n",
      "Epoch 2627/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 128.410 - 0s 56us/step - loss: 121.8525 - val_loss: 107.5664\n",
      "Epoch 2628/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 176.9168 - val_loss: 124.8765\n",
      "Epoch 2629/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 125.1197 - val_loss: 104.9232\n",
      "Epoch 2630/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.3874 - val_loss: 109.4223\n",
      "Epoch 2631/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 123.9401 - val_loss: 108.3386\n",
      "Epoch 2632/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 117.5240 - val_loss: 108.7511\n",
      "Epoch 2633/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 126.1058 - val_loss: 132.2034\n",
      "Epoch 2634/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 122.4170 - val_loss: 127.1058\n",
      "Epoch 2635/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.0177 - val_loss: 112.9948\n",
      "Epoch 2636/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.6323 - val_loss: 187.4408\n",
      "Epoch 2637/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 130.2110 - val_loss: 122.2032\n",
      "Epoch 2638/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.7801 - val_loss: 110.5926\n",
      "Epoch 2639/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.7820 - val_loss: 110.9165\n",
      "Epoch 2640/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.6460 - val_loss: 104.9123\n",
      "Epoch 2641/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 127.0473 - val_loss: 118.9415\n",
      "Epoch 2642/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 127.0734 - val_loss: 124.2264\n",
      "Epoch 2643/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 126.6305 - val_loss: 133.9251\n",
      "Epoch 2644/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 123.9671 - val_loss: 145.9468\n",
      "Epoch 2645/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 122.7574 - val_loss: 116.1898\n",
      "Epoch 2646/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 127.8660 - val_loss: 116.7024\n",
      "Epoch 2647/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 131.2849 - val_loss: 115.6697\n",
      "Epoch 2648/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.7308 - val_loss: 108.1751\n",
      "Epoch 2649/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 122.0370 - val_loss: 106.7343\n",
      "Epoch 2650/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 135.5392 - val_loss: 125.4728\n",
      "Epoch 2651/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 124.9602 - val_loss: 131.4234\n",
      "Epoch 2652/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.8155 - val_loss: 105.7884\n",
      "Epoch 2653/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 137.7005 - val_loss: 113.1292\n",
      "Epoch 2654/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 129.6622 - val_loss: 116.6270\n",
      "Epoch 2655/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 121.9025 - val_loss: 136.9866\n",
      "Epoch 2656/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 130.6274 - val_loss: 120.2589\n",
      "Epoch 2657/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 143.8897 - val_loss: 121.5085\n",
      "Epoch 2658/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 121.0260 - val_loss: 125.6150\n",
      "Epoch 2659/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 116.8867 - val_loss: 127.4536\n",
      "Epoch 2660/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 128.2080 - val_loss: 135.1716\n",
      "Epoch 2661/10000\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 131.0672 - val_loss: 140.1173\n",
      "Epoch 2662/10000\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 137.7526 - val_loss: 139.6087\n",
      "Epoch 2663/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 88us/step - loss: 133.7445 - val_loss: 110.7584\n",
      "Epoch 2664/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 129.3081 - val_loss: 116.6829\n",
      "Epoch 2665/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 128.6509 - val_loss: 113.0464\n",
      "Epoch 2666/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.9469 - val_loss: 151.1811\n",
      "Epoch 2667/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.2635 - val_loss: 168.6425\n",
      "Epoch 2668/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 142.9532 - val_loss: 148.1444\n",
      "Epoch 2669/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 123.1229 - val_loss: 119.9550\n",
      "Epoch 2670/10000\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 208.9172 - val_loss: 117.7269\n",
      "Epoch 2671/10000\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 117.1020 - val_loss: 111.2860\n",
      "Epoch 2672/10000\n",
      "8000/8000 [==============================] - 1s 154us/step - loss: 128.1394 - val_loss: 108.0870\n",
      "Epoch 2673/10000\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 118.9021 - val_loss: 165.2834\n",
      "Epoch 2674/10000\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 117.4146 - val_loss: 114.0825\n",
      "Epoch 2675/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 120.3507 - val_loss: 121.0283\n",
      "Epoch 2676/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 127.3371 - val_loss: 110.2959\n",
      "Epoch 2677/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 127.1186 - val_loss: 130.8488\n",
      "Epoch 2678/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 136.0036 - val_loss: 108.5900\n",
      "Epoch 2679/10000\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 122.3426 - val_loss: 113.3768\n",
      "Epoch 2680/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.8749 - val_loss: 111.4312\n",
      "Epoch 2681/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 130.9429 - val_loss: 113.0557\n",
      "Epoch 2682/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 131.6377 - val_loss: 139.4058\n",
      "Epoch 2683/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 216.7263 - val_loss: 107.5894\n",
      "Epoch 2684/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 116.6685 - val_loss: 106.0414\n",
      "Epoch 2685/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 113.0137 - val_loss: 112.9997\n",
      "Epoch 2686/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 115.3293 - val_loss: 111.7462\n",
      "Epoch 2687/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 128.8706 - val_loss: 109.9983\n",
      "Epoch 2688/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 118.5105 - val_loss: 130.6022\n",
      "Epoch 2689/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.9705 - val_loss: 126.1564\n",
      "Epoch 2690/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 153.5870 - val_loss: 184.0758\n",
      "Epoch 2691/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.8797 - val_loss: 126.0036\n",
      "Epoch 2692/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 116.5067 - val_loss: 111.1268\n",
      "Epoch 2693/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 118.2157 - val_loss: 127.1184\n",
      "Epoch 2694/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 118.4112 - val_loss: 123.3534\n",
      "Epoch 2695/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 123.0147 - val_loss: 108.2521\n",
      "Epoch 2696/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.5742 - val_loss: 114.1935\n",
      "Epoch 2697/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.7418 - val_loss: 135.0753\n",
      "Epoch 2698/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.5753 - val_loss: 121.9252\n",
      "Epoch 2699/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 121.4540 - val_loss: 112.5376\n",
      "Epoch 2700/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.7620 - val_loss: 120.2778\n",
      "Epoch 2701/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.5285 - val_loss: 115.4982\n",
      "Epoch 2702/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.2155 - val_loss: 116.0689\n",
      "Epoch 2703/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.4334 - val_loss: 109.2560\n",
      "Epoch 2704/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 131.4538 - val_loss: 120.7508\n",
      "Epoch 2705/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.1449 - val_loss: 111.8474\n",
      "Epoch 2706/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.7968 - val_loss: 111.9429\n",
      "Epoch 2707/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.6593 - val_loss: 118.1402\n",
      "Epoch 2708/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 273.5312 - val_loss: 138.4418\n",
      "Epoch 2709/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.5557 - val_loss: 118.2167\n",
      "Epoch 2710/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.4583 - val_loss: 115.7274\n",
      "Epoch 2711/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.5770 - val_loss: 118.1307\n",
      "Epoch 2712/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.4171 - val_loss: 107.4568\n",
      "Epoch 2713/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.7667 - val_loss: 111.3893\n",
      "Epoch 2714/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 121.6567 - val_loss: 123.7208\n",
      "Epoch 2715/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 153.0887 - val_loss: 114.9515\n",
      "Epoch 2716/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 146.9232 - val_loss: 114.8789\n",
      "Epoch 2717/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.4329 - val_loss: 111.4582\n",
      "Epoch 2718/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 118.7077 - val_loss: 122.3704\n",
      "Epoch 2719/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.7185 - val_loss: 107.5799\n",
      "Epoch 2720/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 148.0150 - val_loss: 104.9849\n",
      "Epoch 2721/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 133.9147 - val_loss: 115.9696\n",
      "Epoch 2722/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 140.6509 - val_loss: 109.4450\n",
      "Epoch 2723/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.5850 - val_loss: 112.2840\n",
      "Epoch 2724/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 128.4455 - val_loss: 111.4351\n",
      "Epoch 2725/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 136.2230 - val_loss: 116.6198\n",
      "Epoch 2726/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.9373 - val_loss: 119.6690\n",
      "Epoch 2727/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.2709 - val_loss: 115.7034\n",
      "Epoch 2728/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.7712 - val_loss: 115.2664\n",
      "Epoch 2729/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.7688 - val_loss: 120.9457\n",
      "Epoch 2730/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 135.2637 - val_loss: 139.5786\n",
      "Epoch 2731/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 131.6112 - val_loss: 122.3351\n",
      "Epoch 2732/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.7747 - val_loss: 106.0853\n",
      "Epoch 2733/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.9546 - val_loss: 107.2374\n",
      "Epoch 2734/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.2867 - val_loss: 111.5642\n",
      "Epoch 2735/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.8354 - val_loss: 117.1186\n",
      "Epoch 2736/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 162.4387 - val_loss: 117.4463\n",
      "Epoch 2737/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.7486 - val_loss: 111.9217\n",
      "Epoch 2738/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.8370 - val_loss: 107.5095\n",
      "Epoch 2739/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.5966 - val_loss: 135.0951\n",
      "Epoch 2740/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 118.4970 - val_loss: 119.6907\n",
      "Epoch 2741/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 162.2820 - val_loss: 162.6692\n",
      "Epoch 2742/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 199.5948 - val_loss: 112.0228\n",
      "Epoch 2743/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 123.2795 - val_loss: 152.6849\n",
      "Epoch 2744/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 128.1441 - val_loss: 110.8856\n",
      "Epoch 2745/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 127.0534 - val_loss: 117.4300\n",
      "Epoch 2746/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.9328 - val_loss: 113.5024\n",
      "Epoch 2747/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.5091 - val_loss: 161.1165\n",
      "Epoch 2748/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 117.9492 - val_loss: 108.3705\n",
      "Epoch 2749/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 120.3954 - val_loss: 127.2546\n",
      "Epoch 2750/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 119.0023 - val_loss: 117.1240\n",
      "Epoch 2751/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 118.5509 - val_loss: 130.0088\n",
      "Epoch 2752/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 122.8769 - val_loss: 120.5116\n",
      "Epoch 2753/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 116.5102 - val_loss: 110.1893\n",
      "Epoch 2754/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 125.5869 - val_loss: 149.1341\n",
      "Epoch 2755/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 117.8617 - val_loss: 122.0961\n",
      "Epoch 2756/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 170.2121 - val_loss: 113.6063\n",
      "Epoch 2757/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 129.4487 - val_loss: 151.1104\n",
      "Epoch 2758/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 131.5336 - val_loss: 114.3547\n",
      "Epoch 2759/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.9756 - val_loss: 113.6286\n",
      "Epoch 2760/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.2355 - val_loss: 107.9597\n",
      "Epoch 2761/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 134.1930 - val_loss: 110.7125\n",
      "Epoch 2762/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.3629 - val_loss: 148.6944\n",
      "Epoch 2763/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 118.5093 - val_loss: 107.0176\n",
      "Epoch 2764/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 121.8987 - val_loss: 120.2938\n",
      "Epoch 2765/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 121.3619 - val_loss: 119.3503\n",
      "Epoch 2766/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 120.3894 - val_loss: 122.8379\n",
      "Epoch 2767/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 118.3361 - val_loss: 147.2591\n",
      "Epoch 2768/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 127.0509 - val_loss: 120.8933\n",
      "Epoch 2769/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 130.6630 - val_loss: 113.0311\n",
      "Epoch 2770/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 122.1384 - val_loss: 117.9918\n",
      "Epoch 2771/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 124.0801 - val_loss: 108.9840\n",
      "Epoch 2772/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 124.0612 - val_loss: 108.3131\n",
      "Epoch 2773/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 122.5385 - val_loss: 110.2599\n",
      "Epoch 2774/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.5172 - val_loss: 110.9959\n",
      "Epoch 2775/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 125.0430 - val_loss: 110.2244\n",
      "Epoch 2776/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 116.9222 - val_loss: 105.0846\n",
      "Epoch 2777/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 124.7990 - val_loss: 123.8572\n",
      "Epoch 2778/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 120.1791 - val_loss: 178.2257\n",
      "Epoch 2779/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 126.216 - 1s 77us/step - loss: 126.0251 - val_loss: 136.2122\n",
      "Epoch 2780/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 125.3192 - val_loss: 108.1267\n",
      "Epoch 2781/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 127.4040 - val_loss: 109.0963\n",
      "Epoch 2782/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 129.6009 - val_loss: 117.0933\n",
      "Epoch 2783/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 122.5966 - val_loss: 119.4045\n",
      "Epoch 2784/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.1117 - val_loss: 138.6807\n",
      "Epoch 2785/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 186.3556 - val_loss: 115.5831\n",
      "Epoch 2786/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 191.9042 - val_loss: 111.2826\n",
      "Epoch 2787/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 118.3183 - val_loss: 105.3030\n",
      "Epoch 2788/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 118.9807 - val_loss: 119.6522\n",
      "Epoch 2789/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 114.1034 - val_loss: 118.9092\n",
      "Epoch 2790/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 116.9549 - val_loss: 117.9277\n",
      "Epoch 2791/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 124.9421 - val_loss: 136.3103\n",
      "Epoch 2792/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 131.3066 - val_loss: 130.9948\n",
      "Epoch 2793/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 117.5113 - val_loss: 110.0506\n",
      "Epoch 2794/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 117.1178 - val_loss: 140.4681\n",
      "Epoch 2795/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 125.1842 - val_loss: 105.5735\n",
      "Epoch 2796/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 126.9880 - val_loss: 109.9835\n",
      "Epoch 2797/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 121.6027 - val_loss: 152.5573\n",
      "Epoch 2798/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.8509 - val_loss: 131.9413\n",
      "Epoch 2799/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 124.7240 - val_loss: 130.3647\n",
      "Epoch 2800/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 126.9146 - val_loss: 108.1205\n",
      "Epoch 2801/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 126.9197 - val_loss: 180.6107\n",
      "Epoch 2802/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 157.2429 - val_loss: 148.5338\n",
      "Epoch 2803/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 122.8848 - val_loss: 119.9770\n",
      "Epoch 2804/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 121.0702 - val_loss: 115.0635\n",
      "Epoch 2805/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 129.1442 - val_loss: 109.2194\n",
      "Epoch 2806/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 123.3218 - val_loss: 132.6433\n",
      "Epoch 2807/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 73us/step - loss: 186.3051 - val_loss: 121.2122\n",
      "Epoch 2808/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 140.5865 - val_loss: 123.5202\n",
      "Epoch 2809/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 127.7623 - val_loss: 174.5714\n",
      "Epoch 2810/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.6438 - val_loss: 112.9097\n",
      "Epoch 2811/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 120.3966 - val_loss: 118.5612\n",
      "Epoch 2812/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.0193 - val_loss: 109.6835\n",
      "Epoch 2813/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 160.6797 - val_loss: 116.8825\n",
      "Epoch 2814/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 125.3121 - val_loss: 115.4013\n",
      "Epoch 2815/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 119.2937 - val_loss: 116.6347\n",
      "Epoch 2816/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.0289 - val_loss: 124.6249\n",
      "Epoch 2817/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 122.3496 - val_loss: 105.5906\n",
      "Epoch 2818/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 118.0217 - val_loss: 114.8824\n",
      "Epoch 2819/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 156.9438 - val_loss: 139.7271\n",
      "Epoch 2820/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 120.2713 - val_loss: 139.9991\n",
      "Epoch 2821/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 118.6045 - val_loss: 128.8023\n",
      "Epoch 2822/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 119.8117 - val_loss: 144.9857\n",
      "Epoch 2823/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 119.6678 - val_loss: 125.7188\n",
      "Epoch 2824/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.2358 - val_loss: 119.9367\n",
      "Epoch 2825/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 119.2499 - val_loss: 111.5504\n",
      "Epoch 2826/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.8666 - val_loss: 138.2181\n",
      "Epoch 2827/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.3852 - val_loss: 120.9483\n",
      "Epoch 2828/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 126.8122 - val_loss: 128.7733\n",
      "Epoch 2829/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 123.7477 - val_loss: 176.1470\n",
      "Epoch 2830/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.7751 - val_loss: 113.7195\n",
      "Epoch 2831/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 125.0468 - val_loss: 121.7861\n",
      "Epoch 2832/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 121.9529 - val_loss: 253.9932\n",
      "Epoch 2833/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 132.7660 - val_loss: 181.4264\n",
      "Epoch 2834/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 128.2171 - val_loss: 128.6441\n",
      "Epoch 2835/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.7771 - val_loss: 172.5725\n",
      "Epoch 2836/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 129.5538 - val_loss: 115.6070\n",
      "Epoch 2837/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 118.0099 - val_loss: 111.5903\n",
      "Epoch 2838/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 135.8186 - val_loss: 119.9910\n",
      "Epoch 2839/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 115.9457 - val_loss: 118.0048\n",
      "Epoch 2840/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 124.1265 - val_loss: 108.8756\n",
      "Epoch 2841/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.8478 - val_loss: 115.6654\n",
      "Epoch 2842/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 138.3738 - val_loss: 132.1510\n",
      "Epoch 2843/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 162.2012 - val_loss: 150.6943\n",
      "Epoch 2844/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 177.6148 - val_loss: 114.3739\n",
      "Epoch 2845/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 113.6123 - val_loss: 107.9674\n",
      "Epoch 2846/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 115.9809 - val_loss: 106.2504\n",
      "Epoch 2847/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.4545 - val_loss: 120.6943\n",
      "Epoch 2848/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.6208 - val_loss: 119.0185\n",
      "Epoch 2849/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.3774 - val_loss: 126.6459\n",
      "Epoch 2850/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.8534 - val_loss: 113.2376\n",
      "Epoch 2851/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.0929 - val_loss: 119.0805\n",
      "Epoch 2852/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1037 - val_loss: 113.5124\n",
      "Epoch 2853/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 127.7534 - val_loss: 142.0555\n",
      "Epoch 2854/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 124.0219 - val_loss: 115.8816\n",
      "Epoch 2855/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 151.8606 - val_loss: 161.9766\n",
      "Epoch 2856/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.2178 - val_loss: 110.4638\n",
      "Epoch 2857/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 128.6250 - val_loss: 141.3375\n",
      "Epoch 2858/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.3832 - val_loss: 121.9047\n",
      "Epoch 2859/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.4304 - val_loss: 129.4703\n",
      "Epoch 2860/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.3484 - val_loss: 112.6182\n",
      "Epoch 2861/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 146.4106 - val_loss: 141.4471\n",
      "Epoch 2862/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.5543 - val_loss: 108.6513\n",
      "Epoch 2863/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 163.1119 - val_loss: 118.7802\n",
      "Epoch 2864/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.1295 - val_loss: 116.6447\n",
      "Epoch 2865/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.9335 - val_loss: 113.0969\n",
      "Epoch 2866/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.3215 - val_loss: 109.7119\n",
      "Epoch 2867/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.2842 - val_loss: 125.0584\n",
      "Epoch 2868/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.5253 - val_loss: 110.4175\n",
      "Epoch 2869/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.8904 - val_loss: 118.8431\n",
      "Epoch 2870/10000\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 118.6555 - val_loss: 115.5313\n",
      "Epoch 2871/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 126.7532 - val_loss: 115.9049\n",
      "Epoch 2872/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 127.0371 - val_loss: 114.6006\n",
      "Epoch 2873/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.7262 - val_loss: 114.1914\n",
      "Epoch 2874/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 116.9033 - val_loss: 115.6085\n",
      "Epoch 2875/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 136.4205 - val_loss: 127.3762\n",
      "Epoch 2876/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.3622 - val_loss: 113.1769\n",
      "Epoch 2877/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 126.9942 - val_loss: 108.9853\n",
      "Epoch 2878/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 127.3091 - val_loss: 111.8656\n",
      "Epoch 2879/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.7993 - val_loss: 111.0855\n",
      "Epoch 2880/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 146.4694 - val_loss: 194.2506\n",
      "Epoch 2881/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.0841 - val_loss: 126.3508\n",
      "Epoch 2882/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 134.8335 - val_loss: 112.9316\n",
      "Epoch 2883/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.0632 - val_loss: 120.8402\n",
      "Epoch 2884/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.8970 - val_loss: 117.7715\n",
      "Epoch 2885/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.8550 - val_loss: 114.6833\n",
      "Epoch 2886/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.9940 - val_loss: 131.6750\n",
      "Epoch 2887/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.7270 - val_loss: 108.9514\n",
      "Epoch 2888/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.3029 - val_loss: 118.3747\n",
      "Epoch 2889/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.1738 - val_loss: 108.6497\n",
      "Epoch 2890/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.2662 - val_loss: 111.8499\n",
      "Epoch 2891/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.5504 - val_loss: 109.2181\n",
      "Epoch 2892/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.9500 - val_loss: 117.8619\n",
      "Epoch 2893/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.8473 - val_loss: 127.7721\n",
      "Epoch 2894/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 116.0672 - val_loss: 121.8025\n",
      "Epoch 2895/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 123.8575 - val_loss: 112.1978\n",
      "Epoch 2896/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 124.9901 - val_loss: 404.5477\n",
      "Epoch 2897/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 164.3148 - val_loss: 120.8484\n",
      "Epoch 2898/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 119.1855 - val_loss: 108.9533\n",
      "Epoch 2899/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 121.7306 - val_loss: 109.0377\n",
      "Epoch 2900/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 114.9961 - val_loss: 124.8761\n",
      "Epoch 2901/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 113.6589 - val_loss: 116.2819\n",
      "Epoch 2902/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.0590 - val_loss: 110.6674\n",
      "Epoch 2903/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.6317 - val_loss: 121.2353\n",
      "Epoch 2904/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.0948 - val_loss: 127.6644\n",
      "Epoch 2905/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 120.0749 - val_loss: 222.9140\n",
      "Epoch 2906/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 115.5495 - val_loss: 108.6750\n",
      "Epoch 2907/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 116.8238 - val_loss: 118.7251\n",
      "Epoch 2908/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.3453 - val_loss: 137.7875\n",
      "Epoch 2909/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.5562 - val_loss: 140.8434\n",
      "Epoch 2910/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 123.7898 - val_loss: 113.9944\n",
      "Epoch 2911/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 121.6340 - val_loss: 121.0928\n",
      "Epoch 2912/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 118.8054 - val_loss: 115.3681\n",
      "Epoch 2913/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 121.0286 - val_loss: 115.4579\n",
      "Epoch 2914/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 130.1894 - val_loss: 131.0112\n",
      "Epoch 2915/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 116.0988 - val_loss: 128.9449\n",
      "Epoch 2916/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.1520 - val_loss: 115.9295\n",
      "Epoch 2917/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 122.3942 - val_loss: 121.3394\n",
      "Epoch 2918/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 118.4999 - val_loss: 143.8408\n",
      "Epoch 2919/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 123.8602 - val_loss: 110.7036\n",
      "Epoch 2920/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 185.7720 - val_loss: 2568.4469\n",
      "Epoch 2921/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 331.5842 - val_loss: 145.8344\n",
      "Epoch 2922/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 168.4684 - val_loss: 123.3380\n",
      "Epoch 2923/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 172.9204 - val_loss: 132.3786\n",
      "Epoch 2924/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 159.2083 - val_loss: 118.0619\n",
      "Epoch 2925/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 139.8083 - val_loss: 114.1413\n",
      "Epoch 2926/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 135.7574 - val_loss: 121.1302\n",
      "Epoch 2927/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 138.4392 - val_loss: 132.5730\n",
      "Epoch 2928/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 138.3519 - val_loss: 111.1851\n",
      "Epoch 2929/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 151.3571 - val_loss: 173.5103\n",
      "Epoch 2930/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 134.5697 - val_loss: 126.7266\n",
      "Epoch 2931/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 136.5656 - val_loss: 119.2950\n",
      "Epoch 2932/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 133.6554 - val_loss: 131.7554\n",
      "Epoch 2933/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 137.1244 - val_loss: 118.0151\n",
      "Epoch 2934/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 126.1420 - val_loss: 112.0112\n",
      "Epoch 2935/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 127.1403 - val_loss: 117.5127\n",
      "Epoch 2936/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 143.8788 - val_loss: 139.1202\n",
      "Epoch 2937/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 145.7367 - val_loss: 139.7581\n",
      "Epoch 2938/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 134.0234 - val_loss: 111.1413\n",
      "Epoch 2939/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 134.9102 - val_loss: 136.6858\n",
      "Epoch 2940/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 138.6715 - val_loss: 110.7163\n",
      "Epoch 2941/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 133.8031 - val_loss: 108.6164\n",
      "Epoch 2942/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 120.4731 - val_loss: 109.6499\n",
      "Epoch 2943/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 131.2977 - val_loss: 109.6559\n",
      "Epoch 2944/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 119.6506 - val_loss: 114.5727\n",
      "Epoch 2945/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 124.8823 - val_loss: 129.6573\n",
      "Epoch 2946/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 126.8462 - val_loss: 164.3971\n",
      "Epoch 2947/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 124.5291 - val_loss: 109.2185\n",
      "Epoch 2948/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 119.9547 - val_loss: 111.2023\n",
      "Epoch 2949/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 119.1212 - val_loss: 131.6211\n",
      "Epoch 2950/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.5683 - val_loss: 113.1655\n",
      "Epoch 2951/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 59us/step - loss: 124.2597 - val_loss: 111.2021\n",
      "Epoch 2952/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 125.5512 - val_loss: 115.3966\n",
      "Epoch 2953/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 117.6031 - val_loss: 112.5890\n",
      "Epoch 2954/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 157.7799 - val_loss: 126.0566\n",
      "Epoch 2955/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.2126 - val_loss: 125.6720\n",
      "Epoch 2956/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.3728 - val_loss: 105.4232\n",
      "Epoch 2957/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.9441 - val_loss: 107.2731\n",
      "Epoch 2958/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.8066 - val_loss: 111.1739\n",
      "Epoch 2959/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.1861 - val_loss: 107.8614\n",
      "Epoch 2960/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.8559 - val_loss: 126.5845\n",
      "Epoch 2961/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.7946 - val_loss: 110.3754\n",
      "Epoch 2962/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 127.9090 - val_loss: 184.3838\n",
      "Epoch 2963/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 132.9679 - val_loss: 115.7613\n",
      "Epoch 2964/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 146.7601 - val_loss: 126.4105\n",
      "Epoch 2965/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.2563 - val_loss: 139.3047\n",
      "Epoch 2966/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.3336 - val_loss: 131.2272\n",
      "Epoch 2967/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.3020 - val_loss: 117.7875\n",
      "Epoch 2968/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.9031 - val_loss: 114.0909\n",
      "Epoch 2969/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 119.0896 - val_loss: 114.6280\n",
      "Epoch 2970/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 125.2496 - val_loss: 118.4999\n",
      "Epoch 2971/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 126.7649 - val_loss: 116.5686\n",
      "Epoch 2972/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 151.3045 - val_loss: 121.3258\n",
      "Epoch 2973/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 136.1115 - val_loss: 120.8674\n",
      "Epoch 2974/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.0510 - val_loss: 117.1222\n",
      "Epoch 2975/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 119.0478 - val_loss: 113.8070\n",
      "Epoch 2976/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.2878 - val_loss: 114.2643\n",
      "Epoch 2977/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.8314 - val_loss: 117.7819\n",
      "Epoch 2978/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.5106 - val_loss: 119.1661\n",
      "Epoch 2979/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 180.2322 - val_loss: 128.8176\n",
      "Epoch 2980/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.3962 - val_loss: 110.1041\n",
      "Epoch 2981/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.1363 - val_loss: 114.4892\n",
      "Epoch 2982/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 119.0886 - val_loss: 114.2313\n",
      "Epoch 2983/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 116.5533 - val_loss: 116.5248\n",
      "Epoch 2984/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 120.3382 - val_loss: 162.0644\n",
      "Epoch 2985/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.7983 - val_loss: 114.2031\n",
      "Epoch 2986/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 118.2889 - val_loss: 114.0098\n",
      "Epoch 2987/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 126.8888 - val_loss: 117.6653\n",
      "Epoch 2988/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 129.4573 - val_loss: 117.7064\n",
      "Epoch 2989/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 119.3110 - val_loss: 112.7593\n",
      "Epoch 2990/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 117.0861 - val_loss: 116.9409\n",
      "Epoch 2991/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 124.4436 - val_loss: 117.9920\n",
      "Epoch 2992/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.5216 - val_loss: 109.3392\n",
      "Epoch 2993/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 120.2764 - val_loss: 107.3714\n",
      "Epoch 2994/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.6659 - val_loss: 119.5494\n",
      "Epoch 2995/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.2807 - val_loss: 122.5886\n",
      "Epoch 2996/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 323.5984 - val_loss: 244.6549\n",
      "Epoch 2997/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 183.8553 - val_loss: 120.1328\n",
      "Epoch 2998/10000\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 122.9314 - val_loss: 116.0978\n",
      "Epoch 2999/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 125.7113 - val_loss: 108.0892\n",
      "Epoch 3000/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 117.7593 - val_loss: 110.3775\n",
      "Epoch 3001/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 132.9020 - val_loss: 116.6807\n",
      "Epoch 3002/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.3025 - val_loss: 111.0377\n",
      "Epoch 3003/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.0761 - val_loss: 111.9415\n",
      "Epoch 3004/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.4729 - val_loss: 109.8212\n",
      "Epoch 3005/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.1977 - val_loss: 112.1595\n",
      "Epoch 3006/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 154.6300 - val_loss: 108.3106\n",
      "Epoch 3007/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 118.8066 - val_loss: 113.4723\n",
      "Epoch 3008/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 127.6419 - val_loss: 117.5873\n",
      "Epoch 3009/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 119.2991 - val_loss: 110.9180\n",
      "Epoch 3010/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 117.9708 - val_loss: 126.9785\n",
      "Epoch 3011/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 124.6506 - val_loss: 113.3992\n",
      "Epoch 3012/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.8549 - val_loss: 168.2490\n",
      "Epoch 3013/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.6901 - val_loss: 120.3757\n",
      "Epoch 3014/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.6165 - val_loss: 109.0617\n",
      "Epoch 3015/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.4906 - val_loss: 121.8571\n",
      "Epoch 3016/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.3167 - val_loss: 119.1622\n",
      "Epoch 3017/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 121.1360 - val_loss: 112.1962\n",
      "Epoch 3018/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 124.5261 - val_loss: 111.7043\n",
      "Epoch 3019/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 117.6628 - val_loss: 134.2908\n",
      "Epoch 3020/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 125.8202 - val_loss: 188.4255\n",
      "Epoch 3021/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 122.2010 - val_loss: 109.7048\n",
      "Epoch 3022/10000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 122.695 - 1s 64us/step - loss: 125.5300 - val_loss: 112.7909\n",
      "Epoch 3023/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.2303 - val_loss: 122.8580\n",
      "Epoch 3024/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 120.4710 - val_loss: 124.5144\n",
      "Epoch 3025/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 126.1617 - val_loss: 132.5476\n",
      "Epoch 3026/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.8832 - val_loss: 121.8573\n",
      "Epoch 3027/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 125.2482 - val_loss: 174.7934\n",
      "Epoch 3028/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.1176 - val_loss: 114.7373\n",
      "Epoch 3029/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.1206 - val_loss: 119.9507\n",
      "Epoch 3030/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 120.5277 - val_loss: 117.1666\n",
      "Epoch 3031/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.0182 - val_loss: 130.9830\n",
      "Epoch 3032/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 124.3146 - val_loss: 129.1758\n",
      "Epoch 3033/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.0805 - val_loss: 110.1433\n",
      "Epoch 3034/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.4036 - val_loss: 127.9678\n",
      "Epoch 3035/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 156.6598 - val_loss: 359.4329\n",
      "Epoch 3036/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5260 - val_loss: 112.7261\n",
      "Epoch 3037/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.2150 - val_loss: 126.1273\n",
      "Epoch 3038/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 115.0143 - val_loss: 141.4399\n",
      "Epoch 3039/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 121.3370 - val_loss: 120.1461\n",
      "Epoch 3040/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 155.2865 - val_loss: 125.0839\n",
      "Epoch 3041/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 145.0337 - val_loss: 126.5464\n",
      "Epoch 3042/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 134.5446 - val_loss: 143.0091\n",
      "Epoch 3043/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.1797 - val_loss: 111.6759\n",
      "Epoch 3044/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.7180 - val_loss: 116.1197\n",
      "Epoch 3045/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 112.8444 - val_loss: 114.2566\n",
      "Epoch 3046/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.3409 - val_loss: 119.0810\n",
      "Epoch 3047/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.1487 - val_loss: 110.9354\n",
      "Epoch 3048/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 118.4018 - val_loss: 112.8486\n",
      "Epoch 3049/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.2912 - val_loss: 143.1750\n",
      "Epoch 3050/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 154.7750 - val_loss: 117.0628\n",
      "Epoch 3051/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 115.6364 - val_loss: 105.5782\n",
      "Epoch 3052/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.7735 - val_loss: 123.0697\n",
      "Epoch 3053/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.3607 - val_loss: 118.6563\n",
      "Epoch 3054/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 125.8399 - val_loss: 126.5390\n",
      "Epoch 3055/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.9290 - val_loss: 144.2527\n",
      "Epoch 3056/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.0858 - val_loss: 146.4357\n",
      "Epoch 3057/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.6206 - val_loss: 113.4217\n",
      "Epoch 3058/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 115.3149 - val_loss: 119.5943\n",
      "Epoch 3059/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.8332 - val_loss: 107.5363\n",
      "Epoch 3060/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 117.0935 - val_loss: 114.4397\n",
      "Epoch 3061/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 128.5042 - val_loss: 123.3610\n",
      "Epoch 3062/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 118.4345 - val_loss: 140.6099\n",
      "Epoch 3063/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 128.0577 - val_loss: 179.7291\n",
      "Epoch 3064/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 126.6696 - val_loss: 107.8667\n",
      "Epoch 3065/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 121.7903 - val_loss: 145.7144\n",
      "Epoch 3066/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.3621 - val_loss: 125.5163\n",
      "Epoch 3067/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 122.3125 - val_loss: 142.5598\n",
      "Epoch 3068/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 119.1245 - val_loss: 120.8464\n",
      "Epoch 3069/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 121.3841 - val_loss: 120.4834\n",
      "Epoch 3070/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 154.1371 - val_loss: 116.5388\n",
      "Epoch 3071/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 123.9423 - val_loss: 116.8822\n",
      "Epoch 3072/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 115.5445 - val_loss: 110.3504\n",
      "Epoch 3073/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 118.1628 - val_loss: 112.7289\n",
      "Epoch 3074/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.9449 - val_loss: 132.8079\n",
      "Epoch 3075/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 192.0771 - val_loss: 133.0664\n",
      "Epoch 3076/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 115.7456 - val_loss: 114.7906\n",
      "Epoch 3077/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.0673 - val_loss: 113.6734\n",
      "Epoch 3078/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 113.8906 - val_loss: 132.9649\n",
      "Epoch 3079/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 113.5248 - val_loss: 116.0583\n",
      "Epoch 3080/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 119.8002 - val_loss: 107.6009\n",
      "Epoch 3081/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 118.0006 - val_loss: 133.4815\n",
      "Epoch 3082/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.7219 - val_loss: 150.2942\n",
      "Epoch 3083/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 121.9174 - val_loss: 117.8051\n",
      "Epoch 3084/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 117.9742 - val_loss: 117.3186\n",
      "Epoch 3085/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 118.8345 - val_loss: 111.9867\n",
      "Epoch 3086/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 122.1764 - val_loss: 127.1495\n",
      "Epoch 3087/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 128.4183 - val_loss: 115.0087\n",
      "Epoch 3088/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.9996 - val_loss: 133.7891\n",
      "Epoch 3089/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.9659 - val_loss: 130.5395\n",
      "Epoch 3090/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.9713 - val_loss: 130.9403\n",
      "Epoch 3091/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.6392 - val_loss: 116.7115\n",
      "Epoch 3092/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 128.2127 - val_loss: 152.2666\n",
      "Epoch 3093/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.7620 - val_loss: 117.7189\n",
      "Epoch 3094/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.6217 - val_loss: 114.7805\n",
      "Epoch 3095/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.6314 - val_loss: 143.7324\n",
      "Epoch 3096/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 121.0760 - val_loss: 128.3756\n",
      "Epoch 3097/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 129.1518 - val_loss: 119.6275\n",
      "Epoch 3098/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 123.5677 - val_loss: 126.3524\n",
      "Epoch 3099/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 135.9621 - val_loss: 115.9573\n",
      "Epoch 3100/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 124.1679 - val_loss: 115.3355\n",
      "Epoch 3101/10000\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 118.7100 - val_loss: 113.0262\n",
      "Epoch 3102/10000\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 127.0967 - val_loss: 126.3606\n",
      "Epoch 3103/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 128.0793 - val_loss: 110.1729\n",
      "Epoch 3104/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 121.6797 - val_loss: 113.0601\n",
      "Epoch 3105/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 133.2931 - val_loss: 112.0876\n",
      "Epoch 3106/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 126.4071 - val_loss: 107.9609\n",
      "Epoch 3107/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 116.2498 - val_loss: 134.9465\n",
      "Epoch 3108/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 124.5523 - val_loss: 118.3770\n",
      "Epoch 3109/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 129.8297 - val_loss: 183.7638\n",
      "Epoch 3110/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.3002 - val_loss: 129.3041\n",
      "Epoch 3111/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 117.0238 - val_loss: 111.3559\n",
      "Epoch 3112/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 115.5715 - val_loss: 123.0427\n",
      "Epoch 3113/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.1608 - val_loss: 128.8154\n",
      "Epoch 3114/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.3359 - val_loss: 136.0688\n",
      "Epoch 3115/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 138.7097 - val_loss: 135.4732\n",
      "Epoch 3116/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.5321 - val_loss: 110.5026\n",
      "Epoch 3117/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.9746 - val_loss: 111.6010\n",
      "Epoch 3118/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 121.8256 - val_loss: 116.6431\n",
      "Epoch 3119/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.7070 - val_loss: 115.0409\n",
      "Epoch 3120/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 127.5115 - val_loss: 148.1472\n",
      "Epoch 3121/10000\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 127.2266 - val_loss: 117.9978\n",
      "Epoch 3122/10000\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 126.8717 - val_loss: 184.8561\n",
      "Epoch 3123/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 127.2502 - val_loss: 155.0301\n",
      "Epoch 3124/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 122.5931 - val_loss: 117.3269\n",
      "Epoch 3125/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 125.6924 - val_loss: 112.8045\n",
      "Epoch 3126/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 410.3656 - val_loss: 254.8188\n",
      "Epoch 3127/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 174.9883 - val_loss: 130.6662\n",
      "Epoch 3128/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.7236 - val_loss: 111.8610\n",
      "Epoch 3129/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 115.8158 - val_loss: 109.7250\n",
      "Epoch 3130/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 116.8116 - val_loss: 127.7816\n",
      "Epoch 3131/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 115.6478 - val_loss: 123.3948\n",
      "Epoch 3132/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 118.9459 - val_loss: 119.3656\n",
      "Epoch 3133/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 116.2821 - val_loss: 119.5629\n",
      "Epoch 3134/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.9661 - val_loss: 125.7311\n",
      "Epoch 3135/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 125.9909 - val_loss: 175.2478\n",
      "Epoch 3136/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 120.3171 - val_loss: 119.0739\n",
      "Epoch 3137/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 123.3399 - val_loss: 115.4584\n",
      "Epoch 3138/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 113.8130 - val_loss: 121.4479\n",
      "Epoch 3139/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.5723 - val_loss: 108.2094\n",
      "Epoch 3140/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 120.6658 - val_loss: 110.6859\n",
      "Epoch 3141/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.1248 - val_loss: 146.0208\n",
      "Epoch 3142/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 125.5442 - val_loss: 107.8070\n",
      "Epoch 3143/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.4696 - val_loss: 154.2793\n",
      "Epoch 3144/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 133.7800 - val_loss: 124.4945\n",
      "Epoch 3145/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 126.7148 - val_loss: 147.7041\n",
      "Epoch 3146/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 118.4710 - val_loss: 121.6646\n",
      "Epoch 3147/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 119.3654 - val_loss: 118.9656\n",
      "Epoch 3148/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 115.9621 - val_loss: 124.0963\n",
      "Epoch 3149/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.6643 - val_loss: 156.5292\n",
      "Epoch 3150/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 126.7485 - val_loss: 137.0352\n",
      "Epoch 3151/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 132.5891 - val_loss: 112.6373\n",
      "Epoch 3152/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.5238 - val_loss: 187.7377\n",
      "Epoch 3153/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 125.5369 - val_loss: 118.3312\n",
      "Epoch 3154/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.1996 - val_loss: 113.6536\n",
      "Epoch 3155/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.5411 - val_loss: 185.3582\n",
      "Epoch 3156/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.3995 - val_loss: 158.3427\n",
      "Epoch 3157/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.1004 - val_loss: 121.2055\n",
      "Epoch 3158/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 118.3109 - val_loss: 115.2179\n",
      "Epoch 3159/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 123.0060 - val_loss: 112.9655\n",
      "Epoch 3160/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.2426 - val_loss: 119.1107\n",
      "Epoch 3161/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.2861 - val_loss: 186.1796\n",
      "Epoch 3162/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 125.8973 - val_loss: 119.7488\n",
      "Epoch 3163/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.8913 - val_loss: 128.1674\n",
      "Epoch 3164/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.6286 - val_loss: 113.2217\n",
      "Epoch 3165/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.4778 - val_loss: 109.8102\n",
      "Epoch 3166/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.6584 - val_loss: 110.0062\n",
      "Epoch 3167/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.2446 - val_loss: 111.1630\n",
      "Epoch 3168/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 115.1278 - val_loss: 109.1392\n",
      "Epoch 3169/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.9319 - val_loss: 120.1794\n",
      "Epoch 3170/10000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 119.1298 - val_loss: 119.2128\n",
      "Epoch 3171/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.5793 - val_loss: 115.8182\n",
      "Epoch 3172/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.0016 - val_loss: 137.3890\n",
      "Epoch 3173/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.6308 - val_loss: 123.0854\n",
      "Epoch 3174/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 133.4137 - val_loss: 128.4945\n",
      "Epoch 3175/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.6466 - val_loss: 116.1437\n",
      "Epoch 3176/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.5105 - val_loss: 108.6233\n",
      "Epoch 3177/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.2698 - val_loss: 119.9505\n",
      "Epoch 3178/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.1913 - val_loss: 113.2307\n",
      "Epoch 3179/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.8539 - val_loss: 110.2807\n",
      "Epoch 3180/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.9335 - val_loss: 119.2121\n",
      "Epoch 3181/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 129.0109 - val_loss: 115.3094\n",
      "Epoch 3182/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.0989 - val_loss: 114.4701\n",
      "Epoch 3183/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.6434 - val_loss: 133.5357\n",
      "Epoch 3184/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 122.1867 - val_loss: 112.4860\n",
      "Epoch 3185/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 121.9771 - val_loss: 110.6017\n",
      "Epoch 3186/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.9142 - val_loss: 131.4514\n",
      "Epoch 3187/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.2775 - val_loss: 132.2971\n",
      "Epoch 3188/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.3762 - val_loss: 121.3436\n",
      "Epoch 3189/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5095 - val_loss: 137.5148\n",
      "Epoch 3190/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.4101 - val_loss: 115.9175\n",
      "Epoch 3191/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 137.4031 - val_loss: 109.9243\n",
      "Epoch 3192/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.4704 - val_loss: 108.9493\n",
      "Epoch 3193/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 116.7836 - val_loss: 117.9857\n",
      "Epoch 3194/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.9050 - val_loss: 121.0306\n",
      "Epoch 3195/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 122.1917 - val_loss: 117.0801\n",
      "Epoch 3196/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 119.5986 - val_loss: 118.4511\n",
      "Epoch 3197/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 121.0965 - val_loss: 129.3421\n",
      "Epoch 3198/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.2772 - val_loss: 120.5930\n",
      "Epoch 3199/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 130.6017 - val_loss: 123.7516\n",
      "Epoch 3200/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 113.1424 - val_loss: 117.4609\n",
      "Epoch 3201/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 126.2277 - val_loss: 137.3296\n",
      "Epoch 3202/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.7921 - val_loss: 113.0917\n",
      "Epoch 3203/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.8289 - val_loss: 119.1053\n",
      "Epoch 3204/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 123.0417 - val_loss: 115.1649\n",
      "Epoch 3205/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.9825 - val_loss: 117.7132\n",
      "Epoch 3206/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 125.7071 - val_loss: 110.0249\n",
      "Epoch 3207/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.1039 - val_loss: 110.6785\n",
      "Epoch 3208/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.9033 - val_loss: 144.1379\n",
      "Epoch 3209/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 123.6771 - val_loss: 120.0859\n",
      "Epoch 3210/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 127.9283 - val_loss: 122.4765\n",
      "Epoch 3211/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.5989 - val_loss: 120.2449\n",
      "Epoch 3212/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.9051 - val_loss: 143.6742\n",
      "Epoch 3213/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.0132 - val_loss: 122.2734\n",
      "Epoch 3214/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 123.8229 - val_loss: 116.4623\n",
      "Epoch 3215/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 117.1982 - val_loss: 109.2348\n",
      "Epoch 3216/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 200.2972 - val_loss: 517.2667\n",
      "Epoch 3217/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 192.5462 - val_loss: 115.1115\n",
      "Epoch 3218/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.3332 - val_loss: 109.4142\n",
      "Epoch 3219/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 108.7880 - val_loss: 141.7684\n",
      "Epoch 3220/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 110.7776 - val_loss: 111.2943\n",
      "Epoch 3221/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 115.7353 - val_loss: 109.0090\n",
      "Epoch 3222/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 110.8895 - val_loss: 106.9589\n",
      "Epoch 3223/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 115.9950 - val_loss: 120.6898\n",
      "Epoch 3224/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 115.5690 - val_loss: 123.8794\n",
      "Epoch 3225/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 114.7875 - val_loss: 118.5289\n",
      "Epoch 3226/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 117.3066 - val_loss: 120.5699\n",
      "Epoch 3227/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 121.8569 - val_loss: 115.8022\n",
      "Epoch 3228/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 113.4340 - val_loss: 136.4052\n",
      "Epoch 3229/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 125.7607 - val_loss: 121.5234\n",
      "Epoch 3230/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 115.4172 - val_loss: 124.0315\n",
      "Epoch 3231/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 135.0696 - val_loss: 119.6197\n",
      "Epoch 3232/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 122.8529 - val_loss: 118.7111\n",
      "Epoch 3233/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 121.4199 - val_loss: 137.6666\n",
      "Epoch 3234/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 117.6756 - val_loss: 116.2870\n",
      "Epoch 3235/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.9253 - val_loss: 147.7330\n",
      "Epoch 3236/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 134.6589 - val_loss: 121.7096\n",
      "Epoch 3237/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 120.6653 - val_loss: 208.6348\n",
      "Epoch 3238/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.6847 - val_loss: 131.8681\n",
      "Epoch 3239/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 52us/step - loss: 120.5036 - val_loss: 114.6237\n",
      "Epoch 3240/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 118.1057 - val_loss: 126.7445\n",
      "Epoch 3241/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.3357 - val_loss: 124.7263\n",
      "Epoch 3242/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 149.2005 - val_loss: 137.3089\n",
      "Epoch 3243/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 127.0295 - val_loss: 119.3839\n",
      "Epoch 3244/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.8968 - val_loss: 134.4037\n",
      "Epoch 3245/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 114.1869 - val_loss: 119.6807\n",
      "Epoch 3246/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 112.0394 - val_loss: 122.8925\n",
      "Epoch 3247/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 122.8733 - val_loss: 113.9581\n",
      "Epoch 3248/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 115.9145 - val_loss: 116.9963\n",
      "Epoch 3249/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 123.4289 - val_loss: 111.7086\n",
      "Epoch 3250/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 117.1021 - val_loss: 114.6710\n",
      "Epoch 3251/10000\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 126.4345 - val_loss: 111.8264\n",
      "Epoch 3252/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 119.5342 - val_loss: 114.2670\n",
      "Epoch 3253/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 115.3990 - val_loss: 113.4524\n",
      "Epoch 3254/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 117.6015 - val_loss: 216.3951\n",
      "Epoch 3255/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 125.7142 - val_loss: 120.8869\n",
      "Epoch 3256/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.6664 - val_loss: 128.9639\n",
      "Epoch 3257/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 119.1952 - val_loss: 116.0690\n",
      "Epoch 3258/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 134.7925 - val_loss: 126.3263\n",
      "Epoch 3259/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 117.2307 - val_loss: 115.3876\n",
      "Epoch 3260/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 120.7277 - val_loss: 125.5348\n",
      "Epoch 3261/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 119.7519 - val_loss: 180.8972\n",
      "Epoch 3262/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 123.7444 - val_loss: 135.7727\n",
      "Epoch 3263/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 121.3877 - val_loss: 112.8010\n",
      "Epoch 3264/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 120.4410 - val_loss: 122.1440\n",
      "Epoch 3265/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 116.9203 - val_loss: 116.1082\n",
      "Epoch 3266/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.8595 - val_loss: 119.9777\n",
      "Epoch 3267/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 122.8871 - val_loss: 114.8685\n",
      "Epoch 3268/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 123.5946 - val_loss: 128.2119\n",
      "Epoch 3269/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.3554 - val_loss: 113.5155\n",
      "Epoch 3270/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.2529 - val_loss: 121.6481\n",
      "Epoch 3271/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 131.5263 - val_loss: 128.3073\n",
      "Epoch 3272/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 115.6859 - val_loss: 179.3774\n",
      "Epoch 3273/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.2930 - val_loss: 123.5631\n",
      "Epoch 3274/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 142.7344 - val_loss: 224.0263\n",
      "Epoch 3275/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.7479 - val_loss: 121.2331\n",
      "Epoch 3276/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 114.8168 - val_loss: 121.0998\n",
      "Epoch 3277/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 112.1777 - val_loss: 109.8903\n",
      "Epoch 3278/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 121.9062 - val_loss: 120.1376\n",
      "Epoch 3279/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 117.4367 - val_loss: 114.8210\n",
      "Epoch 3280/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 113.3189 - val_loss: 150.2634\n",
      "Epoch 3281/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 124.6165 - val_loss: 113.8898\n",
      "Epoch 3282/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 114.4701 - val_loss: 106.9617\n",
      "Epoch 3283/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.2500 - val_loss: 130.3667\n",
      "Epoch 3284/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.0516 - val_loss: 113.3747\n",
      "Epoch 3285/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.2409 - val_loss: 147.7395\n",
      "Epoch 3286/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.4912 - val_loss: 152.5205\n",
      "Epoch 3287/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.8916 - val_loss: 117.1375\n",
      "Epoch 3288/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.3613 - val_loss: 122.9427\n",
      "Epoch 3289/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.9226 - val_loss: 111.1909\n",
      "Epoch 3290/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.2815 - val_loss: 130.0319\n",
      "Epoch 3291/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 117.2490 - val_loss: 139.5587\n",
      "Epoch 3292/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 128.2701 - val_loss: 107.7589\n",
      "Epoch 3293/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 133.0736 - val_loss: 126.2328\n",
      "Epoch 3294/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.5643 - val_loss: 176.4800\n",
      "Epoch 3295/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 120.0357 - val_loss: 120.6407\n",
      "Epoch 3296/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.7136 - val_loss: 119.8403\n",
      "Epoch 3297/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.9142 - val_loss: 115.1677\n",
      "Epoch 3298/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.5240 - val_loss: 125.9155\n",
      "Epoch 3299/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.2445 - val_loss: 146.6760\n",
      "Epoch 3300/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.2996 - val_loss: 112.5230\n",
      "Epoch 3301/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 116.3180 - val_loss: 113.2431\n",
      "Epoch 3302/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 123.9368 - val_loss: 126.1206\n",
      "Epoch 3303/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 115.2968 - val_loss: 112.3245\n",
      "Epoch 3304/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 117.6530 - val_loss: 105.7858\n",
      "Epoch 3305/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 125.7520 - val_loss: 120.4564\n",
      "Epoch 3306/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.7202 - val_loss: 112.3800\n",
      "Epoch 3307/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 111.4069 - val_loss: 109.6841\n",
      "Epoch 3308/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.5265 - val_loss: 114.5658\n",
      "Epoch 3309/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 120.0223 - val_loss: 115.8498\n",
      "Epoch 3310/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 150.1235 - val_loss: 109.7485\n",
      "Epoch 3311/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 56us/step - loss: 119.9338 - val_loss: 125.3099\n",
      "Epoch 3312/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 118.9930 - val_loss: 114.8201\n",
      "Epoch 3313/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 110.1554 - val_loss: 119.1134\n",
      "Epoch 3314/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 113.5843 - val_loss: 106.2401\n",
      "Epoch 3315/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 120.0634 - val_loss: 140.1558\n",
      "Epoch 3316/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 125.4349 - val_loss: 123.1548\n",
      "Epoch 3317/10000\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 114.8204 - val_loss: 120.7070\n",
      "Epoch 3318/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 125.3860 - val_loss: 116.4724\n",
      "Epoch 3319/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 120.4488 - val_loss: 141.5382\n",
      "Epoch 3320/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 119.9904 - val_loss: 132.4155\n",
      "Epoch 3321/10000\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 131.5212 - val_loss: 117.6030\n",
      "Epoch 3322/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 128.1235 - val_loss: 110.6121\n",
      "Epoch 3323/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 113.7392 - val_loss: 109.1047\n",
      "Epoch 3324/10000\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 117.9858 - val_loss: 112.9269\n",
      "Epoch 3325/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 130.3712 - val_loss: 116.6318\n",
      "Epoch 3326/10000\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 121.7193 - val_loss: 133.2240\n",
      "Epoch 3327/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 120.9390 - val_loss: 126.0301\n",
      "Epoch 3328/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 124.0919 - val_loss: 132.3792\n",
      "Epoch 3329/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 121.6385 - val_loss: 114.9260\n",
      "Epoch 3330/10000\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 116.7716 - val_loss: 113.1104\n",
      "Epoch 3331/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 116.9326 - val_loss: 118.2315\n",
      "Epoch 3332/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 126.4595 - val_loss: 118.9755\n",
      "Epoch 3333/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 125.1083 - val_loss: 123.8021\n",
      "Epoch 3334/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.2259 - val_loss: 113.5410\n",
      "Epoch 3335/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 117.6589 - val_loss: 132.3827\n",
      "Epoch 3336/10000\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 127.0002 - val_loss: 121.0755\n",
      "Epoch 3337/10000\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 116.7018 - val_loss: 151.0122\n",
      "Epoch 3338/10000\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 121.0735 - val_loss: 133.9400\n",
      "Epoch 3339/10000\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 112.0401 - val_loss: 117.5336\n",
      "Epoch 3340/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 118.8402 - val_loss: 117.4504\n",
      "Epoch 3341/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 122.8785 - val_loss: 112.0213\n",
      "Epoch 3342/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 115.6210 - val_loss: 124.3875\n",
      "Epoch 3343/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 114.5202 - val_loss: 113.7452\n",
      "Epoch 3344/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 130.9963 - val_loss: 126.6812\n",
      "Epoch 3345/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 239.1041 - val_loss: 124.1318\n",
      "Epoch 3346/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 114.2560 - val_loss: 110.1829\n",
      "Epoch 3347/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 116.4415 - val_loss: 121.0930\n",
      "Epoch 3348/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 111.3512 - val_loss: 114.9803\n",
      "Epoch 3349/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 108.0187 - val_loss: 126.9020\n",
      "Epoch 3350/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 110.7797 - val_loss: 114.7110\n",
      "Epoch 3351/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 113.1788 - val_loss: 121.1787\n",
      "Epoch 3352/10000\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 115.5171 - val_loss: 123.1174\n",
      "Epoch 3353/10000\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 122.0443 - val_loss: 112.3367\n",
      "Epoch 3354/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 117.0763 - val_loss: 123.5824\n",
      "Epoch 3355/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 118.7669 - val_loss: 121.1368\n",
      "Epoch 3356/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.1465 - val_loss: 155.0710\n",
      "Epoch 3357/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 120.4616 - val_loss: 118.9884\n",
      "Epoch 3358/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 115.6526 - val_loss: 137.2892\n",
      "Epoch 3359/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 125.1578 - val_loss: 108.5505\n",
      "Epoch 3360/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 113.7851 - val_loss: 111.0631\n",
      "Epoch 3361/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 120.0198 - val_loss: 155.8675\n",
      "Epoch 3362/10000\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 119.3832 - val_loss: 129.2083\n",
      "Epoch 3363/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 131.5250 - val_loss: 133.0823\n",
      "Epoch 3364/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 118.4106 - val_loss: 111.8991\n",
      "Epoch 3365/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 121.7478 - val_loss: 158.0084\n",
      "Epoch 3366/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 119.6509 - val_loss: 119.5991\n",
      "Epoch 3367/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 121.9033 - val_loss: 124.4239\n",
      "Epoch 3368/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 117.2216 - val_loss: 164.9446\n",
      "Epoch 3369/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 121.2990 - val_loss: 116.2716\n",
      "Epoch 3370/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 115.7172 - val_loss: 125.2228\n",
      "Epoch 3371/10000\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 116.5648 - val_loss: 120.2054\n",
      "Epoch 3372/10000\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 113.6529 - val_loss: 115.7017\n",
      "Epoch 3373/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 118.2250 - val_loss: 111.7317\n",
      "Epoch 3374/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 117.8130 - val_loss: 109.8198\n",
      "Epoch 3375/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 120.2341 - val_loss: 118.1057\n",
      "Epoch 3376/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 116.5290 - val_loss: 108.2454\n",
      "Epoch 3377/10000\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 122.4062 - val_loss: 119.8419\n",
      "Epoch 3378/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 124.4151 - val_loss: 111.5823\n",
      "Epoch 3379/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 124.3276 - val_loss: 118.3044\n",
      "Epoch 3380/10000\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 119.2346 - val_loss: 119.5726\n",
      "Epoch 3381/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 115.7689 - val_loss: 127.8617\n",
      "Epoch 3382/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 120.7602 - val_loss: 135.0485\n",
      "Epoch 3383/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 117.1542 - val_loss: 153.5233\n",
      "Epoch 3384/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 124.5667 - val_loss: 216.9253\n",
      "Epoch 3385/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 114.9340 - val_loss: 118.7555\n",
      "Epoch 3386/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 115.7449 - val_loss: 135.5622\n",
      "Epoch 3387/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 126.4091 - val_loss: 141.3227\n",
      "Epoch 3388/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 125.8545 - val_loss: 121.0311\n",
      "Epoch 3389/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 124.6718 - val_loss: 131.6303\n",
      "Epoch 3390/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 126.7409 - val_loss: 115.5611\n",
      "Epoch 3391/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 118.1754 - val_loss: 113.5832\n",
      "Epoch 3392/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.0870 - val_loss: 122.5857\n",
      "Epoch 3393/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 116.5555 - val_loss: 124.4866\n",
      "Epoch 3394/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 115.7814 - val_loss: 115.6125\n",
      "Epoch 3395/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 112.1437 - val_loss: 113.0874\n",
      "Epoch 3396/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.9981 - val_loss: 170.4950\n",
      "Epoch 3397/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.2436 - val_loss: 114.3990\n",
      "Epoch 3398/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.3339 - val_loss: 120.1233\n",
      "Epoch 3399/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 116.9734 - val_loss: 114.7174\n",
      "Epoch 3400/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 117.3429 - val_loss: 144.6213\n",
      "Epoch 3401/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 125.9417 - val_loss: 114.1007\n",
      "Epoch 3402/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 123.2521 - val_loss: 116.1549\n",
      "Epoch 3403/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 139.5812 - val_loss: 128.4861\n",
      "Epoch 3404/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 119.2853 - val_loss: 115.6882\n",
      "Epoch 3405/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 111.3553 - val_loss: 123.2327\n",
      "Epoch 3406/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 114.8893 - val_loss: 119.2030\n",
      "Epoch 3407/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 113.2484 - val_loss: 114.6452\n",
      "Epoch 3408/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 116.0508 - val_loss: 125.4578\n",
      "Epoch 3409/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 121.6150 - val_loss: 149.2329\n",
      "Epoch 3410/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 121.9836 - val_loss: 125.3772\n",
      "Epoch 3411/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 118.7561 - val_loss: 121.8407\n",
      "Epoch 3412/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 116.7242 - val_loss: 123.5486\n",
      "Epoch 3413/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 121.0908 - val_loss: 144.4190\n",
      "Epoch 3414/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 172.8107 - val_loss: 718.4011\n",
      "Epoch 3415/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 136.9625 - val_loss: 117.3796\n",
      "Epoch 3416/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 113.3717 - val_loss: 116.1906\n",
      "Epoch 3417/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 114.3805 - val_loss: 117.6146\n",
      "Epoch 3418/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 108.0056 - val_loss: 113.1479\n",
      "Epoch 3419/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 111.2765 - val_loss: 112.8564\n",
      "Epoch 3420/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 123.8933 - val_loss: 111.9061\n",
      "Epoch 3421/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 127.4041 - val_loss: 118.8678\n",
      "Epoch 3422/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 115.3027 - val_loss: 109.9846\n",
      "Epoch 3423/10000\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 114.3196 - val_loss: 112.2620\n",
      "Epoch 3424/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 122.2866 - val_loss: 116.8679\n",
      "Epoch 3425/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 114.1304 - val_loss: 189.7765\n",
      "Epoch 3426/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 128.5944 - val_loss: 109.7742\n",
      "Epoch 3427/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 111.4648 - val_loss: 115.7865\n",
      "Epoch 3428/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 115.5729 - val_loss: 140.9994\n",
      "Epoch 3429/10000\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 115.2356 - val_loss: 167.3009\n",
      "Epoch 3430/10000\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 117.5643 - val_loss: 122.0771\n",
      "Epoch 3431/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 126.5908 - val_loss: 125.9055\n",
      "Epoch 3432/10000\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 120.4992 - val_loss: 120.3753\n",
      "Epoch 3433/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 114.5308 - val_loss: 196.7176\n",
      "Epoch 3434/10000\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 120.6020 - val_loss: 132.2274\n",
      "Epoch 3435/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 112.6570 - val_loss: 131.3359\n",
      "Epoch 3436/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 118.1088 - val_loss: 120.4593\n",
      "Epoch 3437/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 129.1801 - val_loss: 142.4853\n",
      "Epoch 3438/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 133.1338 - val_loss: 116.7420\n",
      "Epoch 3439/10000\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 118.4369 - val_loss: 121.3248\n",
      "Epoch 3440/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 117.0506 - val_loss: 113.4150\n",
      "Epoch 3441/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 123.5199 - val_loss: 138.4911\n",
      "Epoch 3442/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 115.6885 - val_loss: 131.7064\n",
      "Epoch 3443/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 112.8902 - val_loss: 119.7445\n",
      "Epoch 3444/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 114.7801 - val_loss: 131.0210\n",
      "Epoch 3445/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.7754 - val_loss: 134.6051\n",
      "Epoch 3446/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 122.1753 - val_loss: 125.0887\n",
      "Epoch 3447/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.0223 - val_loss: 133.8146\n",
      "Epoch 3448/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 122.3749 - val_loss: 109.0895\n",
      "Epoch 3449/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.4688 - val_loss: 141.6575\n",
      "Epoch 3450/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.8371 - val_loss: 140.4463\n",
      "Epoch 3451/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 127.7501 - val_loss: 111.6690\n",
      "Epoch 3452/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 113.9842 - val_loss: 118.7116\n",
      "Epoch 3453/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.2787 - val_loss: 123.8780\n",
      "Epoch 3454/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 115.8198 - val_loss: 119.4497\n",
      "Epoch 3455/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 117.4476 - val_loss: 115.6148\n",
      "Epoch 3456/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 132.7667 - val_loss: 121.1742\n",
      "Epoch 3457/10000\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 121.5520 - val_loss: 121.5298\n",
      "Epoch 3458/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 116.3358 - val_loss: 111.8179\n",
      "Epoch 3459/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 115.6753 - val_loss: 151.4354\n",
      "Epoch 3460/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 124.4842 - val_loss: 110.4219\n",
      "Epoch 3461/10000\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 115.3715 - val_loss: 168.6867\n",
      "Epoch 3462/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 127.5873 - val_loss: 114.4067\n",
      "Epoch 3463/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.9139 - val_loss: 126.5519\n",
      "Epoch 3464/10000\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 139.2253 - val_loss: 112.3560\n",
      "Epoch 3465/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 112.5551 - val_loss: 136.3427\n",
      "Epoch 3466/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.3135 - val_loss: 134.3218\n",
      "Epoch 3467/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 118.6995 - val_loss: 152.0969\n",
      "Epoch 3468/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.2109 - val_loss: 160.1876\n",
      "Epoch 3469/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.1959 - val_loss: 116.8748\n",
      "Epoch 3470/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 121.0806 - val_loss: 120.6286\n",
      "Epoch 3471/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 120.0457 - val_loss: 117.3976\n",
      "Epoch 3472/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 109.4699 - val_loss: 132.7443\n",
      "Epoch 3473/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.1906 - val_loss: 114.2940\n",
      "Epoch 3474/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 119.1523 - val_loss: 116.8124\n",
      "Epoch 3475/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 119.1631 - val_loss: 149.8270\n",
      "Epoch 3476/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 118.8411 - val_loss: 168.4002\n",
      "Epoch 3477/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 121.1152 - val_loss: 122.8512\n",
      "Epoch 3478/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 115.9904 - val_loss: 110.8399\n",
      "Epoch 3479/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 116.7317 - val_loss: 136.9165\n",
      "Epoch 3480/10000\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 116.6712 - val_loss: 114.2712\n",
      "Epoch 3481/10000\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 114.5726 - val_loss: 129.2364\n",
      "Epoch 3482/10000\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 117.5760 - val_loss: 132.5620\n",
      "Epoch 3483/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 112.0627 - val_loss: 111.0557\n",
      "Epoch 3484/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 121.8975 - val_loss: 110.5733\n",
      "Epoch 3485/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 114.5595 - val_loss: 112.4317\n",
      "Epoch 3486/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 126.5930 - val_loss: 112.6915\n",
      "Epoch 3487/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 118.2041 - val_loss: 109.6359\n",
      "Epoch 3488/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 199.4867 - val_loss: 110.8776\n",
      "Epoch 3489/10000\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 109.3873 - val_loss: 132.1446\n",
      "Epoch 3490/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 113.9793 - val_loss: 113.5375\n",
      "Epoch 3491/10000\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 112.9044 - val_loss: 118.1889\n",
      "Epoch 3492/10000\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 129.0002 - val_loss: 117.3825\n",
      "Epoch 3493/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 115.3988 - val_loss: 120.4004\n",
      "Epoch 3494/10000\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 115.2732 - val_loss: 115.3968\n",
      "Epoch 3495/10000\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 109.7067 - val_loss: 114.8072\n",
      "Epoch 3496/10000\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 113.4445 - val_loss: 138.2018\n",
      "Epoch 3497/10000\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 110.6531 - val_loss: 151.2071\n",
      "Epoch 3498/10000\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 118.9625 - val_loss: 120.9485\n",
      "Epoch 3499/10000\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 115.5495 - val_loss: 119.2282\n",
      "Epoch 03499: early stopping\n",
      "Fold score (RMSE): 10.873358726501465\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validate\n",
    "kf = KFold(5)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filename_checkpoint, verbose=0, save_best_only=True)\n",
    "\n",
    "# Turn off KFold\n",
    "#if (0):\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "    \n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dropout(0.01)) # Dropout Layer\n",
    "    model.add(Dense(50, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(25, \n",
    "                    kernel_regularizer=regularizers.l2(0.01), #L2 regularization\n",
    "                    #activity_regularizer=regularizers.l1(0.01), #L1 Lasso regularization\n",
    "                    activation='relu')) # Hidden 3 \n",
    "    model.add(Dense(10, activation='relu')) # Hidden 4\n",
    "    model.add(Dense(1)) # Output\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=1000, verbose=1, mode='auto')\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpoint],verbose=1,epochs=10000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's RMSE\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#pred = model.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "#score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "#print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "#chart_regression(pred.flatten(),y_test)\n",
    "#chart_regression(pred.flatten(),y_test,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(filename_checkpoint)\n",
    "\n",
    "df_test = pd.read_csv(filename_test,na_values=['NA','?'])\n",
    "\n",
    "extract_and_encode_features(df_test)\n",
    "\n",
    "ids_test = df_test['id']\n",
    "df_test.drop('id',1,inplace=True)\n",
    "\n",
    "names_test = df_test['name']\n",
    "df_test.drop('name',1,inplace=True)\n",
    "\n",
    "x_submit = df_test.as_matrix().astype(np.float32)\n",
    "pred_submit = model.predict(x_submit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = [n if n > 0 else n * -1 for n in pred_submit[:,0]]\n",
    "df_submit = pd.DataFrame({'id': ids_test,'cost': cost})\n",
    "df_submit = df_submit[['id', 'cost']]\n",
    "df_submit.to_csv(filename_submit, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
